{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import logging\n",
    "\n",
    "from pydantic import Field, BaseModel\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "import llm\n",
    "from llm.models import Usage\n",
    "import anthropic\n",
    "import langsmith as ls\n",
    "\n",
    "from lovely_docs.settings import Settings, settings\n",
    "import asyncio\n",
    "\n",
    "from tenacity import AsyncRetrying, stop_after_attempt, wait_exponential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TokenCounts(BaseModel):\n",
    "    fulltext: int = 0\n",
    "    digest: int = 0\n",
    "    short_digest: int = 0\n",
    "\n",
    "class DocItem(BaseModel):\n",
    "    path: Path\n",
    "    name: str = \"\"\n",
    "    digest: str = \"\"\n",
    "    short_digest: str = \"\"\n",
    "    essence: str = \"\"\n",
    "    relevant: bool = True\n",
    "    usage: Usage|None = Field(default_factory=Usage)\n",
    "    type: Literal[\"page\", \"dir\"]\n",
    "    token_counts: TokenCounts = Field(default_factory=TokenCounts)\n",
    "\n",
    "\n",
    "class DocPage(DocItem):\n",
    "    \"\"\"Represents a single documentation page\"\"\"\n",
    "    fulltext: str\n",
    "    type: str = \"page\"\n",
    "\n",
    "\n",
    "class DocDirectory(DocItem):\n",
    "    \"\"\"Represents a directory in the documentation structure\"\"\"\n",
    "    pages: list[DocPage] = Field(default_factory=list)\n",
    "    subdirs: list['DocDirectory'] = Field(default_factory=list)\n",
    "    fulltext: str = \"\"\n",
    "    type: str = \"dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's load all markdown files from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def build_markdown_doc_tree(root:Path, path:Path = Path()) -> DocDirectory:\n",
    "    \"\"\"Recursively build a documentation tree from markdown files.\n",
    "\n",
    "    Args:\n",
    "        root: Root directory containing the documentation\n",
    "        path: Relative path from root to process (default: root itself)\n",
    "\n",
    "    Returns:\n",
    "        DocDirectory containing pages and subdirectories\n",
    "    \"\"\"\n",
    "    assert root.exists() and root.is_dir()\n",
    "    assert (root/path).exists() and (root/path).is_dir()\n",
    "\n",
    "    doc_dir = DocDirectory(path=path)\n",
    "\n",
    "    # Get immediate children only\n",
    "    for item in sorted((root/path).iterdir()):\n",
    "        if item.is_file() and item.suffix == '.md':\n",
    "            # We'll process files later, just record them\n",
    "            doc_dir.pages.append(DocPage(path=item.relative_to(root), fulltext=item.read_text()))\n",
    "        if item.is_dir():\n",
    "            doc_dir.subdirs.append(build_markdown_doc_tree(root, item.relative_to(root)))\n",
    "\n",
    "    return doc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'digest': '',\n",
      " 'essence': '',\n",
      " 'fulltext': '',\n",
      " 'name': '',\n",
      " 'path': Path('.'),\n",
      " 'relevant': True,\n",
      " 'short_digest': '',\n",
      " 'token_counts': {'digest': 0, 'fulltext': 0, 'short_digest': 0},\n",
      " 'type': 'dir',\n",
      " 'usage': {'details': None, 'input': None, 'output': None}}\n",
      "01-introduction/\n",
      "01-introduction/01-overview.md -> ---title: Overview---Svelte is a framework for...\n",
      "01-introduction/02-getting-started.md -> ---title: Getting started---We recommend using...\n",
      "01-introduction/03-svelte-files.md -> ---title: .svelte files---Components are the b...\n",
      "01-introduction/04-svelte-js-files.md -> ---title: .svelte.js and .svelte.ts files---Be...\n",
      "01-introduction/index.md -> ---title: Introduction---...\n",
      "02-runes/\n",
      "02-runes/01-what-are-runes.md -> ---title: What are runes?---> [!NOTE] **rune**...\n",
      "02-runes/02-$state.md -> ---title: $state---The `$state` rune allows yo...\n",
      "02-runes/03-$derived.md -> ---title: $derived---Derived state is declared...\n",
      "02-runes/04-$effect.md -> ---title: $effect---Effects are functions that...\n",
      "02-runes/05-$props.md -> ---title: $props---The inputs to a component a...\n",
      "02-runes/06-$bindable.md -> ---title: $bindable---Ordinarily, props go one...\n",
      "02-runes/07-$inspect.md -> ---title: $inspect---> [!NOTE] `$inspect` only...\n",
      "02-runes/08-$host.md -> ---title: $host---When compiling a component a...\n",
      "02-runes/index.md -> ---title: Runes---...\n"
     ]
    }
   ],
   "source": [
    "tree = build_markdown_doc_tree(Path(\"test_data\"))\n",
    "pprint.pprint(tree.model_dump(exclude=[\"pages\", \"subdirs\"]))\n",
    "\n",
    "for d in tree.subdirs:\n",
    "    # for dd in d.subdirs:\n",
    "    print(str(d.path) + \"/\")\n",
    "    for pp in d.pages:\n",
    "        print(f\"{str(pp.path)} -> {pp.fulltext[:50].replace(\"\\n\", \"\")}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's process one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class PageReplySchema(BaseModel):\n",
    "    better_name: str = Field(description=\"\")\n",
    "    digest: str = Field(title=\"Digest, format: markdown\", )\n",
    "    short_digest: str = Field(title=\"Short digest, format:markdown\")\n",
    "    essence: str = Field(title=\"Essence, format:txt\")\n",
    "    relevant: bool\n",
    "\n",
    "\n",
    "async def anthropic_count_tokens(client: anthropic.AsyncAnthropic, model: str, text: str):\n",
    "    res = await client.messages.count_tokens(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }],\n",
    "    )\n",
    "    return res.input_tokens\n",
    "\n",
    "async def llm_process_page(settings: Settings, page: DocPage, libname: str) -> DocPage:\n",
    "    with ls.trace(name=f\"Process page: {page.path}\", run_type=\"chain\") as trace:\n",
    "        logger.debug(f\"Processing {page.path}\")\n",
    "\n",
    "\n",
    "        model = llm.get_async_model(settings.model)\n",
    "        model.key = settings.api_key\n",
    "\n",
    "        # We need to use anthropic client directly to count tokens.\n",
    "        anthropic_client = anthropic.AsyncAnthropic(api_key=settings.api_key)\n",
    "\n",
    "\n",
    "        template = Environment(loader=FileSystemLoader(settings.templates_dir)).get_template(\"process_page.j2\")\n",
    "        inputs = {\n",
    "            \"text\": page.fulltext,\n",
    "            \"filename\": page.path.name,\n",
    "            \"path\": page.path.parent.name + \"/\",\n",
    "            \"libname\": libname\n",
    "        }\n",
    "        with ls.trace(\"Template\", \"prompt\", inputs=inputs) as template_trace:\n",
    "            prompt = template.render(**inputs)\n",
    "            template_trace.end(outputs=prompt)\n",
    "\n",
    "        with ls.trace(\"LLM call\", \"llm\", inputs={\"prompt\": prompt}) as llm_trace:\n",
    "            async for attempt in AsyncRetrying(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=3, max=60)):\n",
    "                with attempt:\n",
    "                    try:\n",
    "                        res = await model.prompt(prompt=prompt, schema=PageReplySchema, max_tokens=32768, temperature=0)\n",
    "                        llm_trace.end(outputs=await res.text())\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Retry {attempt.retry_state.attempt_number}: {str(e)}\")\n",
    "                        raise\n",
    "\n",
    "        with ls.trace(\"Parse\", \"parser\", inputs={\"input\": await res.text()}) as parse_trace:\n",
    "            reply = PageReplySchema.model_validate_json(await res.text())\n",
    "            # Normalize better_name: lowercase, replace spaces with hyphens, remove .md extension\n",
    "            reply.better_name = (reply.better_name.lower()  .replace(' ', '-')\n",
    "                                                            .removesuffix('.md')\n",
    "                                                            .replace(\"/\", \"∕\")) # No / in filenames!\n",
    "            parse_trace.end(outputs=reply)\n",
    "            usage = await res.usage()\n",
    "\n",
    "        # Count tokens for fulltext, digest, and short_digest in parallel\n",
    "        fulltext_tokens, digest_tokens, short_digest_tokens = await asyncio.gather(\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", page.fulltext),\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", reply.digest),\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", reply.short_digest)\n",
    "        )\n",
    "        token_counts = TokenCounts(\n",
    "            fulltext=fulltext_tokens,\n",
    "            digest=digest_tokens,\n",
    "            short_digest=short_digest_tokens\n",
    "        )\n",
    "\n",
    "        result = DocPage(\n",
    "            path=page.path,\n",
    "            fulltext=page.fulltext,\n",
    "            name=reply.better_name,\n",
    "            digest=reply.digest,\n",
    "            short_digest=reply.short_digest,\n",
    "            essence=reply.essence,\n",
    "            relevant=reply.relevant,\n",
    "            token_counts=token_counts,\n",
    "            usage=usage)\n",
    "\n",
    "        trace.end(outputs=result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lovely_docs.settings import settings\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.222s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/03-$derived.md\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = await llm_process_page(\n",
    "    settings=settings,\n",
    "    page=tree.subdirs[1].pages[2],\n",
    "    libname=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`02-runes/03-$derived.md -> $derived:`\n",
       "\n",
       "$derived creates reactive computed values that automatically update when their dependencies change, with support for complex derivations via $derived.by and temporary value overrides."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# **==== Short digest ====**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## $derived\n",
       "\n",
       "Declares reactive derived state that recalculates when dependencies change:\n",
       "\n",
       "```svelte\n",
       "let doubled = $derived(count * 2);\n",
       "let total = $derived.by(() => { /* complex logic */ });\n",
       "```\n",
       "\n",
       "Expressions must be side-effect free. Derived values can be temporarily reassigned for optimistic UI. Uses push-pull reactivity: state changes notify dependents immediately, but derived values only re-evaluate when read."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# **==== Full digest ====**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## $derived\n",
       "\n",
       "Declares derived state that automatically updates when dependencies change:\n",
       "\n",
       "```svelte\n",
       "let count = $state(0);\n",
       "let doubled = $derived(count * 2);\n",
       "```\n",
       "\n",
       "Expressions must be side-effect free. Svelte prevents state mutations inside derived expressions.\n",
       "\n",
       "### $derived.by\n",
       "\n",
       "For complex derivations, use `$derived.by` with a function:\n",
       "\n",
       "```svelte\n",
       "let numbers = $state([1, 2, 3]);\n",
       "let total = $derived.by(() => {\n",
       "\tlet total = 0;\n",
       "\tfor (const n of numbers) {\n",
       "\t\ttotal += n;\n",
       "\t}\n",
       "\treturn total;\n",
       "});\n",
       "```\n",
       "\n",
       "`$derived(expression)` is equivalent to `$derived.by(() => expression)`.\n",
       "\n",
       "### Dependencies\n",
       "\n",
       "Anything read synchronously inside the derived expression is a dependency. When dependencies change, the derived is marked dirty and recalculated on next read. Use `untrack` to exempt state from being treated as a dependency.\n",
       "\n",
       "### Overriding derived values\n",
       "\n",
       "Derived values can be temporarily reassigned (unless declared with `const`), useful for optimistic UI:\n",
       "\n",
       "```svelte\n",
       "let likes = $derived(post.likes);\n",
       "async function onclick() {\n",
       "\tlikes += 1;\n",
       "\ttry {\n",
       "\t\tawait like();\n",
       "\t} catch {\n",
       "\t\tlikes -= 1;\n",
       "\t}\n",
       "}\n",
       "```\n",
       "\n",
       "### Reactivity behavior\n",
       "\n",
       "Unlike `$state`, `$derived` values are not converted to deeply reactive proxies. However, if a derived value is an object/array from state, mutating its properties affects the underlying state.\n",
       "\n",
       "Svelte uses push-pull reactivity: state changes immediately notify dependents (push), but derived values only re-evaluate when read (pull). If a derived's new value is referentially identical to its previous value, downstream updates are skipped."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"`{res.path} -> {res.name}:`\\n\\n{res.essence}\"))\n",
    "display(Markdown(\"# **==== Short digest ====**\"))\n",
    "display(Markdown(res.short_digest))\n",
    "display(Markdown(\"# **==== Full digest ====**\"))\n",
    "display(Markdown(res.digest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks decent, let's process all pages in a sub-directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+8.689s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/01-what-are-runes.md\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/02-$state.md\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/03-$derived.md\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/04-$effect.md\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/05-$props.md\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/06-$bindable.md\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/07-$inspect.md\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/08-$host.md\u001b[0m\n",
      "+0.014s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/index.md\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "pages = []\n",
    "tasks = []\n",
    "for page in tree.subdirs[1].pages:\n",
    "    tasks.append(asyncio.create_task(llm_process_page(settings, page, \"svelte\")))\n",
    "\n",
    "pages = await asyncio.gather(*tasks)\n",
    "\n",
    "pages.sort(key=lambda x: x.path)\n",
    "\n",
    "tree.subdirs[1].pages = pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`02-runes/04-$effect.md -> $effect:`\n",
       "\n",
       "The $effect rune runs functions when state updates for side effects, with automatic dependency tracking and lifecycle management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# **==== Short digest ====**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## $effect\n",
       "\n",
       "Effects run when state updates for side effects (API calls, canvas drawing, etc). They track synchronously-read reactive values and re-run when dependencies change. Asynchronously-read values are not tracked.\n",
       "\n",
       "```svelte\n",
       "$effect(() => {\n",
       "\tcontext.fillStyle = color;\n",
       "\tcontext.fillRect(0, 0, size, size);\n",
       "});\n",
       "```\n",
       "\n",
       "Effects can return teardown functions that run before re-runs or on component destroy.\n",
       "\n",
       "**$effect.pre**: Runs before DOM updates.\n",
       "**$effect.tracking()**: Returns whether code runs in a tracking context.\n",
       "**$effect.root()**: Creates non-tracked scope for manual control.\n",
       "\n",
       "Don't use effects for state synchronization—use `$derived` instead."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page = tree.subdirs[1].pages[3]\n",
    "display(Markdown(f\"`{page.path} -> {page.name}:`\\n\\n{page.essence}\"))\n",
    "display(Markdown(\"# **==== Short digest ====**\"))\n",
    "display(Markdown(page.short_digest))\n",
    "# display(Markdown(\"# **==== Full digest ====**\"))\n",
    "# display(Markdown(page.digest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's process a directory. The input is all pages digests (+sub-directory digests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DirReplySchema(BaseModel):\n",
    "    better_name: str\n",
    "    digest: str = Field(title=\"Directory digest, fmt:markdown\")\n",
    "    short_digest: str = Field(title=\"Short digest, format:markdown\")\n",
    "    essence: str\n",
    "    relevant: bool\n",
    "\n",
    "async def llm_process_directory(settings: Settings, directory: DocDirectory,  libname: str) -> DocDirectory:\n",
    "    \"\"\"Create a summary for a directory based on its relevant pages and subdirectories\"\"\"\n",
    "\n",
    "    with ls.trace(name=f\"Process directory: {directory.path}\", run_type=\"chain\") as trace:\n",
    "        logger.debug(f\"Processing {directory.path}\")\n",
    "\n",
    "        # If the directory did not have any relevant pages / subdirs, we should not be called.\n",
    "        assert any(x for x in directory.pages+directory.subdirs if x.relevant)\n",
    "\n",
    "        model = llm.get_async_model(settings.model)\n",
    "        model.key = settings.api_key\n",
    "\n",
    "        # We need to use anthropic client directly to count tokens.\n",
    "        anthropic_client = anthropic.AsyncAnthropic(api_key=settings.api_key)\n",
    "\n",
    "        template = Environment(loader=FileSystemLoader(settings.templates_dir)).get_template(\"process_directory.j2\")\n",
    "\n",
    "        input = {\n",
    "            \"dirname\": directory.path.name,\n",
    "            \"path\": directory.path.parent.name,\n",
    "            \"pages\": [p for p in directory.pages if p.relevant],\n",
    "            \"subdirs\": [s for s in directory.subdirs if s.relevant],\n",
    "            \"libname\": libname\n",
    "        }\n",
    "        with ls.trace(\"Template\", \"prompt\", inputs=input) as template_trace:\n",
    "            prompt = template.render(**input)\n",
    "            template_trace.end(outputs=prompt)\n",
    "\n",
    "\n",
    "        with ls.trace(\"LLM call\", \"llm\", inputs={\"prompt\": prompt}) as llm_trace:\n",
    "            async for attempt in AsyncRetrying(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=3, max=60)):\n",
    "                with attempt:\n",
    "                    try:\n",
    "                        res = await model.prompt(prompt=prompt, schema=DirReplySchema, max_tokens=32768, temperature=0)\n",
    "                        llm_trace.end(outputs=await res.text())\n",
    "                        usage = await res.usage()\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Retry {attempt.retry_state.attempt_number}: {str(e)}\")\n",
    "                        raise\n",
    "\n",
    "        with ls.trace(\"Parse\", \"parser\", inputs={\"input\": await res.text()}) as parse_trace:\n",
    "            reply = DirReplySchema.model_validate_json(await res.text())\n",
    "            reply.better_name = (reply.better_name.lower()  .replace(' ', '-')\n",
    "                                                            .removesuffix('.md')\n",
    "                                                            .replace(\"/\", \"∕\")) # No / in filenames!\n",
    "            parse_trace.end(outputs=reply)\n",
    "\n",
    "\n",
    "        # We save a generated fulltext for a directory which is the sum of digests of all the pages and subdirs within.\n",
    "        fulltext_template = Environment(loader=FileSystemLoader(settings.templates_dir)).get_template(\"directory_fulltext.j2\")\n",
    "        fulltext = fulltext_template.render(**input)\n",
    "\n",
    "        # Count tokens for fulltext, digest, and short_digest in parallel\n",
    "        fulltext_tokens, digest_tokens, short_digest_tokens = await asyncio.gather(\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", fulltext),\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", reply.digest),\n",
    "            anthropic_count_tokens(anthropic_client, \"claude-haiku-4-5\", reply.short_digest)\n",
    "        )\n",
    "        token_counts = TokenCounts(\n",
    "            fulltext=fulltext_tokens,\n",
    "            digest=digest_tokens,\n",
    "            short_digest=short_digest_tokens\n",
    "        )\n",
    "\n",
    "        result = directory.model_copy(deep=True)\n",
    "        result.name = reply.better_name\n",
    "        result.digest = reply.digest\n",
    "        result.short_digest = reply.short_digest\n",
    "        result.essence = reply.essence\n",
    "        result.relevant = reply.relevant\n",
    "        result.fulltext = fulltext\n",
    "        result.token_counts = token_counts\n",
    "        result.usage = usage\n",
    "\n",
    "        trace.end(outputs=result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+12.714s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:14\u001b[0m llm_process_directory Processing 02-runes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tree.subdirs[1] = await llm_process_directory(settings, tree.subdirs[1], \"svelte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`02-runes -> runes:`\n",
       "\n",
       "Runes are $-prefixed compiler keywords that control reactivity, state management, side effects, and component communication in Svelte."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# **==== Short digest ====**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Runes\n",
       "\n",
       "`$`-prefixed compiler keywords for reactivity and component behavior.\n",
       "\n",
       "**$state**: Reactive state with deep reactivity for objects/arrays. `$state.raw` for non-reactive, `$state.snapshot` to convert proxy.\n",
       "\n",
       "**$derived**: Reactive computed values. `$derived.by()` for complex logic. Auto-tracks dependencies.\n",
       "\n",
       "**$effect**: Runs on state updates for side effects. Returns teardown functions. `$effect.pre` runs before DOM updates.\n",
       "\n",
       "**$props**: Destructure component props with defaults and renaming. `$props.id()` generates unique IDs.\n",
       "\n",
       "**$bindable**: Enables two-way prop binding with `bind:` directive.\n",
       "\n",
       "**$inspect**: Dev-only logging of reactive changes. `$inspect.trace()` traces state changes.\n",
       "\n",
       "**$host**: Access host element in custom elements for event dispatch."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subdir = tree.subdirs[1]\n",
    "display(Markdown(f\"`{subdir.path} -> {subdir.name}:`\\n\\n{subdir.essence}\"))\n",
    "display(Markdown(\"# **==== Short digest ====**\"))\n",
    "display(Markdown(subdir.short_digest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great! Now let's do the whole tree recursively.\n",
    "When processing a directory:\n",
    "- process all pages\n",
    "- process all-sibdirectories\n",
    "- Generate digests for the whole directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def process_tree_depth_first(settings: Settings, doc_dir: DocDirectory, libname: str) -> DocDirectory:\n",
    "    \"\"\"\n",
    "    Process documentation tree depth-first with parallel processing.\n",
    "    Mutates the doc_dir object.\n",
    "    \"\"\"\n",
    "\n",
    "    with ls.trace(name=f\"Process tree: {libname}/{doc_dir.path}\", run_type=\"chain\") as trace:\n",
    "        # First, recursively process all subdirectories in parallel\n",
    "        subdirs: list[DocDirectory] = await asyncio.gather(*[\n",
    "            process_tree_depth_first(settings, subdir, libname) for subdir in doc_dir.subdirs\n",
    "        ])\n",
    "        subdirs = sorted(subdirs, key=lambda s: s.path)\n",
    "\n",
    "        # Then process all pages in this directory in parallel\n",
    "        pages = await asyncio.gather(*[\n",
    "            llm_process_page(settings, page, libname) for page in doc_dir.pages\n",
    "        ])\n",
    "        pages = sorted(pages, key=lambda s: s.path)\n",
    "\n",
    "        # .name is llm-generated and might be not unique. Make it unique.\n",
    "        names: set[str] = set()\n",
    "        for x in subdirs + pages:\n",
    "            name, i = x.name, 2\n",
    "            while name in names:\n",
    "                name = f\"{x.name}_{str(i)}\"\n",
    "                x.name = name\n",
    "            names.add(name)\n",
    "\n",
    "        if not any(x for x in subdirs+pages if x.relevant):\n",
    "            result = DocDirectory(path=doc_dir.path, pages=pages, relevant=False)\n",
    "            trace.end(outputs=result)\n",
    "            return result\n",
    "\n",
    "        result = await llm_process_directory(settings, DocDirectory(path=doc_dir.path, pages=pages, subdirs=subdirs), libname)\n",
    "        trace.end(outputs=result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+10.923s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 01-introduction/01-overview.md\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 01-introduction/02-getting-started.md\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 01-introduction/03-svelte-files.md\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 01-introduction/04-svelte-js-files.md\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 01-introduction/index.md\u001b[0m\n",
      "+0.022s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/01-what-are-runes.md\u001b[0m\n",
      "+0.021s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/02-$state.md\u001b[0m\n",
      "+0.023s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/03-$derived.md\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/04-$effect.md\u001b[0m\n",
      "+0.020s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/05-$props.md\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/06-$bindable.md\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/07-$inspect.md\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/08-$host.md\u001b[0m\n",
      "+0.021s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:23\u001b[0m llm_process_page Processing 02-runes/index.md\u001b[0m\n",
      "+5.141s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:14\u001b[0m llm_process_directory Processing 01-introduction\u001b[0m\n",
      "+6.457s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:14\u001b[0m llm_process_directory Processing 02-runes\u001b[0m\n",
      "+7.995s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:14\u001b[0m llm_process_directory Processing .\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Clean tree\n",
    "tree = build_markdown_doc_tree(Path(\"test_data\"))\n",
    "processed_tree = await process_tree_depth_first(settings, tree, \"svelte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`. -> runes:`\n",
       "\n",
       "Compiler keywords prefixed with `$` that manage reactivity, state, effects, props, and debugging in Svelte components."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# **==== Digest ====**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Runes\n",
       "\n",
       "`$`-prefixed compiler keywords that control reactivity, state management, side effects, and component communication. They are not functions and cannot be imported, assigned to variables, or passed as arguments.\n",
       "\n",
       "### $state\n",
       "Creates reactive state with automatic deep reactivity for objects and arrays:\n",
       "```js\n",
       "let count = $state(0);\n",
       "let todos = $state([{ done: false, text: 'add' }]);\n",
       "todos[0].done = true; // triggers updates\n",
       "```\n",
       "Use `$state.raw` for non-reactive state (reassign only) and `$state.snapshot(value)` to convert proxies to plain objects.\n",
       "\n",
       "### $derived\n",
       "Creates reactive computed values that automatically update when dependencies change:\n",
       "```js\n",
       "let doubled = $derived(count * 2);\n",
       "let result = $derived.by(() => { /* complex logic */ });\n",
       "```\n",
       "\n",
       "### $effect\n",
       "Runs functions when state updates for side effects:\n",
       "```js\n",
       "$effect(() => {\n",
       "\tcontext.fillStyle = color;\n",
       "\tcontext.fillRect(0, 0, size, size);\n",
       "});\n",
       "```\n",
       "Return teardown functions that run before re-runs or on destroy. Use `$effect.pre` to run before DOM updates.\n",
       "\n",
       "### $props\n",
       "Receives component props with destructuring and defaults:\n",
       "```js\n",
       "let { adjective = 'happy', ...others } = $props();\n",
       "```\n",
       "Generate unique component instance IDs with `$props.id()`.\n",
       "\n",
       "### $bindable\n",
       "Enables two-way prop binding:\n",
       "```js\n",
       "let { value = $bindable() } = $props();\n",
       "```\n",
       "\n",
       "### $inspect\n",
       "Development-only debugging rune that logs reactive state changes:\n",
       "```js\n",
       "$inspect(count, message);\n",
       "$inspect(count).with((type, value) => { /* custom handler */ });\n",
       "$inspect.trace(); // traces what caused effect to re-run\n",
       "```\n",
       "\n",
       "### $host\n",
       "Accesses the host element in custom element components:\n",
       "```js\n",
       "$host().dispatchEvent(new CustomEvent(type));\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"`{processed_tree.path} -> {processed_tree.name}:`\\n\\n{processed_tree.essence}\"))\n",
    "display(Markdown(\"# **==== Digest ====**\"))\n",
    "display(Markdown(processed_tree.digest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks decent. Keep in mind, this it the digest for the while 2 first section of the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much did it cost us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def calculate_total_usage(doc_dir: DocDirectory) -> Usage:\n",
    "    \"\"\"Calculate total usage for a directory tree including all pages, subdirs, and summaries\"\"\"\n",
    "    total_input = 0\n",
    "    total_output = 0\n",
    "\n",
    "    # Add usage from all pages in this directory\n",
    "    for page in doc_dir.pages:\n",
    "        total_input += page.usage.input or 0\n",
    "        total_output += page.usage.output or 0\n",
    "\n",
    "    # Add usage from directory summarization\n",
    "    if doc_dir.usage:\n",
    "        total_input += doc_dir.usage.input or 0\n",
    "        total_output += doc_dir.usage.output or 0\n",
    "\n",
    "    # Recursively add usage from subdirectories\n",
    "    for subdir in doc_dir.subdirs:\n",
    "        subdir_usage = calculate_total_usage(subdir)\n",
    "        total_input += subdir_usage.input or 0\n",
    "        total_output += subdir_usage.output or 0\n",
    "\n",
    "    return Usage(input=total_input, output=total_output)\n",
    "\n",
    "\n",
    "def calculate_cost(usage: Usage, input_cost: float, output_cost: float) -> tuple[float, float, float]:\n",
    "    total_input = usage.input or 0\n",
    "    total_output = usage.output or 0\n",
    "    input_cost_total = (total_input / 1_000_000) * input_cost\n",
    "    output_cost_total = (total_output / 1_000_000) * output_cost\n",
    "    cost = input_cost_total + output_cost_total\n",
    "    return cost, input_cost_total, output_cost_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Usage:\n",
      "  Input tokens: 37,958\n",
      "  Output tokens: 9,138\n",
      "  Total tokens: 47,096\n",
      "\n",
      "Cost:\n",
      "  Total: $0.08\n",
      "  Input: $0.04\n",
      "  Output: $0.05\n"
     ]
    }
   ],
   "source": [
    "usage =calculate_total_usage(processed_tree)\n",
    "print(f\"\\nTotal Usage:\")\n",
    "print(f\"  Input tokens: {usage.input:,}\")\n",
    "print(f\"  Output tokens: {usage.output:,}\")\n",
    "print(f\"  Total tokens: {(usage.input + usage.output):,}\")\n",
    "\n",
    "cost, input_cost, output_cost = calculate_cost(usage, 1, 5)\n",
    "\n",
    "print(f\"\\nCost:\")\n",
    "print(f\"  Total: ${cost:.2f}\")\n",
    "print(f\"  Input: ${input_cost:.2f}\")\n",
    "print(f\"  Output: ${output_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's save the results. First the markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_doc_files(path: Path, doc: DocDirectory):\n",
    "    \"\"\"Save a DocDirectory structure to disk at the specified path.\n",
    "\n",
    "    Args:\n",
    "        path: Directory path where the documentation will be saved\n",
    "        doc: DocDirectory object containing the documentation structure to save\n",
    "    \"\"\"\n",
    "    if path.exists(): shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    (path/\"digest.md\").write_text(doc.digest)\n",
    "    (path/\"short_digest.md\").write_text(doc.short_digest)\n",
    "    (path/\"essence.md\").write_text(doc.essence)\n",
    "    (path/\"fulltext.md\").write_text(doc.fulltext)\n",
    "\n",
    "\n",
    "    for page in doc.pages:\n",
    "        (path/page.name).mkdir(parents=True, exist_ok=True)\n",
    "        (path/page.name/\"essence.md\").write_text(page.essence)\n",
    "        (path/page.name/\"fulltext.md\").write_text(page.fulltext)\n",
    "        (path/page.name/\"digest.md\").write_text(page.digest)\n",
    "        (path/page.name/\"short_digest.md\").write_text(page.short_digest)\n",
    "\n",
    "    for subdir in doc.subdirs:\n",
    "        save_doc_files(path/subdir.name, subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digest.md  essence.md  fulltext.md  introduction  runes  short_digest.md\n",
      "digest.md   fulltext.md      introduction  short_digest.md\n",
      "essence.md  getting-started  overview\t   svelte-files\n",
      "digest.md  essence.md  fulltext.md  short_digest.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Svelte is a compiler-based framework for building web user interfaces. It transforms declarative components written in HTML, CSS, and JavaScript into optimized JavaScript code.\n",
       "\n",
       "Example component:\n",
       "```svelte\n",
       "<script>\n",
       "\tfunction greet() {\n",
       "\t\talert('Welcome to Svelte!');\n",
       "\t}\n",
       "</script>\n",
       "\n",
       "<button onclick={greet}>click me</button>\n",
       "\n",
       "<style>\n",
       "\tbutton {\n",
       "\t\tfont-size: 2em;\n",
       "\t}\n",
       "</style>\n",
       "```\n",
       "\n",
       "Use cases range from standalone components to full-stack applications using SvelteKit. For learning, the interactive tutorial is recommended as a starting point, with this documentation serving as reference material. Online environments are available via the playground or StackBlitz."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_doc_files(Path(\"test-out\"), processed_tree)\n",
    "!ls test-out\n",
    "!ls \"test-out/{processed_tree.subdirs[0].name}\"\n",
    "!ls \"test-out/{processed_tree.subdirs[0].name}/{processed_tree.subdirs[0].pages[0].name}\"\n",
    "Markdown((Path(\"test-out\")/processed_tree.subdirs[0].name/processed_tree.subdirs[0].pages[0].name / \"digest.md\").read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import git\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from lovely_docs.settings import Source, WebSource, GitSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f5802e3f465dd546722723e1a413294fd81f9d26-dirty'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = git.Repo(search_parent_directories=True)\n",
    "commit = repo.head.commit.hexsha\n",
    "# Check if repo is dirty\n",
    "if repo.is_dirty(untracked_files=True):\n",
    "    commit += \"-dirty\"\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def file_map(doc: DocDirectory, prefix: Path):\n",
    "    filemap = {}\n",
    "\n",
    "    path = prefix / doc.name\n",
    "\n",
    "    # The filemap is keyed by original name so it's easy to get the pages in the original order.\n",
    "    logger.debug(f\"Added {path.as_posix()} -> {doc.name} ({doc.path.as_posix()})\")\n",
    "\n",
    "    for subdir in doc.subdirs:\n",
    "        filemap[(path/subdir.name).as_posix()] =  subdir.model_dump(mode=\"json\", include=[\"path\", \"relevant\", \"usage\", \"token_counts\"]) | {\"type\": \"directory\" }\n",
    "        filemap |= file_map(subdir, path)\n",
    "\n",
    "    for page in doc.pages:\n",
    "        filemap[(path / page.name).as_posix()] = page.model_dump(mode=\"json\", include=[\"path\", \"relevant\", \"usage\", \"token_counts\"]) | {\"type\": \"page\"}\n",
    "        logger.debug(f\"Added page {(path / page.name).as_posix()} -> {page.name} ({page.path.as_posix()})\")\n",
    "    return filemap\n",
    "\n",
    "\n",
    "def build_metadata(source: Source, doc: DocDirectory):\n",
    "\n",
    "    if isinstance(source, GitSource):\n",
    "        source_type = \"git\"\n",
    "    elif isinstance(source, WebSource):\n",
    "        source_type = \"web\"\n",
    "    else:\n",
    "        raise TypeError(f\"Unknown source type: {type(source)}\")\n",
    "\n",
    "    # Get current git commit\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    commit = repo.head.commit.hexsha\n",
    "    # Check if repo is dirty\n",
    "    if repo.is_dirty(untracked_files=True):\n",
    "        commit += \"-dirty\"\n",
    "\n",
    "    return {\n",
    "        \"map\": file_map(doc, Path(\"\")),\n",
    "        \"source_type\": source_type,\n",
    "        \"source\": source.model_dump(mode=\"json\"),\n",
    "        \"date\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"model\": settings.model,\n",
    "        \"commit\": commit,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+6.559s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added . ->  (.)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added introduction -> introduction (01-introduction)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/overview -> overview (01-introduction/01-overview.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/getting-started -> getting-started (01-introduction/02-getting-started.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/svelte-files -> svelte-files (01-introduction/03-svelte-files.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/.svelte.js-and-.svelte.ts-files -> .svelte.js-and-.svelte.ts-files (01-introduction/04-svelte-js-files.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/introduction -> introduction (01-introduction/index.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added runes -> runes (02-runes)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/what-are-runes -> what-are-runes (02-runes/01-what-are-runes.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$state -> $state (02-runes/02-$state.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$derived -> $derived (02-runes/03-$derived.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$effect -> $effect (02-runes/04-$effect.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$props -> $props (02-runes/05-$props.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$bindable -> $bindable (02-runes/06-$bindable.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$inspect -> $inspect (02-runes/07-$inspect.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$host -> $host (02-runes/08-$host.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/runes -> runes (02-runes/index.md)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5562"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_source = GitSource(\n",
    "    commit=\"123456\",\n",
    "    doc_dir=\"path/to/nowhere\",\n",
    "    name=\"svelte\",\n",
    "    repo=\"https://github.com/sveltejs/svelte\"\n",
    ")\n",
    "processed_tree.name = \"\" # The top-level directry does not need a name.\n",
    "Path(\"test-out/index.json\").write_text(json.dumps(build_metadata(fake_source, processed_tree), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"map\": {\n",
      "    \"introduction\": {\n",
      "      \"path\": \"01-introduction\",\n",
      "      \"relevant\": false,\n",
      "      \"usage\": {\n",
      "        \"input\": 1419,\n",
      "        \"output\": 458,\n",
      "        \"details\": null\n",
      "      },\n",
      "      \"token_counts\": {\n",
      "        \"fulltext\": 329,\n",
      "        \"digest\": 246,\n",
      "        \"short_digest\": 110\n",
      "      },\n",
      "      \"type\": \"directory\"\n",
      "    },\n",
      "    \"introduction/overview\": {\n",
      "      \"path\": \"01-introduction/01-overview.md\",\n",
      "      \"relevant\": false,\n",
      "[  .....  ]\n",
      "  \"source\": {\n",
      "    \"name\": \"svelte\",\n",
      "    \"doc_dir\": \"path/to/nowhere\",\n",
      "    \"repo\": \"https://github.com/sveltejs/svelte\",\n",
      "    \"commit\": \"123456\"\n",
      "  },\n",
      "  \"date\": \"2025-11-05T06:14:05.369769+00:00\",\n",
      "  \"model\": \"claude-haiku-4.5\",\n",
      "  \"commit\": \"f5802e3f465dd546722723e1a413294fd81f9d26-dirty\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat test-out/index.json | head -n 20\n",
    "!echo \"[  .....  ]\"\n",
    "!cat test-out/index.json | tail -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_processed_documents(source: Source, path: Path, tree: DocDirectory):\n",
    "    tree = tree.model_copy(deep=True)\n",
    "    tree.name = \"\" # The top-level directry does not need a name.\n",
    "    save_doc_files(path, tree)\n",
    "    (path/\"index.json\").write_text(json.dumps(build_metadata(source, tree), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.884s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added . ->  (.)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added introduction -> introduction (01-introduction)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/overview -> overview (01-introduction/01-overview.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/getting-started -> getting-started (01-introduction/02-getting-started.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/svelte-files -> svelte-files (01-introduction/03-svelte-files.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/.svelte.js-and-.svelte.ts-files -> .svelte.js-and-.svelte.ts-files (01-introduction/04-svelte-js-files.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page introduction/introduction -> introduction (01-introduction/index.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:9\u001b[0m file_map Added runes -> runes (02-runes)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/what-are-runes -> what-are-runes (02-runes/01-what-are-runes.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$state -> $state (02-runes/02-$state.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$derived -> $derived (02-runes/03-$derived.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$effect -> $effect (02-runes/04-$effect.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$props -> $props (02-runes/05-$props.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$bindable -> $bindable (02-runes/06-$bindable.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$inspect -> $inspect (02-runes/07-$inspect.md)\u001b[0m\n",
      "+0.001s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/$host -> $host (02-runes/08-$host.md)\u001b[0m\n",
      "+0.000s \u001b[36mDEBUG\u001b[0m \u001b[34m<ipykernel>:17\u001b[0m file_map Added page runes/runes -> runes (02-runes/index.md)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "save_processed_documents(fake_source, Path(\"test-out\"), processed_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
