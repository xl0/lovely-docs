{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda54d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drizzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2d04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp drizzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dd6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40985134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from lovely_docs.settings import settings, GitSource\n",
    "from lovely_docs.git import clone_repo\n",
    "from lovely_docs.docs import (\n",
    "    build_markdown_doc_tree, process_tree_depth_first, calculate_total_usage, calculate_cost,\n",
    "    save_processed_documents\n",
    ")\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372069ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e990730",
   "metadata": {},
   "source": [
    "#### Clone the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c2e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66: 7472.0/7472.0 0 27.69 MiB | 14.60 MiB/s"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "source = GitSource(\n",
    "    name=\"drizzle-orm\",\n",
    "    doc_dir=\"src/content/docs\",\n",
    "    repo=\"https://github.com/drizzle-team/drizzle-orm-docs\",\n",
    "    commit=\"main\",\n",
    "    ecosystems=[\"js\"]\n",
    ")\n",
    "\n",
    "commit, clone_dir = clone_repo(source)\n",
    "source.commit = commit  # Replace the literal commit (master) with the hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a4f23",
   "metadata": {},
   "source": [
    "#### Read the markdown files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocItem(origPath=Path('arktype.mdx'), name='arktype.mdx', displayName='arktype.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# drizzle-arktype\\n\\n`drizzle-arktype` is a plugin for **[Drizzle ORM](https://github.com/drizzle-team/drizzle-orm)** that allows you to generate **[Arktype](https://arktype.io/)** schemas from Drizzle ORM schemas.\\n\\n### Install the dependencies\\n\\n<Npm>\\ndrizzle-arktype\\n</Npm>\\n\\n<Callout type=\"warning\">\\nThis documentation is for `drizzle-arktype@0.1.0` and higher\\n\\nYou must also have Drizzle ORM v0.36.0 or greater and Arktype v2.0.0 or greater installed.\\n</Callout>\\n\\n### Select schema\\n\\nDefines the shape of data queried from the database - can be used to validate API responses.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-arktype\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users);\\n\\nconst rows = await db.select({ id: users.id, name: users.name }).from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = userSelectSchema(rows[0]); // Error: `age` is not returned in the above query\\n\\nconst rows = await db.select().from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = userSelectSchema(rows[0]); // Will parse successfully\\n```\\n\\nViews and enums are also supported.\\n\\n```ts copy\\nimport { pgEnum } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-arktype\\';\\n\\nconst roles = pgEnum(\\'roles\\', [\\'admin\\', \\'basic\\']);\\nconst rolesSchema = createSelectSchema(roles);\\nconst parsed: \\'admin\\' | \\'basic\\' = rolesSchema(...);\\n\\nconst usersView = pgView(\\'users_view\\').as((qb) => qb.select().from(users).where(gt(users.age, 18)));\\nconst usersViewSchema = createSelectSchema(usersView);\\nconst parsed: { id: number; name: string; age: number } = usersViewSchema(...);\\n```\\n\\n### Insert schema\\n\\nDefines the shape of data to be inserted into the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createInsertSchema } from \\'drizzle-arktype\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userInsertSchema = createInsertSchema(users);\\n\\nconst user = { name: \\'John\\' };\\nconst parsed: { name: string, age: number } = userInsertSchema(user); // Error: `age` is not defined\\n\\nconst user = { name: \\'Jane\\', age: 30 };\\nconst parsed: { name: string, age: number } = userInsertSchema(user); // Will parse successfully\\nawait db.insert(users).values(parsed);\\n```\\n\\n### Update schema\\n\\nDefines the shape of data to be updated in the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createUpdateSchema } from \\'drizzle-arktype\\';\\nimport { parse } from \\'arktype\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userUpdateSchema = createUpdateSchema(users);\\n\\nconst user = { id: 5, name: \\'John\\' };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = userUpdateSchema(user); // Error: `id` is a generated column, it can\\'t be updated\\n\\nconst user = { age: 35 };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = userUpdateSchema(user); // Will parse successfully\\nawait db.update(users).set(parsed).where(eq(users.name, \\'Jane\\'));\\n```\\n\\n### Refinements\\n\\nEach create schema function accepts an additional optional parameter that you can used to extend, modify or completely overwite a field\\'s schema. Defining a callback function will extend or modify while providing a arktype schema will overwrite it.\\n\\n```ts copy\\nimport { pgTable, text, integer, json } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-arktype\\';\\nimport { parse, pipe, maxLength, object, string } from \\'arktype\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  bio: text(),\\n  preferences: json()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users, {\\n  name: (schema) => pipe(schema, maxLength(20)), // Extends schema\\n  bio: (schema) => pipe(schema, maxLength(1000)), // Extends schema before becoming nullable/optional\\n  preferences: object({ theme: string() }) // Overwrites the field, including its nullability\\n});\\n\\nconst parsed: {\\n  id: number;\\n  name: string,\\n  bio?: string | undefined;\\n  preferences: {\\n    theme: string;\\n  };\\n} = userSelectSchema(...);\\n```\\n\\n### Data type reference\\n\\n```ts\\npg.boolean();\\n\\nmysql.boolean();\\n\\nsqlite.integer({ mode: \\'boolean\\' });\\n\\n// Schema\\ntype.boolean;\\n```\\n\\n```ts\\npg.date({ mode: \\'date\\' });\\npg.timestamp({ mode: \\'date\\' });\\n\\nmysql.date({ mode: \\'date\\' });\\nmysql.datetime({ mode: \\'date\\' });\\nmysql.timestamp({ mode: \\'date\\' });\\n\\nsqlite.integer({ mode: \\'timestamp\\' });\\nsqlite.integer({ mode: \\'timestamp_ms\\' });\\n\\n// Schema\\ntype.Date;\\n```\\n\\n```ts\\npg.date({ mode: \\'string\\' });\\npg.timestamp({ mode: \\'string\\' });\\npg.cidr();\\npg.inet();\\npg.interval();\\npg.macaddr();\\npg.macaddr8();\\npg.numeric();\\npg.text();\\npg.sparsevec();\\npg.time();\\n\\nmysql.binary();\\nmysql.date({ mode: \\'string\\' });\\nmysql.datetime({ mode: \\'string\\' });\\nmysql.decimal();\\nmysql.time();\\nmysql.timestamp({ mode: \\'string\\' });\\nmysql.varbinary();\\n\\nsqlite.numeric();\\nsqlite.text({ mode: \\'text\\' });\\n\\n// Schema\\ntype.string;\\n```\\n\\n```ts\\npg.bit({ dimensions: ... });\\n\\n// Schema\\ntype(`/^[01]{${column.dimensions}}$/`);\\n```\\n\\n```ts\\npg.uuid();\\n\\n// Schema\\ntype(/^[\\\\da-f]{8}(?:-[\\\\da-f]{4}){3}-[\\\\da-f]{12}$/iu);\\n```\\n\\n```ts\\npg.char({ length: ... });\\n\\nmysql.char({ length: ... });\\n\\n// Schema\\ntype.string.exactlyLength(length);\\n```\\n\\n```ts\\npg.varchar({ length: ... });\\n\\nmysql.varchar({ length: ... });\\n\\nsqlite.text({ mode: \\'text\\', length: ... });\\n\\n// Schema\\ntype.string.atMostLength(length);\\n```\\n\\n```ts\\nmysql.tinytext();\\n\\n// Schema\\ntype.string.atMostLength(255); // unsigned 8-bit integer limit\\n```\\n\\n```ts\\nmysql.text();\\n\\n// Schema\\ntype.string.atMostLength(65_535); // unsigned 16-bit integer limit\\n```\\n\\n```ts\\nmysql.mediumtext();\\n\\n// Schema\\ntype.string.atMostLength(16_777_215); // unsigned 24-bit integer limit\\n```\\n\\n```ts\\nmysql.longtext();\\n\\n// Schema\\ntype.string.atMostLength(4_294_967_295); // unsigned 32-bit integer limit\\n```\\n\\n```ts\\npg.text({ enum: ... });\\npg.char({ enum: ... });\\npg.varchar({ enum: ... });\\n\\nmysql.tinytext({ enum: ... });\\nmysql.mediumtext({ enum: ... });\\nmysql.text({ enum: ... });\\nmysql.longtext({ enum: ... });\\nmysql.char({ enum: ... });\\nmysql.varchar({ enum: ... });\\nmysql.mysqlEnum(..., ...);\\n\\nsqlite.text({ mode: \\'text\\', enum: ... });\\n\\n// Schema\\ntype.enumerated(...enum);\\n```\\n\\n```ts\\nmysql.tinyint();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(-128).atMost(127); // 8-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.tinyint({ unsigned: true });\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(0).atMost(255); // unsigned 8-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.smallint();\\npg.smallserial();\\n\\nmysql.smallint();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(-32_768).atMost(32_767); // 16-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.smallint({ unsigned: true });\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(0).atMost(65_535); // unsigned 16-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.real();\\n\\nmysql.float();\\n\\n// Schema\\ntype.number.atLeast(-8_388_608).atMost(8_388_607); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(-8_388_608).atMost(8_388_607); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.float({ unsigned: true });\\n\\n// Schema\\ntype.number.atLeast(0).atMost(16_777_215); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint({ unsigned: true });\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(0).atMost(16_777_215); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.integer();\\npg.serial();\\n\\nmysql.int();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(-2_147_483_648).atMost(2_147_483_647); // 32-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.int({ unsigned: true });\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(0).atMost(4_294_967_295); // unsgined 32-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.doublePrecision();\\n\\nmysql.double();\\nmysql.real();\\n\\nsqlite.real();\\n\\n// Schema\\ntype.number.atLeast(-140_737_488_355_328).atMost(140_737_488_355_327); // 48-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.double({ unsigned: true });\\n\\n// Schema\\ntype.number.atLeast(0).atMost(281_474_976_710_655); // unsigned 48-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.bigint({ mode: \\'number\\' });\\npg.bigserial({ mode: \\'number\\' });\\n\\nmysql.bigint({ mode: \\'number\\' });\\nmysql.bigserial({ mode: \\'number\\' });\\n\\nsqlite.integer({ mode: \\'number\\' });\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(-9_007_199_254_740_991).atMost(9_007_199_254_740_991); // Javascript min. and max. safe integers\\n```\\n\\n```ts\\nmysql.serial();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(0).atMost(9_007_199_254_740_991); // Javascript max. safe integer\\n```\\n\\n```ts\\npg.bigint({ mode: \\'bigint\\' });\\npg.bigserial({ mode: \\'bigint\\' });\\n\\nmysql.bigint({ mode: \\'bigint\\' });\\n\\nsqlite.blob({ mode: \\'bigint\\' });\\n\\n// Schema\\ntype.bigint.narrow(\\n  (value, ctx) => value < -9_223_372_036_854_775_808n ? ctx.mustBe(\\'greater than\\') : value > 9_223_372_036_854_775_807n ? ctx.mustBe(\\'less than\\') : true\\n); // 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.bigint({ mode: \\'bigint\\', unsigned: true });\\n\\n// Schema\\ntype.bigint.narrow(\\n  (value, ctx) => value < 0n ? ctx.mustBe(\\'greater than\\') : value > 18_446_744_073_709_551_615n ? ctx.mustBe(\\'less than\\') : true\\n); // unsigned 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.year();\\n\\n// Schema\\ntype.keywords.number.integer.atLeast(1_901).atMost(2_155);\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'tuple\\' });\\npg.point({ mode: \\'tuple\\' });\\n\\n// Schema\\ntype([type.number, type.number]);\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'xy\\' });\\npg.point({ mode: \\'xy\\' });\\n\\n// Schema\\ntype({ x: type.number, y: type.number });\\n```\\n\\n```ts\\npg.halfvec({ dimensions: ... });\\npg.vector({ dimensions: ... });\\n\\n// Schema\\ntype.number.array().exactlyLength(dimensions);\\n```\\n\\n```ts\\npg.line({ mode: \\'abc\\' });\\n\\n// Schema\\ntype({ a: type.number, b: type.number, c: type.number });\\n```\\n\\n```ts\\npg.line({ mode: \\'tuple\\' });\\n\\n// Schema\\ntype([type.number, type.number, type.number]);\\n```\\n\\n```ts\\npg.json();\\npg.jsonb();\\n\\nmysql.json();\\n\\nsqlite.blob({ mode: \\'json\\' });\\nsqlite.text({ mode: \\'json\\' });\\n\\n// Schema\\ntype(\\'string | number | boolean | null\\').or(type(\\'unknown.any[] | Record<string, unknown.any>\\'));\\n```\\n\\n```ts\\nsqlite.blob({ mode: \\'buffer\\' });\\n\\n// Schema\\ntype.instanceOf(Buffer);\\n```\\n\\n```ts\\npg.dataType().array(...);\\n\\n// Schema\\nbaseDataTypeSchema.array().exactlyLength(size);\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('batch-api.mdx'), name='batch-api.mdx', displayName='batch-api.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\n\\n# Batch API\\n\\n**LibSQL Batch API explanation**:\\n_[source](https://docs.turso.tech/sdk/ts/reference#batch-transactions)_\\n\\n> With the libSQL client library, a batch is one or more SQL statements executed in order in an implicit transaction. \\nThe transaction is controlled by the libSQL backend. If all of the statements are successful, \\nthe transaction is committed. If any of the statements fail, the entire transaction is rolled back and no changes are made.\\n\\n**D1 Batch API explanation**:\\n_[source](https://developers.cloudflare.com/d1/worker-api/d1-database/#batch)_\\n\\n> Batching sends multiple SQL statements inside a single call to the database. \\nThis can have a huge performance impact as it reduces latency from network round trips to D1. \\nD1 operates in auto-commit. Our implementation guarantees that each statement in the list will execute and commit,\\nsequentially, non-concurrently.\\nBatched statements are SQL transactions. If a statement in the sequence fails, \\nthen an error is returned for that specific statement, and it aborts or rolls back the entire sequence.\\n\\nDrizzle ORM provides APIs to run SQL statements in batch for `LibSQL`, `Neon` and `D1`:\\n```ts\\nconst batchResponse: BatchResponse = await db.batch([\\n\\tdb.insert(usersTable).values({ id: 1, name: \\'John\\' }).returning({ id: usersTable.id }),\\n\\tdb.update(usersTable).set({ name: \\'Dan\\' }).where(eq(usersTable.id, 1)),\\n\\tdb.query.usersTable.findMany({}),\\n\\tdb.select().from(usersTable).where(eq(usersTable.id, 1)),\\n\\tdb.select({ id: usersTable.id, invitedBy: usersTable.invitedBy }).from(usersTable),\\n]);\\n```\\nType for `batchResponse` in this example would be:\\n<Tabs items={[\"libSQL\", \"Neon\", \"D1\"]}>\\n<Tab>\\n```ts\\ntype BatchResponse = [\\n\\t{\\n\\t\\tid: number;\\n\\t}[],\\n\\tResultSet,\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n]\\n```\\n</Tab>\\n<Tab>\\n```ts\\ntype BatchResponse = [\\n\\t{\\n\\t\\tid: number;\\n\\t}[],\\n\\tNeonHttpQueryResult,\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n]\\n```\\n</Tab>\\n<Tab>\\n```ts\\ntype BatchResponse = [\\n  {\\n    id: number;\\n  }[],\\n  D1Result,\\n  {\\n    id: number;\\n    name: string;\\n    verified: number;\\n    invitedBy: number | null;\\n  }[],\\n  {\\n    id: number;\\n    name: string;\\n    verified: number;\\n    invitedBy: number | null;\\n  }[],\\n  {\\n    id: number;\\n    invitedBy: number | null;\\n  }[],\\n]\\n```\\n</Tab>\\n</Tabs>\\n\\nAll possible builders that can be used inside `db.batch`:\\n```ts\\ndb.all(),\\ndb.get(),\\ndb.values(),\\ndb.run(),\\ndb.execute(),\\ndb.query.<table>.findMany(),\\ndb.query.<table>.findFirst(),\\ndb.select()...,\\ndb.update()...,\\ndb.delete()...,\\ndb.insert()...,\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('cache.mdx'), name='cache.mdx', displayName='cache.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\n\\n# Cache\\n\\nDrizzle sends every query straight to your database by default. There are no hidden actions, no automatic caching \\nor invalidation - you\\'ll always see exactly what runs. If you want caching, you must opt in.\\n\\nBy default, Drizzle uses a `explicit` caching strategy (i.e. `global: false`), so nothing is ever cached unless you ask. \\nThis prevents surprises or hidden performance traps in your application. \\nAlternatively, you can flip on `all` caching (`global: true`) so that every select will look in cache first.\\n\\n## Quickstart\\n\\n### Upstash integration\\n\\nDrizzle provides an `upstashCache()` helper out of the box. By default, this uses Upstash Redis with automatic configuration if environment variables are set.\\n\\n```ts\\nimport { upstashCache } from \"drizzle-orm/cache/upstash\";\\nimport { drizzle } from \"drizzle-orm/...\";\\n\\nconst db = drizzle(process.env.DB_URL!, {\\n  cache: upstashCache(),\\n});\\n```\\n\\nYou can also explicitly define your Upstash credentials, enable global caching for all queries by default or pass custom caching options:\\n\\n```ts\\nimport { upstashCache } from \"drizzle-orm/cache/upstash\";\\nimport { drizzle } from \"drizzle-orm/...\";\\n\\nconst db = drizzle(process.env.DB_URL!, {\\n  cache: upstashCache({\\n    // ðŸ‘‡ Redis credentials (optional â€” can also be pulled from env vars)\\n    url: \\'<UPSTASH_URL>\\',\\n    token: \\'<UPSTASH_TOKEN>\\',\\n\\n    // ðŸ‘‡ Enable caching for all queries by default (optional)\\n    global: true,\\n\\n    // ðŸ‘‡ Default cache behavior (optional)\\n    config: { ex: 60 }\\n  })\\n});\\n```\\n\\n## Cache config reference\\n\\nDrizzle supports the following cache config options for Upstash:\\n\\n```ts\\nexport type CacheConfig = {\\n  /**\\n   * Expiration in seconds (positive integer)\\n   */\\n  ex?: number;\\n  /**\\n   * Set an expiration (TTL or time to live) on one or more fields of a given hash key.\\n   * Used for HEXPIRE command\\n   */\\n  hexOptions?: \"NX\" | \"nx\" | \"XX\" | \"xx\" | \"GT\" | \"gt\" | \"LT\" | \"lt\";\\n};\\n```\\n\\n## Cache usage examples\\n\\nOnce you\\'ve configured caching, here\\'s how the cache behaves:\\n\\n**Case 1: Drizzle with `global: false` (default, opt-in caching)**\\n\\n```ts\\nimport { upstashCache } from \"drizzle-orm/cache/upstash\";\\nimport { drizzle } from \"drizzle-orm/...\";\\n\\nconst db = drizzle(process.env.DB_URL!, {\\n  // ðŸ‘‡ `global: true` is not passed, false by default\\n  cache: upstashCache({ url: \"\", token: \"\" }),\\n});\\n```\\n\\nIn this case, the following query won\\'t read from cache\\n\\n```ts\\nconst res = await db.select().from(users);\\n\\n// Any mutate operation will still trigger the cache\\'s onMutate handler\\n// and attempt to invalidate any cached queries that involved the affected tables\\nawait db.insert(users).value({ email: \"cacheman@upstash.com\" });\\n```\\n\\nTo make this query read from the cache, call `.$withCache()`\\n\\n```ts\\nconst res = await db.select().from(users).$withCache();\\n```\\n\\n`.$withCache` has a set of options you can use to manage and configure this specific query strategy\\n\\n```ts\\n// rewrite the config for this specific query\\n.$withCache({ config: {} })\\n\\n// give this query a custom cache key (instead of hashing query+params under the hood)\\n.$withCache({ tag: \\'custom_key\\' })\\n\\n// turn off auto-invalidation for this query\\n// note: this leads to eventual consistency (explained below)\\n.$withCache({ autoInvalidate: false })\\n```\\n\\n<Callout>\\n**Eventual consistency example**\\n\\nThis example is only relevant if you manually set `autoInvalidate: false`. By default, `autoInvalidate` is enabled. \\n\\nYou might want to turn off `autoInvalidate` if:\\n- your data doesn\\'t change often, and slight staleness is acceptable (e.g. product listings, blog posts)\\n- you handle cache invalidation manually\\n\\nIn those cases, turning it off can reduce unnecessary cache invalidation. However, in most cases, we recommend keeping the default enabled.\\n\\nExample: Imagine you cache the following query on `usersTable` with a 3-second TTL:\\n\\n``` ts\\nconst recent = await db\\n  .select().from(usersTable)\\n  .$withCache({ config: { ex: 3 }, autoInvalidate: false });\\n```\\n\\nIf someone runs `db.insert(usersTable)...` the cache won\\'t be invalidated immediately. For up to 3 seconds, you\\'ll keep seeing the old data until it eventually becomes consistent.\\n</Callout>\\n\\n**Case 2: Drizzle with `global: true` option**\\n\\n```ts\\nimport { upstashCache } from \"drizzle-orm/cache/upstash\";\\nimport { drizzle } from \"drizzle-orm/...\";\\n\\nconst db = drizzle(process.env.DB_URL!, {\\n  cache: upstashCache({ url: \"\", token: \"\", global: true }),\\n});\\n```\\n\\nIn this case, the following query will read from cache\\n\\n```ts\\nconst res = await db.select().from(users);\\n```\\n\\nIf you want to disable cache for this specific query, call `.$withCache(false)`\\n\\n```ts\\n// disable cache for this query\\nconst res = await db.select().from(users).$withCache(false);\\n```\\n\\nYou can also use cache instance from a `db` to invalidate specific tables or tags\\n\\n```ts\\n// Invalidate all queries that use the `users` table. You can do this with the Drizzle instance.\\nawait db.$cache.invalidate({ tables: users });\\n// or\\nawait db.$cache.invalidate({ tables: [users, posts] });\\n\\n// Invalidate all queries that use the `usersTable`. You can do this by using just the table name.\\nawait db.$cache.invalidate({ tables: \"usersTable\" });\\n// or\\nawait db.$cache.invalidate({ tables: [\"usersTable\", \"postsTable\"] });\\n\\n// You can also invalidate custom tags defined in any previously executed select queries.\\nawait db.$cache.invalidate({ tags: \"custom_key\" });\\n// or\\nawait db.$cache.invalidate({ tags: [\"custom_key\", \"custom_key1\"] });\\n```\\n\\n## Custom cache\\n\\nThis example shows how to plug in a custom `cache` in Drizzle: you provide functions to fetch data from the cache, store results back into cache, and invalidate entries whenever a mutation runs.\\n\\nCache extension provides this set of config options\\n```ts\\nexport type CacheConfig = {\\n  /** expire time, in seconds */\\n  ex?: number;\\n  /** expire time, in milliseconds */\\n  px?: number;\\n  /** Unix time (sec) at which the key will expire */\\n  exat?: number;\\n  /** Unix time (ms) at which the key will expire */\\n  pxat?: number;\\n  /** retain existing TTL when updating a key */\\n  keepTtl?: boolean;\\n  /** options for HEXPIRE (hash-field TTL) */\\n  hexOptions?: \\'NX\\' | \\'XX\\' | \\'GT\\' | \\'LT\\' | \\'nx\\' | \\'xx\\' | \\'gt\\' | \\'lt\\';\\n};\\n```\\n\\n```ts\\nconst db = drizzle(process.env.DB_URL!, { cache: new TestGlobalCache() });\\n```\\n\\n```ts\\nimport Keyv from \"keyv\";\\n\\nexport class TestGlobalCache extends Cache {\\n  private globalTtl: number = 1000;\\n  // This object will be used to store which query keys were used\\n  // for a specific table, so we can later use it for invalidation.\\n  private usedTablesPerKey: Record<string, string[]> = {};\\n\\n  constructor(private kv: Keyv = new Keyv()) {\\n    super();\\n  }\\n\\n  // For the strategy, we have two options:\\n  // - \\'explicit\\': The cache is used only when .$withCache() is added to a query.\\n  // - \\'all\\': All queries are cached globally.\\n  // The default behavior is \\'explicit\\'.\\n  override strategy(): \"explicit\" | \"all\" {\\n    return \"all\";\\n  }\\n\\n  // This function accepts query and parameters that cached into key param,\\n  // allowing you to retrieve response values for this query from the cache.\\n  override async get(key: string): Promise<any[] | undefined> {\\n    const res = (await this.kv.get(key)) ?? undefined;\\n    return res;\\n  }\\n\\n  // This function accepts several options to define how cached data will be stored:\\n  // - \\'key\\': A hashed query and parameters.\\n  // - \\'response\\': An array of values returned by Drizzle from the database.\\n  // - \\'tables\\': An array of tables involved in the select queries. This information is needed for cache invalidation.\\n  //\\n  // For example, if a query uses the \"users\" and \"posts\" tables, you can store this information. Later, when the app executes\\n  // any mutation statements on these tables, you can remove the corresponding key from the cache.\\n  // If you\\'re okay with eventual consistency for your queries, you can skip this option.\\n  override async put(\\n    key: string,\\n    response: any,\\n    tables: string[],\\n    config?: CacheConfig,\\n  ): Promise<void> {\\n    const ttl = config?.px ?? (config?.ex ? config.ex * 1000 : this.globalTtl);\\n\\n    await this.kv.set(key, response, ttl);\\n\\n    for (const table of tables) {\\n      const keys = this.usedTablesPerKey[table];\\n      if (keys === undefined) {\\n        this.usedTablesPerKey[table] = [key];\\n      } else {\\n        keys.push(key);\\n      }\\n    }\\n  }\\n\\n  // This function is called when insert, update, or delete statements are executed.\\n  // You can either skip this step or invalidate queries that used the affected tables.\\n  //\\n  // The function receives an object with two keys:\\n  // - \\'tags\\': Used for queries labeled with a specific tag, allowing you to invalidate by that tag.\\n  // - \\'tables\\': The actual tables affected by the insert, update, or delete statements,\\n  //   helping you track which tables have changed since the last cache update.\\n  override async onMutate(params: {\\n    tags: string | string[];\\n    tables: string | string[] | Table<any> | Table<any>[];\\n  }): Promise<void> {\\n    const tagsArray = params.tags\\n      ? Array.isArray(params.tags)\\n        ? params.tags\\n        : [params.tags]\\n      : [];\\n    const tablesArray = params.tables\\n      ? Array.isArray(params.tables)\\n        ? params.tables\\n        : [params.tables]\\n      : [];\\n\\n    const keysToDelete = new Set<string>();\\n\\n    for (const table of tablesArray) {\\n      const tableName = is(table, Table)\\n        ? getTableName(table)\\n        : (table as string);\\n      const keys = this.usedTablesPerKey[tableName] ?? [];\\n      for (const key of keys) keysToDelete.add(key);\\n    }\\n\\n    if (keysToDelete.size > 0 || tagsArray.length > 0) {\\n      for (const tag of tagsArray) {\\n        await this.kv.delete(tag);\\n      }\\n\\n      for (const key of keysToDelete) {\\n        await this.kv.delete(key);\\n        for (const table of tablesArray) {\\n          const tableName = is(table, Table)\\n            ? getTableName(table)\\n            : (table as string);\\n          this.usedTablesPerKey[tableName] = [];\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Limitations\\n\\n#### Queries that won\\'t be handled by the `cache` extension:\\n\\n- Using cache with raw queries, such as:\\n\\n```ts\\ndb.execute(sql`select 1`);\\n```\\n\\n- Using cache with `batch` feature in `d1` and `libsql`\\n\\n```ts\\ndb.batch([\\n    db.insert(users).values(...),\\n    db.update(users).set(...).where()\\n])\\n```\\n\\n- Using cache in transactions\\n```ts\\nawait db.transaction(async (tx) => {\\n  await tx.update(accounts).set(...).where(...);\\n  await tx.update...\\n});\\n```\\n\\n#### Limitations that are temporary and will be handled soon:\\n\\n- Using cache with Drizzle Relational Queries\\n```ts\\nawait db.query.users.findMany();\\n```\\n\\n- Using cache with `better-sqlite3`, `Durable Objects`, `expo sqlite`\\n- Using cache with AWS Data API drivers\\n- Using cache with views\\n', children=[]),\n",
       " DocItem(origPath=Path('column-types'), name='column-types', displayName='column-types', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('column-types/mysql.mdx'), name='mysql.mdx', displayName='mysql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: MySQL column types\\n---\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nWe have native support for all of them, yet if that\\'s not enough for you, feel free to create **[custom types](/docs/custom-types)**.\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nAll examples in this part of the documentation do not use database column name aliases, and column names are generated from TypeScript keys. \\n\\nYou can use database aliases in column names if you want, and you can also use the `casing` parameter to define a mapping strategy for Drizzle. \\n\\nYou can read more about it [here](/docs/sql-schema-declaration#shape-your-data-schema)\\n</Callout>\\n\\n### integer\\n\\nA signed integer, stored in `0`, `1`, `2`, `3`, `4`, `6`, or `8` bytes depending on the magnitude of the value.\\n\\n<Section>\\n```typescript\\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tint: int()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int\\n);\\n```\\n</Section>\\n\\n### tinyint\\n\\n<Section>\\n```typescript\\nimport { tinyint, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttinyint: tinyint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`tinyint` tinyint\\n);\\n```\\n</Section>\\n\\n### smallint\\n\\n<Section>\\n```typescript\\nimport { smallint, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tsmallint: smallint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`smallint` smallint\\n);\\n```\\n</Section>\\n\\n### mediumint\\n\\n<Section>\\n```typescript\\nimport { mediumint, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tmediumint: mediumint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`mediumint` mediumint\\n);\\n```\\n</Section>\\n\\n### bigint\\n\\n<Section>\\n```typescript\\nimport { bigint, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tbigint: bigint({ mode: \\'number\\' })\\n\\tbigintUnsigned: bigint({ mode: \\'number\\', unsigned: true })\\n});\\n\\nbigint(\\'...\\', { mode: \\'number\\' | \\'bigint\\' });\\n\\n// You can also specify unsigned option for bigint\\nbigint(\\'...\\', { mode: \\'number\\' | \\'bigint\\', unsigned: true })\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`bigint` bigint,\\n\\t`bigintUnsigned` bigint unsigned\\n);\\n```\\n</Section>\\n\\nWe\\'ve omitted config of `M` in `bigint(M)`, since it indicates the display width of the numeric type \\n\\n## ---\\n\\n### real\\n\\n<Section>\\n```typescript\\nimport { real, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\treal: real()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`real` real\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { real, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\trealPrecision: real({ precision: 1,}),\\n\\trealPrecisionScale: real({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`realPrecision` real(1),\\n\\t`realPrecisionScale` real(1, 1)\\n);\\n```\\n</Section>\\n\\n### decimal\\n\\n<Section>\\n```typescript\\nimport { decimal, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdecimal: decimal(),\\n\\tdecimalNum: decimal({ scale: 30, mode: \\'number\\' }),\\n\\tdecimalBig: decimal({ scale: 30, mode: \\'bigint\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`decimal` decimal,\\n\\t`decimalNum` decimal(30),\\n\\t`decimalBig` decimal(30)\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { decimal, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdecimalPrecision: decimal({ precision: 1,}),\\n\\tdecimalPrecisionScale: decimal({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`decimalPrecision` decimal(1),\\n\\t`decimalPrecisionScale` decimal(1, 1)\\n);\\n```\\n</Section>\\n\\n### double\\n\\n<Section>\\n```typescript\\nimport { double, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdouble: double(\\'double\\')\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`double` double\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { double, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdoublePrecision: double({ precision: 1,}),\\n\\tdoublePrecisionScale: double({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`doublePrecision` double(1),\\n\\t`doublePrecisionScale` double(1, 1)\\n);\\n```\\n</Section>\\n\\n### float\\n\\n<Section>\\n```typescript\\nimport { float, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tfloat: float()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`float` float\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### serial\\n\\n<Section>\\n\\n`SERIAL` is an alias for `BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE`.\\n\\n```typescript\\nimport { serial, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tserial: serial()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`serial` serial AUTO_INCREMENT\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### binary\\n`BINARY(M)` stores a fixed-length byte string of exactly M bytes.  \\nOn insert, shorter values are right-padded with `0x00` bytes to reach M bytes; on retrieval, no padding is stripped.\\nAll bytesâ€”including trailing `0x00`â€”are significant in comparisons, `ORDER BY`, and `DISTINCT`\\n<Section>\\n```typescript\\nimport { binary, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tbinary: binary()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`binary` binary\\n);\\n```\\n</Section>\\n\\n### varbinary\\n`VARBINARY(M)` stores a variable-length byte string of exactly M bytes.  \\nOn insert, shorter values are right-padded with `0x00` bytes to reach M bytes; on retrieval, no padding is stripped.\\nAll bytesâ€”including trailing `0x00`â€”are significant in comparisons, `ORDER BY`, and `DISTINCT`\\n<Section>\\n```typescript\\nimport { varbinary, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tvarbinary: varbinary({ length: 2}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`varbinary` varbinary(2)\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### char\\n\\n<Section>\\n```typescript\\nimport { char, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tchar: char(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`char` char\\n);\\n```\\n</Section>\\n\\n### varchar\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n<Section>\\n```typescript\\nimport { varchar, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tvarchar: varchar({ length: 2 }),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\nvarchar: varchar({ length: 6, enum: [\"value1\", \"value2\"] })\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`varchar` varchar(2)\\n);\\n```\\n</Section>\\n\\n### text\\n\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n\\n<Section>\\n```typescript\\nimport { text, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttext: text(),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\ntext: text({ enum: [\"value1\", \"value2\"] });\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`text` text\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### boolean\\n\\n<Section>\\n```typescript\\nimport { boolean, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tboolean: boolean(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`boolean` boolean\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### date\\n\\n<Section>\\n```typescript\\nimport { boolean, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdate: date(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`date` date\\n);\\n```\\n</Section>\\n\\n### datetime\\n\\n<Section>\\n```typescript\\nimport { datetime, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdatetime: datetime(),\\n});\\n\\ndatetime(\\'...\\', { mode: \\'date\\' | \"string\"}),\\ndatetime(\\'...\\', { fsp : 0..6}),\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`datetime` datetime\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { datetime, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tdatetime: datetime({ mode: \\'date\\', fsp: 6 }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`datetime` datetime(6)\\n);\\n```\\n</Section>\\n\\n### time \\n\\n<Section>\\n```typescript\\nimport { time, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttime: time(),\\n\\ttimefsp: time({ fsp: 6 }),\\n});\\n\\t\\ntime(\\'...\\', { fsp: 0..6 }),\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`time` time,\\n\\t`timefsp` time(6)\\n);\\n```\\n</Section>\\n\\n### year\\n\\n<Section>\\n```typescript\\nimport { year, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tyear: year(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`year` year\\n);\\n```\\n</Section>\\n\\n### timestamp\\n\\n<Section>\\n```typescript\\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttimestamp: timestamp(),\\n});\\n\\ntimestamp(\\'...\\', { mode: \\'date\\' | \"string\"}),\\ntimestamp(\\'...\\', { fsp : 0..6}),\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`timestamp` timestamp\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttimestamp: timestamp({ mode: \\'date\\', fsp: 6 }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`timestamp` timestamp(6)\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\ttimestamp: timestamp().defaultNow(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`timestamp` timestamp DEFAULT (now())\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### json\\n\\n<Section>\\n```typescript\\nimport { json, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tjson: json(),\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`json` json\\n);\\n```\\n</Section>\\n\\nYou can specify `.$type<..>()` for json object inference, it **won\\'t** check runtime values. \\nIt provides compile time protection for default values, insert and select schemas.\\n```typescript\\n// will be inferred as { foo: string }\\njson: json().$type<{ foo: string }>();\\n\\n// will be inferred as string[]\\njson: json().$type<string[]>();\\n\\n// won\\'t compile\\njson: json().$type<string[]>().default({});\\n```\\n\\n## ---\\n\\n### enum\\n\\n<Section>\\n```typescript\\nimport { mysqlEnum, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tpopularity: mysqlEnum([\\'unknown\\', \\'known\\', \\'popular\\']),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`popularity` enum(\\'unknown\\',\\'known\\',\\'popular\\')\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### Customizing data type\\n\\nEvery column builder has a `.$type()` method, which allows you to customize the data type of the column. This is useful, for example, with unknown or branded types.\\n\\n```ts\\ntype UserId = number & { __brand: \\'user_id\\' };\\ntype Data = {\\n\\tfoo: string;\\n\\tbar: number;\\n};\\n\\nconst users = mysqlTable(\\'users\\', {\\n  id: int().$type<UserId>().primaryKey(),\\n  jsonField: json().$type<Data>(),\\n});\\n```\\n\\n### Not null\\n`NOT NULL` constraint dictates that the associated column may not contain a `NULL` value.\\n\\n<Section>\\n```typescript\\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tint: int().notNull(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int NOT NULL\\n);\\n```\\n</Section>\\n\\n### Default value\\n\\nThe `DEFAULT` clause specifies a default value to use for the column if no value\\nis explicitly provided by the user when doing an `INSERT`.\\nIf there is no explicit `DEFAULT` clause attached to a column definition,\\nthen the default value of the column is `NULL`.\\n\\nAn explicit `DEFAULT` clause may specify that the default value is `NULL`,\\na string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\\n\\n<Section>\\n```typescript\\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tint: int().default(3),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int DEFAULT 3\\n);\\n```\\n</Section>\\n\\nWhen using `$default()` or `$defaultFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all insert queries. \\nThese functions can assist you in utilizing various implementations such as `uuid`, `cuid`, `cuid2`, and many more.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { varchar, mysqlTable } from \"drizzle-orm/mysql-core\";\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tid: varchar({ length: 128 }).$defaultFn(() => createId()),\\n});\\n```\\n\\nWhen using `$onUpdate()` or `$onUpdateFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all update queries. \\n\\nAdds a dynamic update value to the column. The function will be called when the row is updated, \\nand the returned value will be used as the column value if none is provided.\\nIf no default (or $defaultFn) value is provided, the function will be called\\nwhen the row is inserted as well, and the returned value will be used as the column value.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { text, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n    alwaysNull: text().$type<string | null>().$onUpdate(() => null),\\n});\\n```\\n\\n### Primary key \\n\\n<Section>\\n```typescript\\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tint: int().primaryKey(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int PRIMARY KEY NOT NULL\\n);\\n```\\n</Section>\\n\\n### Auto increment\\n\\n<Section>\\n```typescript\\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tint: int().autoincrement(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int AUTO_INCREMENT\\n);\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('column-types/pg.mdx'), name='pg.mdx', displayName='pg.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: PostgreSQL column types\\n---\\n\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nWe have native support for all of them, yet if that\\'s not enough for you, feel free to create **[custom types](/docs/custom-types)**.\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nAll examples in this part of the documentation do not use database column name aliases, and column names are generated from TypeScript keys. \\n\\nYou can use database aliases in column names if you want, and you can also use the `casing` parameter to define a mapping strategy for Drizzle. \\n\\nYou can read more about it [here](/docs/sql-schema-declaration#shape-your-data-schema)\\n</Callout>\\n\\n### integer\\n`integer` `int` `int4`  \\nSigned 4-byte integer     \\n\\nIf you need `integer autoincrement` please refer to **[serial.](#serial)**\\n\\n<Section>\\n```typescript\\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tint: integer()\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"int\" integer\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tint1: integer().default(10),\\n\\tint2: integer().default(sql`\\'10\\'::int`)\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"int1\" integer DEFAULT 10,\\n\\t\"int2\" integer DEFAULT \\'10\\'::int\\n);\\n```\\n</Section>\\n\\n### smallint\\n`smallint` `int2`  \\nSmall-range signed 2-byte integer   \\n\\nIf you need `smallint autoincrement` please refer to **[smallserial.](#smallserial)**\\n<Section>\\n```typescript\\nimport { smallint, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tsmallint: smallint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"smallint\" smallint\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { smallint, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tsmallint1: smallint().default(10),\\n\\tsmallint2: smallint().default(sql`\\'10\\'::smallint`)\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"smallint1\" smallint DEFAULT 10,\\n\\t\"smallint2\" smallint DEFAULT \\'10\\'::smallint\\n);\\n```\\n</Section>\\n\\n### bigint\\n`bigint` `int8`  \\nSigned 8-byte integer  \\n\\nIf you need `bigint autoincrement` please refer to **[bigserial.](#bigserial)**\\n\\nIf you\\'re expecting values above 2^31 but below 2^53, you can utilise `mode: \\'number\\'` and deal with javascript number as opposed to bigint.\\n<Section>\\n```typescript\\nimport { bigint, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tbigint: bigint({ mode: \\'number\\' })\\n});\\n\\n// will be inferred as `number`\\nbigint: bigint({ mode: \\'number\\' })\\n\\n// will be inferred as `bigint`\\nbigint: bigint({ mode: \\'bigint\\' })\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"bigint\" bigint\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { bigint, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tbigint1: bigint().default(10),\\n\\tbigint2: bigint().default(sql`\\'10\\'::bigint`)\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"bigint1\" bigint DEFAULT 10,\\n\\t\"bigint2\" bigint DEFAULT \\'10\\'::bigint\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### serial\\n`serial` `serial4`  \\nAuto incrementing 4-bytes integer, notational convenience for creating unique identifier columns (similar to the `AUTO_INCREMENT` property supported by some other databases). \\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-SERIAL)**\\n<Section>\\n```typescript\\nimport { serial, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  serial: serial(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"serial\" serial NOT NULL\\n);\\n```\\n</Section>\\n\\n### smallserial\\n`smallserial` `serial2`  \\nAuto incrementing 2-bytes integer, notational convenience for creating unique identifier columns (similar to the `AUTO_INCREMENT` property supported by some other databases). \\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-SERIAL)**\\n<Section>\\n```typescript\\nimport { smallserial, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  smallserial: smallserial(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"smallserial\" smallserial NOT NULL\\n);\\n```\\n</Section>\\n\\n### bigserial\\n`bigserial` `serial8`  \\nAuto incrementing 8-bytes integer, notational convenience for creating unique identifier columns (similar to the `AUTO_INCREMENT` property supported by some other databases).\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-SERIAL)**\\n\\nIf you\\'re expecting values above 2^31 but below 2^53, you can utilise `mode: \\'number\\'` and deal with javascript number as opposed to bigint.\\n<Section>\\n```typescript\\nimport { bigserial, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  bigserial: bigserial({ mode: \\'number\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"bigserial\" bigserial NOT NULL\\n);\\n```\\n</Section>\\n\\n### ---\\n\\n### boolean\\nPostgreSQL provides the standard SQL type boolean.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-boolean.html)**\\n\\n<Section>\\n```typescript\\nimport { boolean, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n\\tboolean: boolean()\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"boolean\" boolean\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### text\\n`text`  \\nVariable-length(unlimited) character string.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-character.html)**\\n  \\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n<Section>\\n```typescript\\nimport { text, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  text: text()\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\ntext: text({ enum: [\"value1\", \"value2\"] })\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"text\" text\\n);\\n```\\n</Section>\\n\\n### varchar\\n`character varying(n)` `varchar(n)`  \\nVariable-length character string, can store strings up to **`n`** characters (not bytes). \\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-character.html)**\\n\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n\\nThe `length` parameter is optional according to PostgreSQL docs.\\n<Section>\\n```typescript\\nimport { varchar, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  varchar1: varchar(),\\n  varchar2: varchar({ length: 256 }),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\nvarchar: varchar({ enum: [\"value1\", \"value2\"] }),\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"varchar1\" varchar,\\n\\t\"varchar2\" varchar(256)\\n);\\n```\\n</Section>\\n\\n### char\\n`character(n)` `char(n)`  \\nFixed-length, blank padded character string, can store strings up to **`n`** characters(not bytes).\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-character.html)**\\n\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n\\nThe `length` parameter is optional according to PostgreSQL docs.\\n<Section>\\n```typescript\\nimport { char, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  char1: char(),\\n  char2: char({ length: 256 }),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\nchar: char({ enum: [\"value1\", \"value2\"] }),\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"char1\" char,\\n\\t\"char2\" char(256)\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### numeric\\n`numeric` `decimal`  \\nExact numeric of selectable precision. Can store numbers with a very large number of digits, up to 131072 digits before the decimal point and up to 16383 digits after the decimal point.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-NUMERIC-DECIMAL)**\\n\\n<Section>\\n```typescript\\nimport { numeric, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const table = pgTable(\\'table\\', {\\n  numeric1: numeric(),\\n  numeric2: numeric({ precision: 100 }),\\n  numeric3: numeric({ precision: 100, scale: 20 }),\\n  numericNum: numeric({ mode: \\'number\\' }),\\n  numericBig: numeric({ mode: \\'bigint\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"numeric1\" numeric,\\n\\t\"numeric2\" numeric(100),\\n\\t\"numeric3\" numeric(100, 20),\\n\\t\"numericNum\" numeric,\\n\\t\"numericBig\" numeric\\n);\\n```\\n</Section>\\n\\n### decimal\\nAn alias of **[numeric.](#numeric)**\\n\\n### real\\n`real` `float4`  \\nSingle precision floating-point number (4 bytes)\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html)**  \\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { real, pgTable } from \"drizzle-orm/pg-core\";  \\n\\nconst table = pgTable(\\'table\\', {\\n\\treal1: real(),\\n\\treal2: real().default(10.10),\\n\\treal3: real().default(sql`\\'10.10\\'::real`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"real1\" real,\\n\\t\"real2\" real default 10.10,\\n\\t\"real3\" real default \\'10.10\\'::real\\n);\\n```\\n</Section>\\n\\n### double precision\\n`double precision` `float8`  \\nDouble precision floating-point number (8 bytes)\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-numeric.html)**  \\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { doublePrecision, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tdouble1: doublePrecision(),\\n\\tdouble2: doublePrecision().default(10.10),\\n\\tdouble3: doublePrecision().default(sql`\\'10.10\\'::double precision`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"double1\" double precision,\\n\\t\"double2\" double precision default 10.10,\\n\\t\"double3\" double precision default \\'10.10\\'::double precision\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n\\n### json\\n`json`  \\nTextual JSON data, as specified in **[RFC 7159.](https://tools.ietf.org/html/rfc7159)**\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-json.html)**\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { json, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tjson1: json(),\\n\\tjson2: json().default({ foo: \"bar\" }),\\n\\tjson3: json().default(sql`\\'{foo: \"bar\"}\\'::json`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"json1\" json,\\n\\t\"json2\" json default \\'{\"foo\": \"bar\"}\\'::json,\\n\\t\"json3\" json default \\'{\"foo\": \"bar\"}\\'::json\\n);\\n```\\n</Section>\\n  \\nYou can specify `.$type<..>()` for json object inference, it **won\\'t** check runtime values. \\nIt provides compile time protection for default values, insert and select schemas.\\n```typescript\\n// will be inferred as { foo: string }\\njson: json().$type<{ foo: string }>();\\n\\n// will be inferred as string[]\\njson: json().$type<string[]>();\\n\\n// won\\'t compile\\njson: json().$type<string[]>().default({});\\n```\\n\\n### jsonb\\n`jsonb`  \\nBinary JSON data, decomposed.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-json.html)**\\n<Section>\\n```typescript\\nimport { jsonb, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tjsonb1: jsonb(),\\n\\tjsonb2: jsonb().default({ foo: \"bar\" }),\\n\\tjsonb3: jsonb().default(sql`\\'{foo: \"bar\"}\\'::jsonb`),\\n});\\n```\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"jsonb1\" jsonb,\\n\\t\"jsonb2\" jsonb default \\'{\"foo\": \"bar\"}\\'::jsonb,\\n\\t\"jsonb3\" jsonb default \\'{\"foo\": \"bar\"}\\'::jsonb\\n);\\n```\\n</Section>\\n\\nYou can specify `.$type<..>()` for json object inference, it **won\\'t** check runtime values. \\nIt provides compile time protection for default values, insert and select schemas.\\n\\n```typescript\\n// will be inferred as { foo: string }\\njsonb: jsonb().$type<{ foo: string }>();\\n\\n// will be inferred as string[]\\njsonb: jsonb().$type<string[]>();\\n\\n// won\\'t compile\\njsonb: jsonb().$type<string[]>().default({});\\n```\\n\\n## ---\\n\\n### time\\n`time` `timetz` `time with timezone` `time without timezone`  \\nTime of day with or without time zone.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-datetime.html)**\\n\\n<Section>\\n```typescript\\nimport { time, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n  time1: time(),\\n  time2: time({ withTimezone: true }),\\n  time3: time({ precision: 6 }),\\n  time4: time({ precision: 6, withTimezone: true })\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"time1\" time,\\n\\t\"time2\" time with timezone,\\n\\t\"time3\" time(6),\\n\\t\"time4\" time(6) with timezone\\n);\\n```\\n</Section>\\n\\n### timestamp\\n`timestamp` `timestamptz` `timestamp with time zone` `timestamp without time zone`  \\nDate and time with or without time zone.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-datetime.html)**\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { timestamp, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n  timestamp1: timestamp(),\\n\\ttimestamp2: timestamp({ precision: 6, withTimezone: true }),\\n\\ttimestamp3: timestamp().defaultNow(),\\n\\ttimestamp4: timestamp().default(sql`now()`),\\n});\\n```\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"timestamp1\" timestamp,\\n\\t\"timestamp2\" timestamp (6) with time zone,\\n\\t\"timestamp3\" timestamp default now(),\\n\\t\"timestamp4\" timestamp default now()\\n);\\n```\\n</Section>\\n\\nYou can specify either `date` or `string` infer modes:\\n```typescript\\n// will infer as date\\ntimestamp: timestamp({ mode: \"date\" }),\\n\\n// will infer as string\\ntimestamp: timestamp({ mode: \"string\" }),\\n```\\n\\n> The `string` mode does not perform any mappings for you. This mode was added to Drizzle ORM to provide developers\\nwith the possibility to handle dates and date mappings themselves, depending on their needs.\\nDrizzle will pass raw dates as strings `to` and `from` the database, so the behavior should be as predictable as possible \\nand aligned 100% with the database behavior\\n\\n> The `date` mode is the regular way to work with dates. Drizzle will take care of all mappings between the database and the JS Date object\\n\\n<Callout type=\\'info\\' emoji=\\'â„¹ï¸\\'>\\n How mapping works for `timestamp` and `timestamp with timezone`:\\n\\n As PostgreSQL docs stated:\\n > In a literal that has been determined to be timestamp without time zone, PostgreSQL will silently ignore any time zone indication. \\n > That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.\\n >\\n > For timestamp with time zone, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). \\n An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. \\n If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system\\'s TimeZone parameter, \\n and is converted to UTC using the offset for the timezone zone.\\n\\n So for `timestamp with timezone` you will get back string converted to a timezone set in your Postgres instance. \\n You can check timezone using this sql query: \\n \\n ```sql \\n show timezone;\\n ```\\n\\n\\n</Callout>\\n\\n### date\\n`date`  \\nCalendar date (year, month, day)\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-datetime.html)**\\n<Section>\\n```typescript\\nimport { date, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tdate: date(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"date\" date\\n);\\n```\\n</Section>\\nYou can specify either `date` or `string` infer modes:\\n```typescript\\n// will infer as date\\ndate: date({ mode: \"date\" }),\\n\\n// will infer as string\\ndate: date({ mode: \"string\" }),\\n```\\n### interval\\n`interval`  \\nTime span\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-datetime.html)** \\n\\n<Section>\\n```typescript\\nimport { interval, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tinterval1: interval(),\\n  interval2: interval({ fields: \\'day\\' }),\\n  interval3: interval({ fields: \\'month\\' , precision: 6 }),\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"interval1\" interval,\\n\\t\"interval2\" interval day,\\n\\t\"interval3\" interval(6) month\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### point\\n`point`  \\nGeometric point type\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-geometric.html#DATATYPE-GEOMETRIC-POINTS)** \\n\\nType `point` has 2 modes for mappings from the database: `tuple` and `xy`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database Point(1,2) will be typed as [1,2] with drizzle.\\n\\n- `xy` will be accepted for insert and mapped on select to an object with x, y coordinates. So, the database Point(1,2) will be typed as `{ x: 1, y: 2 }` with drizzle\\n\\n<Section>\\n```typescript\\nconst items = pgTable(\\'items\\', {\\n point: point(),\\n pointObj: point({ mode: \\'xy\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"items\" (\\n\\t\"point\" point,\\n\\t\"pointObj\" point\\n);\\n```\\n</Section>\\n\\n### line\\n`line`  \\nGeometric line type\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-geometric.html#DATATYPE-LINE)** \\n\\nType `line` has 2 modes for mappings from the database: `tuple` and `abc`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database Line{1,2,3} will be typed as [1,2,3] with drizzle.\\n\\n- `abc` will be accepted for insert and mapped on select to an object with a, b, and c constants from the equation `Ax + By + C = 0`. So, the database Line{1,2,3} will be typed as `{ a: 1, b: 2, c: 3 }` with drizzle.\\n\\n<Section>\\n```typescript\\nconst items = pgTable(\\'items\\', {\\n line: line(),\\n lineObj: line({ mode: \\'abc\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"items\" (\\n\\t\"line\" line,\\n\\t\"lineObj\" line\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### enum \\n`enum` `enumerated types`  \\nEnumerated (enum) types are data types that comprise a static, ordered set of values. \\nThey are equivalent to the enum types supported in a number of programming languages. \\nAn example of an enum type might be the days of the week, or a set of status values for a piece of data.\\n\\nFor more info please refer to the official PostgreSQL **[docs.](https://www.postgresql.org/docs/current/datatype-enum.html)**\\n<Section>\\n```typescript\\nimport { pgEnum, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const moodEnum = pgEnum(\\'mood\\', [\\'sad\\', \\'ok\\', \\'happy\\']);\\n\\nexport const table = pgTable(\\'table\\', {\\n  mood: moodEnum(),\\n});\\n```\\n\\n```sql\\nCREATE TYPE mood AS ENUM (\\'sad\\', \\'ok\\', \\'happy\\');\\n\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"mood\" mood\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### Customizing data type\\nEvery column builder has a `.$type()` method, which allows you to customize the data type of the column. \\n\\nThis is useful, for example, with unknown or branded types:\\n```ts\\ntype UserId = number & { __brand: \\'user_id\\' };\\ntype Data = {\\n\\tfoo: string;\\n\\tbar: number;\\n};\\n\\nconst users = pgTable(\\'users\\', {\\n  id: serial().$type<UserId>().primaryKey(),\\n  jsonField: json().$type<Data>(),\\n});\\n```\\n\\n### Identity Columns\\n\\n<Callout type=\"info\">\\nTo use this feature you would need to have `drizzle-orm@0.32.0` or higher and `drizzle-kit@0.23.0` or higher\\n</Callout>\\n\\nPostgreSQL supports identity columns as a way to automatically generate unique integer values for a column. These values are generated using sequences and can be defined using the GENERATED AS IDENTITY clause.\\n\\n**Types of Identity Columns**\\n- `GENERATED ALWAYS AS IDENTITY`: The database always generates a value for the column. Manual insertion or updates to this column are not allowed unless the OVERRIDING SYSTEM VALUE clause is used.\\n- `GENERATED BY DEFAULT AS IDENTITY`: The database generates a value by default, but manual values can also be inserted or updated. If a manual value is provided, it will be used instead of the system-generated value.\\n\\n**Key Features**\\n- Automatic Value Generation: Utilizes sequences to generate unique values for each new row.\\n- Customizable Sequence Options: You can define starting values, increments, and other sequence options.\\n- Support for Multiple Identity Columns: PostgreSQL allows more than one identity column per table.\\n\\n**Limitations**\\n- Manual Insertion Restrictions: For columns defined with GENERATED ALWAYS AS IDENTITY, manual insertion or updates require the OVERRIDING SYSTEM VALUE clause.\\n- Sequence Constraints: Identity columns depend on sequences, which must be managed correctly to avoid conflicts or gaps.\\n\\n**Usage example**\\n```ts\\nimport { pgTable, integer, text } from \\'drizzle-orm/pg-core\\' \\n\\nexport const ingredients = pgTable(\"ingredients\", {\\n  id: integer().primaryKey().generatedAlwaysAsIdentity({ startWith: 1000 }),\\n  name: text().notNull(),\\n  description: text(),\\n});\\n```\\n\\nYou can specify all properties available for sequences in the `.generatedAlwaysAsIdentity()` function. Additionally, you can specify custom names for these sequences\\n\\nPostgreSQL docs [reference](https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-PARMS-GENERATED-IDENTITY).\\n\\n### Default value\\nThe `DEFAULT` clause specifies a default value to use for the column if no value\\nis explicitly provided by the user when doing an `INSERT`.\\nIf there is no explicit `DEFAULT` clause attached to a column definition,\\nthen the default value of the column is `NULL`.\\n\\nAn explicit `DEFAULT` clause may specify that the default value is `NULL`,\\na string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { integer, pgTable, uuid } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tinteger1: integer().default(42),\\n\\tinteger2: integer().default(sql`\\'42\\'::integer`),\\n\\tuuid1: uuid().defaultRandom(),\\n\\tuuid2: uuid().default(sql`gen_random_uuid()`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"integer1\" integer DEFAULT 42,\\n\\t\"integer2\" integer DEFAULT \\'42\\'::integer,\\n\\t\"uuid1\" uuid DEFAULT gen_random_uuid(),\\n\\t\"uuid2\" uuid DEFAULT gen_random_uuid()\\n);\\n```\\n</Section>\\n\\nWhen using `$default()` or `$defaultFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all insert queries. \\n\\nThese functions can assist you in utilizing various implementations such as `uuid`, `cuid`, `cuid2`, and many more.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { text, pgTable } from \"drizzle-orm/pg-core\";\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst table = pgTable(\\'table\\', {\\n\\tid: text().$defaultFn(() => createId()),\\n});\\n```\\n\\nWhen using `$onUpdate()` or `$onUpdateFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all update queries. \\n\\nAdds a dynamic update value to the column. The function will be called when the row is updated, \\nand the returned value will be used as the column value if none is provided.\\nIf no default (or $defaultFn) value is provided, the function will be called\\nwhen the row is inserted as well, and the returned value will be used as the column value.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { integer, timestamp, text, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tupdateCounter: integer().default(sql`1`).$onUpdateFn((): SQL => sql`${table.update_counter} + 1`),\\n\\tupdatedAt: timestamp({ mode: \\'date\\', precision: 3 }).$onUpdate(() => new Date()),\\n    \\talwaysNull: text().$type<string | null>().$onUpdate(() => null),\\n});\\n```\\n\\n\\n### Not null\\n`NOT NULL` constraint dictates that the associated column may not contain a `NULL` value.\\n\\n<Section>\\n```typescript\\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tinteger: integer().notNull(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"integer\" integer NOT NULL\\n);\\n```\\n</Section>\\n\\n\\n### Primary key\\nA primary key constraint indicates that a column, or group of columns, can be used as a unique identifier for rows in the table. \\nThis requires that the values be both unique and not null.\\n<Section>\\n```typescript\\nimport { serial, pgTable } from \"drizzle-orm/pg-core\";\\n\\nconst table = pgTable(\\'table\\', {\\n\\tid: serial().primaryKey(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL\\n);\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('column-types/singlestore.mdx'), name='singlestore.mdx', displayName='singlestore.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SingleStore column types\\n---\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nWe have native support for all of them, yet if that\\'s not enough for you, feel free to create **[custom types](/docs/custom-types)**.\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nAll examples in this part of the documentation do not use database column name aliases, and column names are generated from TypeScript keys. \\n\\nYou can use database aliases in column names if you want, and you can also use the `casing` parameter to define a mapping strategy for Drizzle. \\n\\nYou can read more about it [here](/docs/sql-schema-declaration#shape-your-data-schema)\\n</Callout>\\n\\n### integer\\n\\nA signed integer, stored in `0`, `1`, `2`, `3`, `4`, `6`, or `8` bytes depending on the magnitude of the value.\\n\\n<Section>\\n```typescript\\nimport { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tint: int()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int\\n);\\n```\\n</Section>\\n\\n### tinyint\\n\\n<Section>\\n```typescript\\nimport { tinyint, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\ttinyint: tinyint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`tinyint` tinyint\\n);\\n```\\n</Section>\\n\\n### smallint\\n\\n<Section>\\n```typescript\\nimport { smallint, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tsmallint: smallint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`smallint` smallint\\n);\\n```\\n</Section>\\n\\n### mediumint\\n\\n<Section>\\n```typescript\\nimport { mediumint, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tmediumint: mediumint()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`mediumint` mediumint\\n);\\n```\\n</Section>\\n\\n### bigint\\n\\n<Section>\\n```typescript\\nimport { bigint, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tbigint: bigint({ mode: \\'number\\' })\\n\\tbigintUnsigned: bigint({ mode: \\'number\\', unsigned: true })\\n});\\n\\nbigint(\\'...\\', { mode: \\'number\\' | \\'bigint\\' });\\n\\n// You can also specify unsigned option for bigint\\nbigint(\\'...\\', { mode: \\'number\\' | \\'bigint\\', unsigned: true })\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`bigint` bigint,\\n\\t`bigintUnsigned` bigint unsigned\\n);\\n```\\n</Section>\\n\\nWe\\'ve omitted config of `M` in `bigint(M)`, since it indicates the display width of the numeric type \\n\\n## ---\\n\\n### real\\n\\n<Section>\\n```typescript\\nimport { real, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\treal: real()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`real` real\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { real, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\trealPrecision: real({ precision: 1,}),\\n\\trealPrecisionScale: real({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`realPrecision` real(1),\\n\\t`realPrecisionScale` real(1, 1)\\n);\\n```\\n</Section>\\n\\n### decimal\\n\\n<Section>\\n```typescript\\nimport { decimal, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdecimal: decimal(),\\n\\tdecimalNum: decimal({ scale: 30, mode: \\'number\\' }),\\n\\tdecimalBig: decimal({ scale: 30, mode: \\'bigint\\' }),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`decimal` decimal,\\n\\t`decimalNum` decimal(30),\\n\\t`decimalBig` decimal(30)\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { decimal, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdecimalPrecision: decimal({ precision: 1,}),\\n\\tdecimalPrecisionScale: decimal({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`decimalPrecision` decimal(1),\\n\\t`decimalPrecisionScale` decimal(1, 1)\\n);\\n```\\n</Section>\\n\\n### double\\n\\n<Section>\\n```typescript\\nimport { double, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdouble: double(\\'double\\')\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`double` double\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { double, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdoublePrecision: double({ precision: 1,}),\\n\\tdoublePrecisionScale: double({ precision: 1, scale: 1,}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`doublePrecision` double(1),\\n\\t`doublePrecisionScale` double(1, 1)\\n);\\n```\\n</Section>\\n\\n### float\\n\\n<Section>\\n```typescript\\nimport { float, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tfloat: float()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`float` float\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### serial\\n\\n<Section>\\n\\n`SERIAL` is an alias for `BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE`.\\n\\n```typescript\\nimport { serial, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tserial: serial()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`serial` serial AUTO_INCREMENT\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### binary\\n\\n<Section>\\n```typescript\\nimport { binary, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tbinary: binary()\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`binary` binary\\n);\\n```\\n</Section>\\n\\n### varbinary\\n\\n<Section>\\n```typescript\\nimport { varbinary, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tvarbinary: varbinary({ length: 2}),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`varbinary` varbinary(2)\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### char\\n\\n<Section>\\n```typescript\\nimport { char, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tchar: char(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`char` char\\n);\\n```\\n</Section>\\n\\n### varchar\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n<Section>\\n```typescript\\nimport { varchar, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tvarchar: varchar({ length: 2 }),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\nvarchar: varchar({ length: 6, enum: [\"value1\", \"value2\"] })\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`varchar` varchar(2)\\n);\\n```\\n</Section>\\n\\n### text\\n\\nYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n\\n<Section>\\n```typescript\\nimport { text, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\ttext: text(),\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\ntext: text({ enum: [\"value1\", \"value2\"] });\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`text` text\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### boolean\\n\\n<Section>\\n```typescript\\nimport { boolean, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tboolean: boolean(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`boolean` boolean\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### date\\n\\n<Section>\\n```typescript\\nimport { boolean, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdate: date(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`date` date\\n);\\n```\\n</Section>\\n\\n### datetime\\n\\n<Section>\\n```typescript\\nimport { datetime, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tdatetime: datetime(),\\n});\\n\\ndatetime(\\'...\\', { mode: \\'date\\' | \"string\"}),\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`datetime` datetime\\n);\\n```\\n</Section>\\n\\n### time \\n\\n<Section>\\n```typescript\\nimport { time, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\ttime: time(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`time` time\\n);\\n```\\n</Section>\\n\\n### year\\n\\n<Section>\\n```typescript\\nimport { year, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tyear: year(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`year` year\\n);\\n```\\n</Section>\\n\\n### timestamp\\n\\n<Section>\\n```typescript\\nimport { timestamp, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\ttimestamp: timestamp(),\\n});\\n\\ntimestamp(\\'...\\', { mode: \\'date\\' | \"string\"}),\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`timestamp` timestamp\\n);\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { timestamp, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\ttimestamp: timestamp().defaultNow(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`timestamp` timestamp DEFAULT (now())\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### json\\n\\n<Section>\\n```typescript\\nimport { json, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tjson: json(),\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`json` json\\n);\\n```\\n</Section>\\n\\nYou can specify `.$type<..>()` for json object inference, it **won\\'t** check runtime values. \\nIt provides compile time protection for default values, insert and select schemas.\\n```typescript\\n// will be inferred as { foo: string }\\njson: json().$type<{ foo: string }>();\\n\\n// will be inferred as string[]\\njson: json().$type<string[]>();\\n\\n// won\\'t compile\\njson: json().$type<string[]>().default({});\\n```\\n\\n## ---\\n\\n### enum\\n\\n<Section>\\n```typescript\\nimport { singlestoreEnum, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tpopularity: singlestoreEnum([\\'unknown\\', \\'known\\', \\'popular\\']),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`popularity` enum(\\'unknown\\',\\'known\\',\\'popular\\')\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### Customizing data type\\n\\nEvery column builder has a `.$type()` method, which allows you to customize the data type of the column. This is useful, for example, with unknown or branded types.\\n\\n```ts\\ntype UserId = number & { __brand: \\'user_id\\' };\\ntype Data = {\\n\\tfoo: string;\\n\\tbar: number;\\n};\\n\\nconst users = singlestoreTable(\\'users\\', {\\n  id: int().$type<UserId>().primaryKey(),\\n  jsonField: json().$type<Data>(),\\n});\\n```\\n\\n### Not null\\n`NOT NULL` constraint dictates that the associated column may not contain a `NULL` value.\\n\\n<Section>\\n```typescript\\nimport { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tint: int().notNull(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int NOT NULL\\n);\\n```\\n</Section>\\n\\n### Default value\\n\\nThe `DEFAULT` clause specifies a default value to use for the column if no value\\nis explicitly provided by the user when doing an `INSERT`.\\nIf there is no explicit `DEFAULT` clause attached to a column definition,\\nthen the default value of the column is `NULL`.\\n\\nAn explicit `DEFAULT` clause may specify that the default value is `NULL`,\\na string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\\n\\n<Section>\\n```typescript\\nimport { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tint: int().default(3),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int DEFAULT 3\\n);\\n```\\n</Section>\\n\\nWhen using `$default()` or `$defaultFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all insert queries. \\nThese functions can assist you in utilizing various implementations such as `uuid`, `cuid`, `cuid2`, and many more.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { varchar, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tid: varchar({ length: 128 }).$defaultFn(() => createId()),\\n});\\n```\\n\\nWhen using `$onUpdate()` or `$onUpdateFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all update queries. \\n\\nAdds a dynamic update value to the column. The function will be called when the row is updated, \\nand the returned value will be used as the column value if none is provided.\\nIf no default (or $defaultFn) value is provided, the function will be called\\nwhen the row is inserted as well, and the returned value will be used as the column value.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { text, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n    alwaysNull: text().$type<string | null>().$onUpdate(() => null),\\n});\\n```\\n\\n### Primary key \\n\\n<Section>\\n```typescript\\nimport { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tint: int().primaryKey(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int PRIMARY KEY NOT NULL\\n);\\n```\\n</Section>\\n\\n### Auto increment\\n\\n<Section>\\n```typescript\\nimport { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\nconst table = singlestoreTable(\\'table\\', {\\n\\tint: int().autoincrement(),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`int` int AUTO_INCREMENT\\n);\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('column-types/sqlite.mdx'), name='sqlite.mdx', displayName='sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQLite column types\\n---\\n\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nBased on the official **[SQLite docs](https://www.sqlite.org/datatype3.html)**,\\neach value stored in an SQLite database (or manipulated by the database engine)\\nhas one of the following storage classes `NULL`, `INTEGER`, `REAL`, `TEXT` and `BLOB`.\\n\\nWe have native support for all of them, yet if that\\'s not enough for you, feel free to create **[custom types](/docs/custom-types)**.\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nAll examples in this part of the documentation do not use database column name aliases, and column names are generated from TypeScript keys. \\n\\nYou can use database aliases in column names if you want, and you can also use the `casing` parameter to define a mapping strategy for Drizzle. \\n\\nYou can read more about it [here](/docs/sql-schema-declaration#shape-your-data-schema)\\n</Callout>\\n\\n### Integer\\n\\nA signed integer, stored in `0`, `1`, `2`, `3`, `4`, `6`, or `8` bytes depending on the magnitude of the value.\\n\\n<Section>\\n```typescript\\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tid: integer()\\n});\\n\\n// you can customize integer mode to be number, boolean, timestamp, timestamp_ms\\ninteger({ mode: \\'number\\' })\\ninteger({ mode: \\'boolean\\' })\\ninteger({ mode: \\'timestamp_ms\\' })\\ninteger({ mode: \\'timestamp\\' }) // Date\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`id` integer\\n);\\n```\\n\\n</Section>\\n\\n<Section>\\n```typescript\\n// to make integer primary key auto increment\\ninteger({ mode: \\'number\\' }).primaryKey({ autoIncrement: true })\\n```\\n```sql\\nCREATE TABLE `table` (\\n\\t`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL\\n);\\n```\\n</Section>\\n\\n### Real\\n\\nA floating point value, stored as an `8-byte IEEE` floating point number.\\n\\n<Section>\\n```typescript\\nimport { real, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\treal: real()\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`real` real\\n);\\n```\\n\\n</Section>\\n\\n### Text\\n\\nA text string, stored using the database encoding (`UTF-8`, `UTF-16BE` or `UTF-16LE`).  \\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tYou can define `{ enum: [\"value1\", \"value2\"] }` config to infer `insert` and `select` types, it **won\\'t** check runtime values.\\n</Callout>\\n\\n<Section>\\n```typescript\\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\ttext: text()\\n});\\n\\n// will be inferred as text: \"value1\" | \"value2\" | null\\ntext({ enum: [\"value1\", \"value2\"] })\\ntext({ mode: \\'json\\' })\\ntext({ mode: \\'json\\' }).$type<{ foo: string }>()\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`text` text\\n);\\n```\\n\\n</Section>\\n\\n### Blob\\n\\nA blob of data, stored exactly as it was input.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tIt\\'s recommended to use `text(\\'\\', { mode: \\'json\\' })` instead of `blob(\\'\\', { mode: \\'json\\' })`, \\n\\tbecause it supports JSON functions:\\n\\n\\tAll JSON functions currently throw an error if any of their arguments are BLOBs because BLOBs \\n\\tare reserved for a future enhancement in which BLOBs will store the binary encoding for JSON.\\n\\n\\tSee **https://www.sqlite.org/json1.html**.\\n</Callout>\\n\\n<Section>\\n```typescript\\nimport { blob, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tblob: blob()\\n});\\n\\nblob()\\nblob({ mode: \\'buffer\\' })\\nblob({ mode: \\'bigint\\' })\\n\\nblob({ mode: \\'json\\' })\\nblob({ mode: \\'json\\' }).$type<{ foo: string }>()\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`blob` blob\\n);\\n```\\n\\nYou can specify `.$type<..>()` for blob inference, it **won\\'t** check runtime values. \\nIt provides compile time protection for default values, insert and select schemas.  \\n\\n```typescript\\n// will be inferred as { foo: string }\\njson: blob({ mode: \\'json\\' }).$type<{ foo: string }>();\\n\\n// will be inferred as string[]\\njson: blob({ mode: \\'json\\' }).$type<string[]>();\\n\\n// won\\'t compile\\njson: blob({ mode: \\'json\\' }).$type<string[]>().default({});\\n```\\n\\n</Section>\\n\\n### Boolean\\n\\nSQLite does not have native `boolean` data type, yet you can specify `integer` column to be in a `boolean` mode. \\nThis allows you to operate boolean values in your code and Drizzle stores them as 0 and 1 integer\\nvalues in the database.\\n\\n\\n<Section>\\n```typescript\\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tid: integer({ mode: \\'boolean\\' })\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`id` integer\\n);\\n```\\n\\n</Section>\\n\\n### Bigint\\n\\nSince there is no `bigint` data type in SQLite, Drizzle offers a special `bigint` mode for `blob` columns. \\nThis mode allows you to work with BigInt instances in your code, and Drizzle stores them as blob values in the database.\\n\\n\\n<Section>\\n```typescript\\nimport { blob, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tid: blob({ mode: \\'bigint\\' })\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`id` blob\\n);\\n```\\n</Section>\\n\\n### Numeric\\n\\n<Section>\\n```typescript\\nimport { blob, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tnumeric: numeric(),\\n\\tnumericNum: numeric({ mode: \\'number\\' }),\\n\\tnumericBig: numeric({ mode: \\'bigint\\' }),\\n});\\n\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`numeric` numeric,\\n\\t`numericNum` numeric,\\n\\t`numericBig` numeric\\n);\\n```\\n</Section>\\n\\n## ---\\n\\n### Customizing data type\\nEvery column builder has a `.$type()` method, which allows you to customize the data type of the column. This is useful, for example, with unknown or branded types.\\n```ts\\ntype UserId = number & { __brand: \\'user_id\\' };\\ntype Data = {\\n\\tfoo: string;\\n\\tbar: number;\\n};\\n\\nconst users = sqliteTable(\\'users\\', {\\n  id: integer().$type<UserId>().primaryKey(),\\n  jsonField: blob().$type<Data>(),\\n});\\n```\\n\\n### Not null\\n`NOT NULL` constraint dictates that the associated column may not contain a `NULL` value.\\n<Section>\\n```typescript\\nconst table = sqliteTable(\\'table\\', { \\n\\tnumInt: integer().notNull() \\n});\\n```\\n\\n```sql\\nCREATE TABLE table (\\n\\t`numInt` integer NOT NULL\\n);\\n```\\n</Section>\\n\\n### Default value\\n\\nThe `DEFAULT` clause specifies a default value to use for the column if no value\\nis explicitly provided by the user when doing an `INSERT`.\\nIf there is no explicit `DEFAULT` clause attached to a column definition,\\nthen the default value of the column is `NULL`.\\n\\nAn explicit `DEFAULT` clause may specify that the default value is `NULL`,\\na string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tint1: integer().default(42),\\n\\tint2: integer().default(sql`(abs(42))`)\\n});\\n\\n```\\n```sql\\nCREATE TABLE `table` (\\n\\t`int1` integer DEFAULT 42,\\n\\t`int2` integer DEFAULT (abs(42))\\n);\\n```\\n</Section>\\n\\nA default value may also be one of the special case-independent keywords `CURRENT_TIME`, `CURRENT_DATE` or `CURRENT_TIMESTAMP`.\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\"table\", {\\n  time: text().default(sql`(CURRENT_TIME)`),\\n  date: text().default(sql`(CURRENT_DATE)`),\\n  timestamp: text().default(sql`(CURRENT_TIMESTAMP)`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `table` (\\n\\t`time` text DEFAULT (CURRENT_TIME),\\n\\t`date` text DEFAULT (CURRENT_DATE),\\n\\t`timestamp` text DEFAULT (CURRENT_TIMESTAMP)\\n);\\n```\\n</Section>\\n\\nWhen using `$default()` or `$defaultFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all insert queries. \\nThese functions can assist you in utilizing various implementations such as `uuid`, `cuid`, `cuid2`, and many more.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst table = sqliteTable(\\'table\\', {\\n\\tid: text().$defaultFn(() => createId()),\\n});\\n```\\n\\nWhen using `$onUpdate()` or `$onUpdateFn()`, which are simply different aliases for the same function, \\nyou can generate defaults at runtime and use these values in all update queries. \\n\\nAdds a dynamic update value to the column. The function will be called when the row is updated, \\nand the returned value will be used as the column value if none is provided.\\nIf no default (or $defaultFn) value is provided, the function will be called\\nwhen the row is inserted as well, and the returned value will be used as the column value.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\tNote: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n</Callout>\\n\\n```ts\\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\n    alwaysNull: text().$type<string | null>().$onUpdate(() => null),\\n});\\n```\\n', children=[])]),\n",
       " DocItem(origPath=Path('connect-aws-data-api-mysql.mdx'), name='connect-aws-data-api-mysql.mdx', displayName='connect-aws-data-api-mysql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Callout from '@mdx/Callout.astro';\\n\\n\\n# Drizzle \\\\<\\\\> AWS Data API MySQL\\n\\n<Callout>\\nCurrently AWS Data API for MySQL is not implemented in Drizzle ORM\\n</Callout>\", children=[]),\n",
       " DocItem(origPath=Path('connect-aws-data-api-pg.mdx'), name='connect-aws-data-api-pg.mdx', displayName='connect-aws-data-api-pg.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> AWS Data API Postgres\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- AWS Data API - [website](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html)\\n- AWS SDK - [website](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/Package/-aws-sdk-client-rds-data/)\\n</Prerequisites>\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @aws-sdk/client-rds-data\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/aws-data-api/pg\\';\\n\\n// These three properties are required. You can also specify\\n// any property from the RDSDataClient type inside the connection object.\\nconst db = drizzle({ connection: {\\n  database: process.env[\\'DATABASE\\']!,\\n  secretArn: process.env[\\'SECRET_ARN\\']!,\\n  resourceArn: process.env[\\'RESOURCE_ARN\\']!,\\n}});\\n\\nawait db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/aws-data-api/pg\\';\\nimport { RDSDataClient } from \\'@aws-sdk/client-rds-data\\';\\n\\nconst rdsClient = new RDSDataClient({ region: \\'us-east-1\\' });\\n\\nconst db = drizzle(rdsClient, {\\n  database: process.env[\\'DATABASE\\']!,\\n  secretArn: process.env[\\'SECRET_ARN\\']!,\\n  resourceArn: process.env[\\'RESOURCE_ARN\\']!,\\n});\\n\\nawait db.select().from(...);\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-bun-sql.mdx'), name='connect-bun-sql.mdx', displayName='connect-bun-sql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> Bun SQL\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Bun - [website](https://bun.sh/docs)\\n- Bun SQL - native bindings for working with PostgreSQL databases - [read here](https://bun.sh/docs/api/sql)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://bun.sh/)**, Bun is a fast all-in-one JavaScript runtime. \\n\\nDrizzle ORM natively supports **[`bun sql`](https://bun.sh/docs/api/sql)** module and it\\'s crazy fast ðŸš€  \\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/bun-sql\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/bun-sql\\';\\nimport { SQL } from \\'bun\\';\\n\\nconst client = new SQL(process.env.DATABASE_URL!);\\nconst db = drizzle({ client });\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-bun-sqlite.mdx'), name='connect-bun-sqlite.mdx', displayName='connect-bun-sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> Bun SQLite\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Bun - [website](https://bun.sh/docs)\\n- Bun SQLite driver - [docs](https://bun.sh/docs/api/sqlite)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://bun.sh/)**, Bun is a fast all-in-one JavaScript runtime. \\n\\nDrizzle ORM natively supports **[`bun:sqlite`](https://bun.sh/docs/api/sqlite)** module and it\\'s crazy fast ðŸš€  \\n\\nWe embrace SQL dialects and dialect specific drivers and syntax and unlike any other ORM, \\nfor synchronous drivers like `bun:sqlite` we have both **async** and **sync** APIs and we mirror most popular \\nSQLite-like `all`, `get`, `values` and `run` query methods syntax.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/bun-sqlite\\';\\n\\nconst db = drizzle();\\n\\nconst result = await db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/bun-sqlite\\';\\nimport { Database } from \\'bun:sqlite\\';\\n\\nconst sqlite = new Database(\\'sqlite.db\\');\\nconst db = drizzle({ client: sqlite });\\n\\nconst result = await db.select().from(...);\\n```\\n\\nIf you want to use **sync** APIs:\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/bun-sqlite\\';\\nimport { Database } from \\'bun:sqlite\\';\\n\\nconst sqlite = new Database(\\'sqlite.db\\');\\nconst db = drizzle({ client: sqlite });\\n\\nconst result = db.select().from(users).all();\\nconst result = db.select().from(users).get();\\nconst result = db.select().from(users).values();\\nconst result = db.select().from(users).run();\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-cloudflare-d1.mdx'), name='connect-cloudflare-d1.mdx', displayName='connect-cloudflare-d1.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> Cloudflare D1\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- D1 Database - [website](https://developers.cloudflare.com/d1/)\\n- D1 driver - [website](https://developers.cloudflare.com/d1/build-with-d1/d1-client-api/)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://developers.cloudflare.com/d1/)**, \\nD1 is Cloudflare\\'s first queryable relational database.  \\n  \\nDrizzle ORM fully supports the Cloudflare D1 database and Cloudflare Workers environment.\\nWe embrace SQL dialects and dialect specific drivers and syntax and mirror most popular \\nSQLite-like `all`, `get`, `values` and `run` query methods syntax.\\n\\nTo setup project for your Cloudflare D1 please refer to **[official docs.](https://developers.cloudflare.com/d1/)**\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n\\nYou would need to have either a `wrangler.json` or a `wrangler.toml` file for D1 database and will look something like this:\\n<CodeTabs items={[\"wrangler.json\", \"wrangler.toml\"]}>\\n```json\\n{\\n    \"name\": \"YOUR_PROJECT_NAME\",\\n    \"main\": \"src/index.ts\",\\n    \"compatibility_date\": \"2024-09-26\",\\n    \"compatibility_flags\": [\\n        \"nodejs_compat\"\\n    ],\\n    \"d1_databases\": [\\n        {\\n            \"binding\": \"BINDING_NAME\",\\n            \"database_name\": \"YOUR_DB_NAME\",\\n            \"database_id\": \"YOUR_DB_ID\",\\n            \"migrations_dir\": \"drizzle/migrations\"\\n        }\\n    ]\\n}\\n```\\n```toml\\nname = \"YOUR_PROJECT_NAME\"\\nmain = \"src/index.ts\"\\ncompatibility_date = \"2022-11-07\"\\nnode_compat = true\\n\\n[[ d1_databases ]]\\nbinding = \"BINDING_NAME\"\\ndatabase_name = \"YOUR_DB_NAME\"\\ndatabase_id = \"YOUR_DB_ID\"\\nmigrations_dir = \"drizzle/migrations\"\\n```\\n</CodeTabs>\\n\\nMake your first D1 query:\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/d1\\';\\n\\nexport interface Env {\\n  <BINDING_NAME>: D1Database;\\n}\\n\\nexport default {\\n  async fetch(request: Request, env: Env) {\\n    const db = drizzle(env.<BINDING_NAME>);\\n    const result = await db.select().from(users).all()\\n    return Response.json(result);\\n  },\\n};\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-cloudflare-do.mdx'), name='connect-cloudflare-do.mdx', displayName='connect-cloudflare-do.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> Cloudflare Durable Objects SQLite\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- **Cloudflare SQLite Durable Objects** - SQLite database embedded within a Durable Object - [read here](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend)\\n</Prerequisites>\\n  \\nDrizzle ORM fully supports the Cloudflare Durable Objects database and Cloudflare Workers environment.\\nWe embrace SQL dialects and dialect specific drivers and syntax and mirror most popular \\nSQLite-like `all`, `get`, `values` and `run` query methods syntax.\\n\\nTo setup project for your Cloudflare Durable Objects please refer to **[official docs.](https://developers.cloudflare.com/durable-objects)**\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n\\nYou would need to have a `wrangler.toml` file for Durable Objects database and will look something like this:\\n```toml {16-18,21-24}\\n#:schema node_modules/wrangler/config-schema.json\\nname = \"sqlite-durable-objects\"\\nmain = \"src/index.ts\"\\ncompatibility_date = \"2024-11-12\"\\ncompatibility_flags = [ \"nodejs_compat\" ]\\n\\n# Bind a Durable Object. Durable objects are a scale-to-zero compute primitive based on the actor model.\\n# Durable Objects can live for as long as needed. Use these when you need a long-running \"server\", such as in realtime apps.\\n# Docs: https://developers.cloudflare.com/workers/wrangler/configuration/#durable-objects\\n[[durable_objects.bindings]]\\nname = \"MY_DURABLE_OBJECT\"\\nclass_name = \"MyDurableObject\"\\n\\n# Durable Object migrations.\\n# Docs: https://developers.cloudflare.com/workers/wrangler/configuration/#migrations\\n[[migrations]]\\ntag = \"v1\"\\nnew_sqlite_classes = [\"MyDurableObject\"]\\n\\n# We need rules so we can import migrations in the next steps\\n[[rules]] \\ntype = \"Text\"\\nglobs = [\"**/*.sql\"]\\nfallthrough = true\\n```\\n\\nMake your first Durable Objects SQLite query:\\n```typescript copy\\n/// <reference types=\"@cloudflare/workers-types\" />\\nimport { drizzle, DrizzleSqliteDODatabase } from \\'drizzle-orm/durable-sqlite\\';\\nimport { DurableObject } from \\'cloudflare:workers\\'\\nimport { migrate } from \\'drizzle-orm/durable-sqlite/migrator\\';\\nimport migrations from \\'../drizzle/migrations\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nexport class MyDurableObject extends DurableObject {\\n\\tstorage: DurableObjectStorage;\\n\\tdb: DrizzleSqliteDODatabase<any>;\\n\\n\\tconstructor(ctx: DurableObjectState, env: Env) {\\n\\t\\tsuper(ctx, env);\\n\\t\\tthis.storage = ctx.storage;\\n\\t\\tthis.db = drizzle(this.storage, { logger: false });\\n\\n\\t\\t// Make sure all migrations complete before accepting queries.\\n\\t\\t// Otherwise you will need to run `this.migrate()` in any function\\n\\t\\t// that accesses the Drizzle database `this.db`.\\n\\t\\tctx.blockConcurrencyWhile(async () => {\\n\\t\\t\\tawait this._migrate();\\n\\t\\t});\\n\\t}\\n\\n\\tasync insertAndList(user: typeof usersTable.$inferInsert) {\\n\\t\\tawait this.insert(user);\\n\\t\\treturn this.select();\\n\\t}\\n\\n\\tasync insert(user: typeof usersTable.$inferInsert) {\\n\\t\\tawait this.db.insert(usersTable).values(user);\\n\\t}\\n\\n\\tasync select() {\\n\\t\\treturn this.db.select().from(usersTable);\\n\\t}\\n\\n\\tasync _migrate() {\\n\\t\\tmigrate(this.db, migrations);\\n\\t}\\n}\\n\\nexport default {\\n\\t/**\\n\\t * This is the standard fetch handler for a Cloudflare Worker\\n\\t *\\n\\t * @param request - The request submitted to the Worker from the client\\n\\t * @param env - The interface to reference bindings declared in wrangler.toml\\n\\t * @param ctx - The execution context of the Worker\\n\\t * @returns The response to be sent back to the client\\n\\t */\\n\\tasync fetch(request: Request, env: Env): Promise<Response> {\\n\\t\\tconst id: DurableObjectId = env.MY_DURABLE_OBJECT.idFromName(\\'durable-object\\');\\n\\t\\tconst stub = env.MY_DURABLE_OBJECT.get(id);\\n\\n\\t\\t// Option A - Maximum performance.\\n\\t\\t// Prefer to bundle all the database interaction within a single Durable Object call\\n\\t\\t// for maximum performance, since database access is fast within a DO.\\n\\t\\tconst usersAll = await stub.insertAndList({\\n\\t\\t\\tname: \\'John\\',\\n\\t\\t\\tage: 30,\\n\\t\\t\\temail: \\'john@example.com\\',\\n\\t\\t});\\n\\t\\tconsole.log(\\'New user created. Getting all users from the database: \\', users);\\n\\n\\t\\t// Option B - Slow but maybe useful sometimes for debugging.\\n\\t\\t// You can also directly call individual Drizzle queries if they are exposed\\n\\t\\t// but keep in mind every query is a round-trip to the Durable Object instance.\\n\\t\\tawait stub.insert({\\n\\t\\t\\tname: \\'John\\',\\n\\t\\t\\tage: 30,\\n\\t\\t\\temail: \\'john@example.com\\',\\n\\t\\t});\\n\\t\\tconsole.log(\\'New user created!\\');\\n\\t\\n\\t\\tconst users = await stub.select();\\n\\t\\tconsole.log(\\'Getting all users from the database: \\', users);\\n\\n\\t\\treturn Response.json(users);\\n\\t}\\n}\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-drizzle-proxy.mdx'), name='connect-drizzle-proxy.mdx', displayName='connect-drizzle-proxy.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\n\\n# Drizzle HTTP proxy\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n</Prerequisites>\\n\\nHow an HTTP Proxy works and why you might need it\\n\\nDrizzle Proxy is used when you need to implement your own driver communication with the database. \\nIt can be used in several cases, such as adding custom logic at the query stage with existing drivers. \\nThe most common use is with an HTTP driver, which sends queries to your server with the database, executes the query \\non your database, and responds with raw data that Drizzle ORM can then map to results\\n\\n<Callout collapsed=\"How it works under the hood?\">\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              \\nâ”‚       Drizzle ORM         â”‚                 â”‚  HTTP Server with Database  â”‚             \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜             \\n  â”‚                                                ^                    â”‚\\n  â”‚-- 1. Build query         2. Send built query --â”‚                    â”‚\\n  â”‚                                                â”‚                    â”‚\\n  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                    â”‚\\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                           â”‚â”€â”€â”€â”€â”€â”˜                    â”‚ \\n                 â”‚      HTTP Proxy Driver    â”‚                          â”‚\\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\\n  â”‚                                                  3. Execute a query + send raw results back\\n  â”‚-- 4. Map data and return        \\n  â”‚                   \\n  v\\n```\\n</Callout>\\n\\nDrizzle ORM also supports simply using asynchronous callback function for executing SQL.\\n\\n- `sql` is a query string with placeholders.\\n- `params` is an array of parameters.\\n- One of the following values will set for `method` depending on the SQL statement - `run`, `all`, `values` or `get`.\\n\\nDrizzle always waits for `{rows: string[][]}` or `{rows: string[]}` for the return value.\\n\\n- When the `method` is `get`, you should return a value as `{rows: string[]}`.\\n- Otherwise, you should return `{rows: string[][]}`.\\n\\n<br/>\\n\\n<CodeTabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Section>\\n```typescript copy\\n// Example of driver implementation\\nimport { drizzle } from \\'drizzle-orm/pg-proxy\\';\\n\\nconst db = drizzle(async (sql, params, method) => {\\n  try {\\n    const rows = await axios.post(\\'http://localhost:3000/query\\', { sql, params, method });\\n\\n    return { rows: rows.data };\\n  } catch (e: any) {\\n    console.error(\\'Error from pg proxy server: \\', e.response.data)\\n    return { rows: [] };\\n  }\\n});\\n```\\n```ts\\n// Example of server implementation\\nimport { Client } from \\'pg\\';\\nimport express from \\'express\\';\\n\\nconst app = express();\\n\\napp.use(express.json());\\nconst port = 3000;\\n\\nconst client = new Client(\\'postgres://postgres:postgres@localhost:5432/postgres\\');\\n\\napp.post(\\'/query\\', async (req, res) => {\\n  const { sql, params, method } = req.body;\\n\\n  // prevent multiple queries\\n  const sqlBody = sql.replace(/;/g, \\'\\');\\n\\n  try {\\n    const result = await client.query({\\n      text: sqlBody,\\n      values: params,\\n      rowMode: method === \\'all\\' ? \\'array\\': undefined,\\n    });\\n    res.send(result.rows);\\n  } catch (e: any) {\\n    res.status(500).json({ error: e });\\n  }\\n\\n  res.status(500).json({ error: \\'Unknown method value\\' });\\n});\\n\\napp.listen(port, () => {\\n  console.log(`Example app listening on port ${port}`);\\n});\\n```\\n</Section>\\n<Section>\\n```typescript copy\\n// Example of driver implementation\\nimport { drizzle } from \\'drizzle-orm/mysql-proxy\\';\\n\\nconst db = drizzle(async (sql, params, method) => {\\n  try {\\n    const rows = await axios.post(\\'http://localhost:3000/query\\', { sql, params, method });\\n\\n    return { rows: rows.data };\\n  } catch (e: any) {\\n    console.error(\\'Error from mysql proxy server: \\', e.response.data)\\n    return { rows: [] };\\n  }\\n});\\n```\\n```ts\\n// Example of server implementation\\nimport * as mysql from \\'mysql2/promise\\';\\nimport express from \\'express\\';\\n\\nconst app = express();\\n\\napp.use(express.json());\\nconst port = 3000;\\n\\nconst main = async () => {\\n    const connection = await mysql.createConnection(\\'mysql://root:mysql@127.0.0.1:5432/drizzle\\');\\n\\n    app.post(\\'/query\\', async (req, res) => {\\n      const { sql, params, method } = req.body;\\n\\n      // prevent multiple queries\\n      const sqlBody = sql.replace(/;/g, \\'\\');\\n\\n      try {\\n            const result = await connection.query({\\n                sql: sqlBody,\\n                values: params,\\n                rowsAsArray: method === \\'all\\',\\n                typeCast: function(field: any, next: any) {\\n                    if (field.type === \\'TIMESTAMP\\' || field.type === \\'DATETIME\\' || field.type === \\'DATE\\') {\\n                        return field.string();\\n                    }\\n                    return next();\\n                },\\n            });\\n      } catch (e: any) {\\n        res.status(500).json({ error: e });\\n      }\\n\\n      if (method === \\'all\\') {\\n        res.send(result[0]);\\n      } else if (method === \\'execute\\') {\\n        res.send(result);\\n      }\\n      res.status(500).json({ error: \\'Unknown method value\\' });\\n    });\\n\\n    app.listen(port, () => {\\n      console.log(`Example app listening on port ${port}`);\\n    });\\n}\\n\\nmain();\\n```\\n</Section>\\n<Section>\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/sqlite-proxy\\';\\n\\nconst db = drizzle(async (sql, params, method) => {\\n  try {\\n    const rows = await axios.post(\\'http://localhost:3000/query\\', { sql, params, method });\\n\\n    return { rows: rows.data };\\n  } catch (e: any) {\\n    console.error(\\'Error from sqlite proxy server: \\', e.response.data)\\n    return { rows: [] };\\n  }\\n});\\n```\\n\\n**Batch support**\\n\\nSqlite Proxy supports batch requests, the same as it\\'s done for all other drivers. Check full [docs](/docs/batch-api)\\n\\nYou will need to specify a specific callback for batch queries and handle requests to proxy server:\\n\\n```ts\\nimport { drizzle } from \\'drizzle-orm/sqlite-proxy\\';\\n\\ntype ResponseType = { rows: any[][] | any[] }[];\\n\\nconst db = drizzle(async (sql, params, method) => {\\n  // single queries logic. Same as in code above\\n}, async (queries: { sql: string, params: any[], method: \\'all\\' | \\'run\\' | \\'get\\' | \\'values\\'}[]) => {\\n    try {\\n      const result: ResponseType = await axios.post(\\'http://localhost:3000/batch\\', { queries });\\n\\n      return result;\\n    } catch (e: any) {\\n      console.error(\\'Error from sqlite proxy server:\\', e);\\n      throw e;\\n    }\\n  });\\n```\\n\\nAnd then you can use `db.batch([])` method, that will proxy all queries\\n\\n<Callout>\\n  Response from the batch should be an array of raw values (an array within an array), in the same order as they were sent to the proxy server\\n</Callout>\\n\\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\\n```typescript copy\\nimport { sql } from \"drizzle-orm\";\\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst users = sqliteTable(\\'users\\', {\\n  id: text(\\'id\\'),\\n  textModifiers: text(\\'text_modifiers\\').notNull().default(sql`CURRENT_TIMESTAMP`),\\n  intModifiers: integer(\\'int_modifiers\\', { mode: \\'boolean\\' }).notNull().default(false),\\n});\\n```\\nFor more details about column types, see the **[SQLite column types in Drizzle.](/docs/column-types/sqlite)**\\n</Section>\\n</CodeTabs>\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-expo-sqlite.mdx'), name='connect-expo-sqlite.mdx', displayName='connect-expo-sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n\\n# Drizzle \\\\<\\\\> Expo SQLite\\nAccording to the **[official website](https://expo.dev/)**, Expo is an ecosystem of tools to develop, build and ship applications on React Native. \\nIt\\'s powered by Hermes JavaScript runtime and Metro bundler, Drizzle Expo driver is built to natively support both.  \\n  \\nDrizzle ORM has the best in class toolkit for Expo SQLite:\\n- Native ORM driver for Expo SQLite âœ…\\n- [Drizzle Kit](/docs/kit-overview) support for migration generation and bundling in application âœ…\\n- [Drizzle Studio](https://github.com/drizzle-team/drizzle-studio-expo) dev tools plugin to browse on device database âœ…\\n- Live Queries âœ…\\n  \\n<Npm>\\ndrizzle-orm expo-sqlite@next\\n-D drizzle-kit \\n</Npm>\\n\\n```ts\\nimport { drizzle } from \"drizzle-orm/expo-sqlite\";\\nimport { openDatabaseSync } from \"expo-sqlite\";\\n\\nconst expo = openDatabaseSync(\"db.db\");\\nconst db = drizzle(expo);\\n\\nawait db.select().from(users);\\n```\\n#### Live Queries\\nWith `useLiveQuery` hook you can make any Drizzle query reactive:\\n```ts\\nimport { useLiveQuery, drizzle } from \\'drizzle-orm/expo-sqlite\\';\\nimport { openDatabaseSync } from \\'expo-sqlite\\';\\nimport { Text } from \\'react-native\\';\\nimport * as schema from \\'./schema\\';\\n\\nconst expo = openDatabaseSync(\\'db.db\\', { enableChangeListener: true }); // <-- enable change listeners\\nconst db = drizzle(expo);\\n\\nconst App = () => {\\n  // Re-renders automatically when data changes\\n  const { data } = useLiveQuery(db.select().from(schema.users));\\n  return <Text>{JSON.stringify(data)}</Text>;\\n};\\n\\nexport default App;\\n```\\n\\n#### Expo SQLite migrations with Drizzle Kit\\nYou can use Drizzle Kit for SQL migration generation.  \\nPlease make sure to check how [Drizzle migrations](/docs/kit-overview) work before proceeding.  \\nExpo / React Native requires you to have SQL migrations bundled into the app and we\\'ve got you covered.  \\n\\n<Steps>\\n#### Install babel plugin\\nIt\\'s necessary to bundle SQL migration files as string directly to your bundle.\\n```shell\\nnpm install babel-plugin-inline-import\\n```\\n\\n#### Update config files.\\nYou will need to update `babel.config.js`, `metro.config.js` and `drizzle.config.ts` files\\n```js filename=\\'babel.config.js\\'\\nmodule.exports = function(api) {\\n  api.cache(true);\\n\\n  return {\\n    presets: [\\'babel-preset-expo\\'],\\n    plugins: [[\"inline-import\", { \"extensions\": [\".sql\"] }]] // <-- add this\\n  };\\n};\\n```\\n\\n```js filename=\"metro.config.js\"\\nconst { getDefaultConfig } = require(\\'expo/metro-config\\');\\n\\n/** @type {import(\\'expo/metro-config\\').MetroConfig} */\\nconst config = getDefaultConfig(__dirname);\\n\\nconfig.resolver.sourceExts.push(\\'sql\\'); // <--- add this\\n\\nmodule.exports = config;\\n```\\n\\nMake sure to have `dialect: \\'sqlite\\'` and `driver: \\'expo\\'` in Drizzle Kit config\\n```ts filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n\\tschema: \\'./db/schema.ts\\',\\n\\tout: \\'./drizzle\\',\\n  dialect: \\'sqlite\\',\\n\\tdriver: \\'expo\\', // <--- very important\\n});\\n```\\n\\n#### Generate migrations\\nAfter creating SQL schema file and drizzle.config.ts file, you can generate migrations\\n```bash\\nnpx drizzle-kit generate\\n```\\n\\n#### Add migrations to your app\\nNow you need to import `migrations.js` file into your Expo/React Native app from `./drizzle` folder. \\nYou can run migrations on application startup using our custom `useMigrations` migrations hook on in `useEffect` hook manually as you want.\\n\\n```ts filename=\"App.tsx\"\\nimport { drizzle } from \"drizzle-orm/expo-sqlite\";\\nimport { openDatabaseSync } from \"expo-sqlite\";\\nimport { useMigrations } from \\'drizzle-orm/expo-sqlite/migrator\\';\\nimport migrations from \\'./drizzle/migrations\\';\\n\\nconst expoDb = openDatabaseSync(\"db.db\");\\n\\nconst db = drizzle(expoDb);\\n\\nexport default function App() {\\n  const { success, error } = useMigrations(db, migrations);\\n\\n  if (error) {\\n    return (\\n      <View>\\n        <Text>Migration error: {error.message}</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (!success) {\\n    return (\\n      <View>\\n        <Text>Migration is in progress...</Text>\\n      </View>\\n    );\\n  }\\n\\n  return ...your application component;\\n}\\n```\\n</Steps>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-neon.mdx'), name='connect-neon.mdx', displayName='connect-neon.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Neon Postgres\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Neon serverless database - [website](https://neon.tech)\\n- Neon serverless driver - [docs](https://neon.tech/docs/serverless/serverless-driver) & [GitHub](https://github.com/neondatabase/serverless)\\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\nDrizzle has native support for Neon connections with the `neon-http` and `neon-websockets` drivers. These use the **neon-serverless** driver under the hood.  \\n  \\nWith the `neon-http` and `neon-websockets` drivers, you can access a Neon database from serverless environments over HTTP or WebSockets instead of TCP.  \\nQuerying over HTTP is faster for single, non-interactive transactions.  \\n  \\nIf you need session or interactive transaction support, or a fully compatible drop-in replacement for the `pg` driver, you can use the WebSocket-based `neon-serverless` driver.  \\nYou can connect to a Neon database directly using [Postgres](/docs/get-started/postgresql-new)\\n  \\nFor an example of using Drizzle ORM with the Neon Serverless driver in a Cloudflare Worker, **[see here.](http://driz.link/neon-cf-ex)**  \\nTo use Neon from a serverful environment, you can use the PostgresJS driver, as described in Neon\\'s **[official Node.js docs](https://neon.tech/docs/guides/node)** â€” see **[docs](#postgresjs)**.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @neondatabase/serverless\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"Neon HTTP\", \"Neon Websockets\", \"node-postgres\", \"postgres.js\"]}>\\n```typescript\\nimport { drizzle } from \\'drizzle-orm/neon-http\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n<Section> \\n```typescript \\nimport { drizzle } from \\'drizzle-orm/neon-serverless\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript\\n// For Node.js - make sure to install the \\'ws\\' and \\'bufferutil\\' packages\\nimport { drizzle } from \\'drizzle-orm/neon-serverless\\';\\nimport ws from \\'ws\\';\\n\\nconst db = drizzle({\\n  connection: process.env.DATABASE_URL,\\n  ws: ws,\\n});\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n<Callout type=\"warning\" emoji=\"âš™ï¸\"> \\nAdditional configuration is required to use WebSockets in environments where the `WebSocket` global is not defined, such as Node.js. \\nAdd the `ws` and `bufferutil` packages to your project\\'s dependencies, and set `ws` in the Drizzle config. \\n</Callout>\\n</Section> \\n```typescript \\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript\\n// Make sure to install the \\'postgres\\' package\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing drivers:\\n\\n<CodeTabs items={[\"Neon HTTP\", \"Neon Websockets\", \"node-postgres\", \"postgres.js\"]}>\\n```typescript\\nimport { neon } from \\'@neondatabase/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/neon-http\\';\\n\\nconst sql = neon(process.env.DATABASE_URL!);\\nconst db = drizzle({ client: sql });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n<Section> \\n```typescript \\nimport { Pool } from \\'@neondatabase/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/neon-serverless\\';\\n\\nconst pool = new Pool({ connectionString: process.env.DATABASE_URL });\\nconst db = drizzle({ client: pool })\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript\\n// For Node.js - make sure to install the \\'ws\\' and \\'bufferutil\\' packages\\nimport { Pool, neonConfig } from \\'@neondatabase/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/neon-serverless\\';\\n\\nneonConfig.webSocketConstructor = ws;\\n\\nconst pool = new Pool({ connectionString: process.env.DATABASE_URL });\\nconst db = drizzle({ client: pool })\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n<Callout type=\"warning\" emoji=\"âš™ï¸\"> \\nAdditional configuration is required to use WebSockets in environments where the `WebSocket` global is not defined, such as Node.js. \\nAdd the `ws` and `bufferutil` packages to your project\\'s dependencies, and set `ws` in the Drizzle config. \\n</Callout>\\n</Section> \\n```typescript \\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { Pool } from \"pg\";\\n\\nconst pool = new Pool({\\n  connectionString: process.env.DATABASE_URL,\\n});\\nconst db = drizzle({ client: pool });\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript\\n// Make sure to install the \\'postgres\\' package\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nconst queryClient = postgres(process.env.DATABASE_URL);\\nconst db = drizzle({ client: queryClient });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-nile.mdx'), name='connect-nile.mdx', displayName='connect-nile.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Nile\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Nile Database - [website](https://thenile.dev)\\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://thenile.dev)**, Nile is PostgreSQL re-engineered for multi-tenant apps.\\n\\nCheckout official **[Nile + Drizzle Quickstart](https://www.thenile.dev/docs/getting-started/languages/drizzle)** and **[Migration](https://www.thenile.dev/docs/getting-started/schema_migrations/drizzle)** docs.\\n\\nYou can use Nile with any of Drizzle\\'s Postgres drivers, we\\'ll be showing the use of `node-postgres` below.\\n\\n#### Step 1 - Install packages\\n\\n<Npm>\\ndrizzle-orm postgres\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n\\n```typescript copy filename=\"index.ts\"\\n// Make sure to install the \\'pg\\' package\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\'\\n\\nconst db = drizzle(process.env.NILEDB_URL);\\n\\nconst response = await db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy filename=\"index.ts\"\\n// Make sure to install the \\'pg\\' package\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { Pool } from \"pg\";\\nconst pool = new Pool({\\n  connectionString: process.env.DATABASE_URL,\\n});\\nconst db = drizzle({ client: pool });\\n\\nconst response = await db.select().from(...);\\n```\\n\\n#### Connecting to a virtual tenant database\\n\\nNile provides virtual tenant databases, when you set the tenant context, Nile will direct your queries to the virtual database for this particular tenant and all queries will apply to that tenant (i.e. `select * from table` will result records only for this tenant). \\n\\nIn order to set the tenant context, we wrap each query in a transaction that sets the appropriate tenant context before running the transaction.\\n\\nThe tenant ID can simply be passed into the wrapper as an argument:\\n\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport { todosTable, tenants } from \"./db/schema\";\\nimport { sql } from \\'drizzle-orm\\';\\nimport \\'dotenv/config\\';\\n\\nconst db = drizzle(process.env.NILEDB_URL);\\n\\nfunction tenantDB<T>(tenantId: string, cb: (tx: any) => T | Promise<T>): Promise<T> {\\n  return db.transaction(async (tx) => {\\n    if (tenantId) {\\n      await tx.execute(sql`set local nile.tenant_id = \\'${sql.raw(tenantId)}\\'`);\\n    }\\n\\n    return cb(tx);\\n  }) as Promise<T>;\\n}\\n\\n// In a webapp, you\\'ll likely get it from the request path parameters or headers\\nconst tenantId = \\'01943e56-16df-754f-a7b6-6234c368b400\\'\\n\\nconst response = await tenantDB(tenantId, async (tx) => {\\n    // No need for a \"where\" clause here\\n    return await tx.select().from(todosTable);\\n});\\n\\nconsole.log(response);\\n```\\n\\nIf you are using a web framwork that supports it, you can set up [AsyncLocalStorage](https://nodejs.org/api/async_context.html) and use middleware to populate it with the tenant ID. In this case, your Drizzle client setup will be:\\n\\n```typescript copy filename=\"db/index.ts\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport dotenv from \"dotenv/config\";\\nimport { sql } from \"drizzle-orm\";\\nimport { AsyncLocalStorage } from \"async_hooks\";\\n\\nexport const db = drizzle(process.env.NILEDB_URL);\\nexport const tenantContext = new AsyncLocalStorage<string | undefined>();\\n\\nexport function tenantDB<T>(cb: (tx: any) => T | Promise<T>): Promise<T> {\\n  return db.transaction(async (tx) => {\\n    const tenantId = tenantContext.getStore();\\n    console.log(\"executing query with tenant: \" + tenantId);\\n    // if there\\'s a tenant ID, set it in the transaction context\\n    if (tenantId) {\\n      await tx.execute(sql`set local nile.tenant_id = \\'${sql.raw(tenantId)}\\'`);\\n    }\\n\\n    return cb(tx);\\n  }) as Promise<T>;\\n}\\n```\\n\\nAnd then, configure a middleware to populate the the AsyncLocalStorage and use `tenantDB` method when handling requests:\\n\\n```typescript copy filename=\"app.ts\"\\n// Middleware to set tenant context\\napp.use(\"/api/tenants/:tenantId/*\", async (c, next) => {\\n  const tenantId = c.req.param(\"tenantId\");\\n  console.log(\"setting context to tenant: \" + tenantId);\\n  return tenantContext.run(tenantId, () => next());\\n});\\n\\n// Route handler\\napp.get(\"/api/tenants/:tenantId/todos\", async (c) => {\\n    const todos = await tenantDB(c, async (tx) => {\\n      return await tx\\n        .select({\\n          id: todoSchema.id,\\n          tenant_id: todoSchema.tenantId,\\n          title: todoSchema.title,\\n          estimate: todoSchema.estimate,\\n        })\\n        .from(todoSchema);\\n    });\\n    return c.json(todos);\\n});\\n```\\n\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n\\n\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-op-sqlite.mdx'), name='connect-op-sqlite.mdx', displayName='connect-op-sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n# Drizzle \\\\<\\\\> OP SQLite\\nAccording to the **[official github page](https://github.com/OP-Engineering/op-sqlite)**, \\nOP-SQLite embeds the latest version of SQLite and provides a low-level API to execute SQL queries.\\n\\n<Npm>\\ndrizzle-orm @op-engineering/op-sqlite\\n-D drizzle-kit \\n</Npm>\\n\\n```ts\\nimport { drizzle } from \"drizzle-orm/op-sqlite\";\\nimport { open } from \\'@op-engineering/op-sqlite\\';\\n\\nconst opsqlite = open({\\n  name: \\'myDB\\',\\n});\\nconst db = drizzle(opsqlite);\\n\\nawait db.select().from(users);\\n```\\n\\nYou can use Drizzle Kit for SQL migration generation.  \\nPlease make sure to check how [Drizzle Kit migrations](/docs/kit-overview) work before proceeding.  \\nOP SQLite requires you to have SQL migrations bundled into the app and we\\'ve got you covered.  \\n\\n<Steps>\\n\\n#### Install babel plugin\\nIt\\'s necessary to bundle SQL migration files as string directly to your bundle.\\n```shell\\nnpm install babel-plugin-inline-import\\n```\\n\\n#### Update config files.\\nYou will need to update `babel.config.js`, `metro.config.js` and `drizzle.config.ts` files\\n```js filename=\\'babel.config.js\\'\\nmodule.exports = {\\n  presets: [\\'module:@react-native/babel-preset\\'],\\n  plugins: [\\n    [\\n      \\'inline-import\\',\\n      {\\n        extensions: [\\'.sql\\'],\\n      },\\n    ],\\n  ],\\n};\\n```\\n\\n```js filename=\"metro.config.js\"\\nconst { getDefaultConfig } = require(\\'@react-native/metro-config\\');\\n\\nconst config = getDefaultConfig(__dirname);\\n\\nconfig.resolver.sourceExts.push(\\'sql\\');\\n\\nmodule.exports = config;\\n```\\n\\nMake sure to have `dialect: \\'sqlite\\'` and `driver: \\'expo\\'` in Drizzle Kit config\\n```ts filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n\\tschema: \\'./db/schema.ts\\',\\n\\tout: \\'./drizzle\\',\\n  dialect: \\'sqlite\\',\\n\\tdriver: \\'expo\\', // <--- very important\\n});\\n```\\n\\n#### Generate migrations\\nAfter creating SQL schema file and drizzle.config.ts file, you can generate migrations\\n```bash\\nnpx drizzle-kit generate\\n```\\n\\n#### Add migrations to your app\\nNow you need to import `migrations.js` file into your Expo/React Native app from `./drizzle` folder. \\nYou can run migrations on application startup using our custom `useMigrations` migrations hook on in `useEffect` hook manually as you want.\\n\\n```ts filename=\"App.tsx\"\\nimport { drizzle } from \"drizzle-orm/op-sqlite\";\\nimport { open } from \\'@op-engineering/op-sqlite\\';\\nimport { useMigrations } from \\'drizzle-orm/op-sqlite/migrator\\';\\nimport migrations from \\'./drizzle/migrations\\';\\n\\nconst opsqliteDb = open({\\n  name: \\'myDB\\',\\n});\\n\\nconst db = drizzle(opsqliteDb);\\n\\nexport default function App() {\\n  const { success, error } = useMigrations(db, migrations);\\n\\n  if (error) {\\n    return (\\n      <View>\\n        <Text>Migration error: {error.message}</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (!success) {\\n    return (\\n      <View>\\n        <Text>Migration is in progress...</Text>\\n      </View>\\n    );\\n  }\\n\\n  return ...your application component;\\n}\\n```\\n\\n</Steps>\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-overview.mdx'), name='connect-overview.mdx', displayName='connect-overview.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport LinksList from \"@mdx/LinksList.astro\"\\nimport Flex from \"@mdx/Flex.astro\"\\n\\n# Database connection with Drizzle\\nDrizzle ORM runs SQL queries on your database via **database drivers**.\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\n<CodeTab>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\"\\nimport { users } from \"./schema\"\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\nconst usersCount = await db.$count(users);\\n```\\n```  \\n                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n                        â”‚   db.$count(users)   â”‚ <--- drizzle query\\n                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     \\n                            â”‚               ÊŒ\\nselect count(*) from users -â”‚               â”‚\\n                            â”‚               â”‚- [{ count: 0 }]\\n                            v               â”‚\\n                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n                         â”‚    node-postgres    â”‚ <--- database driver\\n                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n                            â”‚               ÊŒ\\n01101000 01100101 01111001 -â”‚               â”‚\\n                            â”‚               â”‚- 01110011 01110101 01110000\\n                            v               â”‚\\n                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n                         â”‚      Database      â”‚ \\n                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n```\\n</CodeTab>\\n\\n```ts\\nimport { pgTable, integer, text } from \"drizzle-orm\";\\n\\nexport const users = pgTable(\"users\", {\\n  id: integer(\"id\").generateAlwaysAsIdentity(),\\n  name: text(\"name\"),\\n})\\n```\\n</CodeTabs>\\n\\nUnder the hood Drizzle will create a **node-postgres** driver instance which you can access via `db.$client` if necessary\\n<Section>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\"\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\nconst pool = db.$client;\\n```\\n```ts\\n// above is equivalent to\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { Pool } from \"pg\";\\n\\nconst pool = new Pool({\\n  connectionString: process.env.DATABASE_URL,\\n});\\nconst db = drizzle({ client: pool });\\n```\\n</Section>\\n\\nDrizzle is by design natively compatible with every **edge** or **serverless** runtime, whenever you\\'d need access to a serverless database - we\\'ve got you covered\\n\\n<CodeTabs items={[\"Neon HTTP\", \"Neon with websockets\", \"Vercel Postgres\", \"PlanetScale HTTP\", \"Cloudflare d1\"]}>\\n```ts\\nimport { drizzle } from \"drizzle-orm/neon-http\";\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n```\\n```ts\\nimport { drizzle } from \"drizzle-orm/neon-serverless\";\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n```\\n```ts\\nimport { drizzle } from \"drizzle-orm/vercel-postgres\";\\n\\nconst db = drizzle();\\n```\\n```ts\\nimport { drizzle } from \"drizzle-orm/planetscale\";\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n```\\n```ts\\nimport { drizzle } from \"drizzle-orm/d1\";\\n\\nconst db = drizzle({ connection: env.DB });\\n```\\n</CodeTabs>\\n\\nAnd yes, we do support runtime specific drivers like [Bun SQLite](/docs/connect-bun-sqlite) or [Expo SQLite](/docs/connect-expo-sqlite):\\n<Section>\\n```ts\\nimport { drizzle } from \"drizzle-orm/bun-sqlite\"\\n\\nconst db = drizzle(); // <--- will create an in-memory db\\nconst db = drizzle(\"./sqlite.db\");\\n```\\n```ts\\nimport { drizzle } from \"drizzle-orm/expo-sqlite\";\\nimport { openDatabaseSync } from \"expo-sqlite\";\\n\\nconst expo = openDatabaseSync(\"db.db\");\\nconst db = drizzle(expo);\\n```\\n</Section>\\n\\n#### Database connection URL\\nJust in case if you\\'re not familiar with database connection URL concept\\n```\\npostgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname\\n             â””â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜\\n              ÊŒ    ÊŒ          ÊŒ                                              ÊŒ\\n        role -â”‚    â”‚          â”‚- hostname                                    â”‚- database\\n                   â”‚\\n                   â”‚- password\\n\\n```\\n#### Next steps\\nFeel free to check out per-driver documentations  \\n\\n<rem/>\\n<Flex>\\n  <LinksList \\n    title=\\'PostgreSQL drivers\\'\\n    links={[\\n        [\"PostgreSQL\", \"/docs/get-started-postgresql\"], \\n        [\"Neon\", \"/docs/connect-neon\"], \\n        [\"Vercel Postgres\", \"/docs/connect-vercel-postgres\"],\\n        [\"Supabase\", \"/docs/connect-supabase\"],\\n        [\"Xata\", \"/docs/connect-xata\"],\\n        [\"PGLite\", \"/docs/connect-pglite\"],\\n      ]}\\n  />\\n  <LinksList \\n    title=\\'MySQL drivers\\'\\n    links={[\\n        [\"MySQL\", \"/docs/get-started-mysql\"], \\n        [\"PlanetsScale\", \"/docs/connect-planetscale\"], \\n        [\"TiDB\", \"/docs/connect-tidb\"],\\n      ]}\\n  />\\n  <LinksList \\n  title=\\'SQLite drivers\\'\\n  links={[\\n      [\"SQLite\", \"/docs/get-started-sqlite\"], \\n      [\"Turso Cloud\", \"/docs/connect-turso\"], \\n      [\"Turso Database\", \"/docs/connect-turso-database\"], \\n      [\"Cloudflare D1\", \"/docs/connect-cloudflare-d1\"],\\n      [\"Bun SQLite\", \"/docs/connect-bun-sqlite\"],\\n      [\"SQLite Cloud\", \"/docs/connect-sqlite-cloud\"],\\n    ]}\\n  />\\n  <LinksList \\n  title=\\'Native SQLite\\'\\n  links={[\\n      [\"Expo SQLite\", \"/docs/get-started/expo-new\"], \\n      [\"OP SQLite\", \"/docs/connect-op-sqlite\"], \\n      [\"React Native SQLite\", \"/docs/connect-react-native-sqlite\"],\\n    ]}\\n  />\\n  <LinksList \\n  title=\\'Others\\'\\n  links={[\\n      [\"Drizzle Proxy\", \"/docs/connect-drizzle-proxy\"], \\n    ]}\\n  />\\n</Flex>\\n{/* TODO: @AndriiSherman [\"AWS Data API\", \"/docs/get-started/aws-data-api\"],  */}\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-pglite.mdx'), name='connect-pglite.mdx', displayName='connect-pglite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> PGlite\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- ElectricSQL - [website](https://electric-sql.com/)\\n- PgLite driver - [docs](https://pglite.dev/) & [GitHub](https://github.com/electric-sql/pglite)\\n</Prerequisites>\\n\\nAccording to the **[official repo](https://github.com/electric-sql/pglite)**, PGlite is a WASM Postgres build packaged into a TypeScript client library that enables you to run Postgres in the browser, Node.js and Bun, with no need to install any other dependencies. It is only 2.6mb gzipped.\\n\\nIt can be used as an ephemeral in-memory database, or with persistence either to the file system (Node/Bun) or indexedDB (Browser).\\n\\nUnlike previous \"Postgres in the browser\" projects, PGlite does not use a Linux virtual machine - it is simply Postgres in WASM.\\n\\n#### Step 1 - Install packages\\n\\n<Npm>\\ndrizzle-orm @electric-sql/pglite\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"In-Memory\", \"In directory\", \"With extra config options\"]}>\\n```typescript copy\"\\nimport { drizzle } from \\'drizzle-orm/pglite\\';\\n\\nconst db = drizzle();\\n\\nawait db.select().from(...);\\n```\\n```typescript copy\"\\nimport { drizzle } from \\'drizzle-orm/pglite\\';\\n\\nconst db = drizzle(\\'path-to-dir\\');\\n\\nawait db.select().from(...);\\n```\\n```typescript copy\"\\nimport { drizzle } from \\'drizzle-orm/pglite\\';\\n\\n// connection is a native PGLite configuration\\nconst db = drizzle({ connection: { dataDir: \\'path-to-dir\\' }});\\n\\nawait db.select().from(...);\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\"\\nimport { PGlite } from \\'@electric-sql/pglite\\';\\nimport { drizzle } from \\'drizzle-orm/pglite\\';\\n\\n// In-memory Postgres\\nconst client = new PGlite();\\nconst db = drizzle({ client });\\n\\nawait db.select().from(users);\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-planetscale.mdx'), name='connect-planetscale.mdx', displayName='connect-planetscale.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> PlanetScale\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- PlanetScale database - [website](https://planetscale.com/docs)\\n- PlanetScale http driver - [GitHub](https://github.com/planetscale/database-js)\\n- Drizzle MySQL drivers - [docs](/docs/get-started-mysql)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://planetscale.com)**, \\nPlanetScale is the world\\'s most advanced serverless MySQL platform.\\n\\nWith Drizzle ORM you can access PlanetScale over http\\nthrough their official **[`database-js`](https://github.com/planetscale/database-js)**\\ndriver from serverless and serverfull environments with our `drizzle-orm/planetscale-serverless` package.\\n\\nYou can also access PlanetScale through TCP with `mysql2` driver â€” **[see here.](/docs/get-started-mysql)**\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @planetscale/database\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript copy\"\\nimport { drizzle } from \"drizzle-orm/planetscale-serverless\";\\n\\nconst db = drizzle({ connection: {\\n  host: process.env[\"DATABASE_HOST\"],\\n  username: process.env[\"DATABASE_USERNAME\"],\\n  password: process.env[\"DATABASE_PASSWORD\"],\\n}});\\n\\nconst response = await db.select().from(...)\\n```\\n\\nIf you need to provide your existing driver\\n\\n```typescript copy\"\\nimport { drizzle } from \"drizzle-orm/planetscale-serverless\";\\nimport { Client } from \"@planetscale/database\";\\n\\nconst client = new Client({\\n  host: process.env[\"DATABASE_HOST\"],\\n  username: process.env[\"DATABASE_USERNAME\"],\\n  password: process.env[\"DATABASE_PASSWORD\"],\\n});\\n\\nconst db = drizzle({ client });\\n```\\n\\nMake sure to checkout the PlanetScale official **[MySQL courses](https://planetscale.com/courses/mysql-for-developers)**, \\nwe think they\\'re outstanding ðŸ™Œ\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-prisma-postgres.mdx'), name='connect-prisma-postgres.mdx', displayName='connect-prisma-postgres.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Prisma Postgres\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Prisma Postgres serverless database - [website](https://prisma.io/postgres)\\n- Prisma Postgres direct connections - [docs](https://www.prisma.io/docs/postgres/database/direct-connections) \\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\nPrisma Postgres is a serverless database built on [unikernels](https://www.prisma.io/blog/announcing-prisma-postgres-early-access). It has a large free tier, [operation-based pricing](https://www.prisma.io/blog/operations-based-billing) and no cold starts.\\n  \\nYou can connect to it using either the [`node-postgres`](https://node-postgres.com/) or [`postgres.js`](https://github.com/porsager/postgres) drivers for PostgreSQL.\\n\\n<Callout type=\"info\">\\nPrisma Postgres also has a [serverless driver](https://www.prisma.io/docs/postgres/database/serverless-driver) that will be supported with Drizzle ORM in the future.\\n</Callout>\\n\\n#### Step 1 - Install packages\\n<CodeTabs items={[\"node-postgres (pg)\", \"postgres.js\"]}>\\n<Npm>\\ndrizzle-orm pg\\n-D drizzle-kit\\n</Npm>\\n\\n<Npm>\\ndrizzle-orm postres\\n-D drizzle-kit\\n</Npm>\\n\\n</CodeTabs>\\n\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"node-postgres (pg)\", \"postgres.js\"]}>\\n```typescript \\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { Pool } from \"pg\";\\n\\nconst pool = new Pool({\\n  connectionString: process.env.DATABASE_URL,\\n});\\nconst db = drizzle({ client: pool });\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript\\n// Make sure to install the \\'postgres\\' package\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nconst queryClient = postgres(process.env.DATABASE_URL);\\nconst db = drizzle({ client: queryClient });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-react-native-sqlite.mdx'), name='connect-react-native-sqlite.mdx', displayName='connect-react-native-sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n# Drizzle \\\\<\\\\> React Native SQLite\\nPlease use [`Expo SQLite`](#expo-sqlite) to run Drizzle ORM with React Native apps.  \\nThe only [popular library](https://github.com/andpor/react-native-sqlite-storage) we\\'ve found does not support new Hermes JavaScript runtime, \\nwhich is a standard out of the box runtime for React Native and Expo now.\\n\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-sqlite-cloud.mdx'), name='connect-sqlite-cloud.mdx', displayName='connect-sqlite-cloud.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> SQLite Cloud\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- **SQLite Cloud database** - [docs](https://docs.sqlitecloud.io/docs/overview)\\n- **SQLite Cloud driver** - [docs](https://docs.sqlitecloud.io/docs/sdk-js-introduction) & [GitHub](https://github.com/sqlitecloud/sqlitecloud-js)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://docs.sqlitecloud.io/docs/overview)**, SQLite Clouds is a managed, distributed relational database system built on top of the SQLite database engine. \\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm@beta @sqlitecloud/drivers\\n-D drizzle-kit@beta\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript\\nimport { drizzle } from \\'drizzle-orm/sqlite-cloud\\';\\n\\nconst db = drizzle(process.env.SQLITE_CLOUD_CONNECTION_STRING);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\nIf you need to provide your existing drivers:\\n\\n```typescript\\nimport { Database } from \\'@sqlitecloud/drivers\\';\\nimport { drizzle } from \\'drizzle-orm/sqlite-cloud\\';\\n\\nconst client = new Database(process.env.SQLITE_CLOUD_CONNECTION_STRING!);\\nconst db = drizzle({ client });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-supabase.mdx'), name='connect-supabase.mdx', displayName='connect-supabase.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Supabase\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://supabase.com/docs)**, Supabase is an open source Firebase alternative for building secure and performant Postgres backends with minimal configuration.\\n\\nCheckout official **[Supabase + Drizzle](https://supabase.com/docs/guides/database/connecting-to-postgres#connecting-with-drizzle)** docs.\\n\\n#### Step 1 - Install packages\\n\\n<Npm>\\ndrizzle-orm postgres\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\'\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst allUsers = await db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\'\\nimport postgres from \\'postgres\\'\\n\\nconst client = postgres(process.env.DATABASE_URL)\\nconst db = drizzle({ client });\\n\\nconst allUsers = await db.select().from(...);\\n```\\n\\nIf you decide to use connection pooling via Supabase (described [here](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler)), and have \"Transaction\" pool mode enabled, then ensure to turn off prepare, as prepared statements are not supported. \\n\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\'\\nimport postgres from \\'postgres\\'\\n\\n// Disable prefetch as it is not supported for \"Transaction\" pool mode \\nconst client = postgres(process.env.DATABASE_URL, { prepare: false })\\nconst db = drizzle({ client });\\n\\nconst allUsers = await db.select().from(...);\\n```\\n\\nConnect to your database using the Connection Pooler for **serverless environments**, and the Direct Connection for **long-running servers**.\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-tidb.mdx'), name='connect-tidb.mdx', displayName='connect-tidb.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> TiDB Serverless\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- TiDB database - [website](https://docs.pingcap.com/)\\n- TiDB HTTP Driver - [website](https://docs.pingcap.com/tidbcloud/serverless-driver)\\n- Drizzle MySQL drivers - [docs](/docs/get-started-mysql)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://www.pingcap.com/tidb-serverless/)**, \\nTiDB Serverless is a fully-managed, autonomous DBaaS with split-second cluster provisioning and consumption-based pricing.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\nTiDB Serverless is compatible with MySQL, so you can use [MySQL connection guide](/docs/get-started-mysql) to connect to it.\\n</Callout>\\n\\nTiDB Serverless provides an [HTTP driver](https://docs.pingcap.com/tidbcloud/serverless-driver) for edge environments. It is natively supported by Drizzle ORM via `drizzle-orm/tidb-serverless` package.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @tidbcloud/serverless\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/tidb-serverless\\';\\n\\nconst db = drizzle({ connection: { url: process.env.TIDB_URL }});\\n\\nconst response = await db.select().from(...)\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy\"\\nimport { connect } from \\'@tidbcloud/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/tidb-serverless\\';\\n\\nconst client = connect({ url: process.env.TIDB_URL });\\nconst db = drizzle({ client });\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-turso-database.mdx'), name='connect-turso-database.mdx', displayName='connect-turso-database.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport LibsqlTable from \"@mdx/LibsqlTable.mdx\";\\nimport LibsqlTabs from \"@mdx/LibsqlTabs.mdx\";\\n\\n# Drizzle \\\\<\\\\> Turso Database\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Turso Database - [website](https://docs.turso.tech/introduction)\\n- Turso Database driver - [website](https://docs.turso.tech/connect/javascript) & [GitHub](https://github.com/tursodatabase/turso/tree/main/bindings/javascript)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://docs.turso.tech/introduction)**, \\nTurso is the small database to power your big dreams in the age of AI.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm@beta @tursodatabase/database\\n-D drizzle-kit@beta\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n```typescript\\nimport { drizzle } from \\'drizzle-orm/tursodatabase/database\\';\\n\\nconst db = drizzle(\\'sqlite.db\\');\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\nIf you need to provide your existing drivers:\\n\\n```typescript\\nimport { Database } from \\'@tursodatabase/drivers\\';\\nimport { drizzle } from \\'drizzle-orm/tursodatabase/database\\';\\n\\nconst client = new Database(\\'sqlite.db\\');\\nconst db = drizzle({ client });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-turso.mdx'), name='connect-turso.mdx', displayName='connect-turso.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport LibsqlTable from \"@mdx/LibsqlTable.mdx\";\\nimport LibsqlTabs from \"@mdx/LibsqlTabs.mdx\";\\n\\n# Drizzle \\\\<\\\\> Turso Cloud\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Turso Cloud - [website](https://docs.turso.tech/turso-cloud)\\n- Turso Cloud driver - [website](https://docs.turso.tech/sdk/ts/reference) & [GitHub](https://github.com/tursodatabase/libsql-client-ts)\\n</Prerequisites>\\n\\nAccording to the **[official website](https://turso.tech/drizzle)**, \\nTurso is a **[libSQL](https://github.com/libsql/libsql)** powered edge SQLite database as a service.\\n  \\nDrizzle ORM natively supports libSQL driver.\\nWe embrace SQL dialects and dialect specific drivers and syntax and mirror most popular \\nSQLite-like `all`, `get`, `values` and `run` query methods syntax. \\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @libsql/client\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver\\nDrizzle has native support for all `@libsql/client` driver variations:\\n\\n<LibsqlTable />\\n\\n<br />\\n\\n<LibsqlTabs />\\n\\n\\nIf you need to provide your existing driver:\\n\\n<CodeTabs items={[\"default\", \"web\"]}>\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\nimport { createClient } from \\'@libsql/client\\';\\n\\nconst client = createClient({ \\n  url: process.env.DATABASE_URL,\\n  authToken: process.env.DATABASE_AUTH_TOKEN\\n});\\n\\nconst db = drizzle({ client });\\n\\nconst result = await db.select().from(users).all()\\n```\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/libsql/web\\';\\nimport { createClient } from \\'@libsql/client/web\\';\\n\\nconst client = createClient({ \\n  url: process.env.DATABASE_URL,\\n  authToken: process.env.DATABASE_AUTH_TOKEN\\n});\\n\\nconst db = drizzle({ client });\\n\\nconst result = await db.select().from(users).all()\\n```\\n</CodeTabs>\\n\\n#### Step 3 - make a query\\n\\n```ts\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\nimport * as s from \\'drizzle-orm/sqlite-core\\';\\n\\nconst db = drizzle({ connection: {\\n  url: process.env.DATABASE_URL, \\n  authToken: process.env.DATABASE_AUTH_TOKEN \\n}});\\n\\nconst users = s.sqliteTable(\"users\", {\\n  id: s.integer(),\\n  name: s.text(),\\n})\\n\\nconst result = await db.select().from(users);\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('connect-vercel-postgres.mdx'), name='connect-vercel-postgres.mdx', displayName='connect-vercel-postgres.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Vercel Postgres\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Vercel Postgres database - [website](https://vercel.com/docs/storage/vercel-postgres)\\n- Vercel Postgres driver - [docs](https://vercel.com/docs/storage/vercel-postgres/sdk) & [GitHub](https://github.com/vercel/storage/tree/main/packages/postgres)\\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\nAccording to their **[official website](https://vercel.com/docs/storage/vercel-postgres)**,\\nVercel Postgres is a serverless SQL database designed to integrate with Vercel Functions.\\n\\nDrizzle ORM natively supports both **[@vercel/postgres](https://vercel.com/docs/storage/vercel-postgres)** serverless\\ndriver with `drizzle-orm/vercel-postgres` package and **[`postgres`](#postgresjs)** or **[`pg`](#node-postgres)**\\ndrivers to access Vercel Postgres through `postgesql://`\\n\\nCheck out the official **[Vercel Postgres + Drizzle](https://vercel.com/docs/storage/vercel-postgres/using-an-orm#drizzle)** docs.\\n\\n#### Step 1 - Install packages\\n\\n<Npm>\\ndrizzle-orm @vercel/postgres\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Prepare Vercel Postgres\\n\\nSetup a project according to the **[official docs.](https://vercel.com/docs/storage/vercel-postgres/quickstart)** \\n\\n#### Step 3 - Initialize the driver and make a query\\n\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\n\\nconst db = drizzle();\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\nimport { sql } from \\'@vercel/postgres\\';\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\n\\nconst db = drizzle({ client: sql })\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\nWith **[@vercel/postgres](https://vercel.com/docs/storage/vercel-postgres)** severless package\\nyou can access Vercel Postgres from either serverful or serverless environments with no TCP available,\\nlike Cloudflare Workers, through websockets.  \\n  \\nIf you\\'re about to use Vercel Postgres from a _serverfull_ environment, you can do it\\neither with `@vercel/postgres` or directly access the DB through `postgesql://` with \\neither **[`postgres`](#postgresjs)** or **[`pg`](#node-postgres)**.\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('connect-xata.mdx'), name='connect-xata.mdx', displayName='connect-xata.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\n\\n# Drizzle \\\\<\\\\> Xata\\n\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- Drizzle PostgreSQL drivers - [docs](/docs/get-started-postgresql)\\n</Prerequisites>\\n\\n**[Xata](https://xata.io)** is a PostgreSQL database platform designed to help developers operate and scale databases with enhanced productivity and performance. Xata provides features like instant copy-on-write database branches, zero-downtime schema changes, data anonymization, AI-powered performance monitoring, and BYOC. \\n\\nCheckout official **[Xata + Drizzle](https://xata.io/documentation/quickstarts/drizzle)** docs.\\n\\n#### Step 1 - Install packages\\n\\n<Npm>\\ndrizzle-orm postgres\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\'\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst allUsers = await db.select().from(...);\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy filename=\"index.ts\"\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\'\\nimport postgres from \\'postgres\\'\\n\\nconst client = postgres(process.env.DATABASE_URL)\\nconst db = drizzle({ client });\\n\\nconst allUsers = await db.select().from(...);\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('custom-types.mdx'), name='custom-types.mdx', displayName='custom-types.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Tab from '@mdx/Tab.astro';\\nimport Tabs from '@mdx/Tabs.astro';\\n\\n# Common way of defining custom types\\n\\n## Examples\\n\\nThe best way to see how `customType` definition is working is to check how existing data types in postgres and mysql could be defined using `customType` function from Drizzle ORM.\\n\\n\\n<Tabs items={['Postgres Data Types', 'MySql Data Types']}>\\n  <Tab>\\n\\n**Serial**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/pg-core';\\n\\nconst customSerial = customType<{ data: number; notNull: true; default: true }>(\\n  {\\n    dataType() {\\n      return 'serial';\\n    },\\n  },\\n);\\n```\\n\\n**Text**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/pg-core';\\n\\nconst customText = customType<{ data: string }>({\\n  dataType() {\\n    return 'text';\\n  },\\n});\\n```\\n\\n**Boolean**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/pg-core';\\n\\nconst customBoolean = customType<{ data: boolean }>({\\n  dataType() {\\n    return 'boolean';\\n  },\\n});\\n```\\n\\n**Jsonb**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/pg-core';\\n\\nconst customJsonb = <TData>(name: string) =>\\n  customType<{ data: TData; driverData: string }>({\\n    dataType() {\\n      return 'jsonb';\\n    },\\n    toDriver(value: TData): string {\\n      return JSON.stringify(value);\\n    },\\n  })(name);\\n```\\n\\n**Timestamp**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/pg-core';\\n\\nconst customTimestamp = customType<\\n  {\\n    data: Date;\\n    driverData: string;\\n    config: { withTimezone: boolean; precision?: number };\\n  }\\n>({\\n  dataType(config) {\\n    const precision = typeof config.precision !== 'undefined'\\n      ? ` (${config.precision})`\\n      : '';\\n    return `timestamp${precision}${\\n      config.withTimezone ? ' with time zone' : ''\\n    }`;\\n  },\\n  fromDriver(value: string): Date {\\n    return new Date(value);\\n  },\\n});\\n```\\n\\nUsage for all types will be same as defined functions in Drizzle ORM. For example:\\n\\n```typescript copy\\nconst usersTable = pgTable('users', {\\n  id: customSerial('id').primaryKey(),\\n  name: customText('name').notNull(),\\n  verified: customBoolean('verified').notNull().default(false),\\n  jsonb: customJsonb<string[]>('jsonb'),\\n  createdAt: customTimestamp('created_at', { withTimezone: true }).notNull()\\n    .default(sql`now()`),\\n});\\n```\\n  </Tab>\\n  <Tab>\\n\\n**Serial**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/mysql-core';\\n\\nconst customInt = customType<{ data: number; notNull: false; default: false }>(\\n  {\\n    dataType() {\\n      return 'int';\\n    },\\n  },\\n);\\n```\\n\\n**Text**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/mysql-core';\\n\\nconst customText = customType<{ data: string }>({\\n  dataType() {\\n    return 'text';\\n  },\\n});\\n```\\n\\n**Boolean**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/mysql-core';\\n\\nconst customBoolean = customType<{ data: boolean }>({\\n  dataType() {\\n    return 'boolean';\\n  },\\n  fromDriver(value) {\\n    if (typeof value === 'boolean') {\\n      return value;\\n    }\\n    return value === 1;\\n  },\\n});\\n```\\n\\n**Json**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/mysql-core';\\n\\nconst customJson = <TData>(name: string) =>\\n  customType<{ data: TData; driverData: string }>({\\n    dataType() {\\n      return 'json';\\n    },\\n    toDriver(value: TData): string {\\n      return JSON.stringify(value);\\n    },\\n  })(name);\\n```\\n\\n**Timestamp**\\n\\n```typescript copy\\nimport { customType } from 'drizzle-orm/mysql-core';\\n\\nconst customTimestamp = customType<\\n  { data: Date; driverData: string; config: { fsp: number } }\\n>({\\n  dataType(config) {\\n    const precision = typeof config.fsp !== 'undefined'\\n      ? ` (${config.fsp})`\\n      : '';\\n    return `timestamp${precision}`;\\n  },\\n  fromDriver(value: string): Date {\\n    return new Date(value);\\n  },\\n});\\n```\\n\\nUsage for all types will be same as defined functions in Drizzle ORM. For example:\\n\\n```typescript copy\\nconst usersTable = mysqlTable('userstest', {\\n  id: customInt('id').primaryKey(),\\n  name: customText('name').notNull(),\\n  verified: customBoolean('verified').notNull().default(false),\\n  jsonb: customJson<string[]>('jsonb'),\\n  createdAt: customTimestamp('created_at', { fsp: 2 }).notNull().default(\\n    sql`now()`,\\n  ),\\n});\\n```\\n\\n  </Tab>\\n</Tabs>\\n\\n## TS-doc for type definitions \\n\\nYou can check ts-doc for `types` and `param` definition.\\n\\n```typescript\\nexport type CustomTypeValues = {\\n  /**\\n   * Required type for custom column, that will infer proper type model\\n   *\\n   * Examples:\\n   *\\n   * If you want your column to be `string` type after selecting/or on inserting - use `data: string`. Like `text`, `varchar`\\n   *\\n   * If you want your column to be `number` type after selecting/or on inserting - use `data: number`. Like `integer`\\n   */\\n  data: unknown;\\n\\n  /**\\n   * Type helper, that represents what type database driver is accepting for specific database data type\\n   */\\n  driverData?: unknown;\\n\\n  /**\\n   * What config type should be used for {@link CustomTypeParams} `dataType` generation\\n   */\\n  config?: Record<string, unknown>;\\n\\n  /**\\n   * If your custom data type should be notNull by default you can use `notNull: true`\\n   *\\n   * @example\\n   * const customSerial = customType<{ data: number, notNull: true, default: true }>({\\n   *    dataType() {\\n   *      return 'serial';\\n   *    },\\n   * });\\n   */\\n  notNull?: boolean;\\n\\n  /**\\n   * If your custom data type has default you can use `default: true`\\n   *\\n   * @example\\n   * const customSerial = customType<{ data: number, notNull: true, default: true }>({\\n   *    dataType() {\\n   *      return 'serial';\\n   *    },\\n   * });\\n   */\\n  default?: boolean;\\n};\\n\\nexport interface CustomTypeParams<T extends CustomTypeValues> {\\n  /**\\n   * Database data type string representation, that is used for migrations\\n   * @example\\n   * ```\\n   * `jsonb`, `text`\\n   * ```\\n   *\\n   * If database data type needs additional params you can use them from `config` param\\n   * @example\\n   * ```\\n   * `varchar(256)`, `numeric(2,3)`\\n   * ```\\n   *\\n   * To make `config` be of specific type please use config generic in {@link CustomTypeValues}\\n   *\\n   * @example\\n   * Usage example\\n   * ```\\n   *   dataType() {\\n   *     return 'boolean';\\n   *   },\\n   * ```\\n   * Or\\n   * ```\\n   *   dataType(config) {\\n   *     return typeof config.length !== 'undefined' ? `varchar(${config.length})` : `varchar`;\\n   *   }\\n   * ```\\n   */\\n  dataType: (config: T['config']) => string;\\n\\n  /**\\n   * Optional mapping function, between user input and driver\\n   * @example\\n   * For example, when using jsonb we need to map JS/TS object to string before writing to database\\n   * ```\\n   * toDriver(value: TData): string {\\n   *   return JSON.stringify(value);\\n   * }\\n   * ```\\n   */\\n  toDriver?: (value: T['data']) => T['driverData'];\\n\\n  /**\\n   * Optional mapping function, that is responsible for data mapping from database to JS/TS code\\n   * @example\\n   * For example, when using timestamp we need to map string Date representation to JS Date\\n   * ```\\n   * fromDriver(value: string): Date {\\n   *  return new Date(value);\\n   * },\\n   * ```\\n   */\\n  fromDriver?: (value: T['driverData']) => T['data'];\\n}\\n```\\n\", children=[]),\n",
       " DocItem(origPath=Path('data-querying.mdx'), name='data-querying.mdx', displayName='data-querying.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Flex from \"@mdx/Flex.astro\"\\nimport LinksList from \"@mdx/LinksList.astro\"\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n# Drizzle Queries + CRUD\\n\\n<Prerequisites>\\n  - How to define your schema - [Schema Fundamentals](/docs/sql-schema-declaration)\\n  - How to connect to the database - [Connection Fundamentals](/docs/connect-overview)\\n</Prerequisites>\\n\\nDrizzle gives you a few ways for querying your database and it\\'s up to you to decide which one you\\'ll need in your next project.\\nIt can be either SQL-like syntax or Relational Syntax. Let\\'s check them:\\n\\n## Why SQL-like?\\n\\\\\\n**If you know SQL, you know Drizzle.**\\n\\nOther ORMs and data frameworks tend to deviate from or abstract away SQL, leading to a double learning curve: you need to learn both SQL and the framework\\'s API.\\n\\nDrizzle is the opposite.\\nWe embrace SQL and built Drizzle to be SQL-like at its core, so you have little to no learning curve and full access to the power of SQL.\\n\\n<Section>\\n```typescript copy\\n// Access your data\\nawait db\\n  .select()\\n\\t.from(posts)\\n\\t.leftJoin(comments, eq(posts.id, comments.post_id))\\n\\t.where(eq(posts.id, 10))\\n```\\n```sql\\nSELECT * \\nFROM posts\\nLEFT JOIN comments ON posts.id = comments.post_id\\nWHERE posts.id = 10\\n```\\n</Section>\\n\\nWith SQL-like syntax, you can replicate much of what you can do with pure SQL and know \\nexactly what Drizzle will do and what query will be generated. You can perform a wide range of queries, \\nincluding select, insert, update, delete, as well as using aliases, WITH clauses, subqueries, prepared statements, \\nand more. Let\\'s look at more examples\\n\\n<CodeTabs items={[\\'insert\\', \\'update\\', \\'delete\\']}>\\n<Section>\\n```ts\\nawait db.insert(users).values({ email: \\'user@gmail.com\\' })\\n```\\n```sql\\nINSERT INTO users (email) VALUES (\\'user@gmail.com\\')\\n```\\n</Section>\\n<Section>\\n```ts\\nawait db.update(users)\\n        .set({ email: \\'user@gmail.com\\' })\\n        .where(eq(users.id, 1))\\n```\\n```sql\\nUPDATE users \\nSET email = \\'user@gmail.com\\'\\nWHERE users.id = 1\\n```\\n</Section>\\n<Section>\\n```ts\\nawait db.delete(users).where(eq(users.id, 1))\\n```\\n```sql\\nDELETE FROM users WHERE users.id = 1\\n```\\n</Section>\\n</CodeTabs>\\n\\n## Why not SQL-like?\\n\\nWe\\'re always striving for a perfectly balanced solution. While SQL-like queries cover 100% of your needs, \\nthere are certain common scenarios where data can be queried more efficiently.\\n\\nWe\\'ve built the Queries API so you can fetch relational, nested data from the database in the most convenient \\nand performant way, without worrying about joins or data mapping.\\n\\n**Drizzle always outputs exactly one SQL query**. Feel free to use it with serverless databases,\\nand never worry about performance or roundtrip costs!\\n\\n<Section>\\n```ts\\nconst result = await db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: true\\n\\t},\\n});\\n```\\n{/* ```sql\\nSELECT * FROM users ...\\n``` */}\\n</Section>\\n\\n## Advanced\\nWith Drizzle, queries can be composed and partitioned in any way you want. You can compose filters \\nindependently from the main query, separate subqueries or conditional statements, and much more. \\nLet\\'s check a few advanced examples:\\n\\n#### Compose a WHERE statement and then use it in a query\\n```ts\\nasync function getProductsBy({\\n  name,\\n  category,\\n  maxPrice,\\n}: {\\n  name?: string;\\n  category?: string;\\n  maxPrice?: string;\\n}) {\\n  const filters: SQL[] = [];\\n\\n  if (name) filters.push(ilike(products.name, name));\\n  if (category) filters.push(eq(products.category, category));\\n  if (maxPrice) filters.push(lte(products.price, maxPrice));\\n\\n  return db\\n    .select()\\n    .from(products)\\n    .where(and(...filters));\\n}\\n```\\n\\n#### Separate subqueries into different variables, and then use them in the main query\\n```ts\\nconst subquery = db\\n\\t.select()\\n\\t.from(internalStaff)\\n\\t.leftJoin(customUser, eq(internalStaff.userId, customUser.id))\\n\\t.as(\\'internal_staff\\');\\n\\nconst mainQuery = await db\\n\\t.select()\\n\\t.from(ticket)\\n\\t.leftJoin(subquery, eq(subquery.internal_staff.userId, ticket.staffId));\\n```\\n\\n#### What\\'s next?\\n<br/>\\n<Flex>\\n  <LinksList \\n    title=\\'Access your data\\'\\n    links={[\\n        [\"Query\", \"/docs/rqb\"], \\n        [\"Select\", \"/docs/select\"],\\n        [\"Insert\", \"/docs/insert\"],\\n        [\"Update\", \"/docs/update\"],\\n        [\"Delete\", \"/docs/delete\"],\\n        [\"Filters\", \"/docs/operators\"],\\n        [\"Joins\", \"/docs/joins\"],\\n        [\"sql`` operator\", \"/docs/sql\"],\\n      ]}\\n  />\\n  <LinksList \\n    title=\\'Zero to Hero\\'\\n    links={[\\n        [\"Migrations\", \"/docs/migrations\"], \\n      ]}\\n  />\\n</Flex>\\n', children=[]),\n",
       " DocItem(origPath=Path('delete.mdx'), name='delete.mdx', displayName='delete.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# SQL Delete\\nYou can delete all rows in the table:\\n```typescript copy\\nawait db.delete(users);\\n```\\nAnd you can delete with filters and conditions:\\n```typescript copy\\nawait db.delete(users).where(eq(users.name, \\'Dan\\'));\\n```\\n\\n### Limit\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': false, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n\\nUse `.limit()` to add `limit` clause to the query - for example:\\n<Section>\\n```typescript\\nawait db.delete(users).where(eq(users.name, \\'Dan\\')).limit(2);\\n```\\n```sql\\ndelete from \"users\" where \"users\".\"name\" = $1 limit $2;\\n```\\n</Section>\\n\\n### Order By\\nUse `.orderBy()` to add `order by` clause to the query, sorting the results by the specified fields:\\n<Section>\\n```typescript\\nimport { asc, desc } from \\'drizzle-orm\\';\\n\\nawait db.delete(users).where(eq(users.name, \\'Dan\\')).orderBy(users.name);\\nawait db.delete(users).where(eq(users.name, \\'Dan\\')).orderBy(desc(users.name));\\n\\n// order by multiple fields\\nawait db.delete(users).where(eq(users.name, \\'Dan\\')).orderBy(users.name, users.name2);\\nawait db.delete(users).where(eq(users.name, \\'Dan\\')).orderBy(asc(users.name), desc(users.name2));\\n```\\n```sql\\ndelete from \"users\" where \"users\".\"name\" = $1 order by \"name\";\\ndelete from \"users\" where \"users\".\"name\" = $1 order by \"name\" desc;\\n\\ndelete from \"users\" where \"users\".\"name\" = $1 order by \"name\", \"name2\";\\ndelete from \"users\" where \"users\".\"name\" = $1 order by \"name\" asc, \"name2\" desc;\\n```\\n</Section>\\n\\n### Delete with return\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': false, \\'SingleStore\\': false}} />\\nYou can delete a row and get it back in PostgreSQL and SQLite:\\n```typescript copy\\nconst deletedUser = await db.delete(users)\\n  .where(eq(users.name, \\'Dan\\'))\\n  .returning();\\n\\n// partial return\\nconst deletedUserIds: { deletedId: number }[] = await db.delete(users)\\n  .where(eq(users.name, \\'Dan\\'))\\n  .returning({ deletedId: users.id });\\n```\\n\\n## WITH DELETE clause\\n\\n<Callout>\\n  Check how to use WITH statement with [select](/docs/select#with-clause), [insert](/docs/insert#with-insert-clause), [update](/docs/update#with-update-clause)\\n</Callout>\\n\\nUsing the `with` clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\\n<Section>\\n```typescript copy\\nconst averageAmount = db.$with(\\'average_amount\\').as(\\n  db.select({ value: sql`avg(${orders.amount})`.as(\\'value\\') }).from(orders)\\n);\\n\\nconst result = await db\\n\\t.with(averageAmount)\\n\\t.delete(orders)\\n\\t.where(gt(orders.amount, sql`(select * from ${averageAmount})`))\\n\\t.returning({\\n\\t\\tid: orders.id\\n\\t});\\n```\\n```sql\\nwith \"average_amount\" as (select avg(\"amount\") as \"value\" from \"orders\") \\ndelete from \"orders\" \\nwhere \"orders\".\"amount\" > (select * from \"average_amount\") \\nreturning \"id\"\\n```\\n</Section>', children=[]),\n",
       " DocItem(origPath=Path('drizzle-config-file.mdx'), name='drizzle-config-file.mdx', displayName='drizzle-config-file.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport SchemaFilePaths from \"@mdx/SchemaFilePaths.mdx\"\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\nimport Dialects from \"@mdx/Dialects.mdx\"\\nimport Drivers from \"@mdx/Drivers.mdx\"\\nimport DriversExamples from \"@mdx/DriversExamples.mdx\"\\nimport Npx from \"@mdx/Npx.astro\"\\n\\n# Drizzle Kit configuration file\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n</Prerequisites>\\n\\nDrizzle Kit lets you declare configuration options in `TypeScript` or `JavaScript` configuration files.\\n\\n<Section>\\n```plaintext {5}\\nðŸ“¦ <project root>\\n â”œ ...\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ package.json\\n```\\n<CodeTabs items={[\"drizzle.config.ts\", \"drizzle.config.js\"]}>\\n<CodeTab>\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  out: \"./drizzle\",\\n});\\n```\\n</CodeTab>\\n<CodeTab>\\n```js\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  out: \"./drizzle\",\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n</Section>\\n\\nExample of an extended config file\\n```ts collapsable\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  out: \"./drizzle\",\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n\\n  driver: \"pglite\",\\n  dbCredentials: {\\n    url: \"./database/\",\\n  },\\n\\n  extensionsFilters: [\"postgis\"],\\n  schemaFilter: \"public\",\\n  tablesFilter: \"*\",\\n\\n  introspect: {\\n    casing: \"camel\",\\n  },\\n\\n  migrations: {\\n    prefix: \"timestamp\",\\n    table: \"__drizzle_migrations__\",\\n    schema: \"public\",\\n  },\\n\\n  entities: {\\n    roles: {\\n      provider: \\'\\',\\n      exclude: [],\\n      include: []\\n    }\\n  },\\n\\n  breakpoints: true,\\n  strict: true,\\n  verbose: true,\\n});\\n```\\n\\n### Multiple configuration files\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n<Npx>\\n  drizzle-kit generate --config=drizzle-dev.config.ts\\n  drizzle-kit generate --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Migrations folder\\n`out` param lets you define folder for your migrations, it\\'s optional and `drizzle` by default.  \\nIt\\'s very useful since you can have many separate schemas for different databases in the same project \\nand have different migration folders for them.  \\n  \\nMigration folder contains `.sql` migration files and `_meta` folder which is used by `drizzle-kit`\\n\\n<Section>\\n```plaintext {3}\\nðŸ“¦ <project root>\\n â”œ ...\\n â”œ ðŸ“‚ drizzle\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”œ ðŸ“œ user.ts \\n â”‚ â”œ ðŸ“œ post.ts \\n â”‚ â”” ðŸ“œ comment.ts \\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ package.json\\n```\\n```ts {5}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\", // \"mysql\" | \"sqlite\" | \"postgresql\" | \"turso\" | \"singlestore\"\\n  schema: \"./src/schema/*\",\\n  out: \"./drizzle\",\\n});\\n```\\n</Section>\\n\\n## ---\\n\\n### `dialect`\\n<rem025/>\\n\\nDialect of the database you\\'re using \\n|               |                                                 |\\n| :------------ | :-----------------------------------            |\\n| type        | <Dialects/>                                     |\\n| default        | --                                     |\\n| commands    | `generate` `migrate` `push` `pull` `check` `up` |\\n\\n<rem025/>\\n```ts {4}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"mysql\", \\n});\\n```\\n\\n\\n### `schema`\\n<rem025/>\\n\\n[`glob`](https://www.digitalocean.com/community/tools/glob?comments=true&glob=/**/*.js&matches=false&tests=//%20This%20will%20match%20as%20it%20ends%20with%20\\'.js\\'&tests=/hello/world.js&tests=//%20This%20won\\'t%20match!&tests=/test/some/globs)\\n based path to drizzle schema file(s) or folder(s) contaning schema files.\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `string` `string[]` |\\n| default        | --                    |\\n| commands      | `generate` `push`    |\\n\\n<rem025/>\\n<SchemaFilePaths />\\n\\n\\n### `out`\\n<rem025/>\\n\\nDefines output folder of your SQL migration files, json snapshots of your schema and `schema.ts` from `drizzle-kit pull` command.\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `string` `string[]` |\\n| default        | `drizzle`                    |\\n| commands      | `generate` `migrate` `push` `pull` `check` `up`    |\\n\\n<rem025/>\\n```ts {4}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  out: \"./drizzle\", \\n});\\n```\\n\\n### `driver`\\n<rem025/>\\n\\nDrizzle Kit automatically picks available database driver from your current project based on the provided `dialect`, \\nyet some vendor specific databases require a different subset of connection params.\\n\\n`driver` option let\\'s you explicitely pick those exceptions drivers.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | <Drivers/> |\\n| default        | --                    |\\n| commands      | `migrate` `push` `pull`   |\\n\\n<rem025/>\\n\\n<DriversExamples/>\\n\\n## ---\\n\\n### `dbCredentials`\\n<rem025/>\\n\\nDatabase connection credentials in a form of `url`, \\n`user:password@host:port/db` params or exceptions drivers(<Drivers/>) specific connection options.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | union of drivers connection options |\\n| default       | --                    |\\n| commands      | `migrate` `push` `pull`   |\\n\\n<rem025/>\\n\\n<CodeTabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"Turso\", \"Cloudflare D1\", \"AWS Data API\", \"PGLite\"]}>\\n<Section>\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: \"postgres://user:password@host:port/db\",\\n  }\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\n// via connection params\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    host: \"host\",\\n    port: 5432,\\n    user: \"user\",\\n    password: \"password\",\\n    database: \"dbname\",\\n    ssl: true, // can be boolean | \"require\" | \"allow\" | \"prefer\" | \"verify-full\" | options from node:tls\\n  }\\n});\\n```\\n</Section>\\n<Section>\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"mysql\",\\n  dbCredentials: {\\n    url: \"mysql://user:password@host:port/db\",\\n  }\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\n// via connection params\\nexport default defineConfig({\\n  dialect: \"mysql\",\\n  dbCredentials: {\\n    host: \"host\",\\n    port: 5432,\\n    user: \"user\",\\n    password: \"password\",\\n    database: \"dbname\",\\n    ssl: \"...\", // can be: string | SslOptions (ssl options from mysql2 package)\\n  }\\n});\\n```\\n</Section>\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"sqlite\",\\n  dbCredentials: {\\n    url: \":memory:\", // inmemory database\\n    // or\\n    url: \"sqlite.db\", \\n    // or\\n    url: \"file:sqlite.db\" // file: prefix is required by libsql\\n  }\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"turso\",\\n  dbCredentials: {\\n    url: \"libsql://acme.turso.io\" // remote Turso database url\\n    authToken: \"...\",\\n\\n    // or if you need local db\\n\\n    url: \":memory:\", // inmemory database\\n    // or\\n    url: \"file:sqlite.db\", // file: prefix is required by libsql\\n  }\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"sqlite\",\\n  driver: \"d1-http\",\\n  dbCredentials: {\\n    accountId: \"\",\\n    databaseId: \"\",\\n    token: \"\",\\n  }\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  driver: \"aws-data-api\",\\n  dbCredentials: {\\n    database: \"database\",\\n    resourceArn: \"resourceArn\",\\n    secretArn: \"secretArn\",\\n  },\\n});\\n```\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  driver: \"pglite\",\\n  dbCredentials: {\\n    url: \"./database/\", // database folder path\\n  }\\n});\\n```\\n</CodeTabs>\\n\\n### `migrations`\\n<rem025/>\\n\\nWhen running `drizzle-kit migrate` - drizzle will records about \\nsuccessfully applied migrations in your database in log table named `__drizzle_migrations` in `public` schema(PostgreSQL only).\\n\\n`migrations` config options lets you change both migrations log `table` name and `schema`.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `{ table: string, schema: string }` |\\n| default       | `{ table: \"__drizzle_migrations\", schema: \"drizzle\" }`                    |\\n| commands      | `migrate`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  migrations: {\\n    table: \\'my-migrations-table\\', // `__drizzle_migrations` by default\\n    schema: \\'public\\', // used in PostgreSQL only, `drizzle` by default\\n  },\\n});\\n```\\n\\n### `introspect`\\n<rem025/>\\n\\nConfiguration for `drizzle-kit pull` command.\\n\\n`casing` is responsible for in-code column keys casing\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `{ casing: \"preserve\" \\\\| \"camel\" }` |\\n| default       | `{ casing: \"camel\" }`                    |\\n| commands      | `pull`   |\\n\\n<rem025/>\\n\\n<CodeTabs items={[\"camel\", \"preserve\"]}>\\n<Section>\\n```ts\\nimport * as p from \"drizzle-orm/pg-core\"\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial(),\\n  firstName: p.text(\"first-name\"),\\n  lastName: p.text(\"LastName\"),\\n  email: p.text(),\\n  phoneNumber: p.text(\"phone_number\"),\\n});\\n```\\n```sql\\nSELECT a.attname AS column_name, format_type(a.atttypid, a.atttypmod) as data_type FROM pg_catalog.pg_attribute a;\\n```\\n``` \\n column_name   | data_type        \\n---------------+------------------------\\n id            | serial\\n first-name    | text\\n LastName      | text\\n email         | text\\n phone_number  | text\\n```\\n</Section>\\n<Section>\\n```ts\\nimport * as p from \"drizzle-orm/pg-core\"\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial(),\\n  \"first-name\": p.text(\"first-name\"),\\n  LastName: p.text(\"LastName\"),\\n  email: p.text(),\\n  phone_number: p.text(\"phone_number\"),\\n});\\n```\\n```sql\\nSELECT a.attname AS column_name, format_type(a.atttypid, a.atttypmod) as data_type FROM pg_catalog.pg_attribute a;\\n```\\n``` \\n column_name   | data_type        \\n---------------+------------------------\\n id            | serial\\n first-name    | text\\n LastName      | text\\n email         | text\\n phone_number  | text\\n```\\n</Section>\\n</CodeTabs>\\n\\n\\n## --- \\n\\n### `tablesFilter`\\n<Callout>\\nIf you want to run multiple projects with one database - check out [our guide](/docs/goodies#multi-project-schema).\\n</Callout>\\n<rem025/>\\n`drizzle-kit push` and `drizzle-kit pull` will by default manage all tables in `public` schema.\\nYou can configure list of tables, schemas and extensions via `tablesFilters`, `schemaFilter` and `extensionFilters` options.\\n\\n`tablesFilter` option lets you specify [`glob`](https://www.digitalocean.com/community/tools/glob?comments=true&glob=/**/*.js&matches=false&tests=//%20This%20will%20match%20as%20it%20ends%20with%20\\'.js\\'&tests=/hello/world.js&tests=//%20This%20won\\'t%20match!&tests=/test/some/globs) \\nbased table names filter, e.g. `[\"users\", \"user_info\"]` or `\"user*\"`\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `string` `string[]` |\\n| default       | --                    |\\n| commands      | `generate` `push` `pull`   |\\n\\n<rem025/>\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  tablesFilter: [\"users\", \"posts\", \"project1_*\"],\\n});\\n```\\n\\n### `schemaFilter`\\n<Callout>\\nIf you want to run multiple projects with one database - check out [our guide](/docs/goodies#multi-project-schema).\\n</Callout>\\n\\n<rem025/>\\n`drizzle-kit push` and `drizzle-kit pull` will by default manage all tables in `public` schema.\\nYou can configure list of tables, schemas and extensions via `tablesFilters`, `schemaFilter` and `extensionFilters` options.\\n\\n`schemaFilter` option lets you specify list of schemas for Drizzle Kit to manage\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `string[]` |\\n| default       | `[\"public\"]`                    |\\n| commands      | `push` `pull`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schemaFilter: [\"public\", \"schema1\", \"schema2\"],\\n});\\n```\\n\\n### `extensionsFilters`\\n<rem025/>\\n\\nSome extensions like [`postgis`](https://postgis.net/), when installed on the database, create its own tables in public schema. \\nThose tables have to be ignored by `drizzle-kit push` or `drizzle-kit pull`.\\n\\n`extensionsFilters` option lets you declare list of installed extensions for drizzle kit to ignore their tables in the schema.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `[\"postgis\"]` |\\n| default       | `[]`                    |\\n| commands      | `push` `pull`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  extensionsFilters: [\"postgis\"],\\n});\\n```\\n\\n## ---\\n\\n### `entities`\\n\\nThis configuration is created to set up management settings for specific `entities` in the database. \\n\\nFor now, it only includes `roles`, but eventually all database entities will migrate here, such as `tables`, `schemas`, `extensions`, `functions`, `triggers`, etc\\n\\n#### `roles`\\n\\n<rem025/>\\n\\nIf you are using Drizzle Kit to manage your schema and especially the defined roles, there may be situations where you have some roles that are not defined in the Drizzle schema. \\nIn such cases, you may want Drizzle Kit to skip those `roles` without the need to write each role in your Drizzle schema and mark it with `.existing()`.\\n\\nThe `roles` option lets you:\\n\\n- Enable or disable role management with Drizzle Kit.\\n- Exclude specific roles from management by Drizzle Kit.\\n- Include specific roles for management by Drizzle Kit.\\n- Enable modes for providers like `Neon` and `Supabase`, which do not manage their specific roles.\\n- Combine all the options above\\n\\n|               |                       |\\n| :------------ | :-----------------    |\\n| type          | `boolean \\\\| { provider: \"neon\" \\\\| \"supabase\", include: string[], exclude: string[]}`|\\n| default       | `false`                  |\\n| commands      | `push` `pull` `generate` |\\n\\n<rem025/>\\n\\nBy default, `drizzle-kit` won\\'t manage roles for you, so you will need to enable that. in `drizzle.config.ts`\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  entities: {\\n    roles: true\\n  }\\n});\\n```\\n\\n**You have a role `admin` and want to exclude it from the list of manageable roles**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      exclude: [\\'admin\\']\\n    }\\n  }\\n});\\n```\\n\\n**You have a role `admin` and want to include to the list of manageable roles**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      include: [\\'admin\\']\\n    }\\n  }\\n});\\n```\\n\\n**If you are using `Neon` and want to exclude roles defined by `Neon`, you can use the provider option**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'neon\\'\\n    }\\n  }\\n});\\n```\\n\\n**If you are using `Supabase` and want to exclude roles defined by `Supabase`, you can use the provider option**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'supabase\\'\\n    }\\n  }\\n});\\n```\\n\\n<Callout title=\\'important\\'>\\nYou may encounter situations where Drizzle is slightly outdated compared to new roles specified by database providers, \\nso you may need to use both the `provider` option and `exclude` additional roles. You can easily do this with Drizzle:\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'supabase\\',\\n      exclude: [\\'new_supabase_role\\']\\n    }\\n  }\\n});\\n```\\n</Callout>\\n\\n## ---\\n\\n### `strict`\\n<rem025/>\\n\\nPrompts confirmation to run printed SQL statements when running `drizzle-kit push` command.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `boolean` |\\n| default       | `false`                    |\\n| commands      | `push`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  strict: false,\\n});\\n```\\n\\n### `verbose`\\n<rem025/>\\n\\nPrint all SQL statements during `drizzle-kit push` command.\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `boolean` |\\n| default       | `true`                    |\\n| commands      | `generate` `pull`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  verbose: false,\\n});\\n```\\n\\n### `breakpoints`\\n<rem025/>\\n\\nDrizzle Kit will automatically embed `--> statement-breakpoint` into generated SQL migration files, \\nthat\\'s necessary for databases that do not support multiple DDL alternation statements in one transaction(MySQL and SQLite).\\n\\n`breakpoints` option flag lets you switch it on and off\\n\\n|               |                      |\\n| :------------ | :-----------------   |\\n| type          | `boolean` |\\n| default       | `true`                    |\\n| commands      | `generate` `pull`   |\\n\\n<rem025/>\\n\\n```ts\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  breakpoints: false,\\n});\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-check.mdx'), name='drizzle-kit-check.mdx', displayName='drizzle-kit-check.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\n\\n\\n# `drizzle-kit check`\\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n- `drizzle-kit generate` command - [read here](/docs/drizzle-kit-generate)\\n</Prerequisites>\\n\\n`drizzle-kit check` command lets you check consistency of your generated SQL migrations history.\\n\\nThat\\'s extremely useful when you have multiple developers working on the project and \\naltering database schema on different branches - read more about [migrations for teams](/docs/kit-migrations-for-teams).\\n\\n<br/>\\n<hr/>\\n<br/>\\n\\n`drizzle-kit check` command requires you to specify both `dialect` and database connection credentials, \\nyou can provide them either via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options\\n\\n<CodeTabs items={[\"With config file\", \"As CLI options\"]}>\\n<Section>\\n```ts {5,8}\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n});\\n```\\n```shell\\nnpx drizzle-kit check\\n```\\n</Section>\\n```shell\\nnpx drizzle-kit check --dialect=postgresql\\n```\\n</CodeTabs>\\n\\n### Multiple configuration files in one project\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases on the same project:\\n<Npx>\\n  drizzle-kit migrate --config=drizzle-dev.config.ts\\n  drizzle-kit migrate --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Extended list of configurations\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n<rem025/>\\n|           |            |                                                                         |\\n| :-------- | :--------- | :---------------------------------------------------------------------- |\\n| `dialect` | `required` | Database dialect you are using. Can be `postgresql`,`mysql` or `sqlite` |\\n| `out`     |            | Migrations folder, default=`./drizzle`                                  |\\n| `config`  |            | Configuration file path, default=`drizzle.config.ts`                           |\\n<br/>\\n<Npx>\\ndrizzle-kit check --dialect=postgresql\\ndrizzle-kit check --dialect=postgresql --out=./migrations-folder\\n</Npx>\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-export.mdx'), name='drizzle-kit-export.mdx', displayName='drizzle-kit-export.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\nimport Npx from \"@mdx/Npx.astro\";\\nimport SchemaFilePaths from \"@mdx/SchemaFilePaths.mdx\"\\nimport Dialects from \"@mdx/Dialects.mdx\"\\n\\n# `drizzle-kit export` \\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n</Prerequisites>\\n\\n\\n<br/>\\n\\n`drizzle-kit export` lets you export SQL representation of Drizzle schema and print in console SQL DDL representation on it.\\n<Callout collapsed=\"How it works under the hood?\">\\nDrizzle Kit `export` command triggers a sequence of events:\\n1. It will read through your Drizzle schema file(s) and compose a json snapshot of your schema\\n3. Based on json differences it will generate SQL DDL statements\\n4. Output SQL DDL statements to console\\n</Callout>\\n\\nIt\\'s designed to cover [codebase first](/docs/migrations) approach of managing Drizzle migrations. \\nYou can export the SQL representation of the Drizzle schema, allowing external tools like Atlas to handle all the migrations for you\\n\\n`drizzle-kit export` command requires you to provide both `dialect` and `schema` path options, \\nyou can set them either via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options\\n<CodeTabs items={[\"With config file\", \"As CLI options\"]}>\\n<Section>\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n});\\n```\\n```shell\\nnpx drizzle-kit export\\n```\\n</Section>\\n\\n```shell\\nnpx drizzle-kit export --dialect=postgresql --schema=./src/schema.ts\\n```\\n</CodeTabs>\\n\\n### Schema files path\\nYou can have a single `schema.ts` file or as many schema files as you want spread out across the project. \\nDrizzle Kit requires you to specify path(s) to them as a [glob](https://www.digitalocean.com/community/tools/glob?comments=true&glob=/**/*.js&matches=false&tests=//%20This%20will%20match%20as%20it%20ends%20with%20\\'.js\\'&tests=/hello/world.js&tests=//%20This%20won\\'t%20match!&tests=/test/some/globs) via `schema` configuration option.\\n\\n<SchemaFilePaths/>\\n\\n### Multiple configuration files in one project\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n<Npx>\\n  drizzle-kit export --config=drizzle-dev.config.ts\\n  drizzle-kit export --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Extended list of available configurations\\n`drizzle-kit export` has a list of cli-only options\\n\\n<rem025/>\\n\\n|               |                                                      |\\n| :--------     | :--------------------------------------------------- |\\n| `--sql`       | generating SQL representation of Drizzle Schema               |\\n\\nBy default, Drizzle Kit outputs SQL files, but in the future, we want to support different formats\\n\\n<rem025/>\\n\\n<Npx>\\ndrizzle-kit push --name=init\\ndrizzle-kit push --name=seed_users --custom\\n</Npx>\\n\\n<br/>\\n<hr/>\\n<br/>\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n\\n|               |            |                                                                            |\\n| :------------ | :-------   | :----------------------------------------------------------------------    |\\n| `dialect`     | `required` | Database dialect, one of <Dialects/>                                       |\\n| `schema`      | `required` | Path to typescript schema file(s) or folder(s) with multiple schema files  |\\n| `config`      |            | Configuration file path, default is `drizzle.config.ts`                    |\\n\\n### Example\\nExample of how to export drizzle schema to console with Drizzle schema located in `./src/schema.ts`\\n\\nWe will also place drizzle config file in the `configs` folder.\\n\\nLet\\'s create config file:\\n\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ configs\\n â”‚ â”” ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“‚ src\\n â”‚ â”” ðŸ“œ schema.ts\\n â”” â€¦\\n```\\n```ts filename=\\'drizzle.config.ts\\'\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n});\\n```\\n\\n```ts filename=\\'schema.ts\\'\\nimport { pgTable, serial, text } from \\'drizzle-orm/pg-core\\'\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\temail: text(\\'email\\').notNull(),\\n\\tname: text(\\'name\\')\\n});\\n```\\n\\nNow let\\'s run\\n```shell\\nnpx drizzle-kit export --config=./configs/drizzle.config.ts\\n```\\nAnd it will successfully output SQL representation of drizzle schema\\n```bash\\nCREATE TABLE \"users\" (\\n        \"id\" serial PRIMARY KEY NOT NULL,\\n        \"email\" text NOT NULL,\\n        \"name\" text\\n);\\n```', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-generate.mdx'), name='drizzle-kit-generate.mdx', displayName='drizzle-kit-generate.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\nimport Npx from \"@mdx/Npx.astro\";\\nimport SchemaFilePaths from \"@mdx/SchemaFilePaths.mdx\"\\nimport Dialects from \"@mdx/Dialects.mdx\"\\n\\n# `drizzle-kit generate` \\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n</Prerequisites>\\n\\n\\n<br/>\\n\\n`drizzle-kit generate` lets you generate SQL migrations based on your Drizzle schema upon declaration or on subsequent schema changes.\\n<Callout collapsed=\"How it works under the hood?\">\\nDrizzle Kit `generate` command triggers a sequence of events:\\n1. It will read through your Drizzle schema file(s) and compose a json snapshot of your schema\\n2. It will read through your previous migrations folders and compare current json snapshot to the most recent one\\n3. Based on json differences it will generate SQL migrations\\n4. Save `migration.sql` and `snapshot.json` in migration folder under current timestamp\\n\\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"./drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(), \\n};\\n```\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit generate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  â”” 1. read previous migration folders\\n    2. find diff between current and previous scheama\\n    3. prompt developer for renames if necessary\\n  â”Œ 4. generate SQL migration and persist to file\\n  â”‚    â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  \\n  â”‚      ðŸ“‚ drizzle       \\n  â”‚      â”œ ðŸ“‚ _meta\\n  â”‚      â”” ðŸ“œ 0000_premium_mister_fear.sql\\n  v\\n```\\n```sql\\n-- drizzle/0000_premium_mister_fear.sql\\n\\nCREATE TABLE \"users\" (\\n \"id\" SERIAL PRIMARY KEY,\\n \"name\" TEXT,\\n \"email\" TEXT UNIQUE\\n);\\n```\\n</Section>\\n</Callout>\\n\\nIt\\'s designed to cover [code first](/docs/migrations) approach of managing Drizzle migrations. \\nYou can apply generated migrations using [`drizzle-kit migrate`](/docs/drizzle-kit-migrate), using drizzle-orm\\'s `migrate()`, \\nusing external migration tools like [bytebase](https://www.bytebase.com/) or running migrations yourself directly on the database. \\n\\n`drizzle-kit generate` command requires you to provide both `dialect` and `schema` path options, \\nyou can set them either via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options\\n<CodeTabs items={[\"With config file\", \"As CLI options\"]}>\\n<Section>\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n});\\n```\\n```shell\\nnpx drizzle-kit generate\\n```\\n</Section>\\n\\n```shell\\nnpx drizzle-kit generate --dialect=postgresql --schema=./src/schema.ts\\n```\\n</CodeTabs>\\n\\n### Schema files path\\nYou can have a single `schema.ts` file or as many schema files as you want spread out across the project. \\nDrizzle Kit requires you to specify path(s) to them as a [glob](https://www.digitalocean.com/community/tools/glob?comments=true&glob=/**/*.js&matches=false&tests=//%20This%20will%20match%20as%20it%20ends%20with%20\\'.js\\'&tests=/hello/world.js&tests=//%20This%20won\\'t%20match!&tests=/test/some/globs) via `schema` configuration option.\\n\\n<SchemaFilePaths/>\\n\\n\\n### Custom migration file name\\nYou can set custom migration file names by providing `--name` CLI option\\n```shell\\nnpx drizzle-kit generate --name=init\\n```\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”” ðŸ“œ 0000_init.sql \\n â”œ ðŸ“‚ src\\n â”” â€¦\\n```\\n\\n### Multiple configuration files in one project\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n<Npx>\\n  drizzle-kit generate --config=drizzle-dev.config.ts\\n  drizzle-kit generate --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Custom migrations\\nYou can generate empty migration files to write your own custom SQL migrations \\nfor DDL alternations currently not supported by Drizzle Kit or data seeding. Extended docs on custom migrations - [see here](/docs/kit-custom-migrations)\\n\\n```shell\\ndrizzle-kit generate --custom --name=seed-users\\n```\\n<Section>\\n```plaintext {5}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”œ ðŸ“œ 0000_init.sql \\n â”‚ â”” ðŸ“œ 0001_seed-users.sql \\n â”œ ðŸ“‚ src\\n â”” â€¦\\n```\\n```sql\\n-- ./drizzle/0001_seed-users.sql\\n\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dan\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Andrew\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dandrew\\');\\n```\\n</Section>\\n\\n### Extended list of available configurations\\n`drizzle-kit generate` has a list of cli-only options\\n\\n<rem025/>\\n\\n|               |                                                      |\\n| :--------     | :--------------------------------------------------- |\\n| `custom`      | generate empty SQL for custom migration              |\\n| `name`        | generate migration with custom name                  |\\n\\n<rem025/>\\n\\n<Npx>\\ndrizzle-kit generate --name=init\\ndrizzle-kit generate --name=seed_users --custom\\n</Npx>\\n\\n<br/>\\n<hr/>\\n<br/>\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n\\n|               |            |                                                                            |\\n| :------------ | :-------   | :----------------------------------------------------------------------    |\\n| `dialect`     | `required` | Database dialect, one of <Dialects/>                                       |\\n| `schema`      | `required` | Path to typescript schema file(s) or folder(s) with multiple schema files  |\\n| `out`         |            | Migrations output folder, default is `./drizzle`                           |\\n| `config`      |            | Configuration file path, default is `drizzle.config.ts`                    |\\n| `breakpoints` |            | SQL statements breakpoints, default is `true`                              |\\n\\n\\n### Extended example\\nExample of how to create a custom postgresql migration file named `0001_seed-users.sql` \\nwith Drizzle schema located in `./src/schema.ts` and migrations folder named `./migrations` instead of default `./drizzle`.\\n\\nWe will also place drizzle config file in the `configs` folder.\\n\\nLet\\'s create config file:\\n\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ migrations\\n â”œ ðŸ“‚ configs\\n â”‚ â”” ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“‚ src\\n â”” â€¦\\n```\\n```ts filename=\\'drizzle.config.ts\\'\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  out: \"./migrations\",\\n});\\n```\\n\\nNow let\\'s run\\n```shell\\nnpx drizzle-kit generate --config=./configs/drizzle.config.ts --name=seed-users --custom\\n```\\nAnd it will successfully generate\\n<Section>\\n```plaintext {6}\\nðŸ“¦ <project root>\\n â”œ â€¦\\n â”œ ðŸ“‚ migrations\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”œ ðŸ“œ 0000_init.sql \\n â”‚ â”” ðŸ“œ 0001_seed-users.sql \\n â”” â€¦\\n```\\n```sql\\n-- ./drizzle/0001_seed-users.sql\\n\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dan\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Andrew\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dandrew\\');\\n```\\n</Section>\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-migrate.mdx'), name='drizzle-kit-migrate.mdx', displayName='drizzle-kit-migrate.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\n\\n# `drizzle-kit migrate`\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n- `drizzle-kit generate` command - [read here](/docs/drizzle-kit-generate)\\n</Prerequisites>\\n<br/>\\n\\n\\n`drizzle-kit migrate` lets you apply SQL migrations generated by [`drizzle-kit generate`](/docs/drizzle-kit-generate). \\nIt\\'s designed to cover [code first(option 3)](/docs/migrations) approach of managing Drizzle migrations. \\n\\n<Callout collapsed=\"How it works under the hood?\">\\nDrizzle Kit `migrate` command triggers a sequence of events:\\n1. Reads through migration folder and read all `.sql` migration files\\n2. Connects to the database and fetches entries from drizzle migrations log table\\n3. Based on previously applied migrations it will decide which new migrations to run\\n4. Runs SQL migrations and logs applied migrations to drizzle migrations table\\n\\n<Section>\\n```plaintext\\n  â”œ ðŸ“‚ drizzle       \\n  â”‚ â”œ ðŸ“‚ _meta\\n  â”‚ â”œ ðŸ“œ 0000_premium_mister_fear.sql\\n  â”‚ â”” ðŸ“œ 0001_delicate_professor_xavie.sql\\n  â”” â€¦\\n```\\n```plaintext\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit migrate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         \\n  â”” 1. reads migration.sql files in migrations folder       â”‚                          â”‚\\n    2. fetch migration history from database -------------> â”‚                          â”‚\\n  â”Œ 3. pick previously unapplied migrations <-------------- â”‚         DATABASE         â”‚\\n  â”” 4. apply new migration to the database ---------------> â”‚                          â”‚\\n                                                            â”‚                          â”‚\\n                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n[âœ“] done!        \\n```\\n</Section>\\n</Callout>\\n\\n`drizzle-kit migrate` command requires you to specify both `dialect` and database connection credentials, \\nyou can provide them either via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options\\n\\n<CodeTabs items={[\"With config file\", \"As CLI options\"]}>\\n<Section>\\n```ts {5,8}\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\"\\n  },\\n});\\n```\\n```shell\\nnpx drizzle-kit migrate\\n```\\n</Section>\\n```shell\\nnpx drizzle-kit migrate --dialect=postgresql --url=postgresql://user:password@host:port/dbname\\n```\\n</CodeTabs>\\n\\n### Applied migrations log in the database\\nUpon running migrations Drizzle Kit will persist records about successfully applied migrations in your database. \\nIt will store them in migrations log table named `__drizzle_migrations`.\\n\\nYou can customise both **table** and **schema**(PostgreSQL only) of that table via drizzle config file:\\n```ts filename=\"drizzle.config.ts\" {8-9}\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\"\\n  },\\n  migrations: {\\n    table: \\'my-migrations-table\\', // `__drizzle_migrations` by default\\n    schema: \\'public\\', // used in PostgreSQL only, `drizzle` by default\\n  },\\n});\\n```\\n\\n### Multiple configuration files in one project\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases on the same project:\\n<Npx>\\n  drizzle-kit migrate --config=drizzle-dev.config.ts\\n  drizzle-kit migrate --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Extended example\\nLet\\'s generate SQL migration and apply it to our database using `drizzle-kit generate` and `drizzle-kit migrate` commands\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”‚ â”œ ðŸ“œ schema.ts\\n â”‚ â”” ðŸ“œ index.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” â€¦\\n```\\n<CodeTabs items={[\"drizzle.config.ts\", \"src/schema.ts\"]}>\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\"\\n  },\\n  migrations: {\\n    table: \\'journal\\', \\n    schema: \\'drizzle\\', \\n  },\\n});\\n```\\n```ts \\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n})\\n```\\n</CodeTabs>\\n\\nNow let\\'s run\\n```shell\\nnpx drizzle-kit generate --name=init\\n```\\nit will generate\\n<Section>\\n```plaintext {5}\\nðŸ“¦ <project root>\\n â”œ â€¦\\n â”œ ðŸ“‚ migrations\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”” ðŸ“œ 0000_init.sql \\n â”” â€¦\\n```\\n```sql\\n-- ./drizzle/0000_init.sql\\n\\nCREATE TABLE \"users\"(\\n  id serial primary key,\\n  name text\\n)\\n```\\n</Section>\\n\\nNow let\\'s run\\n```shell\\nnpx drizzle-kit migrate\\n```\\n\\nand our SQL migration is now successfully applied to the database âœ…\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-pull.mdx'), name='drizzle-kit-pull.mdx', displayName='drizzle-kit-pull.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Drivers from \"@mdx/Drivers.mdx\"\\nimport Dialects from \"@mdx/Dialects.mdx\"\\nimport Npm from \"@mdx/Npm.astro\"\\nimport Npx from \"@mdx/Npx.astro\"\\n\\n# `drizzle-kit pull`\\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration) \\n- Database connection basics - [read here](/docs/connect-overview) \\n- Drizzle migrations fundamentals - [read here](/docs/migrations) \\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file) docs\\n</Prerequisites>\\n\\n`drizzle-kit pull` lets you literally pull(introspect) your existing database schema and generate `schema.ts` drizzle schema file, \\nit is designed to cover [database first](/docs/migrations) approach of Drizzle migrations.\\n\\n<Callout collapsed=\"How it works under the hood?\">\\nWhen you run Drizzle Kit `pull` command it will:\\n1. Pull database schema(DDL) from your existing database\\n2. Generate `schema.ts` drizzle schema file and save it to `out` folder\\n\\n<Section>\\n```\\n                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \\n                                  â”‚                        â”‚ <---  CREATE TABLE \"users\" (\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                        â”‚        \"id\" SERIAL PRIMARY KEY,\\nâ”‚ ~ drizzle-kit pull       â”‚      â”‚                        â”‚        \"name\" TEXT,\\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚        DATABASE        â”‚        \"email\" TEXT UNIQUE\\n  â”‚                               â”‚                        â”‚       );\\n  â”” Pull datatabase schema -----> â”‚                        â”‚\\n  â”Œ Generate Drizzle       <----- â”‚                        â”‚\\n  â”‚ schema TypeScript file        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n  â”‚\\n  v\\n```\\n```typescript\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(), \\n};\\n```\\n</Section>\\n</Callout>\\n\\nIt is a great approach if you need to manage database schema outside of your TypeScript project or \\nyou\\'re using database, which is managed by somebody else.\\n\\n<br/>\\n<hr/>\\n<br/>\\n\\n`drizzle-kit pull` requires you to specify `dialect` and either\\ndatabase connection `url` or `user:password@host:port/db` params, you can provide them\\neither via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options:\\n\\n<CodeTabs items={[\"With config file\", \"With CLI options\"]}>\\n<Section>\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\",\\n  },\\n});\\n```\\n```shell\\nnpx drizzle-kit pull\\n```\\n</Section>\\n\\n```shell\\nnpx drizzle-kit pull --dialect=postgresql --url=postgresql://user:password@host:port/dbname\\n```\\n</CodeTabs>\\n\\n### Multiple configuration files in one project\\n\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n\\n<Npx>\\n  drizzle-kit pull --config=drizzle-dev.config.ts\\n  drizzle-kit pull --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Specifying database driver\\n<Callout type=\"warning\">\\n**Expo SQLite** and **OP SQLite** are on-device(per-user) databases, there\\'s no way to `pull` database schema from there.<br/>\\nFor embedded databases Drizzle provides **embedded migrations** - check out our [get started](/docs/get-started/expo-new) guide.\\n</Callout>\\nDrizzle Kit does not come with a pre-bundled database driver, \\nit will automatically pick available database driver from your current project based on the `dialect` - [see discussion](https://github.com/drizzle-team/drizzle-orm/discussions/2203).\\n\\nMostly all drivers of the same dialect share the same set of connection params, \\nas for exceptions like `aws-data-api`, `pglight` and `d1-http` - you will have to explicitely specify `driver` param.\\n\\n<CodeTabs items={[\"AWS Data API\", \"PGLite\", \"Cloudflare D1 HTTP\"]}>\\n```ts {6}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  driver: \"aws-data-api\",\\n  dbCredentials: {\\n    database: \"database\",\\n    resourceArn: \"resourceArn\",\\n    secretArn: \"secretArn\",\\n  },\\n};\\n```\\n```ts {6}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  driver: \"pglite\",\\n  dbCredentials: {\\n    // inmemory\\n    url: \":memory:\"\\n    \\n    // or database folder\\n    url: \"./database/\"\\n  },\\n};\\n```\\n```ts {6}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"sqlite\",\\n  driver: \"d1-http\",\\n  dbCredentials: {\\n    accountId: \"accountId\",\\n    databaseId: \"databaseId\",\\n    token: \"token\",\\n  },\\n};\\n```\\n</CodeTabs>\\n\\n### Including tables, schemas and extensions\\n`drizzle-kit push` will by default manage all tables in `public` schema.\\nYou can configure list of tables, schemas and extensions via `tablesFilters`, `schemaFilter` and `extensionFilters` options.\\n\\n|                     |                                                                                               |\\n| :------------------ | :-------------------------------------------------------------------------------------------- |\\n| `tablesFilter`      | `glob` based table names filter, e.g. `[\"users\", \"user_info\"]` or `\"user*\"`. Default is `\"*\"` |\\n| `schemaFilter`      | Schema names filter, e.g. `[\"public\", \"drizzle\"]`. Default is `[\"public\"]`                    |\\n| `extensionsFilters` | List of installed database extensions, e.g. `[\"postgis\"]`. Default is `[]`                    |\\n<br/>\\n\\nLet\\'s configure drizzle-kit to only operate with **all tables** in **public** schema\\nand let drizzle-kit know that there\\'s a **postgis** extension installed, \\nwhich creates it\\'s own tables in public schema, so drizzle can ignore them.\\n\\n<Section>\\n```ts filename=\"drizzle.config.ts\" {9-11}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\",\\n  },\\n  extensionsFilters: [\"postgis\"],\\n  schemaFilter: [\"public\"],\\n  tablesFilter: [\"*\"],\\n});\\n```\\n```shell\\nnpx drizzle-kit push\\n```\\n</Section>\\n\\n### Extended list of configurations\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n\\n|                     |            |                                                                           |\\n| :------------------ | :--------- | :------------------------------------------------------------------------ |\\n| `dialect`           | `required` | Database dialect, one of <Dialects/>                                      |\\n| `driver`            |            | Drivers exceptions <Drivers/>                                             |\\n| `out`               |            | Migrations output folder path, default is `./drizzle`                     |\\n| `url`               |            | Database connection string                                                |\\n| `user`              |            | Database user                                                             |\\n| `password`          |            | Database password                                                         |\\n| `host`              |            | Host                                                                      |\\n| `port`              |            | Port                                                                      |\\n| `database`          |            | Database name                                                             |\\n| `config`            |            | Configuration file path, default is `drizzle.config.ts`                          |\\n| `introspect-casing` |            | Strategy for JS keys creation in columns, tables, etc. `preserve` `camel` |\\n| `tablesFilter`      |            | Table name filter                                                         |\\n| `schemaFilter`      |            | Schema name filter. Default: `[\"public\"]`                                 |\\n| `extensionsFilters` |            | Database extensions internal database filters                             |\\n\\n<Npx>\\ndrizzle-kit pull --dialect=postgresql --url=postgresql://user:password@host:port/dbname\\ndrizzle-kit pull --dialect=postgresql --driver=pglite url=database/\\ndrizzle-kit pull --dialect=postgresql --tablesFilter=\\'user*\\' --extensionsFilters=postgis url=postgresql://user:password@host:port/dbname\\n</Npx>\\n\\n![](@/assets/gifs/introspect_mysql.gif)\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-push.mdx'), name='drizzle-kit-push.mdx', displayName='drizzle-kit-push.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\nimport SchemaFilePaths from \"@mdx/SchemaFilePaths.mdx\";\\nimport Drivers from \"@mdx/Drivers.mdx\"\\nimport Dialects from \"@mdx/Dialects.mdx\"\\nimport DriversExamples from \"@mdx/DriversExamples.mdx\"\\n\\n# `drizzle-kit push`\\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration) \\n- Database connection basics - [read here](/docs/connect-overview) \\n- Drizzle migrations fundamentals - [read here](/docs/migrations) \\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file) docs\\n</Prerequisites>\\n\\n\\n`drizzle-kit push` lets you literally push your schema and subsequent schema changes directly to the\\ndatabase while omitting SQL files generation, it\\'s designed to cover [code first](/docs/migrations)\\napproach of Drizzle migrations.\\n\\n<Callout collapsed=\"How it works under the hood?\">\\nWhen you run Drizzle Kit `push` command it will:\\n1. Read through your Drizzle schema file(s) and compose a json snapshot of your schema\\n2. Pull(introspect) database schema \\n3. Based on differences between those two it will generate SQL migrations\\n4. Apply SQL migrations to the database\\n\\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n};\\n```\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ ~ drizzle-kit push  â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n  â”” Pull current datatabase schema ---------> â”‚                          â”‚\\n                                              â”‚                          â”‚\\n  â”Œ Generate alternations based on diff <---- â”‚         DATABASE         â”‚\\n  â”‚                                           â”‚                          â”‚\\n  â”” Apply migrations to the database -------> â”‚                          â”‚\\n                                       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n                                       â”‚\\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n   create table users(id serial primary key, name text);\\n```\\n</Section>\\n</Callout>\\n\\nIt\\'s the best approach for rapid prototyping and we\\'ve seen dozens of teams\\nand solo developers successfully using it as a primary migrations flow in their production applications.\\nIt pairs exceptionally well with blue/green deployment strategy and serverless databases like\\n[Planetscale](https://planetscale.com), [Neon](https://neon.tech), [Turso](https://turso.tech/drizzle) and others.\\n\\n<br/>\\n<hr/>\\n<br/>\\n\\n\\n`drizzle-kit push` requires you to specify `dialect`, path to the `schema` file(s) and either\\ndatabase connection `url` or `user:password@host:port/db` params, you can provide them\\neither via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options:\\n\\n<CodeTabs items={[\"With config file\", \"With CLI options\"]}>\\n<Section>\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\",\\n  },\\n});\\n```\\n```shell\\nnpx drizzle-kit push\\n```\\n</Section>\\n\\n```shell\\nnpx drizzle-kit push --dialect=postgresql --schema=./src/schema.ts --url=postgresql://user:password@host:port/dbname\\n```\\n\\n</CodeTabs>\\n\\n### Schema files path\\n\\nYou can have a single `schema.ts` file or as many schema files as you want spread out across the project.\\nDrizzle Kit requires you to specify path(s) to them as a [glob](https://www.digitalocean.com/community/tools/glob?comments=true&glob=/**/*.js&matches=false&tests=//%20This%20will%20match%20as%20it%20ends%20with%20\\'.js\\'&tests=/hello/world.js&tests=//%20This%20won\\'t%20match!&tests=/test/some/globs) via `schema` configuration option.\\n\\n<SchemaFilePaths />\\n\\n### Multiple configuration files in one project\\n\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n\\n<Npx>\\n  drizzle-kit push --config=drizzle-dev.config.ts\\n  drizzle-kit push --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Specifying database driver\\n<Callout type=\"warning\">\\n**Expo SQLite** and **OP SQLite** are on-device(per-user) databases, there\\'s no way to `push` migrations there.<br/>\\nFor embedded databases Drizzle provides **embedded migrations** - check out our [get started](/docs/get-started/expo-new) guide.\\n</Callout>\\nDrizzle Kit does not come with a pre-bundled database driver, \\nit will automatically pick available database driver from your current project based on the `dialect` - [see discussion](https://github.com/drizzle-team/drizzle-orm/discussions/2203).\\n\\nMostly all drivers of the same dialect share the same set of connection params, \\nas for exceptions like `aws-data-api`, `pglight` and `d1-http` - you will have to explicitly specify `driver` param.\\n\\n<DriversExamples/>\\n\\n### Including tables, schemas and extensions\\n`drizzle-kit push` will by default manage all tables in `public` schema.\\nYou can configure list of tables, schemas and extensions via `tablesFilters`, `schemaFilter` and `extensionFilters` options.\\n\\n|                     |                                                                                               |\\n| :------------------ | :-------------------------------------------------------------------------------------------- |\\n| `tablesFilter`      | `glob` based table names filter, e.g. `[\"users\", \"user_info\"]` or `\"user*\"`. Default is `\"*\"` |\\n| `schemaFilter`      | Schema names filter, e.g. `[\"public\", \"drizzle\"]`. Default is `[\"public\"]`                    |\\n| `extensionsFilters` | List of installed database extensions, e.g. `[\"postgis\"]`. Default is `[]`                    |\\n<br/>\\n\\nLet\\'s configure drizzle-kit to only operate with **all tables** in **public** schema\\nand let drizzle-kit know that there\\'s a **postgis** extension installed, \\nwhich creates it\\'s own tables in public schema, so drizzle can ignore them.\\n\\n<Section>\\n```ts filename=\"drizzle.config.ts\" {9-11}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\",\\n  },\\n  extensionsFilters: [\"postgis\"],\\n  schemaFilter: [\"public\"],\\n  tablesFilter: [\"*\"],\\n});\\n```\\n```shell\\nnpx drizzle-kit push\\n```\\n</Section>\\n\\n### Extended list of configurations\\n\\n`drizzle-kit push` has a list of cli-only options\\n\\n<rem025/>\\n\\n|           |                                                          |\\n| :-------- | :---------------------------------------------------     |\\n| `verbose` | print all SQL statements prior to execution              |\\n| `strict`  | always ask for approval before executing SQL statements  |\\n| `force`   | auto-accept all data-loss statements                     |\\n<br/>\\n<Npx>\\ndrizzle-kit push --strict --verbose --force\\n</Npx>\\n\\n<br/>\\n<hr/>\\n<br/>\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n\\n|                     |            |                                                                           |\\n| :------------------ | :--------- | :------------------------------------------------------------------------ |\\n| `dialect`           | `required` | Database dialect, one of <Dialects/>                                      |\\n| `schema`            | `required` | Path to typescript schema file(s) or folder(s) with multiple schema files |\\n| `driver`            |            | Drivers exceptions <Drivers/>                                             |\\n| `tablesFilter`      |            | Table name filter                                                         |\\n| `schemaFilter`      |            | Schema name filter. Default: `[\"public\"]`                                 |\\n| `extensionsFilters` |            | Database extensions internal database filters                             |\\n| `url`               |            | Database connection string                                                |\\n| `user`              |            | Database user                                                             |\\n| `password`          |            | Database password                                                         |\\n| `host`              |            | Host                                                                      |\\n| `port`              |            | Port                                                                      |\\n| `database`          |            | Database name                                                             |\\n| `config`            |            | Configuration file path, default=`drizzle.config.ts`                             |\\n\\n<Npx>\\ndrizzle-kit push dialect=postgresql schema=src/schema.ts url=postgresql://user:password@host:port/dbname\\ndrizzle-kit push dialect=postgresql schema=src/schema.ts driver=pglite url=database/\\ndrizzle-kit push dialect=postgresql schema=src/schema.ts --tablesFilter=\\'user*\\' --extensionsFilters=postgis url=postgresql://user:password@host:port/dbname\\n</Npx>\\n\\n\\n### Extended example\\nLet\\'s declare drizzle schema in the project and push it to the database via `drizzle-kit push` command\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚ â”œ ðŸ“œ schema.ts\\n â”‚ â”” ðŸ“œ index.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” â€¦\\n```\\n<CodeTabs items={[\"drizzle.config.ts\", \"src/schema.ts\"]}>\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\"\\n  },\\n});\\n```\\n```ts \\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n})\\n```\\n</CodeTabs>\\n\\nNow let\\'s run\\n```shell\\nnpx drizzle-kit push\\n```\\n\\nit will pull existing(empty) schema from the database and generate SQL migration and apply it under the hood\\n```sql\\nCREATE TABLE \"users\"(\\n  id serial primary key,\\n  name text\\n)\\n```\\n\\nDONE âœ…\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-studio.mdx'), name='drizzle-kit-studio.mdx', displayName='drizzle-kit-studio.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\n\\n\\n# `drizzle-kit studio`\\n<Prerequisites>\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n- Drizzle Studio, our database browser - [read here](/drizzle-studio/overview)\\n</Prerequisites>\\n\\n`drizzle-kit studio` command spins up a server for [Drizzle Studio](/drizzle-studio/overview) hosted on [local.drizzle.studio](https://local.drizzle.studio). \\nIt requires you to specify database connection credentials via [drizzle.config.ts](/docs/drizzle-config-file) config file.\\n\\nBy default it will start a Drizzle Studio server on `127.0.0.1:4983`\\n<Section>\\n```ts {6}\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: \"postgresql://user:password@host:port/dbname\"\\n  },\\n});\\n```\\n```shell\\nnpx drizzle-kit migrate\\n```\\n</Section>\\n\\n### Configuring `host` and `port`\\nBy default Drizzle Studio server starts on `127.0.0.1:4983`, \\nyou can config `host` and `port` via CLI options\\n\\n<Npx>\\ndrizzle-kit studio --port=3000\\ndrizzle-kit studio --host=0.0.0.0\\ndrizzle-kit studio --host=0.0.0.0 --port=3000\\n</Npx>\\n\\n\\n### Logging\\nYou can enable logging of every SQL statement by providing `verbose` flag\\n\\n<Npx>\\ndrizzle-kit studio --verbose\\n</Npx>\\n\\n### Safari and Brave support\\nSafari and Brave block access to localhost by default. \\nYou need to install [mkcert](https://github.com/FiloSottile/mkcert) and generate self-signed certificate:\\n\\n1. Follow the mkcert [installation steps](https://github.com/FiloSottile/mkcert#installation)\\n2. Run `mkcert -install`\\n3. Restart your `drizzle-kit studio`\\n\\n### Embeddable version of Drizzle Studio\\nWhile hosted version of Drizzle Studio for local development is free forever and meant to just enrich Drizzle ecosystem, \\nwe have a B2B offering of an embeddable version of Drizzle Studio for businesses.\\n\\n**Drizzle Studio component** - is a pre-bundled framework agnostic web component of Drizzle Studio \\nwhich you can embed into your UI `React` `Vue` `Svelte` `VanillaJS` etc. \\n\\nThat is an extremely powerful UI element that can elevate your offering \\nif you provide Database as a SaaS or a data centric SaaS solutions based \\non SQL or for private non-customer facing in-house usage.\\n\\nDatabase platforms using Drizzle Studio:\\n- [Turso](https://turso.tech/), our first customers since Oct 2023!\\n- [Neon](https://neon.tech/), [launch post](https://neon.tech/docs/changelog/2024-05-24)\\n- [Hydra](https://www.hydra.so/)\\n\\nData centric platforms using Drizzle Studio:\\n- [Nuxt Hub](https://hub.nuxt.com/), SÃ©bastien Chopin\\'s [launch post](https://x.com/Atinux/status/1768663789832929520)\\n- [Deco.cx](https://deco.cx/)\\n\\nYou can read a detailed overview [here](https://www.npmjs.com/package/@drizzle-team/studio) and \\nif you\\'re interested - hit us in DMs on [Twitter](https://x.com/drizzleorm) or in [Discord #drizzle-studio](https://driz.link/discord) channel.\\n\\n### Drizzle Studio chrome extension\\nDrizzle Studio [chrome extension](https://chromewebstore.google.com/detail/drizzle-studio/mjkojjodijpaneehkgmeckeljgkimnmd) \\nlets you browse your [PlanetScale](https://planetscale.com), \\n[Cloudflare](https://developers.cloudflare.com/d1/) and [Vercel Postgres](https://vercel.com/docs/storage/vercel-postgres)\\nserverless databases directly in their vendor admin panels!\\n\\n### Limitations\\nOur hosted version Drizzle Studio is meant to be used for local development and not meant to be used on remote (VPS, etc).\\n\\nIf you want to deploy Drizzle Studio to your VPS - we have an alpha version of Drizzle Studio Gateway, \\nhit us in DMs on [Twitter](https://x.com/drizzleorm) or in [Discord #drizzle-studio](https://driz.link/discord) channel.\\n\\n### Is it open source?\\nNo. Drizzle ORM and Drizzle Kit are fully open sourced, while Studio is not. \\n\\nDrizzle Studio for local development is free to use forever to enrich Drizzle ecosystem, \\nopen sourcing one would\\'ve break our ability to provide B2B offerings and monetise it, unfortunately.\\n', children=[]),\n",
       " DocItem(origPath=Path('drizzle-kit-up.mdx'), name='drizzle-kit-up.mdx', displayName='drizzle-kit-up.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\n\\n# `drizzle-kit up`\\n\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n- `drizzle-kit generate` command - [read here](/docs/drizzle-kit-generate)\\n</Prerequisites>\\n\\n`drizzle-kit up` command lets you upgrade drizzle schema snapshots to a newer version. \\nIt\\'s required whenever we introduce breaking changes to the json snapshots of the schema and upgrade the internal version.\\n\\n<br/>\\n<hr/>\\n<br/>\\n\\n`drizzle-kit up` command requires you to specify both `dialect` and database connection credentials, \\nyou can provide them either via [drizzle.config.ts](/docs/drizzle-config-file) config file or via CLI options\\n\\n<CodeTabs items={[\"With config file\", \"As CLI options\"]}>\\n<Section>\\n```ts {5,8}\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n});\\n```\\n```shell\\nnpx drizzle-kit up\\n```\\n</Section>\\n```shell\\nnpx drizzle-kit up --dialect=postgresql\\n```\\n</CodeTabs>\\n\\n### Multiple configuration files in one project\\nYou can have multiple config files in the project, it\\'s very useful when you have multiple database stages or multiple databases on the same project:\\n<Npx>\\n  drizzle-kit migrate --config=drizzle-dev.config.ts\\n  drizzle-kit migrate --config=drizzle-prod.config.ts\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n### Extended list of configurations\\nWe recommend configuring `drizzle-kit` through [drizzle.config.ts](/docs/drizzle-config-file) file, \\nyet you can provide all configuration options through CLI if necessary, e.g. in CI/CD pipelines, etc.\\n<rem025/>\\n|           |            |                                                                         |\\n| :-------- | :--------- | :---------------------------------------------------------------------- |\\n| `dialect` | `required` | Database dialect you are using. Can be `postgresql`,`mysql` or `sqlite` |\\n| `out`     |            | Migrations folder, default=`./drizzle`                                  |\\n| `config`  |            | Configuration file path, default=`drizzle.config.ts`                           |\\n<br/>\\n<Npx>\\ndrizzle-kit up --dialect=postgresql\\ndrizzle-kit up --dialect=postgresql --out=./migrations-folder\\n</Npx>\\n\\n![](@/assets/gifs/up_mysql.gif)\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('dynamic-query-building.mdx'), name='dynamic-query-building.mdx', displayName='dynamic-query-building.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\n\\n# Dynamic query building\\n\\nBy default, as all the query builders in Drizzle try to conform to SQL as much as possible, you can only invoke most of the methods once.\\nFor example, in a `SELECT` statement there might only be one `WHERE` clause, so you can only invoke `.where()` once:\\n\\n```ts\\nconst query = db\\n\\t.select()\\n\\t.from(users)\\n\\t.where(eq(users.id, 1))\\n\\t.where(eq(users.name, \\'John\\')); // âŒ Type error - where() can only be invoked once\\n```\\n\\nIn the previous ORM versions, when such restrictions weren\\'t implemented, this example in particular was a source of confusion for many users, as they expected the query builder to \"merge\" multiple `.where()` calls into a single condition.\\n\\nThis behavior is useful for conventional query building, i.e. when you create the whole query at once.\\nHowever, it becomes a problem when you want to build a query dynamically, i.e. if you have a shared function that takes a query builder and enhances it.\\nTo solve this problem, Drizzle provides a special \\'dynamic\\' mode for query builders, which removes the restriction of invoking methods only once.\\nTo enable it, you need to call `.$dynamic()` on a query builder.\\n\\nLet\\'s see how it works by implementing a simple `withPagination` function that adds `LIMIT` and `OFFSET` clauses to a query based on the provided page number and an optional page size:\\n\\n```ts\\nfunction withPagination<T extends PgSelect>(\\n\\tqb: T,\\n\\tpage: number = 1,\\n\\tpageSize: number = 10,\\n) {\\n\\treturn qb.limit(pageSize).offset((page - 1) * pageSize);\\n}\\n\\nconst query = db.select().from(users).where(eq(users.id, 1));\\nwithPagination(query, 1); // âŒ Type error - the query builder is not in dynamic mode\\n\\nconst dynamicQuery = query.$dynamic();\\nwithPagination(dynamicQuery, 1); // âœ… OK\\n```\\n\\nNote that the `withPagination` function is generic, which allows you to modify the result type of the query builder inside it, for example by adding a join:\\n\\n```ts\\nfunction withFriends<T extends PgSelect>(qb: T) {\\n\\treturn qb.leftJoin(friends, eq(friends.userId, users.id));\\n}\\n\\nlet query = db.select().from(users).where(eq(users.id, 1)).$dynamic();\\nquery = withFriends(query);\\n```\\n\\nThis is possible, because `PgSelect` and other similar types are specifically designed to be used in dynamic query building. They can only be used in dynamic mode.\\n\\nHere is the list of all types that can be used as generic parameters in dynamic query building:\\n\\n{\\n\\n<table>\\n\\t<thead align=\\'center\\'>\\n\\t\\t<tr>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Dialect</b>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td colspan=\\'4\\'>\\n\\t\\t\\t\\t<b>Type</b>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Query</b>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Select</b>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Insert</b>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Update</b>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<b>Delete</b>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t</thead>\\n\\t<tbody>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td rowspan=\\'2\\'>Postgres</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>PgSelect</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>PgInsert</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>PgUpdate</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>PgDelete</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>PgSelectQueryBuilder</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td rowspan=\\'2\\'>MySQL</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>MySqlSelect</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>MySqlInsert</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>MySqlUpdate</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>MySqlDelete</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>MySqlSelectQueryBuilder</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td rowspan=\\'2\\'>SQLite</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>SQLiteSelect</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>SQLiteInsert</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>SQLiteUpdate</code>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td rowspan=\\'2\\'>\\n\\t\\t\\t\\t<code>SQLiteDelete</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t\\t<tr align=\\'center\\'>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<code>SQLiteSelectQueryBuilder</code>\\n\\t\\t\\t</td>\\n\\t\\t</tr>\\n\\t</tbody>\\n</table>\\n\\n}\\n\\n<Callout type=\\'info\\'>\\n\\tThe `...QueryBuilder` types are for usage with [standalone query builder\\n\\tinstances](/docs/goodies#standalone-query-builder). DB query builders are\\n\\tsubclasses of them, so you can use them as well.\\n\\n    ```ts\\n    \\timport { QueryBuilder } from \\'drizzle-orm/pg-core\\';\\n\\n    \\tfunction withFriends<T extends PgSelectQueryBuilder>(qb: T) {\\n    \\t\\treturn qb.leftJoin(friends, eq(friends.userId, users.id));\\n    \\t}\\n\\n    \\tconst qb = new QueryBuilder();\\n    \\tlet query = qb.select().from(users).where(eq(users.id, 1)).$dynamic();\\n    \\tquery = withFriends(query);\\n    ```\\n\\n</Callout>\\n', children=[]),\n",
       " DocItem(origPath=Path('eslint-plugin.mdx'), name='eslint-plugin.mdx', displayName='eslint-plugin.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tabs from \\'@mdx/Tabs.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\n\\n# ESLint Drizzle Plugin\\n\\nFor cases where it\\'s impossible to perform type checks for specific scenarios, or where it\\'s possible but error messages would be challenging to understand, we\\'ve decided to create an ESLint package with recommended rules. This package aims to assist developers in handling crucial scenarios during development\\n\\n## Install\\n\\n<Npm>\\neslint-plugin-drizzle\\n@typescript-eslint/eslint-plugin @typescript-eslint/parser\\n</Npm>\\n\\n## Usage\\n\\n**`.eslintrc.yml` example**\\n```yml\\nroot: true\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\nrules:\\n  \\'drizzle/enforce-delete-with-where\\': \"error\"\\n  \\'drizzle/enforce-update-with-where\\': \"error\"\\n```\\n\\n**All config**\\n\\nThis plugin exports an `all` that makes use of all rules (except for deprecated ones).\\n\\n```yml\\nroot: true\\nextends:\\n  - \"plugin:drizzle/all\"\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\n```\\n\\n**Recommended config**\\n\\nAt the moment, `all` is equivalent to `recommended`\\n\\n```yml\\nroot: true\\nextends:\\n  - \"plugin:drizzle/recommended\"\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\n```\\n\\n## Rules\\n\\n### **enforce-delete-with-where**\\n\\nEnforce using `delete` with the`.where()` clause in the `.delete()` statement. Most of the time, \\nyou don\\'t need to delete all rows in the table and require some kind of `WHERE` statements.\\n\\nOptionally, you can define a `drizzleObjectName` in the plugin options that accept a `string` or\\n`string[]`. This is useful when you have objects or classes with a delete method that\\'s not from\\nDrizzle. Such a `delete` method will trigger the ESLint rule. To avoid that, you can define the \\nname of the Drizzle object that you use in your codebase (like db) so that the rule would only \\ntrigger if the delete method comes from this object:\\n\\nExample, config 1:\\n```yml\\nrules:\\n  \\'drizzle/enforce-delete-with-where\\': \"error\"\\n```\\n\\n```ts\\nclass MyClass {\\n  public delete() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will be triggered by ESLint Rule\\nmyClassObj.delete()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.delete()\\n```\\n\\nExample, config 2:\\n```yml\\nrules:\\n  \\'drizzle/enforce-delete-with-where\\':\\n    - \"error\"\\n    - \"drizzleObjectName\": \\n      - \"db\"\\n```\\n```ts\\nclass MyClass {\\n  public delete() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will NOT be triggered by ESLint Rule\\nmyClassObj.delete()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.delete()\\n```\\n\\n### **enforce-update-with-where**: \\n\\nEnforce using `update` with the`.where()` clause in the `.update()` statement. \\nMost of the time, you don\\'t need to update all rows in the table and require \\nsome kind of `WHERE` statements.\\n\\nOptionally, you can define a `drizzleObjectName` in the plugin options that accept \\na `string` or `string[]`. This is useful when you have objects or classes with a delete \\nmethod that\\'s not from Drizzle. Such as `update` method will trigger the ESLint rule. To \\navoid that, you can define the name of the Drizzle object that you use in your codebase (like db) \\nso that the rule would only trigger if the delete method comes from this object:\\n\\nExample, config 1:\\n```yml\\nrules:\\n  \\'drizzle/enforce-update-with-where\\': \"error\"\\n```\\n\\n```ts\\nclass MyClass {\\n  public update() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will be triggered by ESLint Rule\\nmyClassObj.update()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.update()\\n```\\n\\nExample, config 2:\\n```yml\\nrules:\\n  \\'drizzle/enforce-update-with-where\\':\\n    - \"error\"\\n    - \"drizzleObjectName\": \\n      - \"db\"\\n```\\n```ts\\nclass MyClass {\\n  public update() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will NOT be triggered by ESLint Rule\\nmyClassObj.update()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.update()\\n```', children=[]),\n",
       " DocItem(origPath=Path('extensions'), name='extensions', displayName='extensions', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('extensions/mysql.mdx'), name='mysql.mdx', displayName='mysql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: MySQL extensions\\n---\\n\\nimport Callout from '@mdx/Callout.astro';\\n\\n<Callout>\\nCurrently, there are no MySQL extensions natively supported by Drizzle. Once those are added, we will have them here!\\n</Callout>\", children=[]), DocItem(origPath=Path('extensions/pg.mdx'), name='pg.mdx', displayName='pg.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: PostgreSQL extensions\\n---\\n\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n### `pg_vector`\\n\\n<Callout>\\nThere is no specific code to create an extension inside the Drizzle schema. We assume that if you are using vector types, \\nindexes, and queries, you have a PostgreSQL database with the pg_vector extension installed.\\n</Callout>\\n\\n[`pg_vector`](https://github.com/pgvector/pgvector) is open-source vector similarity search for Postgres\\n\\nStore your vectors with the rest of your data. Supports:\\n\\n- exact and approximate nearest neighbor search\\n- single-precision, half-precision, binary, and sparse vectors\\n- L2 distance, inner product, cosine distance, L1 distance, Hamming distance, and Jaccard distance\\n\\n#### Column Types\\n\\n**`vector`**\\n\\nStore your vectors with the rest of your data\\n\\nFor more info please refer to the official pg_vector docs **[docs.](https://github.com/pgvector/pgvector)**\\n\\n\\n<Section>\\n```ts\\nconst table = pgTable(\\'table\\', {\\n    embedding: vector({ dimensions: 3 })\\n})\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"table\" (\\n\\t\"embedding\" vector(3)\\n);\\n```\\n</Section>\\n\\n#### Indexes\\n\\nYou can now specify indexes for `pg_vector` and utilize `pg_vector` functions for querying, ordering, etc.\\n\\nLet\\'s take a few examples of `pg_vector` indexes from the `pg_vector` docs and translate them to Drizzle\\n\\n#### L2 distance, Inner product and Cosine distance\\n\\n```ts\\n// CREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\\n// CREATE INDEX ON items USING hnsw (embedding vector_ip_ops);\\n// CREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\\n\\nconst table = pgTable(\\'items\\', {\\n    embedding: vector({ dimensions: 3 })\\n}, (table) => [\\n  index(\\'l2_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_l2_ops\\'))\\n  index(\\'ip_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_ip_ops\\'))\\n  index(\\'cosine_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_cosine_ops\\'))\\n])\\n```\\n\\n#### L1 distance, Hamming distance and Jaccard distance - added in pg_vector 0.7.0 version\\n\\n```ts\\n// CREATE INDEX ON items USING hnsw (embedding vector_l1_ops);\\n// CREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);\\n// CREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);\\n\\nconst table = pgTable(\\'table\\', {\\n    embedding: vector({ dimensions: 3 })\\n}, (table) => [\\n  index(\\'l1_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_l1_ops\\'))\\n  index(\\'hamming_index\\').using(\\'hnsw\\', table.embedding.op(\\'bit_hamming_ops\\'))\\n  index(\\'bit_jaccard_index\\').using(\\'hnsw\\', table.embedding.op(\\'bit_jaccard_ops\\'))\\n])\\n```\\n\\n#### Helper Functions\\n\\nFor queries, you can use predefined functions for vectors or create custom ones using the SQL template operator.\\n\\nYou can also use the following helpers:\\n\\n```ts\\nimport { l2Distance, l1Distance, innerProduct, \\n          cosineDistance, hammingDistance, jaccardDistance } from \\'drizzle-orm\\'\\n\\nl2Distance(table.column, [3, 1, 2]) // table.column <-> \\'[3, 1, 2]\\'\\nl1Distance(table.column, [3, 1, 2]) // table.column <+> \\'[3, 1, 2]\\'\\n\\ninnerProduct(table.column, [3, 1, 2]) // table.column <#> \\'[3, 1, 2]\\'\\ncosineDistance(table.column, [3, 1, 2]) // table.column <=> \\'[3, 1, 2]\\'\\n\\nhammingDistance(table.column, \\'101\\') // table.column <~> \\'101\\'\\njaccardDistance(table.column, \\'101\\') // table.column <%> \\'101\\'\\n```\\n\\nIf `pg_vector` has some other functions to use, you can replicate implementation from existing one we have. Here is how it can be done\\n\\n```ts\\nexport function l2Distance(\\n  column: SQLWrapper | AnyColumn,\\n  value: number[] | string[] | TypedQueryBuilder<any> | string,\\n): SQL {\\n  if (is(value, TypedQueryBuilder<any>) || typeof value === \\'string\\') {\\n    return sql`${column} <-> ${value}`;\\n  }\\n  return sql`${column} <-> ${JSON.stringify(value)}`;\\n}\\n```\\n\\nName it as you wish and change the operator. This example allows for a numbers array, strings array, string, or even a select query. Feel free to create any other type you want or even contribute and submit a PR\\n\\n#### Examples\\n\\nLet\\'s take a few examples of `pg_vector` queries from the `pg_vector` docs and translate them to Drizzle\\n\\n```ts\\nimport { l2Distance } from \\'drizzle-orm\\';\\n\\n// SELECT * FROM items ORDER BY embedding <-> \\'[3,1,2]\\' LIMIT 5;\\ndb.select().from(items).orderBy(l2Distance(items.embedding, [3,1,2]))\\n\\n// SELECT embedding <-> \\'[3,1,2]\\' AS distance FROM items;\\ndb.select({ distance: l2Distance(items.embedding, [3,1,2]) })\\n\\n// SELECT * FROM items ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\\nconst subquery = db.select({ embedding: items.embedding }).from(items).where(eq(items.id, 1));\\ndb.select().from(items).orderBy(l2Distance(items.embedding, subquery)).limit(5)\\n\\n// SELECT (embedding <#> \\'[3,1,2]\\') * -1 AS inner_product FROM items;\\ndb.select({ innerProduct: sql`(${maxInnerProduct(items.embedding, [3,1,2])}) * -1` }).from(items)\\n\\n// and more!\\n```\\n\\n### `postgis`\\n\\n<Callout>\\nThere is no specific code to create an extension inside the Drizzle schema. We assume that if you are using postgis types, indexes, and queries, you have a PostgreSQL database with the `postgis` extension installed.\\n</Callout>\\n\\nAs [PostGIS](https://postgis.net/) website mentions:\\n\\n> PostGIS extends the capabilities of the PostgreSQL relational database by adding support for storing, indexing, and querying geospatial data.\\n\\n<Callout type=\"info\">\\nIf you are using the `introspect` or `push` commands with the PostGIS extension and don\\'t want PostGIS tables to be included, you can use [`extensionsFilters`](/docs/drizzle-config-file#extensionsfilters) to ignore all the PostGIS tables\\n</Callout>\\n\\n#### Column Types\\n\\n**`geometry`**\\n\\nStore your geometry data with the rest of your data\\n\\nFor more info please refer to the official PostGIS docs **[docs.](https://postgis.net/workshops/postgis-intro/geometries.html)**\\n\\n```ts\\nconst items = pgTable(\\'items\\', {\\n  geo: geometry(\\'geo\\', { type: \\'point\\' }),\\n  geoObj: geometry(\\'geo_obj\\', { type: \\'point\\', mode: \\'xy\\' }),\\n  geoSrid: geometry(\\'geo_options\\', { type: \\'point\\', mode: \\'xy\\', srid: 4000 }),\\n});\\n```\\n\\n**mode**\\n\\nType `geometry` has 2 modes for mappings from the database: `tuple` and `xy`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database geometry will be typed as [1,2] with drizzle.\\n- `xy` will be accepted for insert and mapped on select to an object with x, y coordinates. So, the database geometry will be typed as `{ x: 1, y: 2 }` with drizzle\\n\\n**type**\\n\\nThe current release has a predefined type: `point`, which is the `geometry(Point)` type in the PostgreSQL PostGIS extension. You can specify any string there if you want to use some other type\\n\\n#### Indexes\\n\\nWith the available Drizzle indexes API, you should be able to write any indexes for PostGIS\\n\\n**Examples**\\n\\n```ts\\n// CREATE INDEX custom_idx ON table USING GIST (geom);\\n\\nconst table = pgTable(\\'table\\', {\\n  \\tgeo: geometry({ type: \\'point\\' }),\\n}, (table) => [\\n  index(\\'custom_idx\\').using(\\'gist\\', table.geo)\\n])\\n```', children=[]), DocItem(origPath=Path('extensions/singlestore.mdx'), name='singlestore.mdx', displayName='singlestore.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: SingleStore extensions\\n---\\n\\nimport Callout from '@mdx/Callout.astro';\\n\\n<Callout>\\nCurrently, there are no SingleStore extensions natively supported by Drizzle. Once those are added, we will have them here!\\n</Callout>\", children=[]), DocItem(origPath=Path('extensions/sqlite.mdx'), name='sqlite.mdx', displayName='sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: SQLite extensions\\n---\\n\\nimport Callout from '@mdx/Callout.astro';\\n\\n<Callout>\\nCurrently, there are no SQLite extensions natively supported by Drizzle. Once those are added, we will have them here!\\n</Callout>\", children=[])]),\n",
       " DocItem(origPath=Path('faq.mdx'), name='faq.mdx', displayName='faq.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Callout from '@mdx/Callout.astro';\\n\\n# FAQ & Troubleshooting\\n\\n## **Should I use `generate` or `push`?**\\n\\nThose are logically 2 different commands. `generate` is used to create an sql file together with additional\\ninformation needed for `drizzle-kit` (or any other migration tool).\\n\\nAfter generating those migrations, they won't be applied to a database. \\nYou need to do it in the next step. You can read more about it **[here](/docs/migrations)**\\n\\nOn the other hand, `push` doesn't need any migrations to be generated. It will\\nsimply sync your schema with the database schema. Please be careful when using it;\\nwe recommend it only for local development and local databases. To read more about it, check out **[`drizzle-kit push`](/docs/drizzle-kit-push)**\\n\\n## How `push` and `generate` works for PostgreSQL indexes\\n\\n### Limitations\\n\\n1. **You should specify a name for your index manually if you have an index on at least one expression**\\n\\nExample\\n\\n```ts\\nindex().on(table.id, table.email) // will work well and name will be autogeneretaed\\nindex('my_name').on(table.id, table.email) // will work well\\n\\n// but\\n\\nindex().on(sql`lower(${table.email})`) // error\\nindex('my_name').on(sql`lower(${table.email})`) // will work well\\n```\\n\\n2. **Push won't generate statements if these fields(list below) were changed in an existing index:**\\n\\n- expressions inside `.on()` and `.using()`\\n- `.where()` statements\\n- operator classes `.op()` on columns\\n\\nIf you are using `push` workflows and want to change these fields in the index, you would need to:\\n\\n1. Comment out the index\\n2. Push\\n3. Uncomment the index and change those fields\\n4. Push again\\n\\nFor the `generate` command, `drizzle-kit` will be triggered by any changes in the index for any property in the new drizzle indexes API, so there are no limitations here.\", children=[]),\n",
       " DocItem(origPath=Path('generated-columns.mdx'), name='generated-columns.mdx', displayName='generated-columns.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# Generated Columns\\n\\n<Callout type=\"info\">\\nTo use this feature you would need to have `drizzle-orm@0.32.0` or higher and `drizzle-kit@0.23.0` or higher\\n</Callout>\\n\\nGenerated columns in SQL are a feature that allows you to create columns in a table whose values are automatically computed based on expressions involving other columns within the same table. This can help ensure data consistency, simplify database design, and improve query performance.\\n\\nThere are two types of generated columns:\\n\\n1. Virtual (or non-persistent) Generated Columns: These columns are computed dynamically whenever they are queried. They do not occupy storage space in the database.\\n\\n2. Stored (or persistent) Generated Columns: These columns are computed when a row is inserted or updated and their values are stored in the database. This allows them to be indexed and can improve query performance since the values do not need to be recomputed for each query.\\n\\nGenerated columns can be especially useful for:\\n\\n- Deriving new data from existing columns\\n- Automating calculations to avoid manual updates\\n- Enforcing data integrity and consistency\\n- Simplifying application logic by keeping complex calculations within the database schema\\n\\n<Callout type=\"info\">\\n    The implementation and usage of generated columns can vary significantly across different SQL databases. PostgreSQL, MySQL, and SQLite each have unique features, capabilities, and limitations when it comes to generated columns. In this section, we will explore these differences in detail to help you understand how to best utilize generated columns in each database system.\\n</Callout>\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore(WIP)\"]}>\\n  <Tab>\\n    #### Database side\\n    **Types**: `STORED` only\\n\\n    **How It Works**\\n    - Automatically computes values based on other columns during insert or update.\\n\\n    **Capabilities**\\n    - Simplifies data access by precomputing complex expressions.\\n    - Enhances query performance with index support on generated columns.\\n\\n    **Limitations**\\n    - Cannot specify default values.\\n    - Expressions cannot reference other generated columns or include subqueries.\\n    - Schema changes required to modify generated column expressions.\\n    - Cannot directly use in primary keys, foreign keys, or unique constraints   \\n\\n    For more info, please check [PostgreSQL](https://www.postgresql.org/docs/current/ddl-generated-columns.html) docs \\n\\n    #### Drizzle side\\n    In Drizzle you can specify `.generatedAlwaysAs()` function on any column type and add a supported sql query, \\n    that will generate this column data for you.\\n\\n    #### Features \\n    This function can accept generated expression in 3 ways:\\n\\n    **`string`**\\n    <CodeTab>\\n    ```ts\\n    export const test = pgTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(`hello world!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE IF NOT EXISTS \"test\" (\\n\\t    \"gen_name\" text GENERATED ALWAYS AS (hello world!) STORED\\n    );\\n    ```\\n    </CodeTab>\\n\\n    **`sql`** tag - if you want drizzle to escape some values for you\\n\\n    <CodeTab>\\n    ```ts\\n    export const test = pgTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(sql`hello \"world\"!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE IF NOT EXISTS \"test\" (\\n\\t    \"gen_name\" text GENERATED ALWAYS AS (hello \"world\"!) STORED\\n    );\\n    ```\\n    </CodeTab>\\n\\n    **`callback`** - if you need to reference columns from a table\\n    <CodeTab>\\n    ```ts\\n    export const test = pgTable(\"test\", {\\n        name: text(\"first_name\"),\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(\\n          (): SQL => sql`hi, ${test.name}!`\\n        ),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE IF NOT EXISTS \"test\" (\\n\\t    \"first_name\" text,\\n\\t    \"gen_name\" text GENERATED ALWAYS AS (hi, \"test\".\"first_name\"!) STORED\\n    );\\n    ```\\n    </CodeTab>\\n\\n    **Example** generated columns with full-text search\\n   <CodeTabs items={[\"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy {17-19}\\n    import { SQL, sql } from \"drizzle-orm\";\\n    import { customType, index, integer, pgTable, text } from \"drizzle-orm/pg-core\";\\n\\n    const tsVector = customType<{ data: string }>({\\n      dataType() {\\n        return \"tsvector\";\\n      },\\n    });\\n\\n    export const test = pgTable(\\n      \"test\",\\n      {\\n        id: integer(\"id\").primaryKey().generatedAlwaysAsIdentity(),\\n        content: text(\"content\"),\\n        contentSearch: tsVector(\"content_search\", {\\n          dimensions: 3,\\n        }).generatedAlwaysAs(\\n          (): SQL => sql`to_tsvector(\\'english\\', ${test.content})`\\n        ),\\n      },\\n      (t) => [\\n        index(\"idx_content_search\").using(\"gin\", t.contentSearch)\\n      ]\\n    );\\n    ```\\n    ```sql {4}\\n    CREATE TABLE IF NOT EXISTS \"test\" (\\n    \\t\"id\" integer PRIMARY KEY GENERATED ALWAYS AS IDENTITY (sequence name \"test_id_seq\" INCREMENT BY 1 MINVALUE 1 MAXVALUE 2147483647 START WITH 1 CACHE 1),\\n    \\t\"content\" text,\\n    \\t\"content_search\" \"tsvector\" GENERATED ALWAYS AS (to_tsvector(\\'english\\', \"test\".\"content\")) STORED\\n    );\\n    --> statement-breakpoint\\n    CREATE INDEX IF NOT EXISTS \"idx_content_search\" ON \"test\" USING gin (\"content_search\");\\n    ```\\n    </CodeTab>\\n   </CodeTabs>\\n  </Tab> \\n  <Tab>\\n    #### Database side\\n    **Types**: `STORED`, `VIRTUAL`\\n\\n    **How It Works**\\n    - Defined with an expression in the table schema.\\n    - Virtual columns are computed during read operations.\\n    - Stored columns are computed during write operations and stored.\\n\\n    **Capabilities**\\n    - Used in SELECT, INSERT, UPDATE, and DELETE statements.\\n    - Can be indexed, both virtual and stored.\\n    - Can specify NOT NULL and other constraints.\\n    \\n    **Limitations**\\n    - Cannot directly insert or update values in a generated column \\n\\n    For more info, please check [MySQL Alter Generated](https://dev.mysql.com/doc/refman/8.4/en/alter-table-generated-columns.html) docs and [MySQL create generated](https://dev.mysql.com/doc/refman/8.4/en/create-table-generated-columns.html) docs\\n\\n    #### Drizzle side\\n\\n    #### Features \\n\\n    **`string`**\\n    <CodeTab>\\n    ```ts\\n    export const test = mysqlTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(`hello world!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n\\t    `gen_name` text GENERATED ALWAYS AS (hello world!) VIRTUAL\\n    );\\n    ```\\n    </CodeTab>\\n\\n    **`sql`** tag - if you want drizzle to escape some values for you\\n\\n    <CodeTab>\\n    ```ts\\n    export const test = mysqlTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(sql`hello \"world\"!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n\\t    `gen_name` text GENERATED ALWAYS AS (hello \"world\"!) VIRTUAL\\n    );\\n    ```\\n    </CodeTab>\\n\\n    **`callback`** - if you need to reference columns from a table\\n\\n    <CodeTab>\\n    ```ts\\n    export const test = mysqlTable(\"test\", {\\n        name: text(\"first_name\"),\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(\\n          (): SQL => sql`hi, ${test.name}!`\\n        ),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n    \\t`first_name` text,\\n    \\t`gen_name` text GENERATED ALWAYS AS (hi, `test`.`first_name`!) VIRTUAL\\n    );\\n    ```\\n    </CodeTab>\\n    #### Limitations\\n    Drizzle Kit will also have limitations for `push` command:\\n    1. You can\\'t change the generated constraint expression and type using `push`. Drizzle-kit will ignore this change. To make it work, you would need to `drop the column`, `push`, and then `add a column with a new expression`. This was done due to the complex mapping from the database side, where the schema expression will be modified on the database side and, on introspection, we will get a different string. We can\\'t be sure if you changed this expression or if it was changed and formatted by the database. As long as these are generated columns and `push` is mostly used for prototyping on a local database, it should be fast to `drop` and `create` generated columns. Since these columns are `generated`, all the data will be restored\\n    2. `generate` should have no limitations\\n\\n  <CodeTabs items={[\"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    export const users = mysqlTable(\"users\", {\\n        id: int(\"id\"),\\n        id2: int(\"id2\"),\\n        name: text(\"name\"),\\n        storedGenerated: text(\"stored_gen\").generatedAlwaysAs(\\n          (): SQL => sql`${users.name} || \\'hello\\'`,\\n          { mode: \"stored\" }\\n        ),\\n        virtualGenerated: text(\"virtual_gen\").generatedAlwaysAs(\\n          (): SQL => sql`${users.name} || \\'hello\\'`,\\n          { mode: \"virtual\" }\\n        ),\\n    })\\n    ```\\n    ```sql\\n    CREATE TABLE `users` (\\n\\t    `id` int,\\n\\t    `id2` int,\\n\\t    `name` text,\\n\\t    `stored_gen` text GENERATED ALWAYS AS (`users`.`name` || \\'hello\\') STORED,\\n\\t    `virtual_gen` text GENERATED ALWAYS AS (`users`.`name` || \\'hello\\') VIRTUAL\\n    );\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n    #### Database side\\n    **Types**: `STORED`, `VIRTUAL`\\n\\n    **How It Works**\\n    - Defined with an expression in the table schema.\\n    - Virtual columns are computed during read operations.\\n    - Stored columns are computed during write operations and stored.\\n\\n    **Capabilities**\\n    - Used in SELECT, INSERT, UPDATE, and DELETE statements.\\n    - Can be indexed, both virtual and stored.\\n    - Can specify NOT NULL and other constraints.\\n    \\n    **Limitations**\\n    - Cannot directly insert or update values in a generated column \\n\\n    For more info, please check [SQLite](https://www.sqlite.org/gencol.html) docs \\n\\n    #### Drizzle side\\n\\n    #### Features\\n    **`string`**\\n    ```ts\\n    export const test = sqliteTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(`hello world!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n\\t    `gen_name` text GENERATED ALWAYS AS (hello world!) VIRTUAL\\n    );\\n    ```\\n\\n    **`sql`** tag - if you want drizzle to escape some values for you\\n\\n    ```ts\\n    export const test = sqliteTable(\"test\", {\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(sql`hello \"world\"!`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n\\t    `gen_name` text GENERATED ALWAYS AS (hello \"world\"!) VIRTUAL\\n    );\\n    ```\\n\\n    **`callback`** - if you need to reference columns from a table\\n\\n    ```ts\\n    export const test = sqliteTable(\"test\", {\\n        name: text(\"first_name\"),\\n        generatedName: text(\"gen_name\").generatedAlwaysAs(\\n          (): SQL => sql`hi, ${test.name}!`\\n        ),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `test` (\\n\\t    `first_name` text,\\n\\t    `gen_name` text GENERATED ALWAYS AS (hi, \"first_name\"!) VIRTUAL\\n    );\\n    ```\\n\\n    #### Limitations\\n    Drizzle Kit will also have limitations for `push` and `generate` command:\\n    1. You can\\'t change the generated constraint expression with the stored type in an existing table. You would need to delete this table and create it again. This is due to SQLite limitations for such actions. We will handle this case in future releases (it will involve the creation of a new table with data migration).\\n    2. You can\\'t add a `stored` generated expression to an existing column for the same reason as above. However, you can add a `virtual` expression to an existing column.\\n    3. You can\\'t change a `stored` generated expression in an existing column for the same reason as above. However, you can change a `virtual` expression.\\n    4. You can\\'t change the generated constraint type from `virtual` to `stored` for the same reason as above. However, you can change from `stored` to `virtual`.\\n\\n   <CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    export const users = sqliteTable(\"users\", {\\n      id: int(\"id\"),\\n      name: text(\"name\"),\\n      storedGenerated: text(\"stored_gen\").generatedAlwaysAs(\\n        (): SQL => sql`${users.name} || \\'hello\\'`,\\n        { mode: \"stored\" }\\n      ),\\n      virtualGenerated: text(\"virtual_gen\").generatedAlwaysAs(\\n        (): SQL => sql`${users.name} || \\'hello\\'`,\\n        { mode: \"virtual\" }\\n      ),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `users` (\\n\\t    `id` integer,\\n\\t    `name` text,\\n\\t    `stored_gen` text GENERATED ALWAYS AS (\"name\" || \\'hello\\') STORED,\\n\\t    `virtual_gen` text GENERATED ALWAYS AS (\"name\" || \\'hello\\') VIRTUAL\\n    );\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  Work in Progress\\n  </Tab>\\n</Tabs>\\n', children=[]),\n",
       " DocItem(origPath=Path('get-started'), name='get-started', displayName='get-started', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('get-started/bun-sql-existing.mdx'), name='bun-sql-existing.mdx', displayName='bun-sql-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport ConnectBun from \\'@mdx/get-started/postgresql/ConnectBun.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **bun** - javaScript all-in-one toolkit - [read here](https://bun.sh/)\\n  - **Bun SQL** - native bindings for working with PostgreSQL databases - [read here](https://bun.sh/docs/api/sql)\\n</Prerequisites>\\n\\n<Callout type=\\'error\\'>\\nIn version `1.2.0`, Bun has issues with executing concurrent statements, which may lead to errors if you try to run several queries simultaneously.\\nWe\\'ve created a [github issue](https://github.com/oven-sh/bun/issues/16774) that you can track. Once it\\'s fixed, you should no longer encounter any such errors on Bun\\'s SQL side\\n</Callout>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n\\n<Npm>\\n  drizzle-orm dotenv\\n  -D drizzle-kit @types/bun\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectBun/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'bun-sql\\' env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 8 - Run index.ts file\\n\\nTo run a script with `bun`, use the following command:\\n```bash copy\\nbun src/index.ts\\n```\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 9 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 10 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'bun-sql\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/bun-sql-new.mdx'), name='bun-sql-new.mdx', displayName='bun-sql-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\';\\nimport ConnectBun from \\'@mdx/get-started/postgresql/ConnectBun.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Bun:SQLite\\n\\n<Prerequisites>  \\n  - **bun** - javaScript all-in-one toolkit - [read here](https://bun.sh/)\\n  - **Bun SQL** - native bindings for working with PostgreSQL databases - [read here](https://bun.sh/docs/api/sql)\\n</Prerequisites>\\n\\n<Callout type=\\'error\\'>\\nIn version `1.2.0`, Bun has issues with executing concurrent statements, which may lead to errors if you try to run several queries simultaneously.\\nWe\\'ve created a [github issue](https://github.com/oven-sh/bun/issues/16774) that you can track. Once it\\'s fixed, you should no longer encounter any such errors on Bun\\'s SQL side\\n</Callout>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<Npm>\\n  drizzle-orm\\n  -D drizzle-kit @types/bun\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectBun/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'bun-sql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\nTo run a script with `bun`, use the following command:\\n```bash copy\\nbun src/index.ts\\n```', children=[]), DocItem(origPath=Path('get-started/bun-sqlite-existing.mdx'), name='bun-sqlite-existing.mdx', displayName='bun-sqlite-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport IntrospectSqlite from \\'@mdx/get-started/sqlite/IntrospectSqlite.mdx\\';\\nimport ConnectBun from \\'@mdx/get-started/sqlite/ConnectBun.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/sqlite/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Bun:SQLite in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **bun** - javaScript all-in-one toolkit - [read here](https://bun.sh/)\\n  - **bun:sqlite** - native implementation of a high-performance SQLite3 driver - [read here](https://bun.sh/docs/api/sqlite)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n\\n<Npm>\\n  drizzle-orm dotenv\\n  -D drizzle-kit tsx @types/bun\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you have an SQLite database file in the root of your project, you can use this example:\\n```plaintext copy\\nDB_FILE_NAME=mydb.sqlite\\n```\\n</Callout>\\n\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSqlite/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectBun/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'bun-sqlite\\' env_variable=\\'DB_FILE_NAME\\' />\\n\\n#### Step 8 - Run index.ts file\\n\\nTo run a script with `bun`, use the following command:\\n```bash copy\\nbun src/index.ts\\n```\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 9 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 10 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'bun-sqlite\\' env_variable=\\'DB_FILE_NAME\\' />', children=[]), DocItem(origPath=Path('get-started/bun-sqlite-new.mdx'), name='bun-sqlite-new.mdx', displayName='bun-sqlite-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectBun from \\'@mdx/get-started/sqlite/ConnectBun.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Bun:SQLite\\n\\n<Prerequisites>  \\n  - **bun** - javaScript all-in-one toolkit - [read here](https://bun.sh/)\\n  - **bun:sqlite** - native implementation of a high-performance SQLite3 driver - [read here](https://bun.sh/docs/api/sqlite)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<Npm>\\n  drizzle-orm\\n  -D drizzle-kit @types/bun\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you want to create an SQLite database file in the root of your project for testing purposes, you can use this example:\\n```plaintext copy\\nDB_FILE_NAME=mydb.sqlite\\n```\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectBun/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'bun-sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\nTo run a script with `bun`, use the following command:\\n```bash copy\\nbun src/index.ts\\n```', children=[]), DocItem(origPath=Path('get-started/d1-new.mdx'), name='d1-new.mdx', displayName='d1-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryTurso from \\'@mdx/get-started/sqlite/QueryTurso.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and D1\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Cloudflare D1** - Serverless SQL database to query from your Workers and Pages projects - [read here](https://developers.cloudflare.com/d1/)\\n  - **wrangler** - Cloudflare Developer Platform command-line interface - [read here](https://developers.cloudflare.com/workers/wrangler)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<InstallPackages lib=\\'\\'/>\\n\\n#### Step 2 - Setup wrangler.toml\\n\\nYou would need to have a `wrangler.toml` file for D1 database and will look something like this:\\n```toml\\nname = \"YOUR PROJECT NAME\"\\nmain = \"src/index.ts\"\\ncompatibility_date = \"2022-11-07\"\\nnode_compat = true\\n\\n[[ d1_databases ]]\\nbinding = \"DB\"\\ndatabase_name = \"YOUR DB NAME\"\\ndatabase_id = \"YOUR DB ID\"\\nmigrations_dir = \"drizzle\"\\n```\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/d1\\';\\n\\nexport interface Env {\\n  <BINDING_NAME>: D1Database;\\n}\\nexport default {\\n  async fetch(request: Request, env: Env) {\\n    const db = drizzle(env.<BINDING_NAME>);\\n  },\\n};\\n```\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  out: \\'./drizzle\\',\\n  schema: \\'./src/db/schema.ts\\',\\n  dialect: \\'sqlite\\',\\n  driver: \\'d1-http\\',\\n  dbCredentials: {\\n    accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,\\n    databaseId: process.env.CLOUDFLARE_DATABASE_ID!,\\n    token: process.env.CLOUDFLARE_D1_TOKEN!,\\n  },\\n});\\n```\\n<Callout title=\\'tips\\'>\\nYou can check [our tutorial](/docs/guides/d1-http-with-drizzle-kit) on how to get env variables from CloudFlare\\n</Callout>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/d1\\';\\n\\nexport interface Env {\\n  <BINDING_NAME>: D1Database;\\n}\\nexport default {\\n  async fetch(request: Request, env: Env) {\\n    const db = drizzle(env.<BINDING_NAME>);\\n    const result = await db.select().from(users).all()\\n    return Response.json(result);\\n  },\\n};\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/do-new.mdx'), name='do-new.mdx', displayName='do-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryTurso from \\'@mdx/get-started/sqlite/QueryTurso.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite Durable Objects\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Cloudflare SQLite Durable Objects** - SQLite database embedded within a Durable Object - [read here](https://developers.cloudflare.com/durable-objects/api/sql-storage/)\\n  - **wrangler** - Cloudflare Developer Platform command-line interface - [read here](https://developers.cloudflare.com/workers/wrangler)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<Npm>\\n  drizzle-orm dotenv\\n  -D drizzle-kit wrangler @cloudflare/workers-types\\n</Npm>\\n\\n#### Step 2 - Setup wrangler.toml\\n\\nYou would need to have a `wrangler.toml` file for D1 database and will look something like this:\\n```toml\\n#:schema node_modules/wrangler/config-schema.json\\nname = \"sqlite-durable-objects\"\\nmain = \"src/index.ts\"\\ncompatibility_date = \"2024-11-12\"\\ncompatibility_flags = [ \"nodejs_compat\" ]\\n\\n# Bind a Durable Object. Durable objects are a scale-to-zero compute primitive based on the actor model.\\n# Durable Objects can live for as long as needed. Use these when you need a long-running \"server\", such as in realtime apps.\\n# Docs: https://developers.cloudflare.com/workers/wrangler/configuration/#durable-objects\\n[[durable_objects.bindings]]\\nname = \"MY_DURABLE_OBJECT\"\\nclass_name = \"MyDurableObject\"\\n\\n# Durable Object migrations.\\n# Docs: https://developers.cloudflare.com/workers/wrangler/configuration/#migrations\\n[[migrations]]\\ntag = \"v1\"\\nnew_sqlite_classes = [\"MyDurableObject\"]\\n\\n# We need rules so we can import migrations in the next steps\\n[[rules]] \\ntype = \"Text\"\\nglobs = [\"**/*.sql\"]\\nfallthrough = true\\n```\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n```ts\\n/// <reference types=\"@cloudflare/workers-types\" />\\nimport { drizzle, type DrizzleSqliteDODatabase } from \\'drizzle-orm/durable-sqlite\\';\\nimport { DurableObject } from \\'cloudflare:workers\\'\\n\\nexport class MyDurableObject extends DurableObject {\\n\\tstorage: DurableObjectStorage;\\n\\tdb: DrizzleSqliteDODatabase;\\n\\n\\tconstructor(ctx: DurableObjectState, env: Env) {\\n\\t\\tsuper(ctx, env);\\n\\t\\tthis.storage = ctx.storage;\\n\\t\\tthis.db = drizzle(this.storage, { logger: false });\\n\\t}\\n}\\n```\\n\\n#### Step 4 - Generate wrangler types \\n\\n<Npx>\\nwrangler types\\n</Npx>\\n\\n<Callout>\\nThe output of this command will be a `worker-configuration.d.ts` file.\\n</Callout>\\n\\n#### Step 5 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 6 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  out: \\'./drizzle\\',\\n  schema: \\'./src/db/schema.ts\\',\\n  dialect: \\'sqlite\\',\\n  driver: \\'durable-sqlite\\',\\n});\\n```\\n\\n#### Step 7 - Applying changes to the database\\n\\nGenerate migrations:\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nYou can apply migrations only from Cloudflare Workers. \\nTo achieve this, let\\'s define the migrate functionality in MyDurableObject:\\n```ts copy {4-5,17-19}\\n/// <reference types=\"@cloudflare/workers-types\" />\\nimport { drizzle, type DrizzleSqliteDODatabase } from \\'drizzle-orm/durable-sqlite\\';\\nimport { DurableObject } from \\'cloudflare:workers\\'\\nimport { migrate } from \\'drizzle-orm/durable-sqlite/migrator\\';\\nimport migrations from \\'../drizzle/migrations\\';\\n\\nexport class MyDurableObject extends DurableObject {\\n\\tstorage: DurableObjectStorage;\\n\\tdb: DrizzleSqliteDODatabase;\\n\\n\\tconstructor(ctx: DurableObjectState, env: Env) {\\n\\t\\tsuper(ctx, env);\\n\\t\\tthis.storage = ctx.storage;\\n\\t\\tthis.db = drizzle(this.storage, { logger: false });\\n\\t}\\n\\n\\tasync migrate() {\\n\\t\\tmigrate(this.db, migrations);\\n\\t}\\n}\\n```\\n\\n#### Step 8 - Migrate and Query the database\\n\\n```typescript copy\\n/// <reference types=\"@cloudflare/workers-types\" />\\nimport { drizzle, DrizzleSqliteDODatabase } from \\'drizzle-orm/durable-sqlite\\';\\nimport { DurableObject } from \\'cloudflare:workers\\'\\nimport { migrate } from \\'drizzle-orm/durable-sqlite/migrator\\';\\nimport migrations from \\'../drizzle/migrations\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nexport class MyDurableObject extends DurableObject {\\n\\tstorage: DurableObjectStorage;\\n\\tdb: DrizzleSqliteDODatabase<any>;\\n\\n\\tconstructor(ctx: DurableObjectState, env: Env) {\\n\\t\\tsuper(ctx, env);\\n\\t\\tthis.storage = ctx.storage;\\n\\t\\tthis.db = drizzle(this.storage, { logger: false });\\n\\n\\t\\t// Make sure all migrations complete before accepting queries.\\n\\t\\t// Otherwise you will need to run `this.migrate()` in any function\\n\\t\\t// that accesses the Drizzle database `this.db`.\\n\\t\\tctx.blockConcurrencyWhile(async () => {\\n\\t\\t\\tawait this._migrate();\\n\\t\\t});\\n\\t}\\n\\n\\tasync insertAndList(user: typeof usersTable.$inferInsert) {\\n\\t\\tawait this.insert(user);\\n\\t\\treturn this.select();\\n\\t}\\n\\n\\tasync insert(user: typeof usersTable.$inferInsert) {\\n\\t\\tawait this.db.insert(usersTable).values(user);\\n\\t}\\n\\n\\tasync select() {\\n\\t\\treturn this.db.select().from(usersTable);\\n\\t}\\n\\n\\tasync _migrate() {\\n\\t\\tmigrate(this.db, migrations);\\n\\t}\\n}\\n\\nexport default {\\n\\t/**\\n\\t * This is the standard fetch handler for a Cloudflare Worker\\n\\t *\\n\\t * @param request - The request submitted to the Worker from the client\\n\\t * @param env - The interface to reference bindings declared in wrangler.toml\\n\\t * @param ctx - The execution context of the Worker\\n\\t * @returns The response to be sent back to the client\\n\\t */\\n\\tasync fetch(request: Request, env: Env): Promise<Response> {\\n\\t\\tconst id: DurableObjectId = env.MY_DURABLE_OBJECT.idFromName(\\'durable-object\\');\\n\\t\\tconst stub = env.MY_DURABLE_OBJECT.get(id);\\n\\n\\t\\t// Option A - Maximum performance.\\n\\t\\t// Prefer to bundle all the database interaction within a single Durable Object call\\n\\t\\t// for maximum performance, since database access is fast within a DO.\\n\\t\\tconst usersAll = await stub.insertAndList({\\n\\t\\t\\tname: \\'John\\',\\n\\t\\t\\tage: 30,\\n\\t\\t\\temail: \\'john@example.com\\',\\n\\t\\t});\\n\\t\\tconsole.log(\\'New user created. Getting all users from the database: \\', users);\\n\\n\\t\\t// Option B - Slow but maybe useful sometimes for debugging.\\n\\t\\t// You can also directly call individual Drizzle queries if they are exposed\\n\\t\\t// but keep in mind every query is a round-trip to the Durable Object instance.\\n\\t\\tawait stub.insert({\\n\\t\\t\\tname: \\'John\\',\\n\\t\\t\\tage: 30,\\n\\t\\t\\temail: \\'john@example.com\\',\\n\\t\\t});\\n\\t\\tconsole.log(\\'New user created!\\');\\n\\t\\n\\t\\tconst users = await stub.select();\\n\\t\\tconsole.log(\\'Getting all users from the database: \\', users);\\n\\n\\t\\treturn Response.json(users);\\n\\t}\\n}\\n```', children=[]), DocItem(origPath=Path('get-started/expo-existing.mdx'), name='expo-existing.mdx', displayName='expo-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Breadcrumbs from '@mdx/Breadcrumbs.astro';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Expo in existing project\\n\\nWe don't have a proper guide for getting started with Expo in an existing project, and we believe that\\nall the information from this [getting started guide](/docs/get-started/expo-new) should be sufficient\", children=[]), DocItem(origPath=Path('get-started/expo-new.mdx'), name='expo-new.mdx', displayName='expo-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Expo\\n\\n<Prerequisites>  \\n  - **Expo SQLite** - A library that provides access to a database that can be queried through a SQLite API - [read here](https://docs.expo.dev/versions/latest/sdk/sqlite/)\\n</Prerequisites>\\n\\n\\n#### Step 1 - Setup a project from Expo Template\\n<Npx>\\ncreate expo-app --template blank-typescript\\n</Npx>\\n\\nYou can read more about this template [here](https://docs.expo.dev/more/create-expo/#create-a-new-project).\\n\\n#### Basic file structure\\n\\nAfter installing the template and adding the `db` folder, you\\'ll find the following content: In the `db/schema.ts` file with drizzle table definitions. The `drizzle` folder contains SQL migration files and snapshots\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ assets\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ db\\n â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“œ .gitignore\\n â”œ ðŸ“œ .npmrc\\n â”œ ðŸ“œ app.json\\n â”œ ðŸ“œ App.tsx\\n â”œ ðŸ“œ babel.config.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Step 2 - Install expo-sqlite package\\n<Npx>\\nexpo install expo-sqlite\\n</Npx>\\n\\n#### Step 3 - Install required packages\\n<Npm>\\n  drizzle-orm\\n  -D drizzle-kit\\n</Npm>\\n\\n#### Step 4 - Connect Drizzle ORM to the database\\n\\nCreate a `App.tsx` file in the root directory and initialize the connection:\\n\\n```ts\\nimport * as SQLite from \\'expo-sqlite\\';\\nimport { drizzle } from \\'drizzle-orm/expo-sqlite\\';\\n\\nconst expo = SQLite.openDatabaseSync(\\'db.db\\');\\n\\nconst db = drizzle(expo);\\n```\\n\\n#### Step 4 - Create a table\\n\\nCreate a `schema.ts` file in the `db` directory and declare your table:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\nexport const usersTable = sqliteTable(\"users_table\", {\\n  id: int().primaryKey({ autoIncrement: true }),\\n  name: text().notNull(),\\n  age: int().notNull(),\\n  email: text().notNull().unique(),\\n});\\n```\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'sqlite\\',\\n  driver: \\'expo\\',\\n  schema: \\'./db/schema.ts\\',\\n  out: \\'./drizzle\\',\\n});\\n```\\n\\n#### Step 6 - Setup `metro` config\\n\\nCreate a file `metro.config.js` in root folder and add this code inside:\\n\\n```js copy filename=\"metro.config.js\"\\nconst { getDefaultConfig } = require(\\'expo/metro-config\\');\\n/** @type {import(\\'expo/metro-config\\').MetroConfig} */\\nconst config = getDefaultConfig(__dirname);\\nconfig.resolver.sourceExts.push(\\'sql\\');\\nmodule.exports = config;\\n```\\n\\n#### Step 7 - Update `babel` config\\n```js copy filename=\"babel.config.js\"\\nmodule.exports = function(api) {\\n  api.cache(true);\\n  return {\\n    presets: [\\'babel-preset-expo\\'],\\n    plugins: [[\"inline-import\", { \"extensions\": [\".sql\"] }]] // <-- add this\\n  };\\n};\\n```\\n\\n#### Step 8 - Applying changes to the database\\n\\nWith Expo, you would need to generate migrations using the `drizzle-kit generate` command and then apply them at runtime using the `drizzle-orm` `migrate()` function\\n\\nGenerate migrations:\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\n#### Step 9 - Apply migrations and query your db:\\n\\nLet\\'s **App.tsx** file with migrations and queries to create, read, update, and delete users\\n\\n```ts copy\\nimport { Text, View } from \\'react-native\\';\\nimport * as SQLite from \\'expo-sqlite\\';\\nimport { useEffect, useState } from \\'react\\';\\nimport { drizzle } from \\'drizzle-orm/expo-sqlite\\';\\nimport { usersTable } from \\'./db/schema\\';\\nimport { useMigrations } from \\'drizzle-orm/expo-sqlite/migrator\\';\\nimport migrations from \\'./drizzle/migrations\\';\\n\\nconst expo = SQLite.openDatabaseSync(\\'db.db\\');\\n\\nconst db = drizzle(expo);\\n\\nexport default function App() {\\n  const { success, error } = useMigrations(db, migrations);\\n  const [items, setItems] = useState<typeof usersTable.$inferSelect[] | null>(null);\\n\\n  useEffect(() => {\\n    if (!success) return;\\n\\n    (async () => {\\n      await db.delete(usersTable);\\n\\n      await db.insert(usersTable).values([\\n        {\\n            name: \\'John\\',\\n            age: 30,\\n            email: \\'john@example.com\\',\\n        },\\n      ]);\\n\\n      const users = await db.select().from(usersTable);\\n      setItems(users);\\n    })();\\n  }, [success]);\\n\\n  if (error) {\\n    return (\\n      <View>\\n        <Text>Migration error: {error.message}</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (!success) {\\n    return (\\n      <View>\\n        <Text>Migration is in progress...</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (items === null || items.length === 0) {\\n    return (\\n      <View>\\n        <Text>Empty</Text>\\n      </View>\\n    );\\n  }\\n\\n  return (\\n    <View\\n      style={{\\n        display: \\'flex\\',\\n        flexDirection: \\'column\\',\\n        alignItems: \\'center\\',\\n        width: \\'100%\\',\\n        height: \\'100%\\',\\n        justifyContent: \\'center\\',\\n      }}\\n    >\\n      {items.map((item) => (\\n        <Text key={item.id}>{item.email}</Text>\\n      ))}\\n    </View>\\n  );\\n}\\n```\\n\\n#### Step 10 - Prebuild and run expo app\\n\\n<CodeTabs items={[\\'npm\\', \\'yarn\\', \\'pnpm\\', \\'bun\\']}>\\n```bash copy\\nnpx expo run:ios\\n```\\n```bash copy\\nyarn expo run:ios\\n```\\n```bash copy\\npnpm expo run:ios\\n```\\n```bash copy\\nbun expo run:ios\\n```\\n</CodeTabs>\\n', children=[]), DocItem(origPath=Path('get-started/gel-existing.mdx'), name='gel-existing.mdx', displayName='gel-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectPostgreSQL from \\'@mdx/get-started/postgresql/ConnectPostgreSQL.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Gel in existing project\\n\\n<Prerequisites>\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **gel-js** - package for querying your Gel database - [read here](https://github.com/geldata/gel-js)\\n</Prerequisites>\\n\\nDrizzle has native support for Gel connections with the `gel` client.\\n\\nThis is the basic file structure of the project. In the `src` directory, we have table definition in `index.ts`. In `drizzle` folder there are generated Gel to Drizzle schema\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ dbschema\\n â”‚ â”œ ðŸ“‚ migrations\\n â”‚ â”œ ðŸ“œ default.esdl\\n â”‚ â”” ðŸ“œ scoping.esdl\\n â”œ ðŸ“‚ src\\n â”‚ â”” ðŸ“œ index.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ edgedb.toml\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Step 1 - Install required packages\\n<Npm>\\n  drizzle-orm gel\\n  -D drizzle-kit tsx\\n</Npm>\\n\\n#### Step 2 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'gel\\',\\n});\\n```\\n\\n#### Step 3 - Pull Gel types to Drizzle schema\\n\\nPull your database schema:\\n<Npx>\\ndrizzle-kit pull\\n</Npx>\\n\\nHere is an example of the generated schema.ts file:\\n\\n```typescript filename=\"drizzle/schema.ts\"\\nimport { gelTable, uniqueIndex, uuid, smallint, text } from \"drizzle-orm/gel-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const users = gelTable(\"users\", {\\n\\tid: uuid().default(sql`uuid_generate_v4()`).primaryKey().notNull(),\\n\\tage: smallint(),\\n\\temail: text().notNull(),\\n\\tname: text(),\\n}, (table) => [\\n\\tuniqueIndex(\"a8c6061c-f37f-11ef-9249-0d78f6c1807b;schemaconstr\").using(\"btree\", table.id.asc().nullsLast().op(\"uuid_ops\")),\\n]);\\n```\\n\\n#### Step 4 - Connect Drizzle ORM to the database\\n\\nCreate a `index.ts` file in the `src` directory and initialize the connection:\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport { drizzle } from \"drizzle-orm/gel\";\\nimport { createClient } from \"gel\";\\n\\nconst gelClient = createClient();\\nconst db = drizzle({ client: gelClient });\\n```\\n\\n#### Step 5 - Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport { eq } from \"drizzle-orm\";\\nimport { drizzle } from \"drizzle-orm/gel\";\\nimport { createClient } from \"gel\";\\nimport { users } from \"../drizzle/schema\";\\n\\nconst gelClient = createClient();\\nconst db = drizzle({ client: gelClient });\\n\\nasync function main() {\\n  const user: typeof users.$inferInsert = {\\n    name: \"John\",\\n    age: 30,\\n    email: \"john@example.com\",\\n  };\\n\\n  await db.insert(users).values(user);\\n  console.log(\"New user created!\");\\n\\n  const usersResponse = await db.select().from(users);\\n  console.log(\"Getting all users from the database: \", usersResponse);\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(users)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(users.email, user.email));\\n  console.log(\"User info updated!\");\\n\\n  await db.delete(users).where(eq(users.email, user.email));\\n  console.log(\"User deleted!\");\\n}\\n\\nmain();\\n```\\n\\n#### Step 6 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/gel-new.mdx'), name='gel-new.mdx', displayName='gel-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectPostgreSQL from \\'@mdx/get-started/postgresql/ConnectPostgreSQL.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Gel\\n\\n<Prerequisites>\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **gel-js** - package for querying your Gel database - [read here](https://github.com/geldata/gel-js)\\n</Prerequisites>\\n\\nDrizzle has native support for Gel connections with the `gel` client.\\n\\nThis is the basic file structure of the project. In the `src` directory, we have table definition in `index.ts`. In `drizzle` folder there are generated Gel to Drizzle schema\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”‚ â”” ðŸ“œ index.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Step 1 - Install and init **Gel** project\\n\\n<Npx>\\ngel project init\\n</Npx>\\n\\n#### Step 2 - Define basic Gel schema\\n\\nIn `dbschema/default.esdl` file add a basic Gel schema\\n\\n```esdl\\nmodule default {\\n    type user {\\n        name: str;\\n        required email: str;\\n        age: int16;\\n    }\\n}\\n```\\n\\n#### Step 3 - Push Gel schema to the database\\n\\nGenerate Gel migration file:\\n```bash\\ngel migration create\\n```\\n\\nApply Gel migrations to the database\\n```bash\\ngel migration apply\\n```\\n\\n<Callout>\\nNow you should have this file structure\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ dbschema\\n â”‚ â”œ ðŸ“‚ migrations\\n â”‚ â”œ ðŸ“œ default.esdl\\n â”‚ â”” ðŸ“œ scoping.esdl\\n â”œ ðŸ“‚ src\\n â”‚ â”” ðŸ“œ index.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ edgedb.toml\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n</Callout>\\n\\n#### Step 4 - Install required packages\\n<Npm>\\n  drizzle-orm gel\\n  -D drizzle-kit tsx\\n</Npm>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'gel\\',\\n});\\n```\\n\\n#### Step 6 - Pull Gel types to Drizzle schema\\n\\nPull your database schema:\\n<Npx>\\ndrizzle-kit pull\\n</Npx>\\n\\nHere is an example of the generated schema.ts file:\\n\\n```typescript filename=\"drizzle/schema.ts\"\\nimport { gelTable, uniqueIndex, uuid, smallint, text } from \"drizzle-orm/gel-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const users = gelTable(\"users\", {\\n\\tid: uuid().default(sql`uuid_generate_v4()`).primaryKey().notNull(),\\n\\tage: smallint(),\\n\\temail: text().notNull(),\\n\\tname: text(),\\n}, (table) => [\\n\\tuniqueIndex(\"a8c6061c-f37f-11ef-9249-0d78f6c1807b;schemaconstr\").using(\"btree\", table.id.asc().nullsLast().op(\"uuid_ops\")),\\n]);\\n```\\n\\n#### Step 7 - Connect Drizzle ORM to the database\\n\\nCreate a `index.ts` file in the `src` directory and initialize the connection:\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport { drizzle } from \"drizzle-orm/gel\";\\nimport { createClient } from \"gel\";\\n\\nconst gelClient = createClient();\\nconst db = drizzle({ client: gelClient });\\n```\\n\\n#### Step 8 - Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport { eq } from \"drizzle-orm\";\\nimport { drizzle } from \"drizzle-orm/gel\";\\nimport { createClient } from \"gel\";\\nimport { users } from \"../drizzle/schema\";\\n\\nconst gelClient = createClient();\\nconst db = drizzle({ client: gelClient });\\n\\nasync function main() {\\n  const user: typeof users.$inferInsert = {\\n    name: \"John\",\\n    age: 30,\\n    email: \"john@example.com\",\\n  };\\n\\n  await db.insert(users).values(user);\\n  console.log(\"New user created!\");\\n\\n  const usersResponse = await db.select().from(users);\\n  console.log(\"Getting all users from the database: \", usersResponse);\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(users)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(users.email, user.email));\\n  console.log(\"User info updated!\");\\n\\n  await db.delete(users).where(eq(users.email, user.email));\\n  console.log(\"User deleted!\");\\n}\\n\\nmain();\\n```\\n\\n#### Step 9 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/mysql-existing.mdx'), name='mysql-existing.mdx', displayName='mysql-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectMySQL from \\'@mdx/get-started/mysql/ConnectMySQL.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/mysql/UpdateSchema.mdx\\';\\nimport IntrospectMySQL from \\'@mdx/get-started/mysql/IntrospectMySQL.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and MySQL in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **mysql2** - package for querying your MySQL database - [read here](https://github.com/sidorares/node-mysql2)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install the `mysql2` package\\n\\n<InstallPackages lib=\\'mysql2\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectMySQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectMySQL/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'mysql2\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'mysql2\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/mysql-new.mdx'), name='mysql-new.mdx', displayName='mysql-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectMySQL from \\'@mdx/get-started/mysql/ConnectMySQL.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and MySQL\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **mysql2** - package for querying your MySQL database - [read here](https://github.com/sidorares/node-mysql2)\\n</Prerequisites>\\n\\nTo use Drizzle with a MySQL database, you should use the `mysql2` driver\\n\\nAccording to the **[official website](https://github.com/sidorares/node-mysql2)**, \\n`mysql2` is a MySQL client for Node.js with focus on performance.  \\n\\nDrizzle ORM natively supports `mysql2` with `drizzle-orm/mysql2` package.\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **mysql2** package\\n\\n<InstallPackages lib=\\'mysql2\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n<Callout title=\\'tips\\'>\\nIf you don\\'t have a MySQL database yet and want to create one for testing, you can use our guide on how to set up MySQL in Docker.\\n\\nThe MySQL in Docker guide is available [here](/docs/guides/mysql-local-setup). Go set it up, generate a database URL (explained in the guide), and come back for the next steps\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectMySQL/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'mysql2\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/neon-existing.mdx'), name='neon-existing.mdx', displayName='neon-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectNeon from \\'@mdx/get-started/postgresql/ConnectNeon.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Neon in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Neon** - serverless Postgres platform - [read here](https://neon.tech/docs/introduction)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@neondatabase/serverless** package\\n<InstallPackages lib=\\'@neondatabase/serverless\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectNeon/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'neon-http\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'neon-http\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/neon-new.mdx'), name='neon-new.mdx', displayName='neon-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectNeon from \\'@mdx/get-started/postgresql/ConnectNeon.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Neon\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Neon** - serverless Postgres platform - [read here](https://neon.tech/docs/introduction)\\n</Prerequisites>\\n\\nDrizzle has native support for Neon connections with the `neon-http` and `neon-websockets` drivers. These use the **neon-serverless** driver under the hood.  \\n  \\nWith the `neon-http` and `neon-websockets` drivers, you can access a Neon database from serverless environments over HTTP or WebSockets instead of TCP. Querying over HTTP is faster for single, non-interactive transactions.  \\n  \\nIf you need session or interactive transaction support, or a fully compatible drop-in replacement for the `pg` driver, you can use the WebSocket-based `neon-serverless` driver. You can connect to a Neon database directly using [Postgres](/docs/get-started/postgresql-new)\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@neondatabase/serverless** package\\n<InstallPackages lib=\\'@neondatabase/serverless\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectNeon/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'neon-http\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/nile-existing.mdx'), name='nile-existing.mdx', displayName='nile-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectNile from \\'@mdx/get-started/postgresql/ConnectNile.mdx\\'\\nimport QueryNile from \\'@mdx/get-started/postgresql/QueryNile.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Nile in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Nile** - PostgreSQL re-engineered for multi-tenant apps - [read here](https://thenile.dev/)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'pg\\' devlib=\\' @types/pg\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'NILEDB_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'NILEDB_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\nDrizzle Kit provides a CLI command to introspect your database and generate a schema file with migrations. The schema file contains all the information about your database tables, columns, relations, and indices.\\n\\nFor example, you have such table in your database:\\n\\n```sql copy\\nCREATE TABLE IF NOT EXISTS \"todos\" (\\n  \"id\" uuid DEFAULT gen_random_uuid(),\\n  \"tenant_id\" uuid,\\n  \"title\" varchar(256),\\n  \"estimate\" varchar(256),\\n  \"embedding\" vector(3),\\n  \"complete\" boolean\\n);\\n```\\n\\nPull your database schema:\\n\\n```bash copy\\nnpx drizzle-kit pull\\n```\\n\\nThe result of introspection will be a `schema.ts` file, `meta` folder with snapshots of your database schema, sql file with the migration and `relations.ts` file for [relational queries](/docs/rqb).\\n\\n<Callout title=\\'built-in tables\\'>\\nNile has several built-in tables that are part of every database. When you introspect a Nile database, the built-in tables will be included. \\nFor example, the `tenants` table that you see in the example below. This will allow you to easily create new tenants, list tenants and other operations.\\n</Callout>\\n\\nHere is an example of the generated `schema.ts` file:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\n// table schema generated by introspection\\nimport { pgTable, uuid, text, timestamp, varchar, vector, boolean } from \"drizzle-orm/pg-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const tenants = pgTable(\"tenants\", {\\n\\tid: uuid().default(sql`public.uuid_generate_v7()`).primaryKey().notNull(),\\n\\tname: text(),\\n\\tcreated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tupdated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tdeleted: timestamp({ mode: \\'string\\' }),\\n});\\n\\nexport const todos = pgTable(\"todos\", {\\n\\tid: uuid().defaultRandom(),\\n\\ttenantId: uuid(\"tenant_id\"),\\n\\ttitle: varchar({ length: 256 }),\\n\\testimate: varchar({ length: 256 }),\\n\\tembedding: vector({ dimensions: 3 }),\\n\\tcomplete: boolean(),\\n});\\n```\\n\\nLearn more about introspection in the [documentation](/docs/drizzle-kit-pull).\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectNile/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryNile />\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\nIf you want to update your table schema, you can do it in the `schema.ts` file. For example, let\\'s add a new column `deadline` to the `todos` table`:\\n\\n```typescript copy filename=\"src/db/schema.ts\" {19}\\nimport { pgTable, uuid, text, timestamp, varchar, vector, boolean } from \"drizzle-orm/pg-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const tenants = pgTable(\"tenants\", {\\n\\tid: uuid().default(sql`public.uuid_generate_v7()`).primaryKey().notNull(),\\n\\tname: text(),\\n\\tcreated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tupdated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tdeleted: timestamp({ mode: \\'string\\' }),\\n});\\n\\nexport const todos = pgTable(\"todos\", {\\n\\tid: uuid().defaultRandom(),\\n\\ttenantId: uuid(\"tenant_id\"),\\n\\ttitle: varchar({ length: 256 }),\\n\\testimate: varchar({ length: 256 }),\\n\\tembedding: vector({ dimensions: 3 }),\\n\\tcomplete: boolean(),\\n  deadline: timestamp({ mode: \\'string\\' })\\n});\\n```\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\nIf you run the `index.ts` file again, you\\'ll be able to see the new field that you\\'ve just added. \\nThe field will be `null` since we did not populate deadlines when inserting todos previously.\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/nile-new.mdx'), name='nile-new.mdx', displayName='nile-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectNile from \\'@mdx/get-started/postgresql/ConnectNile.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryNile from \\'@mdx/get-started/postgresql/QueryNile.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Nile\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Nile** - PostgreSQL re-engineered for multi-tenant apps - [read here](https://thenile.dev/)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'pg\\' devlib=\\' @types/pg\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'NILEDB_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectNile />\\n\\n#### Step 4 - Create a table\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare your tables. Since Nile is Postgres for multi-tenant apps, our schema includes a table for tenants and a todos table with a `tenant_id` column (we refer to those as tenant-aware tables):\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { pgTable, uuid, text, timestamp, varchar, vector, boolean } from \"drizzle-orm/pg-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const tenantsTable = pgTable(\"tenants\", {\\n\\tid: uuid().default(sql`public.uuid_generate_v7()`).primaryKey().notNull(),\\n\\tname: text(),\\n\\tcreated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tupdated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tdeleted: timestamp({ mode: \\'string\\' }),\\n});\\n\\nexport const todos = pgTable(\"todos\", {\\n\\tid: uuid().defaultRandom(),\\n\\ttenantId: uuid(\"tenant_id\"),\\n\\ttitle: varchar({ length: 256 }),\\n\\testimate: varchar({ length: 256 }),\\n\\tembedding: vector({ dimensions: 3 }),\\n\\tcomplete: boolean(),\\n});\\n```\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'NILEDB_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges dialect=\\'postgresql\\'/>\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryNile />\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/op-sqlite-existing.mdx'), name='op-sqlite-existing.mdx', displayName='op-sqlite-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Breadcrumbs from '@mdx/Breadcrumbs.astro';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and OP-SQLite in existing project\\n\\nWe don't have a proper guide for getting started with OP-SQLite in an existing project, and we believe that\\nall the information from this [getting started guide](/docs/get-started/op-sqlite-new) should be sufficient\", children=[]), DocItem(origPath=Path('get-started/op-sqlite-new.mdx'), name='op-sqlite-new.mdx', displayName='op-sqlite-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and OP-SQLite\\n\\n<Prerequisites>  \\n  - **OP-SQLite** - SQLite library for react-native - [read here](https://github.com/OP-Engineering/op-sqlite)\\n</Prerequisites>\\n\\n\\n#### Step 1 - Setup a project from Expo Template\\n<Npx>\\ncreate expo-app --template blank-typescript\\n</Npx>\\n\\nYou can read more about this template [here](https://docs.expo.dev/more/create-expo/#create-a-new-project).\\n\\n#### Basic file structure\\n\\nAfter installing the template and adding the `db` folder, you\\'ll find the following content: In the `db/schema.ts` file with drizzle table definitions. The `drizzle` folder contains SQL migration files and snapshots\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ assets\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ db\\n â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“œ .gitignore\\n â”œ ðŸ“œ .npmrc\\n â”œ ðŸ“œ app.json\\n â”œ ðŸ“œ App.tsx\\n â”œ ðŸ“œ babel.config.ts\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Step 2 - Install required packages\\n<Npm>\\n  drizzle-orm @op-engineering/op-sqlite\\n  -D drizzle-kit\\n</Npm>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\nCreate a `App.tsx` file in the root directory and initialize the connection:\\n\\n```ts\\nimport { open } from \\'@op-engineering/op-sqlite\\';\\nimport { drizzle } from \\'drizzle-orm/op-sqlite\\';\\n\\nconst opsqliteDb = open({\\n  name: \\'db\\',\\n});\\n\\nconst db = drizzle(opsqliteDb);\\n```\\n\\n#### Step 4 - Create a table\\n\\nCreate a `schema.ts` file in the `db` directory and declare your table:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\nexport const usersTable = sqliteTable(\"users_table\", {\\n  id: int().primaryKey({ autoIncrement: true }),\\n  name: text().notNull(),\\n  age: int().notNull(),\\n  email: text().notNull().unique(),\\n});\\n```\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'sqlite\\',\\n  driver: \\'expo\\',\\n  schema: \\'./db/schema.ts\\',\\n  out: \\'./drizzle\\',\\n});\\n```\\n\\n#### Step 6 - Setup `metro` config\\n\\nCreate a file `metro.config.js` in root folder and add this code inside:\\n\\n```js copy filename=\"metro.config.js\"\\nconst { getDefaultConfig } = require(\\'expo/metro-config\\');\\n/** @type {import(\\'expo/metro-config\\').MetroConfig} */\\nconst config = getDefaultConfig(__dirname);\\nconfig.resolver.sourceExts.push(\\'sql\\');\\nmodule.exports = config;\\n```\\n\\n#### Step 7 - Update `babel` config\\n```js copy filename=\"babel.config.js\"\\nmodule.exports = function(api) {\\n  api.cache(true);\\n  return {\\n    presets: [\\'babel-preset-expo\\'],\\n    plugins: [[\"inline-import\", { \"extensions\": [\".sql\"] }]] // <-- add this\\n  };\\n};\\n```\\n\\n#### Step 8 - Applying changes to the database\\n\\nWith Expo, you would need to generate migrations using the `drizzle-kit generate` command and then apply them at runtime using the `drizzle-orm` `migrate()` function\\n\\nGenerate migrations:\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\n#### Step 9 - Apply migrations and query your db:\\n\\nLet\\'s **App.tsx** file with migrations and queries to create, read, update, and delete users\\n\\n```ts copy\\nimport { Text, View } from \\'react-native\\';\\nimport { open } from \\'@op-engineering/op-sqlite\\';\\nimport { useEffect, useState } from \\'react\\';\\nimport { drizzle } from \\'drizzle-orm/op-sqlite\\';\\nimport { usersTable } from \\'./db/schema\\';\\nimport { useMigrations } from \\'drizzle-orm/op-sqlite/migrator\\';\\nimport migrations from \\'./drizzle/migrations\\';\\n\\nconst opsqliteDb = open({\\n  name: \\'db\\',\\n});\\n\\nconst db = drizzle(opsqliteDb);\\n\\nexport default function App() {\\n  const { success, error } = useMigrations(db, migrations);\\n  const [items, setItems] = useState<typeof usersTable.$inferSelect[] | null>(null);\\n\\n  useEffect(() => {\\n    if (!success) return;\\n\\n    (async () => {\\n      await db.delete(usersTable);\\n\\n      await db.insert(usersTable).values([\\n        {\\n            name: \\'John\\',\\n            age: 30,\\n            email: \\'john@example.com\\',\\n        },\\n      ]);\\n\\n      const users = await db.select().from(usersTable);\\n      setItems(users);\\n    })();\\n  }, [success]);\\n\\n  if (error) {\\n    return (\\n      <View>\\n        <Text>Migration error: {error.message}</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (!success) {\\n    return (\\n      <View>\\n        <Text>Migration is in progress...</Text>\\n      </View>\\n    );\\n  }\\n\\n  if (items === null || items.length === 0) {\\n    return (\\n      <View>\\n        <Text>Empty</Text>\\n      </View>\\n    );\\n  }\\n\\n  return (\\n    <View\\n      style={{\\n        display: \\'flex\\',\\n        flexDirection: \\'column\\',\\n        alignItems: \\'center\\',\\n        width: \\'100%\\',\\n        height: \\'100%\\',\\n        justifyContent: \\'center\\',\\n      }}\\n    >\\n      {items.map((item) => (\\n        <Text key={item.id}>{item.email}</Text>\\n      ))}\\n    </View>\\n  );\\n}\\n```\\n\\n#### Step 10 - Prebuild and run expo app\\n\\n<CodeTabs items={[\\'npm\\', \\'yarn\\', \\'pnpm\\', \\'bun\\']}>\\n```bash copy\\nnpx expo run:ios\\n```\\n```bash copy\\nyarn expo run:ios\\n```\\n```bash copy\\npnpm expo run:ios\\n```\\n```bash copy\\nbun expo run:ios\\n```\\n</CodeTabs>', children=[]), DocItem(origPath=Path('get-started/pglite-existing.mdx'), name='pglite-existing.mdx', displayName='pglite-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectPgLite from \\'@mdx/get-started/postgresql/ConnectPgLite.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PGLite in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **ElectricSQL** - [website](https://electric-sql.com/)\\n  - **pglite driver** - [docs](https://pglite.dev/) & [GitHub](https://github.com/electric-sql/pglite)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install all needed packages\\n<InstallPackages lib=\\'@electric-sql/pglite\\' />\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectPgLite/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'pglite\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'pglite\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/pglite-new.mdx'), name='pglite-new.mdx', displayName='pglite-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectPgLite from \\'@mdx/get-started/postgresql/ConnectPgLite.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PGlite\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **ElectricSQL** - [website](https://electric-sql.com/)\\n  - **pglite driver** - [docs](https://pglite.dev/) & [GitHub](https://github.com/electric-sql/pglite)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install all needed packages\\n<InstallPackages lib=\\'@electric-sql/pglite\\' />\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectPgLite/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'pglite\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/planetscale-existing.mdx'), name='planetscale-existing.mdx', displayName='planetscale-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectPlanetScale from \\'@mdx/get-started/mysql/ConnectPlanetScale.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/mysql/UpdateSchema.mdx\\';\\nimport IntrospectMySQL from \\'@mdx/get-started/mysql/IntrospectMySQL.mdx\\';\\nimport QueryPlanetScale from \\'@mdx/get-started/mysql/QueryPlanetScale.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PlanetScale in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is)\\n  - **PlanetScale** - MySQL database platform - [read here](https://planetscale.com)\\n  - **database-js** - PlanetScale serverless driver - [read here](https://github.com/planetscale/database-js)\\n</Prerequisites>\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nFor this tutorial, we will use the `database-js` driver to make **HTTP** calls to the PlanetScale database. If you need to\\nconnect to PlanetScale through TCP, you can refer to our [MySQL Get Started](/docs/get-started/mysql-new) page\\n</Callout>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@planetscale/database** package\\n\\n<InstallPackages lib=\\'@planetscale/database\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectMySQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectPlanetScale/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryPlanetScale />\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/planetscale-serverless\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle({ connection: {\\n      host: process.env.DATABASE_HOST!,\\n      username: process.env.DATABASE_USERNAME!,\\n      password: process.env.DATABASE_PASSWORD!,\\n    }});\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n    phone: \\'123-456-7890\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n    phone: string | null;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```', children=[]), DocItem(origPath=Path('get-started/planetscale-new.mdx'), name='planetscale-new.mdx', displayName='planetscale-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectPlanetScale from \\'@mdx/get-started/mysql/ConnectPlanetScale.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport QueryPlanetScale from \\'@mdx/get-started/mysql/QueryPlanetScale.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PlanetScale\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is)\\n  - **PlanetScale** - MySQL database platform - [read here](https://planetscale.com)\\n  - **database-js** - PlanetScale serverless driver - [read here](https://github.com/planetscale/database-js)\\n</Prerequisites>\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nFor this tutorial, we will use the `database-js` driver to make **HTTP** calls to the PlanetScale database. If you need to\\nconnect to PlanetScale through TCP, you can refer to our [MySQL Get Started](/docs/get-started/mysql-new) page\\n</Callout>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@planetscale/database** package\\n\\n<InstallPackages lib=\\'@planetscale/database\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\nCreate a `.env` file in the root of your project and add your database connection variable:\\n\\n```plaintext copy\\nDATABASE_HOST=\\nDATABASE_USERNAME=\\nDATABASE_PASSWORD=\\n```\\n\\n<Callout title=\\'tips\\'>\\nTo get all the necessary environment variables to connect through the `database-js` driver, you can check the [PlanetScale docs](https://planetscale.com/docs/tutorials/planetscale-serverless-driver-node-example#use-the-sample-repository)\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectPlanetScale/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryPlanetScale />\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/postgresql-existing.mdx'), name='postgresql-existing.mdx', displayName='postgresql-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectPostgreSQL from \\'@mdx/get-started/postgresql/ConnectPostgreSQL.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PostgreSQL in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **node-postgres** - package for querying your PostgreSQL database - [read here](https://node-postgres.com/)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **node-postgres** package\\n<InstallPackages lib=\\'pg\\' devlib=\\' @types/pg\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n<Callout title=\\'tips\\'>\\nIf you don\\'t have a PostgreSQL database yet and want to create one for testing, you can use our guide on how to set up PostgreSQL in Docker.\\n\\nThe PostgreSQL in Docker guide is available [here](/docs/guides/postgresql-local-setup). Go set it up, generate a database URL (explained in the guide), and come back for the next steps\\n</Callout>\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectPostgreSQL/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'node-postgres\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'node-postgres\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/postgresql-new.mdx'), name='postgresql-new.mdx', displayName='postgresql-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectPostgreSQL from \\'@mdx/get-started/postgresql/ConnectPostgreSQL.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and PostgreSQL\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **node-postgres** - package for querying your PostgreSQL database - [read here](https://node-postgres.com/)\\n</Prerequisites>\\n\\nDrizzle has native support for PostgreSQL connections with the `node-postgres` and `postgres.js` drivers.\\n\\nWe will use `node-postgres` for this get started example. But if you want to find more ways to connect to postgresql check\\nour [PostgreSQL Connection](/docs/get-started-postgresql) page \\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **node-postgres** package\\n<InstallPackages lib=\\'pg\\' devlib=\\' @types/pg\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n<Callout title=\\'tips\\'>\\nIf you don\\'t have a PostgreSQL database yet and want to create one for testing, you can use our guide on how to set up PostgreSQL in Docker.\\n\\nThe PostgreSQL in Docker guide is available [here](/docs/guides/postgresql-local-setup). Go set it up, generate a database URL (explained in the guide), and come back for the next steps\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectPostgreSQL/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'node-postgres\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/singlestore-existing.mdx'), name='singlestore-existing.mdx', displayName='singlestore-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectSingleStore from \\'@mdx/get-started/singlestore/ConnectSingleStore.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/singlestore/UpdateSchema.mdx\\';\\nimport IntrospectSingleStore from \\'@mdx/get-started/singlestore/IntrospectSingleStore.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SingleStore in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **mysql2** - package for querying your SingleStore database - [read here](https://github.com/sidorares/node-mysql2)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install the `mysql2` package\\n\\n<InstallPackages lib=\\'mysql2\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'singlestore\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSingleStore/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectSingleStore/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'singlestore\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'singlestore\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/singlestore-new.mdx'), name='singlestore-new.mdx', displayName='singlestore-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectSingleStore from \\'@mdx/get-started/singlestore/ConnectSingleStore.mdx\\';\\nimport CreateSingleStoreTable from \\'@mdx/get-started/singlestore/CreateSingleStoreTable.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SingleStore\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **mysql2** - package for querying your MySQL database - [read here](https://github.com/sidorares/node-mysql2)\\n</Prerequisites>\\n\\nTo use Drizzle with a SingleStore database, you should use the `singlestore` driver\\n\\nAccording to the **[official website](https://github.com/sidorares/node-mysql2)**, \\n`mysql2` is a MySQL client for Node.js with focus on performance.  \\n\\nDrizzle ORM natively supports `mysql2` with `drizzle-orm/singlestore` package for SingleStore database.\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **mysql2** package\\n\\n<InstallPackages lib=\\'mysql2\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectSingleStore/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateSingleStoreTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'singlestore\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'singlestore\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/sqlite-cloud-existing.mdx'), name='sqlite-cloud-existing.mdx', displayName='sqlite-cloud-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectSQLite from \\'@mdx/get-started/sqlite/IntrospectSqlite.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectSQLiteCloud from \\'@mdx/get-started/sqlite/ConnectSQLiteCloud.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/sqlite/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite Cloud in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **SQLite Cloud database** - [read here](https://docs.sqlitecloud.io/docs/overview)\\n  - **SQLite Cloud driver** - [read here](https://docs.sqlitecloud.io/docs/sdk-js-introduction) & [GitHub](https://github.com/sqlitecloud/sqlitecloud-js)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<Npm>\\n  drizzle-orm@beta @sqlitecloud/drivers dotenv\\n  -D drizzle-kit@beta tsx\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'SQLITE_CLOUD_CONNECTION_STRING\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'SQLITE_CLOUD_CONNECTION_STRING\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSQLite/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectSQLiteCloud/>\\n\\n#### Step 7 - Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/sqlite-cloud\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/sqlite-cloud\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n    phone: \\'123-456-7890\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n    phone: string | null;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```', children=[]), DocItem(origPath=Path('get-started/sqlite-cloud-new.mdx'), name='sqlite-cloud-new.mdx', displayName='sqlite-cloud-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectSQLiteCloud from \\'@mdx/get-started/sqlite/ConnectSQLiteCloud.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite Cloud\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **SQLite Cloud database** - [read here](https://docs.sqlitecloud.io/docs/overview)\\n  - **SQLite Cloud driver** - [read here](https://docs.sqlitecloud.io/docs/sdk-js-introduction) & [GitHub](https://github.com/sqlitecloud/sqlitecloud-js)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<Npm>\\n  drizzle-orm@beta @sqlitecloud/drivers dotenv\\n  -D drizzle-kit@beta tsx\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'SQLITE_CLOUD_CONNECTION_STRING\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectSQLiteCloud/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'SQLITE_CLOUD_CONNECTION_STRING\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/sqlite-cloud\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/sqlite-existing.mdx'), name='sqlite-existing.mdx', displayName='sqlite-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport IntrospectSqlite from \\'@mdx/get-started/sqlite/IntrospectSqlite.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/sqlite/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **libsql** - a fork of SQLite optimized for low query latency, making it suitable for global applications - [read here](https://docs.turso.tech/libsql)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n\\n<InstallPackages lib=\\'@libsql/client\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you want to create an SQLite database file in the root of your project for testing purposes, you need to use `file:` before the actual filename, as this is the format required by `LibSQL`, like this:\\n```plaintext copy\\nDB_FILE_NAME=file:local.db\\n```\\nYou can check the **[LibSQL docs](https://docs.turso.tech/sdk/ts/reference#local-development)** for more info.\\n</Callout>\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSqlite/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectLibsql/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'libsql\\' env_variable=\\'DB_FILE_NAME\\' />\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 9 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 10 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'libsql\\' env_variable=\\'DB_FILE_NAME\\' />', children=[]), DocItem(origPath=Path('get-started/sqlite-new.mdx'), name='sqlite-new.mdx', displayName='sqlite-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and SQLite\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **libsql** - a fork of SQLite optimized for low query latency, making it suitable for global applications - [read here](https://docs.turso.tech/libsql)\\n</Prerequisites>\\n\\nDrizzle has native support for SQLite connections with the `libsql` and `better-sqlite3` drivers.\\n\\nWe will use `libsql` for this get started example. But if you want to find more ways to connect to SQLite check\\nour [SQLite Connection](/docs/get-started-sqlite) page \\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<InstallPackages lib=\\'@libsql/client\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you want to create an SQLite database file in the root of your project for testing purposes, you need to use `file:` before the actual filename, as this is the format required by `LibSQL`, like this:\\n```plaintext copy\\nDB_FILE_NAME=file:local.db\\n```\\nYou can check the **[LibSQL docs](https://docs.turso.tech/sdk/ts/reference#local-development)** for more info.\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectLibsql/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'libsql\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/supabase-existing.mdx'), name='supabase-existing.mdx', displayName='supabase-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectSupabase from \\'@mdx/get-started/postgresql/ConnectSupabase.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Supabase in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Supabase** - open source Firebase alternative - [read here](https://supabase.com/)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectSupabase/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/supabase-new.mdx'), name='supabase-new.mdx', displayName='supabase-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectSupabase from \\'@mdx/get-started/postgresql/ConnectSupabase.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Supabase\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Supabase** - open source Firebase alternative - [read here](https://supabase.com/)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectSupabase/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/tidb-existing.mdx'), name='tidb-existing.mdx', displayName='tidb-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectTiDB from \\'@mdx/get-started/mysql/ConnectTiDB.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/mysql/UpdateSchema.mdx\\';\\nimport IntrospectMySQL from \\'@mdx/get-started/mysql/IntrospectMySQL.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and TiDB in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **TiDB** - The Distributed SQL Database by PingCAP - [read here](https://www.pingcap.com/)\\n  - **serverless-js** - package for serverless and edge compute platforms that require HTTP external connections - [read here](https://github.com/tidbcloud/serverless-js)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@tidbcloud/serverless** package\\n\\n<InstallPackages lib=\\'@tidbcloud/serverless\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectMySQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectTiDB/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'tidb-serverless\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'tidb-serverless\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/tidb-new.mdx'), name='tidb-new.mdx', displayName='tidb-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport ConnectTiDB from \\'@mdx/get-started/mysql/ConnectTiDB.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/mysql/CreateTable.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and TiDB\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **TiDB** - The Distributed SQL Database by PingCAP - [read here](https://www.pingcap.com/)\\n  - **serverless-js** - package for serverless and edge compute platforms that require HTTP external connections - [read here](https://github.com/tidbcloud/serverless-js)\\n</Prerequisites>\\n\\n<Callout title=\\'important\\' type=\\'warning\\'>\\nFor this tutorial, we will use the `@tidbcloud/serverless` driver to make **HTTP** calls. If you need to\\nconnect to TiDB through TCP, you can refer to our [MySQL Get Started](/docs/get-started/mysql-new) page\\n</Callout>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **@tidbcloud/serverless** package\\n\\n<InstallPackages lib=\\'@tidbcloud/serverless\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectTiDB/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'mysql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'tidb-serverless\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/turso-database-existing.mdx'), name='turso-database-existing.mdx', displayName='turso-database-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectSQLite from \\'@mdx/get-started/sqlite/IntrospectSqlite.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectTursoDatabase from \\'@mdx/get-started/sqlite/ConnectTursoDatabase.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/sqlite/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Turso Database in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - Turso Database - [website](https://docs.turso.tech/introduction)\\n  - Turso Database driver - [website](https://docs.turso.tech/connect/javascript) & [GitHub](https://github.com/tursodatabase/turso/tree/main/bindings/javascript)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<Npm>\\n  drizzle-orm@beta @tursodatabase/database dotenv\\n  -D drizzle-kit@beta tsx\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you want to create an SQLite database file in the root of your project for testing purposes, you can use this example:\\n```plaintext copy\\nDB_FILE_NAME=mydb.sqlite\\n```\\n</Callout>\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSQLite/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectTursoDatabase/>\\n\\n#### Step 7 - Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/tursodatabase/database\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/tursodatabase/database\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n    phone: \\'123-456-7890\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n    phone: string | null;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```', children=[]), DocItem(origPath=Path('get-started/turso-database-new.mdx'), name='turso-database-new.mdx', displayName='turso-database-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectTursoDatabase from \\'@mdx/get-started/sqlite/ConnectTursoDatabase.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Turso Database\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - Turso Database - [website](https://docs.turso.tech/introduction)\\n  - Turso Database driver - [website](https://docs.turso.tech/connect/javascript) & [GitHub](https://github.com/tursodatabase/turso/tree/main/bindings/javascript)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<Npm>\\n  drizzle-orm@beta @tursodatabase/database dotenv\\n  -D drizzle-kit@beta tsx\\n</Npm>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DB_FILE_NAME\\' />\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nFor example, if you want to create an SQLite database file in the root of your project for testing purposes, you can use this example:\\n```plaintext copy\\nDB_FILE_NAME=mydb.sqlite\\n```\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectTursoDatabase/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'sqlite\\' env_variable=\\'DB_FILE_NAME\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/tursodatabase/database\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/turso-existing.mdx'), name='turso-existing.mdx', displayName='turso-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport IntrospectSqlite from \\'@mdx/get-started/sqlite/IntrospectSqlite.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/sqlite/UpdateSchema.mdx\\';\\nimport QueryTurso from \\'@mdx/get-started/sqlite/QueryTurso.mdx\\';\\nimport QueryTursoUpdated from \\'@mdx/get-started/sqlite/QueryTursoUpdated.mdx\\';\\nimport LibsqlTable from \\'@mdx/LibsqlTable.mdx\\';\\nimport LibsqlTabs from \\'@mdx/LibsqlTabs.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Turso Cloud in existing project\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **turso** - SQLite for Production - [read here](https://turso.tech/)\\n  - **libsql** - a fork of SQLite optimized for low query latency, making it suitable for global applications - [read here](https://docs.turso.tech/libsql)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n\\n<InstallPackages lib=\\'@libsql/client\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\nCreate a `.env` file in the root of your project and add you Turso database url and auth token:\\n\\n```plaintext copy\\nTURSO_DATABASE_URL=\\nTURSO_AUTH_TOKEN=\\n```\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nIf you don\\'t know your `TURSO_DATABASE_URL` and `TURSO_AUTH_TOKEN` values, you can refer to the LibSQL Driver SDK tutorial. \\nCheck it out [here](https://docs.turso.tech/sdk/ts/quickstart), then return with all the values generated and added to the `.env` file\\n</Callout>\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  out: \\'./drizzle\\',\\n  schema: \\'./src/db/schema.ts\\',\\n  dialect: \\'turso\\',\\n  dbCredentials: {\\n    url: process.env.TURSO_DATABASE_URL,\\n    authToken: process.env.TURSO_AUTH_TOKEN,\\n  },\\n});\\n```\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectSqlite/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\nDrizzle has native support for all @libsql/client driver variations:\\n\\n<LibsqlTable />\\n<br/>\\n<LibsqlTabs />\\n\\nCreate a `index.ts` file in the `src` directory and initialize the connection:\\n\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\n// You can specify any property from the libsql connection options\\nconst db = drizzle({ \\n  connection: { \\n    url: process.env.TURSO_DATABASE_URL!, \\n    authToken: process.env.TURSO_AUTH_TOKEN!\\n  }\\n});\\n```\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\nimport { createClient } from \\'@libsql/client\\';\\n\\nconst client = createClient({ \\n  url: process.env.TURSO_DATABASE_URL!, \\n  authToken: process.env.TURSO_AUTH_TOKEN!\\n});\\n\\nconst db = drizzle({ client });\\n```\\n\\n#### Step 7 - Query the database\\n\\n<QueryTurso/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 9 - Applying changes to the database (optional)\\n\\n<ApplyChanges/>\\n\\n#### Step 10 - Query the database with a new field (optional)\\n\\n<QueryTursoUpdated />', children=[]), DocItem(origPath=Path('get-started/turso-new.mdx'), name='turso-new.mdx', displayName='turso-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport QueryTurso from \\'@mdx/get-started/sqlite/QueryTurso.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport CreateTable from \\'@mdx/get-started/sqlite/CreateTable.mdx\\';\\nimport ConnectLibsql from \\'@mdx/get-started/sqlite/ConnectLibsql.mdx\\';\\nimport LibsqlTable from \\'@mdx/LibsqlTable.mdx\\';\\nimport LibsqlTabs from \\'@mdx/LibsqlTabs.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Turso Cloud\\n\\n<Prerequisites>  \\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **turso** - SQLite for Production - [read here](https://turso.tech/)\\n  - **libsql** - a fork of SQLite optimized for low query latency, making it suitable for global applications - [read here](https://docs.turso.tech/libsql)\\n</Prerequisites>\\n\\n<FileStructure />\\n\\n#### Step 1 - Install required packages\\n<InstallPackages lib=\\'@libsql/client\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\nCreate a `.env` file in the root of your project and add you Turso database url and auth token:\\n\\n```plaintext copy\\nTURSO_DATABASE_URL=\\nTURSO_AUTH_TOKEN=\\n```\\n\\n<Callout type=\\'info\\' title=\\'important\\'>\\nIf you don\\'t know your `TURSO_DATABASE_URL` and `TURSO_AUTH_TOKEN` values, you can refer to the LibSQL Driver SDK tutorial. \\nCheck it out [here](https://docs.turso.tech/sdk/ts/quickstart), then return with all the values generated and added to the `.env` file\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\nDrizzle has native support for all @libsql/client driver variations:\\n\\n<LibsqlTable />\\n<br/>\\n<LibsqlTabs />\\n\\nCreate a `index.ts` file in the `src` directory and initialize the connection:\\n\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\n// You can specify any property from the libsql connection options\\nconst db = drizzle({ \\n  connection: { \\n    url: process.env.TURSO_DATABASE_URL!, \\n    authToken: process.env.TURSO_AUTH_TOKEN!\\n  }\\n});\\n```\\n\\nIf you need to provide your existing driver:\\n```typescript copy\\nimport \\'dotenv/config\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\nimport { createClient } from \\'@libsql/client\\';\\n\\nconst client = createClient({ \\n  url: process.env.TURSO_DATABASE_URL!, \\n  authToken: process.env.TURSO_AUTH_TOKEN!\\n});\\nconst db = drizzle({ client });\\n```\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable/>\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  out: \\'./drizzle\\',\\n  schema: \\'./src/db/schema.ts\\',\\n  dialect: \\'turso\\',\\n  dbCredentials: {\\n    url: process.env.TURSO_DATABASE_URL,\\n    authToken: process.env.TURSO_AUTH_TOKEN,\\n  },\\n});\\n```\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryTurso/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/vercel-existing.mdx'), name='vercel-existing.mdx', displayName='vercel-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectVercel from \\'@mdx/get-started/postgresql/ConnectVercel.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Vercel Postgres in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Vercel Postgres database** - [read here](https://vercel.com/docs/storage/vercel-postgres)\\n  - **Vercel Postgres driver** - [read here](https://vercel.com/docs/storage/vercel-postgres/sdk) & [GitHub](https://github.com/vercel/storage/tree/main/packages/postgres)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<InstallPackages lib=\\'@vercel/postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'POSTGRES_URL\\' />\\n\\n<Callout title=\\'warning\\'>\\nIt\\'s important to name the variable `POSTGRES_URL` for Vercel Postgres.\\n\\nIn the Vercel Postgres storage tab, you can find the `.env.local` tab and copy the `POSTGRES_URL` variable\\n</Callout>\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'POSTGRES_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectVercel/>\\n\\n#### Step 7 - Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n    phone: \\'123-456-7890\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n    phone: string | null;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```', children=[]), DocItem(origPath=Path('get-started/vercel-new.mdx'), name='vercel-new.mdx', displayName='vercel-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectVercel from \\'@mdx/get-started/postgresql/ConnectVercel.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Vercel Postgres\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Vercel Postgres database** - [read here](https://vercel.com/docs/storage/vercel-postgres)\\n  - **Vercel Postgres driver** - [read here](https://vercel.com/docs/storage/vercel-postgres/sdk) & [GitHub](https://github.com/vercel/storage/tree/main/packages/postgres)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install required package\\n<InstallPackages lib=\\'@vercel/postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'POSTGRES_URL\\' />\\n\\n<Callout title=\\'warning\\'>\\nIt\\'s important to name the variable `POSTGRES_URL` for Vercel Postgres.\\n\\nIn the Vercel Postgres storage tab, you can find the `.env.local` tab and copy the `POSTGRES_URL` variable\\n</Callout>\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectVercel/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'POSTGRES_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\nimport { usersTable } from \\'./db/schema\\';\\n\\nasync function main() {\\n  const db = drizzle();\\n\\n  const user: typeof usersTable.$inferInsert = {\\n    name: \\'John\\',\\n    age: 30,\\n    email: \\'john@example.com\\',\\n  };\\n\\n  await db.insert(usersTable).values(user);\\n  console.log(\\'New user created!\\')\\n\\n  const users = await db.select().from(usersTable);\\n  console.log(\\'Getting all users from the database: \\', users)\\n  /*\\n  const users: {\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }[]\\n  */\\n\\n  await db\\n    .update(usersTable)\\n    .set({\\n      age: 31,\\n    })\\n    .where(eq(usersTable.email, user.email));\\n  console.log(\\'User info updated!\\')\\n\\n  await db.delete(usersTable).where(eq(usersTable.email, user.email));\\n  console.log(\\'User deleted!\\')\\n}\\n\\nmain();\\n```\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[]), DocItem(origPath=Path('get-started/xata-existing.mdx'), name='xata-existing.mdx', displayName='xata-existing.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IntrospectPostgreSQL from \\'@mdx/get-started/postgresql/IntrospectPostgreSQL.mdx\\';\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport ConnectXata from \\'@mdx/get-started/postgresql/ConnectXata.mdx\\'\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport QueryDatabaseUpdated from \\'@mdx/get-started/QueryDatabaseUpdated.mdx\\';\\nimport UpdateSchema from \\'@mdx/get-started/postgresql/UpdateSchema.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Xata in existing project\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Xata Postgres database** - [read here](https://xata.io/documentation)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\nYou can obtain a connection string by following the [Xata documentation](https://xata.io/documentation/getting-started).\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 4 - Introspect your database\\n\\n<IntrospectPostgreSQL/>\\n\\n#### Step 5 - Transfer code to your actual schema file\\n\\n<TransferCode/>\\n\\n#### Step 6 - Connect Drizzle ORM to the database\\n\\n<ConnectXata/>\\n\\n#### Step 7 - Query the database\\n\\n<QueryDatabase dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>\\n\\n#### Step 9 - Update your table schema (optional)\\n\\n<UpdateSchema/>\\n\\n#### Step 10 - Applying changes to the database (optional)\\n\\n<ApplyChanges />\\n\\n#### Step 11 - Query the database with a new field (optional)\\n\\n<QueryDatabaseUpdated dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\' />', children=[]), DocItem(origPath=Path('get-started/xata-new.mdx'), name='xata-new.mdx', displayName='xata-new.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Breadcrumbs from \\'@mdx/Breadcrumbs.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport FileStructure from \\'@mdx/get-started/FileStructure.mdx\\';\\nimport InstallPackages from \\'@mdx/get-started/InstallPackages.mdx\\';\\nimport ConnectXata from \\'@mdx/get-started/postgresql/ConnectXata.mdx\\'\\nimport CreateTable from \\'@mdx/get-started/postgresql/CreateTable.mdx\\'\\nimport SetupConfig from \\'@mdx/get-started/SetupConfig.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\nimport QueryDatabase from \\'@mdx/get-started/QueryDatabase.mdx\\';\\nimport SetupEnv from \\'@mdx/get-started/SetupEnv.mdx\\';\\n\\n<Breadcrumbs/>\\n\\n# Get Started with Drizzle and Xata\\n\\n<Prerequisites>\\n  - **dotenv** - package for managing environment variables - [read here](https://www.npmjs.com/package/dotenv)\\n  - **tsx** - package for running TypeScript files - [read here](https://tsx.is/)\\n  - **Xata Postgres database** - [read here](https://xata.io/documentation)\\n</Prerequisites>\\n\\n<FileStructure/>\\n\\n#### Step 1 - Install **postgres** package\\n<InstallPackages lib=\\'postgres\\'/>\\n\\n#### Step 2 - Setup connection variables\\n\\n<SetupEnv env_variable=\\'DATABASE_URL\\' />\\n\\nYou can obtain a connection string by following the [Xata documentation](https://xata.io/documentation/getting-started).\\n\\n#### Step 3 - Connect Drizzle ORM to the database\\n\\n<ConnectXata/>\\n\\n#### Step 4 - Create a table\\n\\n<CreateTable />\\n\\n#### Step 5 - Setup Drizzle config file\\n\\n<SetupConfig dialect=\\'postgresql\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 6 - Applying changes to the database\\n\\n<ApplyChanges />\\n\\n#### Step 7 - Seed and Query the database\\n\\n<QueryDatabase dialect=\\'postgres-js\\' env_variable=\\'DATABASE_URL\\'/>\\n\\n#### Step 8 - Run index.ts file\\n\\n<RunFile/>', children=[])]),\n",
       " DocItem(origPath=Path('get-started-gel.mdx'), name='get-started-gel.mdx', displayName='get-started-gel.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> Gel\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- gel-js [basics](https://github.com/geldata/gel-js)\\n</Prerequisites>\\n\\nDrizzle has native support for Gel connections with the `gel-js` client.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm gel\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"gel\", \"gel with config\"]}>\\n```typescript copy\\n// Make sure to install the \\'gel\\' package \\nimport { drizzle } from \\'drizzle-orm/gel\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript copy\\n// Make sure to install the \\'gel\\' package\\nimport { drizzle } from \"drizzle-orm/gel\";\\n\\n// You can specify any property from the gel connection options\\nconst db = drizzle({\\n  connection: {\\n    dsn: process.env.DATABASE_URL,\\n    tlsSecurity: \"default\",\\n  },\\n});\\n\\nconst result = await db.execute(\"select 1\");\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\n// Make sure to install the \\'gel\\' package \\nimport { drizzle } from \"drizzle-orm/gel\";\\nimport { createClient } from \"gel\";\\n\\nconst gelClient = createClient();\\nconst db = drizzle({ client: gelClient });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('get-started-mysql.mdx'), name='get-started-mysql.mdx', displayName='get-started-mysql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> MySQL\\n\\nTo use Drizzle with a MySQL database, you should use the `mysql2` driver\\n\\nAccording to the **[official website](https://github.com/sidorares/node-mysql2)**, \\n`mysql2` is a MySQL client for Node.js with focus on performance.  \\n\\nDrizzle ORM natively supports `mysql2` with `drizzle-orm/mysql2` package.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm mysql2\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\\'mysql2\\', \\'mysql with config\\']}>\\n```typescript copy\\nimport { drizzle } from \"drizzle-orm/mysql2\";\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst response = await db.select().from(...)\\n```\\n```typescript copy\\nimport { drizzle } from \"drizzle-orm/mysql2\";\\n\\n// You can specify any property from the mysql2 connection options\\nconst db = drizzle({ connection:{ uri: process.env.DATABASE_URL }});\\n\\nconst response = await db.select().from(...)\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n<CodeTabs items={[\\'Client connection\\', \\'Pool connection\\']}>\\n  ```typescript copy\\n  import { drizzle } from \"drizzle-orm/mysql2\";\\n  import mysql from \"mysql2/promise\";\\n\\n  const connection = await mysql.createConnection({\\n    host: \"host\",\\n    user: \"user\",\\n    database: \"database\",\\n    ...\\n  });\\n\\n  const db = drizzle({ client: connection });\\n  ```\\n  ```typescript copy\\n  import { drizzle } from \"drizzle-orm/mysql2\";\\n  import mysql from \"mysql2/promise\";\\n\\n  const poolConnection = mysql.createPool({\\n    host: \"host\",\\n    user: \"user\",\\n    database: \"database\",\\n    ...\\n  });\\n\\n  const db = drizzle({ client: poolConnection });\\n  ```\\n</CodeTabs>\\n\\n<Callout type=\"warning\" emoji=\"âš™ï¸\">\\n  For the built in `migrate` function with DDL migrations we and drivers strongly encourage you to use single `client` connection.  \\n\\n  For querying purposes feel free to use either `client` or `pool` based on your business demands.\\n</Callout>\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('get-started-postgresql.mdx'), name='get-started-postgresql.mdx', displayName='get-started-postgresql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> PostgreSQL\\n<Prerequisites>\\n- Database [connection basics](/docs/connect-overview) with Drizzle\\n- node-postgres [basics](https://node-postgres.com/)\\n- postgres.js [basics](https://github.com/porsager/postgres?tab=readme-ov-file#usage)\\n</Prerequisites>\\n\\nDrizzle has native support for PostgreSQL connections with the `node-postgres` and `postgres.js` drivers.\\n\\nThere are a few differences between the `node-postgres` and `postgres.js` drivers that we discovered while using both and integrating them with the Drizzle ORM. For example:\\n\\n- With `node-postgres`, you can install `pg-native` to boost the speed of both `node-postgres` and Drizzle by approximately 10%.\\n- `node-postgres` supports providing type parsers on a per-query basis without globally patching things. For more details, see [Types Docs](https://node-postgres.com/features/queries#types).\\n- `postgres.js` uses prepared statements by default, which you may need to opt out of. This could be a potential issue in AWS environments, among others, so please keep that in mind.\\n- If there\\'s anything else you\\'d like to contribute, we\\'d be happy to receive your PRs [here](https://github.com/drizzle-team/drizzle-orm-docs/pulls)\\n\\n## node-postgres\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm pg\\n-D drizzle-kit @types/pg\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"node-postgres\", \"node-postgres with config\"]}>\\n```typescript copy\\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript copy\\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\n\\n// You can specify any property from the node-postgres connection options\\nconst db = drizzle({ \\n  connection: { \\n    connectionString: process.env.DATABASE_URL,\\n    ssl: true\\n  }\\n});\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\n// Make sure to install the \\'pg\\' package \\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { Pool } from \"pg\";\\n\\nconst pool = new Pool({\\n  connectionString: process.env.DATABASE_URL,\\n});\\nconst db = drizzle({ client: pool });\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n## postgres.js\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm postgres\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"postgres.js\", \"postgres.js with config\"]}>\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\n\\n// You can specify any property from the postgres-js connection options\\nconst db = drizzle({ \\n  connection: { \\n    url: process.env.DATABASE_URL, \\n    ssl: true \\n  }\\n});\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n```typescript copy\\n// Make sure to install the \\'postgres\\' package\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nconst queryClient = postgres(process.env.DATABASE_URL);\\nconst db = drizzle({ client: queryClient });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('get-started-singlestore.mdx'), name='get-started-singlestore.mdx', displayName='get-started-singlestore.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\n\\n# Drizzle \\\\<\\\\> SingleStore\\n\\nTo use Drizzle with a SingleStore database, you should use the `mysql2` driver\\n\\nDrizzle ORM natively supports `mysql2` with `drizzle-orm/singlestore` package.\\n\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm mysql2\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\\'mysql2\\', \\'mysql with config\\']}>\\n```typescript copy\\nimport { drizzle } from \"drizzle-orm/singlestore\";\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst response = await db.select().from(...)\\n```\\n```typescript copy\\nimport { drizzle } from \"drizzle-orm/singlestore\";\\n\\n// You can specify any property from the mysql2 connection options\\nconst db = drizzle({ connection:{ uri: process.env.DATABASE_URL }});\\n\\nconst response = await db.select().from(...)\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n\\n<CodeTabs items={[\\'Client connection\\', \\'Pool connection\\']}>\\n  ```typescript copy\\n  import { drizzle } from \"drizzle-orm/singlestore\";\\n  import mysql from \"mysql2/promise\";\\n\\n  const connection = await mysql.createConnection({\\n    host: \"host\",\\n    user: \"user\",\\n    database: \"database\",\\n    ...\\n  });\\n\\n  const db = drizzle({ client: connection });\\n  ```\\n  ```typescript copy\\n  import { drizzle } from \"drizzle-orm/singlestore\";\\n  import mysql from \"mysql2/promise\";\\n\\n  const poolConnection = mysql.createPool({\\n    host: \"host\",\\n    user: \"user\",\\n    database: \"database\",\\n    ...\\n  });\\n\\n  const db = drizzle({ client: poolConnection });\\n  ```\\n</CodeTabs>\\n\\n<Callout type=\"warning\" emoji=\"âš™ï¸\">\\n  For the built in `migrate` function with DDL migrations we and drivers strongly encourage you to use single `client` connection.  \\n\\n  For querying purposes feel free to use either `client` or `pool` based on your business demands.\\n</Callout>\\n\\n#### Limitations\\n\\nCurrently, the SingleStore dialect has a set of limitations and features that do not work on the SingleStore database side:\\n\\n- SingleStore\\'s serial column type only ensures the uniqueness of column values.\\n- `ORDER BY` and `LIMIT` cannot be chained together.\\n- Foreign keys are not supported (check).\\n- `INTERSECT ALL` and `EXCEPT ALL` operations are not supported by SingleStore.\\n- Nested transactions are not supported by [SingleStore](https://docs.singlestore.com/cloud/reference/sql-reference/procedural-sql-reference/transactions-in-stored-procedures/).\\n- SingleStore [only supports](https://docs.singlestore.com/cloud/getting-started-with-singlestore-helios/about-singlestore-helios/singlestore-helios-faqs/durability/) one `isolationLevel`.\\n- The FSP option in `DATE`, `TIMESTAMP`, and `DATETIME` is not supported.\\n- The relational API is not supported and will be implemented once the SingleStore team develops all the necessary APIs for it.\\n- There may be more limitations because SingleStore is not 100% compatible with MySQL.\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>', children=[]),\n",
       " DocItem(origPath=Path('get-started-sqlite.mdx'), name='get-started-sqlite.mdx', displayName='get-started-sqlite.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport AnchorCards from \\'@mdx/AnchorCards.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport WhatsNextPostgres from \"@mdx/WhatsNextPostgres.astro\";\\nimport LibsqlTable from \\'@mdx/LibsqlTable.mdx\\';\\nimport LibsqlTabs from \\'@mdx/LibsqlTabs.mdx\\';\\n\\n# Drizzle \\\\<\\\\> SQLite\\n\\nDrizzle has native support for SQLite connections with the `libsql` and `better-sqlite3` drivers.\\n  \\nThere are a few differences between the `libsql` and `better-sqlite3` drivers that we discovered while using both and integrating them with the Drizzle ORM. For example:\\n\\nAt the driver level, there may not be many differences between the two, but the main one is that `libSQL` can connect to both SQLite files and `Turso` remote databases. LibSQL is a fork of SQLite that offers a bit more functionality compared to standard SQLite, such as:\\n\\n- More ALTER statements are available with the `libSQL` driver, allowing you to manage your schema more easily than with just `better-sqlite3`.\\n- You can configure the encryption at rest feature natively.\\n- A large set of extensions supported by the SQLite database is also supported by `libSQL`.\\n\\n## libsql\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm @libsql/client\\n-D drizzle-kit\\n</Npm>\\n\\n#### Step 2 - Initialize the driver\\nDrizzle has native support for all @libsql/client driver variations:\\n\\n<LibsqlTable />\\n<br/>\\n<LibsqlTabs />\\n\\n#### Step 3 - make a query\\n<CodeTabs items={[\"libsql\", \"libsql with config\"]}>\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\n// You can specify any property from the libsql connection options\\nconst db = drizzle({ connection: { url:\\'\\', authToken: \\'\\' }});\\n \\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\nIf you need a synchronous connection, you can use our additional connection API, \\nwhere you specify a driver connection and pass it to the Drizzle instance.\\n\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\nimport { createClient } from \\'@libsql/client\\';\\n\\nconst client = createClient({ url: process.env.DATABASE_URL, authToken: process.env.DATABASE_AUTH_TOKEN });\\nconst db = drizzle(client);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n## better-sqlite3\\n#### Step 1 - Install packages\\n<Npm>\\ndrizzle-orm better-sqlite3\\n-D drizzle-kit @types/better-sqlite3\\n</Npm>\\n\\n#### Step 2 - Initialize the driver and make a query\\n<CodeTabs items={[\"better-sqlite3\", \"better-sqlite3 with config\"]}>\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\n\\n// You can specify any property from the better-sqlite3 connection options\\nconst db =  drizzle({ connection: { source: process.env.DATABASE_URL }});\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n</CodeTabs>\\n\\nIf you need to provide your existing driver:\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\nimport Database from \\'better-sqlite3\\';\\n\\nconst sqlite = new Database(\\'sqlite.db\\');\\nconst db = drizzle({ client: sqlite });\\n\\nconst result = await db.execute(\\'select 1\\');\\n```\\n\\n#### What\\'s next?\\n\\n<WhatsNextPostgres/>\\n', children=[]),\n",
       " DocItem(origPath=Path('get-started.mdx'), name='get-started.mdx', displayName='get-started.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Callout from '@mdx/Callout.astro';\\nimport CodeTabs from '@mdx/CodeTabs.astro';\\nimport YoutubeCards from '@mdx/YoutubeCards.astro';\\nimport GetStartedLinks from '@mdx/GetStartedLinks/index.astro';\\n\\n# Get started with Drizzle\\n<GetStartedLinks />\", children=[]),\n",
       " DocItem(origPath=Path('goodies.mdx'), name='goodies.mdx', displayName='goodies.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\n\\n## Type API\\nTo retrieve a type from your table schema for `select` and `insert` queries, you can make use of our type helpers.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n<Tab>\\n```ts\\nimport { serial, text, pgTable } from \\'drizzle-orm/pg-core\\';\\nimport { type InferSelectModel, type InferInsertModel } from \\'drizzle-orm\\'\\n\\nconst users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\ntype SelectUser = typeof users.$inferSelect;\\ntype InsertUser = typeof users.$inferInsert;\\n// or\\ntype SelectUser = typeof users._.$inferSelect;\\ntype InsertUser = typeof users._.$inferInsert;\\n// or\\ntype SelectUser = InferSelectModel<typeof users>;\\ntype InsertUser = InferInsertModel<typeof users>;\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { int, text, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\nimport { type InferSelectModel, type InferInsertModel } from \\'drizzle-orm\\'\\n\\nconst users = mysqlTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\ntype SelectUser = typeof users.$inferSelect;\\ntype InsertUser = typeof users.$inferInsert;\\n// or\\ntype SelectUser = typeof users._.$inferSelect;\\ntype InsertUser = typeof users._.$inferInsert;\\n// or\\ntype SelectUser = InferSelectModel<typeof users>;\\ntype InsertUser = InferInsertModel<typeof users>;\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { int, text, sqliteTable } from \\'drizzle-orm/sqlite-core\\';\\nimport { type InferSelectModel, type InferInsertModel } from \\'drizzle-orm\\'\\n\\nconst users = sqliteTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\ntype SelectUser = typeof users.$inferSelect;\\ntype InsertUser = typeof users.$inferInsert;\\n// or\\ntype SelectUser = typeof users._.$inferSelect;\\ntype InsertUser = typeof users._.$inferInsert;\\n// or\\ntype SelectUser = InferSelectModel<typeof users>;\\ntype InsertUser = InferInsertModel<typeof users>;\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { int, text, singlestoreTable } from \\'drizzle-orm/singlestore-core\\';\\nimport { type InferSelectModel, type InferInsertModel } from \\'drizzle-orm\\'\\n\\nconst users = singlestoreTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\ntype SelectUser = typeof users.$inferSelect;\\ntype InsertUser = typeof users.$inferInsert;\\n// or\\ntype SelectUser = typeof users._.$inferSelect;\\ntype InsertUser = typeof users._.$inferInsert;\\n// or\\ntype SelectUser = InferSelectModel<typeof users>;\\ntype InsertUser = InferInsertModel<typeof users>;\\n```\\n</Tab>\\n</Tabs>\\n\\n\\n## Logging\\nTo enable default query logging, just pass `{ logger: true }` to the `drizzle` initialization function:\\n```typescript copy\\nimport { drizzle } from \\'drizzle-orm/...\\'; // driver specific\\n\\nconst db = drizzle({ logger: true });\\n```\\n\\nYou can change the logs destination by creating a `DefaultLogger` instance and providing a custom `writer` to it:\\n```typescript copy\\nimport { DefaultLogger, LogWriter } from \\'drizzle-orm/logger\\';\\nimport { drizzle } from \\'drizzle-orm/...\\'; // driver specific\\n\\nclass MyLogWriter implements LogWriter {\\n  write(message: string) {\\n    // Write to file, stdout, etc.\\n  }\\n}\\n\\nconst logger = new DefaultLogger({ writer: new MyLogWriter() });\\nconst db = drizzle({ logger });\\n```\\n\\nYou can also create a custom logger:\\n```typescript copy\\nimport { Logger } from \\'drizzle-orm/logger\\';\\nimport { drizzle } from \\'drizzle-orm/...\\'; // driver specific\\n\\nclass MyLogger implements Logger {\\n  logQuery(query: string, params: unknown[]): void {\\n    console.log({ query, params });\\n  }\\n}\\n\\nconst db = drizzle({ logger: new MyLogger() });\\n```\\n\\n\\n## Multi-project schema\\n**Table creator** API lets you define customise table names.  \\nIt\\'s very useful when you need to keep schemas of different projects in one database.\\n\\n<CodeTabs items={[\"PostgreSQL\",\"MySQL\",\"SQLite\", \"SingleStore\"]}>\\n```ts {3}\\nimport { serial, text, pgTableCreator } from \\'drizzle-orm/pg-core\\';\\n\\nconst pgTable = pgTableCreator((name) => `project1_${name}`);\\n\\nconst users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n```\\n```ts {3}\\nimport { int, text, mysqlTableCreator } from \\'drizzle-orm/mysql-core\\';\\n\\nconst mysqlTable = mysqlTableCreator((name) => `project1_${name}`);\\n\\nconst users = mysqlTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n```\\n```ts {3}\\nimport { int, text, sqliteTableCreator } from \\'drizzle-orm/sqlite-core\\';\\n\\nconst sqliteTable = sqliteTableCreator((name) => `project1_${name}`);\\n\\nconst users = sqliteTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n```\\n```ts {3}\\nimport { int, text, singlestoreTableCreator } from \\'drizzle-orm/singlestore-core\\';\\n\\nconst mysqlTable = singlestoreTableCreator((name) => `project1_${name}`);\\n\\nconst users = singlestoreTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n```\\n</CodeTabs>\\n```ts {10}\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/schema/*\",\\n  out: \"./drizzle\",\\n  dialect: \"mysql\", \\n  dbCredentials: {\\n    url: process.env.DATABASE_URL,\\n  }\\n  tablesFilter: [\"project1_*\"],\\n});\\n```\\n\\nYou can apply multiple `or` filters:\\n```ts\\ntablesFilter: [\"project1_*\", \"project2_*\"]\\n```\\n\\n\\n## Printing SQL query\\nYou can print SQL queries with `db` instance or by using **[`standalone query builder`](#standalone-query-builder)**.\\n```typescript copy\\nconst query = db\\n  .select({ id: users.id, name: users.name })\\n  .from(users)\\n  .groupBy(users.id)\\n  .toSQL();\\n// query:\\n{\\n  sql: \\'select \\'id\\', \\'name\\' from \\'users\\' group by \\'users\\'.\\'id\\'\\',\\n  params: [],\\n}\\n```\\n\\n## Raw SQL queries execution\\nIf you have some complex queries to execute and `drizzle-orm` can\\'t handle them yet,\\nyou can use the `db.execute` method to execute raw `parametrized` queries.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n    <Tab>\\n    ```ts\\n    const statement = sql`select * from ${users} where ${users.id} = ${userId}`;\\n    const res: postgres.RowList<Record<string, unknown>[]> = await db.execute(statement)\\n    ```\\n    </Tab>\\n    <Tab>\\n    ```typescript copy\\n    import { ..., MySqlQueryResult } from \"drizzle-orm/mysql2\";\\n\\n    const statement = sql`select * from ${users} where ${users.id} = ${userId}`;\\n    const res: MySqlRawQueryResult = await db.execute(statement);\\n    ```\\n    </Tab>\\n    <Tab>\\n    ```ts\\n    const statement = sql`select * from ${users} where ${users.id} = ${userId}`;\\n\\n    const res: unknown[] = db.all(statement)\\n    const res: unknown = db.get(statement)\\n    const res: unknown[][] = db.values(statement)\\n    const res: Database.RunResult = db.run(statement)\\n    ```\\n    </Tab>\\n    <Tab>\\n    ```typescript copy\\n    import { ..., SingleStoreQueryResult } from \"drizzle-orm/singlestore\";\\n\\n    const statement = sql`select * from ${users} where ${users.id} = ${userId}`;\\n    const res: SingleStoreRawQueryResult = await db.execute(statement);\\n    ```\\n    </Tab>\\n</Tabs>\\n\\n\\n## Standalone query builder\\nDrizzle ORM provides a standalone query builder that allows you to build queries\\nwithout creating a database instance and get generated SQL.\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \"SingleStore\"]}>\\n    <Tab>\\n        ```typescript copy\\n        import { QueryBuilder } from \\'drizzle-orm/pg-core\\';\\n\\n        const qb = new QueryBuilder();\\n\\n        const query = qb.select().from(users).where(eq(users.name, \\'Dan\\'));\\n        const { sql, params } = query.toSQL();\\n        ```\\n    </Tab>\\n    <Tab>\\n        ```typescript copy\\n        import { QueryBuilder } from \\'drizzle-orm/mysql-core\\';\\n\\n        const qb = new QueryBuilder();\\n\\n        const query = qb.select().from(users).where(eq(users.name, \\'Dan\\'));\\n        const { sql, params } = query.toSQL();\\n        ```\\n    </Tab>\\n    <Tab>\\n        ```typescript copy\\n        import { QueryBuilder } from \\'drizzle-orm/sqlite-core\\';\\n\\n        const qb = new QueryBuilder();\\n\\n        const query = qb.select().from(users).where(eq(users.name, \\'Dan\\'));\\n        const { sql, params } = query.toSQL();\\n        ```\\n    </Tab>\\n    <Tab>\\n        ```typescript copy\\n        import { QueryBuilder } from \\'drizzle-orm/singlestore-core\\';\\n\\n        const qb = new QueryBuilder();\\n\\n        const query = qb.select().from(users).where(eq(users.name, \\'Dan\\'));\\n        const { sql, params } = query.toSQL();\\n        ```\\n    </Tab>\\n</Tabs>\\n\\n## Get typed table columns\\nYou can get a typed table columns map,\\nvery useful when you need to omit certain columns upon selection.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \"SingleStore\"]}>\\n  <Tab>\\n      <CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n        ```ts\\n        import { getTableColumns } from \"drizzle-orm\";\\n        import { user } from \"./schema\";\\n\\n        const { password, role, ...rest } = getTableColumns(user);\\n\\n        await db.select({ ...rest }).from(users);\\n        ```\\n        ```ts\\n        import { serial, text, pgTable } from \"drizzle-orm/pg-core\";\\n\\n        export const user = pgTable(\"user\", {\\n          id: serial(\"id\").primaryKey(),\\n          name: text(\"name\"),\\n          email: text(\"email\"),\\n          password: text(\"password\"),\\n          role: text(\"role\").$type<\"admin\" | \"customer\">(),\\n        });\\n        ```\\n      </CodeTabs>\\n  </Tab>\\n  <Tab>\\n      <CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n        ```ts\\n        import { getTableColumns } from \"drizzle-orm\";\\n        import { user } from \"./schema\";\\n\\n        const { password, role, ...rest } = getTableColumns(user);\\n\\n        await db.select({ ...rest }).from(users);\\n        ```\\n        ```ts\\n        import { int, text, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n        export const user = mysqlTable(\"user\", {\\n          id: int(\"id\").primaryKey().autoincrement(),\\n          name: text(\"name\"),\\n          email: text(\"email\"),\\n          password: text(\"password\"),\\n          role: text(\"role\").$type<\"admin\" | \"customer\">(),\\n        });\\n        ```\\n      </CodeTabs>\\n  </Tab>\\n  <Tab>\\n      <CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n        ```ts\\n        import { getTableColumns } from \"drizzle-orm\";\\n        import { user } from \"./schema\";\\n\\n        const { password, role, ...rest } = getTableColumns(user);\\n\\n        await db.select({ ...rest }).from(users);\\n        ```\\n        ```ts\\n        import { integer, text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n        export const user = sqliteTable(\"user\", {\\n          id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n          name: text(\"name\"),\\n          email: text(\"email\"),\\n          password: text(\"password\"),\\n          role: text(\"role\").$type<\"admin\" | \"customer\">(),\\n        });\\n        ```\\n      </CodeTabs>\\n  </Tab>\\n  <Tab>\\n      <CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n        ```ts\\n        import { getTableColumns } from \"drizzle-orm\";\\n        import { user } from \"./schema\";\\n\\n        const { password, role, ...rest } = getTableColumns(user);\\n\\n        await db.select({ ...rest }).from(users);\\n        ```\\n        ```ts\\n        import { int, text, mysqlTable } from \"drizzle-orm/singlestore-core\";\\n\\n        export const user = singlestoreTable(\"user\", {\\n          id: int(\"id\").primaryKey().autoincrement(),\\n          name: text(\"name\"),\\n          email: text(\"email\"),\\n          password: text(\"password\"),\\n          role: text(\"role\").$type<\"admin\" | \"customer\">(),\\n        });\\n        ```\\n      </CodeTabs>\\n  </Tab>\\n</Tabs>\\n\\n## Get table information\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \"SingleStore\"]}>\\n  <Tab>\\n    ```ts copy\\n    import { getTableConfig, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\n    export const table = pgTable(...);\\n\\n    const {\\n      columns,\\n      indexes,\\n      foreignKeys,\\n      checks,\\n      primaryKeys,\\n      name,\\n      schema,\\n    } = getTableConfig(table);\\n    ```\\n  </Tab>\\n  <Tab>\\n  ```ts copy\\n  import { getTableConfig, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\n\\n  export const table = mysqlTable(...);\\n\\n  const {\\n    columns,\\n    indexes,\\n    foreignKeys,\\n    checks,\\n    primaryKeys,\\n    name,\\n    schema,\\n  } = getTableConfig(table);\\n  ```\\n  </Tab>\\n  <Tab>\\n  ```ts copy\\n  import { getTableConfig, sqliteTable } from \\'drizzle-orm/sqlite-core\\';\\n\\n  export const table = sqliteTable(...);\\n\\n  const {\\n    columns,\\n    indexes,\\n    foreignKeys,\\n    checks,\\n    primaryKeys,\\n    name,\\n    schema,\\n  } = getTableConfig(table);\\n  ```\\n  </Tab>\\n  <Tab>\\n  ```ts copy\\n  import { getTableConfig, mysqlTable } from \\'drizzle-orm/singlestore-core\\';\\n\\n  export const table = singlestoreTable(...);\\n\\n  const {\\n    columns,\\n    indexes,\\n    checks,\\n    primaryKeys,\\n    name,\\n    schema,\\n  } = getTableConfig(table);\\n  ```\\n  </Tab>\\n</Tabs>\\n\\n## Compare objects types (instanceof alternative)\\n\\nYou can check if an object is of a specific Drizzle type using the `is()` function. \\nYou can use it with any available type in Drizzle.\\n\\n<Callout type=\"warning\" emoji=\"â­ï¸\">\\n  You should always use `is()` instead of `instanceof`\\n</Callout>\\n\\n**Few examples**\\n```ts\\nimport { Column, is } from \\'drizzle-orm\\';\\n\\nif (is(value, Column)) {\\n  // value\\'s type is narrowed to Column\\n}\\n```\\n\\n### Mock Driver\\nThis API is a successor to an undefined `drizzle({} as any)` API which we\\'ve used internally in Drizzle tests and rarely recommended to external developers. \\n\\nWe decided to build and expose a proper API, every `drizzle` driver now has `drizzle.mock()`:\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\n\\nconst db = drizzle.mock();\\n```\\n\\nyou can provide schema if necessary for types\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport * as schema from \"./schema\"\\n\\nconst db = drizzle.mock({ schema });\\n```', children=[]),\n",
       " DocItem(origPath=Path('gotchas.mdx'), name='gotchas.mdx', displayName='gotchas.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \"@mdx/CodeTab.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\n# Drizzle gotchas\\n\\nThis will be a library of `gotchas` with Drizzle use cases', children=[]),\n",
       " DocItem(origPath=Path('graphql.mdx'), name='graphql.mdx', displayName='graphql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Tab from '@mdx/Tab.astro';\\nimport Tabs from '@mdx/Tabs.astro';\\nimport Callout from '@mdx/Callout.astro';\\nimport CodeTab from '@mdx/CodeTab.astro';\\nimport CodeTabs from '@mdx/CodeTabs.astro';\\nimport Npm from '@mdx/Npm.astro';\\n\\n# drizzle-graphql\\n\\nCreate a GraphQL server from a Drizzle schema in one line, and easily enhance it with custom queries and mutations.\\n\\n## Quick start\\n\\nMake sure your `drizzle-orm` version is at least `0.30.9`, and update if needed:\\n<Npm>drizzle-orm@latest</Npm>\\n\\n### Apollo Server\\n\\n<Npm>drizzle-graphql @apollo/server graphql</Npm>\\n\\n<CodeTabs items={['server.ts', 'schema.ts']}>\\n<CodeTab>\\n```ts copy {1, 10}\\nimport { buildSchema } from 'drizzle-graphql';\\nimport { drizzle } from 'drizzle-orm/...';\\nimport client from './db';\\nimport { ApolloServer } from '@apollo/server';\\nimport { startStandaloneServer } from '@apollo/server/standalone';\\n\\nimport * as dbSchema from './schema';\\n\\nconst db = drizzle({ client, schema: dbSchema });\\n\\nconst { schema } = buildSchema(db);\\n\\nconst server = new ApolloServer({ schema });\\nconst { url } = await startStandaloneServer(server);\\n\\nconsole.log(`ðŸš€ Server ready at ${url}`);\\n```\\n</CodeTab>\\n<CodeTab>\\n```typescript copy\\nimport { integer, serial, text, pgTable } from 'drizzle-orm/pg-core';\\nimport { relations } from 'drizzle-orm';\\n\\nexport const users = pgTable('users', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull(),\\n});\\n\\nexport const usersRelations = relations(users, ({ many }) => ({\\n  posts: many(posts),\\n}));\\n\\nexport const posts = pgTable('posts', {\\n  id: serial('id').primaryKey(),\\n  content: text('content').notNull(),\\n  authorId: integer('author_id').notNull(),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one }) => ({\\n  author: one(users, { fields: [posts.authorId], references: [users.id] }),\\n}));\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n### GraphQL Yoga\\n\\n<Npm>drizzle-graphql graphql-yoga graphql</Npm>\\n\\n<CodeTabs items={['server.ts', 'schema.ts']}>\\n<CodeTab>\\n```ts copy {1, 10}\\nimport { buildSchema } from 'drizzle-graphql';\\nimport { drizzle } from 'drizzle-orm/...';\\nimport { createYoga } from 'graphql-yoga';\\nimport { createServer } from 'node:http';\\n\\nimport * as dbSchema from './schema';\\n\\nconst db = drizzle({ schema: dbSchema });\\n\\nconst { schema } = buildSchema(db);\\n\\nconst yoga = createYoga({ schema });\\nconst server = createServer(yoga);\\n\\nserver.listen(4000, () => {\\n  console.info('Server is running on http://localhost:4000/graphql');\\n});\\n```\\n</CodeTab>\\n<CodeTab>\\n```typescript copy\\nimport { integer, serial, text, pgTable } from 'drizzle-orm/pg-core';\\nimport { relations } from 'drizzle-orm';\\n\\nexport const users = pgTable('users', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull(),\\n});\\n\\nexport const usersRelations = relations(users, ({ many }) => ({\\n  posts: many(posts),\\n}));\\n\\nexport const posts = pgTable('posts', {\\n  id: serial('id').primaryKey(),\\n  content: text('content').notNull(),\\n  authorId: integer('author_id').notNull(),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one }) => ({\\n  author: one(users, { fields: [posts.authorId], references: [users.id] }),\\n}));\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n## Customizing schema\\n\\n<Callout type='info' emoji='â„¹ï¸'>\\n`buildSchema()` produces schema and types using standard `graphql` SDK, so its output is compatible with any library that supports it.\\n</Callout>\\n\\nIf you want to customize your schema, you can use `entities` object to build your own new schema:\\n\\n<CodeTabs items={['server.ts', 'schema.ts']}>\\n<CodeTab>\\n```ts {1, 11}\\nimport { buildSchema } from 'drizzle-graphql';\\nimport { drizzle } from 'drizzle-orm/...';\\nimport { GraphQLList, GraphQLNonNull, GraphQLObjectType, GraphQLSchema } from 'graphql';\\nimport { createYoga } from 'graphql-yoga';\\nimport { createServer } from 'node:http';\\n\\nimport * as dbSchema from './schema';\\n\\nconst db = drizzle({ schema: dbSchema });\\n\\nconst { entities } = buildSchema(db);\\n\\n// You can customize which parts of queries or mutations you want\\nconst schema = new GraphQLSchema({\\n  query: new GraphQLObjectType({\\n    name: 'Query',\\n    fields: {\\n      // Select only wanted queries out of all generated\\n      users: entities.queries.users,\\n      customer: entities.queries.customersSingle,\\n\\n      // Create a custom one\\n      customUsers: {\\n        // You can reuse and customize types from original schema\\n        type: new GraphQLList(new GraphQLNonNull(entities.types.UsersItem)),\\n        args: {\\n          // You can reuse inputs as well\\n          where: {\\n            type: entities.inputs.UsersFilters\\n          },\\n        },\\n        resolve: async (source, args, context, info) => {\\n          // Your custom logic goes here...\\n          const result = await db.select(schema.users).where()...\\n\\n          return result;\\n        },\\n      },\\n    },\\n  }),\\n  // Same rules apply to mutations\\n  mutation: new GraphQLObjectType({\\n    name: 'Mutation',\\n    fields: entities.mutations,\\n  }),\\n  // In case you need types inside your schema\\n  types: [...Object.values(entities.types), ...Object.values(entities.inputs)],\\n});\\n\\nconst yoga = createYoga({\\n  schema,\\n});\\n\\nconst server = createServer(yoga);\\n\\nserver.listen(4000, () => {\\n  console.info('Server is running on http://localhost:4000/graphql');\\n})\\n```\\n</CodeTab>\\n<CodeTab>\\n```typescript copy\\nimport { integer, serial, text, pgTable } from 'drizzle-orm/pg-core';\\nimport { relations } from 'drizzle-orm';\\n\\nexport const users = pgTable('users', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull(),\\n});\\n\\nexport const usersRelations = relations(users, ({ many }) => ({\\n  posts: many(posts),\\n}));\\n\\nexport const posts = pgTable('posts', {\\n  id: serial('id').primaryKey(),\\n  content: text('content').notNull(),\\n  authorId: integer('author_id').notNull(),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one }) => ({\\n  author: one(users, { fields: [posts.authorId], references: [users.id] }),\\n}));\\n```\\n</CodeTab>\\n</CodeTabs>\\n\", children=[]),\n",
       " DocItem(origPath=Path('guides'), name='guides', displayName='guides', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('guides/conditional-filters-in-query.mdx'), name='conditional-filters-in-query.mdx', displayName='conditional-filters-in-query.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Conditional filters in query\\nslug: conditional-filters-in-query\\n---\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite);\\n- [Select statement](/docs/select);\\n- [Filtering](/docs/select#filtering) and [Filter operators](/docs/operators);\\n</Prerequisites>\\n\\nTo pass a conditional filter in query you can use `.where()` method and logical operator like below:\\n\\n<Section>\\n```ts copy {9}\\nimport { ilike } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...)\\n\\nconst searchPosts = async (term?: string) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(term ? ilike(posts.title, term) : undefined);\\n};\\n\\nawait searchPosts();\\nawait searchPosts(\\'AI\\');\\n```\\n\\n\\n```sql\\nselect * from posts;\\nselect * from posts where title ilike \\'AI\\';\\n```\\n</Section>\\n\\nTo combine conditional filters you can use `and()` or `or()` operators like below:\\n\\n<Section>\\n```ts copy {7,8,9,10,11,12,13}\\nimport { and, gt, ilike, inArray } from \\'drizzle-orm\\';\\n\\nconst searchPosts = async (term?: string, categories: string[] = [], views = 0) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(\\n      and(\\n        term ? ilike(posts.title, term) : undefined,\\n        categories.length > 0 ? inArray(posts.category, categories) : undefined,\\n        views > 100 ? gt(posts.views, views) : undefined,\\n      ),\\n    );\\n};\\n\\nawait searchPosts();\\nawait searchPosts(\\'AI\\', [\\'Tech\\', \\'Art\\', \\'Science\\'], 200);\\n```\\n\\n```sql\\nselect * from posts;\\nselect * from posts\\n  where (\\n    title ilike \\'AI\\'\\n    and category in (\\'Tech\\', \\'Science\\', \\'Art\\')\\n    and views > 200\\n  );\\n```\\n</Section>\\n\\nIf you need to combine conditional filters in different part of the project you can create a variable, push filters and then use it in `.where()` method with `and()` or `or()` operators like below:\\n\\n```ts copy {7,10}\\nimport { SQL, ... } from \\'drizzle-orm\\';\\n\\nconst searchPosts = async (filters: SQL[]) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(and(...filters));\\n};\\n\\nconst filters: SQL[] = [];\\nfilters.push(ilike(posts.title, \\'AI\\'));\\nfilters.push(inArray(posts.category, [\\'Tech\\', \\'Art\\', \\'Science\\']));\\nfilters.push(gt(posts.views, 200));\\n\\nawait searchPosts(filters);\\n```\\n\\nDrizzle has useful and flexible API, which lets you create your custom solutions. This is how you can create a custom filter operator:\\n\\n<Section>\\n\\n```ts copy {5,14}\\nimport { AnyColumn, ... } from \\'drizzle-orm\\';\\n\\n// length less than\\nconst lenlt = (column: AnyColumn, value: number) => {\\n  return sql`length(${column}) < ${value}`;\\n};\\n\\nconst searchPosts = async (maxLen = 0, views = 0) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(\\n      and(\\n        maxLen ? lenlt(posts.title, maxLen) : undefined,\\n        views > 100 ? gt(posts.views, views) : undefined,\\n      ),\\n    );\\n};\\n\\nawait searchPosts(8);\\nawait searchPosts(8, 200);\\n```\\n\\n```sql\\nselect * from posts where length(title) < 8;\\nselect * from posts where (length(title) < 8 and views > 200);\\n```\\n</Section>\\n\\nDrizzle filter operators are just SQL expressions under the hood. This is example of how `lt` operator is implemented in Drizzle:\\n\\n```js\\nconst lt = (left, right) => {\\n  return sql`${left} < ${bindIfParam(right, left)}`; // bindIfParam is internal magic function\\n};\\n```\\n', children=[]), DocItem(origPath=Path('guides/count-rows.mdx'), name='count-rows.mdx', displayName='count-rows.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Count rows\\nslug: count-rows\\n---\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Select statement](/docs/select)\\n- [Filters](/docs/operators) and [sql operator](/docs/sql)\\n- [Aggregations](/docs/select#aggregations) and [Aggregation helpers](/docs/select#aggregations-helpers)\\n- [Joins](/docs/joins)\\n</Prerequisites>\\n\\nTo count all rows in table you can use `count()` function or `sql` operator like below:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {6,9}\\n    import { count, sql } from \\'drizzle-orm\\';\\n    import { products } from \\'./schema\\';\\n\\n    const db = drizzle(...);\\n\\n    await db.select({ count: count() }).from(products);\\n\\n    // Under the hood, the count() function casts its result to a number at runtime.\\n    await db.select({ count: sql`count(*)`.mapWith(Number) }).from(products);\\n    ```\\n\\n    ```ts\\n    // result type\\n    type Result = {\\n      count: number;\\n    }[];\\n    ```\\n\\n    ```sql\\n    select count(*) from products;\\n    ```\\n  </CodeTab>\\n  ```ts\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const products = pgTable(\\'products\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n    discount: integer(\\'discount\\'),\\n    price: integer(\\'price\\').notNull(),\\n  });\\n  ```\\n</CodeTabs>\\n\\nTo count rows where the specified column contains non-NULL values you can use `count()` function with a column:\\n\\n<Section>\\n```ts copy {1}\\nawait db.select({ count: count(products.discount) }).from(products);\\n```\\n\\n```ts\\n// result type\\ntype Result = {\\n  count: number;\\n}[];\\n```\\n\\n```sql\\nselect count(\"discount\") from products;\\n```\\n</Section>\\n\\nDrizzle has simple and flexible API, which lets you create your custom solutions. In PostgreSQL and MySQL `count()` function returns bigint, which is interpreted as string by their drivers, so it should be casted to integer:\\n\\n<Section>\\n```ts copy {5,7,11,12}\\nimport { AnyColumn, sql } from \\'drizzle-orm\\';\\n\\nconst customCount = (column?: AnyColumn) => {\\n  if (column) {\\n    return sql<number>`cast(count(${column}) as integer)`; // In MySQL cast to unsigned integer\\n  } else {\\n    return sql<number>`cast(count(*) as integer)`; // In MySQL cast to unsigned integer\\n  }\\n};\\n\\nawait db.select({ count: customCount() }).from(products);\\nawait db.select({ count: customCount(products.discount) }).from(products);\\n```\\n\\n```sql\\nselect cast(count(*) as integer) from products;\\nselect cast(count(\"discount\") as integer) from products;\\n```\\n</Section>\\n\\nIn SQLite, `count()` result returns as integer.\\n\\n<Section>\\n```ts copy {3,4}\\nimport { sql } from \\'drizzle-orm\\';\\n\\nawait db.select({ count: sql<number>`count(*)` }).from(products);\\nawait db.select({ count: sql<number>`count(${products.discount})` }).from(products);\\n```\\n\\n```sql\\nselect count(*) from products;\\nselect count(\"discount\") from products;\\n```\\n</Section>\\n\\n<Callout type=\"warning\">\\nBy specifying `sql<number>`, you are telling Drizzle that the **expected** type of the field is `number`.<br />\\nIf you specify it incorrectly (e.g. use `sql<string>` for a field that will be returned as a number), the runtime value won\\'t match the expected type.\\nDrizzle cannot perform any type casts based on the provided type generic, because that information is not available at runtime.\\n\\nIf you need to apply runtime transformations to the returned value, you can use the [`.mapWith()`](/docs/sql#sqlmapwith) method.\\n</Callout>\\n\\nTo count rows that match a condition you can use `.where()` method:\\n\\n<Section>\\n```ts copy {4,6}\\nimport { count, gt } from \\'drizzle-orm\\';\\n\\nawait db\\n  .select({ count: count() })\\n  .from(products)\\n  .where(gt(products.price, 100));\\n```\\n\\n```sql\\nselect count(*) from products where price > 100\\n```\\n</Section>\\n\\nThis is how you can use `count()` function with joins and aggregations:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n    ```ts copy {8,11,12,13}\\n    import { count, eq } from \\'drizzle-orm\\';\\n    import { countries, cities } from \\'./schema\\';\\n\\n    // Count cities in each country\\n    await db\\n      .select({\\n        country: countries.name,\\n        citiesCount: count(cities.id),\\n      })\\n      .from(countries)\\n      .leftJoin(cities, eq(countries.id, cities.countryId))\\n      .groupBy(countries.id)\\n      .orderBy(countries.name);\\n    ```\\n\\n    ```sql\\n    select countries.name, count(\"cities\".\"id\") from countries\\n      left join cities on countries.id = cities.country_id\\n      group by countries.id\\n      order by countries.name;\\n    ```\\n  </CodeTab>\\n  ```ts\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const countries = pgTable(\\'countries\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n  });\\n\\n  export const cities = pgTable(\\'cities\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n    countryId: integer(\\'country_id\\').notNull().references(() => countries.id),\\n  });\\n  ```\\n</CodeTabs>\\n', children=[]), DocItem(origPath=Path('guides/cursor-based-pagination.mdx'), name='cursor-based-pagination.mdx', displayName='cursor-based-pagination.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Cursor-based pagination\\nslug: cursor-based-pagination\\n---\\n\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Select statement](/docs/select) with [order by clause](/docs/select#order-by)\\n- [Relational queries](/docs/rqb) with [order by clause](/docs/rqb#order-by)\\n- [Indices](/docs/indexes-constraints)\\n</Prerequisites>\\n\\nThis guide demonstrates how to implement `cursor-based` pagination in Drizzle:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n  ```ts copy {10,11,12}\\n  import { asc, gt } from \\'drizzle-orm\\';\\n  import { users } from \\'./schema\\';\\n\\n  const db = drizzle(...);\\n\\n  const nextUserPage = async (cursor?: number, pageSize = 3) => {\\n    await db\\n      .select()\\n      .from(users)\\n      .where(cursor ? gt(users.id, cursor) : undefined) // if cursor is provided, get rows after it\\n      .limit(pageSize) // the number of rows to return\\n      .orderBy(asc(users.id)); // ordering\\n  };\\n\\n  // pass the cursor of the last row of the previous page (id)\\n  await nextUserPage(3);\\n  ```\\n\\n  ```sql\\n  select * from users order by id asc limit 3;\\n  ```\\n\\n  ```ts\\n  // next page, 4-6 rows returned\\n  [\\n    {\\n      id: 4,\\n      firstName: \\'Brian\\',\\n      lastName: \\'Brown\\',\\n      createdAt: 2024-03-08T12:34:55.182Z\\n    },\\n    {\\n      id: 5,\\n      firstName: \\'Beth\\',\\n      lastName: \\'Davis\\',\\n      createdAt: 2024-03-08T12:40:55.182Z\\n    },\\n    {\\n      id: 6,\\n      firstName: \\'Charlie\\',\\n      lastName: \\'Miller\\',\\n      createdAt: 2024-03-08T13:04:55.182Z\\n    }\\n  ]\\n  ```\\n  </CodeTab>\\n  <CodeTab>\\n  ```ts copy\\n  import { pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    firstName: text(\\'first_name\\').notNull(),\\n    lastName: text(\\'last_name\\').notNull(),\\n    createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  });\\n  ```\\n\\n  ```plaintext\\n  +----+------------+------------+----------------------------+\\n  | id | first_name | last_name  |         created_at         |\\n  +----+------------+------------+----------------------------+\\n  |  1 | Alice      | Johnson    | 2024-03-08 12:23:55.251797 |\\n  +----+------------+------------+----------------------------+\\n  |  2 | Alex       | Smith      | 2024-03-08 12:25:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  3 | Aaron      | Williams   | 2024-03-08 12:28:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  4 | Brian      | Brown      | 2024-03-08 12:34:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  5 | Beth       | Davis      | 2024-03-08 12:40:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  6 | Charlie    | Miller     | 2024-03-08 13:04:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  7 | Clara      | Wilson     | 2024-03-08 13:22:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  8 | David      | Moore      | 2024-03-08 13:34:55.182    |\\n  +----+------------+------------+----------------------------+\\n  |  9 | Aaron      | Anderson   | 2024-03-08 12:40:33.677235 |\\n  +----+------------+------------+----------------------------+\\n  ```\\n  </CodeTab>\\n\\n</CodeTabs>\\n\\nIf you need dynamic order by you can do like below:\\n\\n```ts copy {6,8}\\nconst nextUserPage = async (order: \\'asc\\' | \\'desc\\' = \\'asc\\', cursor?: number, pageSize = 3) => {\\n  await db\\n    .select()\\n    .from(users)\\n    // cursor comparison\\n    .where(cursor ? (order === \\'asc\\' ? gt(users.id, cursor) : lt(users.id, cursor)) : undefined)\\n    .limit(pageSize)\\n    .orderBy(order === \\'asc\\' ? asc(users.id) : desc(users.id));\\n};\\n\\nawait nextUserPage();\\nawait nextUserPage(\\'asc\\', 3);\\n// descending order\\nawait nextUserPage(\\'desc\\');\\nawait nextUserPage(\\'desc\\', 7);\\n```\\n\\nThe main idea of this pagination is to use cursor as a pointer to a specific row in a dataset, indicating the end of the previous page. For correct ordering and cursor comparison, cursor should be unique and sequential.\\n\\nIf you need to order by a non-unique and non-sequential column, you can use multiple columns for cursor. This is how you can do it:\\n\\n<Section>\\n```ts copy {14,15,16,17,18,19,22}\\nimport { and, asc, eq, gt, or } from \\'drizzle-orm\\';\\n\\nconst nextUserPage = async (\\n  cursor?: {\\n    id: number;\\n    firstName: string;\\n  },\\n  pageSize = 3,\\n) => {\\n  await db\\n    .select()\\n    .from(users)\\n    .where(\\n      cursor\\n        ? or(\\n            gt(users.firstName, cursor.firstName),\\n            and(eq(users.firstName, cursor.firstName), gt(users.id, cursor.id)),\\n          )\\n        : undefined,\\n    )\\n    .limit(pageSize)\\n    .orderBy(asc(users.firstName), asc(users.id));\\n};\\n\\n// pass the cursor from previous page (id & firstName)\\nawait nextUserPage({\\n  id: 2,\\n  firstName: \\'Alex\\',\\n});\\n```\\n\\n```sql\\nselect * from users\\n  where (first_name > \\'Alex\\' or (first_name = \\'Alex\\' and id > 2))\\n  order by first_name asc, id asc limit 3;\\n```\\n\\n```ts\\n// next page, 4-6 rows returned\\n[\\n  {\\n    id: 1,\\n    firstName: \\'Alice\\',\\n    lastName: \\'Johnson\\',\\n    createdAt: 2024-03-08T12:23:55.251Z\\n  },\\n  {\\n    id: 5,\\n    firstName: \\'Beth\\',\\n    lastName: \\'Davis\\',\\n    createdAt: 2024-03-08T12:40:55.182Z\\n  },\\n  {\\n    id: 4,\\n    firstName: \\'Brian\\',\\n    lastName: \\'Brown\\',\\n    createdAt: 2024-03-08T12:34:55.182Z\\n  }\\n]\\n```\\n</Section>\\n\\nMake sure to create indices for the columns that you use for cursor to make query efficient.\\n\\n<Section>\\n```ts copy {7,8}\\nimport { index, ...imports } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n  // columns declaration\\n},\\n(t) => [\\n  index(\\'first_name_index\\').on(t.firstName).asc(),\\n  index(\\'first_name_and_id_index\\').on(t.firstName, t.id).asc(),\\n]);\\n```\\n\\n```sql\\n-- As of now drizzle-kit only supports index name and on() param, so you have to add order manually\\nCREATE INDEX IF NOT EXISTS \"first_name_index\" ON \"users\" (\"first_name\" ASC);\\nCREATE INDEX IF NOT EXISTS \"first_name_and_id_index\" ON \"users\" (\"first_name\" ASC,\"id\" ASC);\\n```\\n</Section>\\n\\nIf you are using primary key which is not sequential (e.g. `UUIDv4`), you should add sequential column (e.g. `created_at` column) and use multiple cursor.\\nThis is how you can do it:\\n\\n<Section>\\n```ts copy {12,13,14,15,16,17,18,21}\\n\\nconst nextUserPage = async (\\n  cursor?: {\\n    id: string;\\n    createdAt: Date;\\n  },\\n  pageSize = 3,\\n) => {\\n  await db\\n    .select()\\n    .from(users)\\n    .where(\\n      // make sure to add indices for the columns that you use for cursor\\n      cursor\\n        ? or(\\n            gt(users.createdAt, cursor.createdAt),\\n            and(eq(users.createdAt, cursor.createdAt), gt(users.id, cursor.id)),\\n          )\\n        : undefined,\\n    )\\n    .limit(pageSize)\\n    .orderBy(asc(users.createdAt), asc(users.id));\\n};\\n\\n// pass the cursor from previous page (id & createdAt)\\nawait nextUserPage({\\n  id: \\'66ed00a4-c020-4dfd-a1ca-5d2e4e54d174\\',\\n  createdAt: new Date(\\'2024-03-09T17:59:36.406Z\\'),\\n});\\n```\\n</Section>\\n\\nDrizzle has useful relational queries API, that lets you easily implement `cursor-based` pagination:\\n\\n```ts copy {7,8,9}\\nimport * as schema from \\'./db/schema\\';\\n\\nconst db = drizzle(..., { schema });\\n\\nconst nextUserPage = async (cursor?: number, pageSize = 3) => {\\n  await db.query.users.findMany({\\n    where: (users, { gt }) => (cursor ? gt(users.id, cursor) : undefined),\\n    orderBy: (users, { asc }) => asc(users.id),\\n    limit: pageSize,\\n  });\\n};\\n\\n// next page, cursor of last row of the first page (id = 3)\\nawait nextUserPage(3);\\n```\\n\\n**Benefits** of `cursor-based` pagination: consistent query results, with no skipped or duplicated rows due to insert or delete operations, and greater efficiency compared to `limit/offset` pagination because it does not need to scan and skip previous rows to access the next page.\\n\\n**Drawbacks** of `cursor-based` pagination: the inability to directly navigate to a specific page and complexity of implementation. Since you add more columns to the sort order, you\\'ll need to add more filters to the `where` clause for the cursor comparison to ensure consistent pagination.\\n\\nSo, if you need to directly navigate to a specific page or you need simpler implementation of pagination, you should consider using [offset/limit](/docs/guides/limit-offset-pagination) pagination instead.\\n', children=[]), DocItem(origPath=Path('guides/d1-http-with-drizzle-kit.mdx'), name='d1-http-with-drizzle-kit.mdx', displayName='d1-http-with-drizzle-kit.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Cloudflare D1 HTTP API with Drizzle Kit\\nslug: d1-http-with-drizzle-kit\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<Prerequisites>\\n- [Drizzle Kit](/docs/kit-overview)\\n- [Drizzle Studio](/docs/kit-overview#drizzle-studio)\\n- [Drizzle Chrome Extension](https://chromewebstore.google.com/detail/drizzle-studio/mjkojjodijpaneehkgmeckeljgkimnmd)\\n- You should have installed `drizzle-kit@0.21.3` or higher\\n- You should have [Cloudflare account](https://dash.cloudflare.com/login), deployed [D1 database](https://developers.cloudflare.com/d1/) and token with D1 edit permissions\\n</Prerequisites>\\n\\nTo use Drizzle kit with Cloudflare D1 HTTP API, you need to configure the `drizzle.config.ts` file like this:\\n\\n```ts copy filename=\"drizzle.config.ts\" {7, 9-11}\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  schema: \\'./src/schema.ts\\',\\n  out: \\'./migrations\\',\\n  dialect: \\'sqlite\\',\\n  driver: \\'d1-http\\',\\n  dbCredentials: {\\n    accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,\\n    databaseId: process.env.CLOUDFLARE_DATABASE_ID!,\\n    token: process.env.CLOUDFLARE_D1_TOKEN!,\\n  },\\n});\\n```\\n\\nYou can find `accountId`, `databaseId` and `token` in [Cloudflare dashboard](https://dash.cloudflare.com/login?).\\n\\n1. To get `accountId` go to **Workers & Pages** -> **Overview** -> copy **Account ID** from the right sidebar.\\n2. To get `databaseId` open D1 database you want to connect to and copy **Database ID**.\\n3. To get `token` go to **My profile** -> **API Tokens** and create token with D1 edit permissions.\\n\\nAfter you have configured `drizzle.config.ts` file, Drizzle Kit lets you run `migrate`, `push`, `introspect` and `studio` commands using Cloudflare D1 HTTP API.\\n\\nYou can also use [Drizzle Chrome Extension](https://chromewebstore.google.com/detail/drizzle-studio/mjkojjodijpaneehkgmeckeljgkimnmd) to browse Cloudflare D1 database directly in their admin panel.\\n\\n\\n', children=[]), DocItem(origPath=Path('guides/decrementing-a-value.mdx'), name='decrementing-a-value.mdx', displayName='decrementing-a-value.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Decrement value\\nslug: decrementing-a-value\\n---\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Update statement](/docs/update)\\n- [Filters](/docs/operators) and [sql operator](/docs/sql)\\n</Prerequisites>\\n\\nTo decrement a column value you can use `update().set()` method like below:\\n\\n<Section>\\n```ts copy {8}\\nimport { eq, sql } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...)\\n  \\nawait db\\n  .update(table)\\n  .set({\\n    counter: sql`${table.counter} - 1`,\\n  })\\n  .where(eq(table.id, 1));\\n```\\n\\n```sql\\nupdate \"table\" set \"counter\" = \"counter\" - 1 where \"id\" = 1;\\n```\\n</Section>\\n\\nDrizzle has simple and flexible API, which lets you easily create custom solutions. This is how you do custom decrement function:\\n\\n```ts copy {4,10,11}\\nimport { AnyColumn } from \\'drizzle-orm\\';\\n\\nconst decrement = (column: AnyColumn, value = 1) => {\\n  return sql`${column} - ${value}`;\\n};\\n\\nawait db\\n  .update(table)\\n  .set({\\n    counter1: decrement(table.counter1),\\n    counter2: decrement(table.counter2, 10),\\n  })\\n  .where(eq(table.id, 1));\\n```\\n', children=[]), DocItem(origPath=Path('guides/empty-array-default-value.mdx'), name='empty-array-default-value.mdx', displayName='empty-array-default-value.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Empty array as a default value\\nslug: empty-array-default-value\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- Learn about column data types for [PostgreSQL](/docs/column-types/pg), [MySQL](/docs/column-types/mysql) and [SQLite](/docs/column-types/sqlite)\\n- [sql operator](/docs/sql)\\n</Prerequisites>\\n\\n### PostgreSQL\\n\\nTo set an empty array as a default value in PostgreSQL, you can use `sql` operator with `\\'{}\\'` or `ARRAY[]` syntax:\\n\\n<Section>\\n```ts copy {10,14}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  tags1: text(\\'tags1\\')\\n    .array()\\n    .notNull()\\n    .default(sql`\\'{}\\'::text[]`),\\n  tags2: text(\\'tags2\\')\\n    .array()\\n    .notNull()\\n    .default(sql`ARRAY[]::text[]`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"users\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"tags1\" text[] DEFAULT \\'{}\\'::text[] NOT NULL,\\n\\t\"tags2\" text[] DEFAULT ARRAY[]::text[] NOT NULL\\n);\\n```\\n</Section>\\n\\n\\n### MySQL\\n\\nMySQL doesn\\'t have an array data type, but you can use `json` data type for the same purpose. To set an empty array as a default value in MySQL, you can use `JSON_ARRAY()` function or `sql` operator with `(\\'[]\\')` syntax:\\n\\n<Section>\\n```ts copy {7,11,15}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { json, mysqlTable, serial, varchar } from \\'drizzle-orm/mysql-core\\';\\n\\nexport const users = mysqlTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: varchar(\\'name\\', { length: 255 }).notNull(),\\n  tags1: json(\\'tags1\\').$type<string[]>().notNull().default([]),\\n  tags2: json(\\'tags2\\')\\n    .$type<string[]>()\\n    .notNull()\\n    .default(sql`(\\'[]\\')`), // the same as default([])\\n  tags3: json(\\'tags3\\')\\n    .$type<string[]>()\\n    .notNull()\\n    .default(sql`(JSON_ARRAY())`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` serial AUTO_INCREMENT NOT NULL,\\n\\t`name` varchar(255) NOT NULL,\\n\\t`tags1` json NOT NULL DEFAULT (\\'[]\\'),\\n\\t`tags2` json NOT NULL DEFAULT (\\'[]\\'),\\n\\t`tags3` json NOT NULL DEFAULT (JSON_ARRAY()),\\n\\tCONSTRAINT `users_id` PRIMARY KEY(`id`)\\n);\\n```\\n</Section>\\n\\nThe `mode` option defines how values are handled in the application. With `json` mode, values are treated as JSON object literal. \\n\\nYou can specify `.$type<..>()` for json object inference, it will not check runtime values. It provides compile time protection for default values, insert and select schemas.\\n\\n### SQLite\\n\\nSQLite doesn\\'t have an array data type, but you can use `text` data type for the same purpose. To set an empty array as a default value in SQLite, you can use `json_array()` function or `sql` operator with `\\'[]\\'` syntax:\\n\\n<Section>\\n```ts copy {9,13}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\n\\nexport const users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  tags1: text(\\'tags1\\', { mode: \\'json\\' })\\n    .notNull()\\n    .$type<string[]>()\\n    .default(sql`(json_array())`),\\n  tags2: text(\\'tags2\\', { mode: \\'json\\' })\\n    .notNull()\\n    .$type<string[]>()\\n    .default(sql`\\'[]\\'`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`tags1` text DEFAULT (json_array()) NOT NULL,\\n\\t`tags2` text DEFAULT \\'[]\\' NOT NULL\\n);\\n```\\n</Section>\\n\\nThe `mode` option defines how values are handled in the application. With `json` mode, values are treated as JSON object literal. \\n\\nYou can specify `.$type<..>()` for json object inference, it will not check runtime values. It provides compile time protection for default values, insert and select schemas.\\n', children=[]), DocItem(origPath=Path('guides/full-text-search-with-generated-columns.mdx'), name='full-text-search-with-generated-columns.mdx', displayName='full-text-search-with-generated-columns.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Full-text search with Generated Columns\\nslug: full-text-search-with-generated-columns\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql)\\n- [Select statement](/docs/select)\\n- [Indexes](/docs/indexes-constraints#indexes)\\n- [sql operator](/docs/sql) \\n- [Full-text search](/learn/guides/postgresql-full-text-search)\\n- [Generated columns](/docs/generated-columns)\\n</Prerequisites>\\n\\nThis guide demonstrates how to implement full-text search in PostgreSQL with Drizzle and generated columns. A generated column is a special column that is always computed from other columns. It is useful because you don\\'t have to compute the value of the column every time you query the table:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {18,19,20,23}\\nimport { SQL, sql } from \\'drizzle-orm\\';\\nimport { index, pgTable, serial, text, customType } from \\'drizzle-orm/pg-core\\';\\n\\nexport const tsvector = customType<{\\n  data: string;\\n}>({\\n  dataType() {\\n    return `tsvector`;\\n  },\\n});\\n\\nexport const posts = pgTable(\\n  \\'posts\\',\\n  {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    body: text(\\'body\\').notNull(),\\n    bodySearch: tsvector(\\'body_search\\')\\n      .notNull()\\n      .generatedAlwaysAs((): SQL => sql`to_tsvector(\\'english\\', ${posts.body})`),\\n  },\\n  (t) => [\\n    index(\\'idx_body_search\\').using(\\'gin\\', t.bodySearch),\\n  ]\\n);\\n  ```\\n  </CodeTab>\\n  ```sql\\nCREATE TABLE \"posts\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"body\" text NOT NULL,\\n\\t\"body_search\" \"tsvector\" GENERATED ALWAYS AS (to_tsvector(\\'english\\', \"posts\".\"body\")) STORED NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE INDEX \"idx_body_search\" ON \"posts\" USING gin (\"body_search\");\\n  ```\\n</CodeTabs>\\n\\nWhen you insert a row into a table, the value of a generated column is computed from an expression that you provide when you create the column:\\n\\n<Section>\\n```ts \\nimport { posts } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst body = \"Golden leaves cover the quiet streets as a crisp breeze fills the air, bringing the scent of rain and the promise of change\"\\n\\nawait db.insert(posts).values({\\n    body,\\n    title: \"The Beauty of Autumn\",\\n  }\\n).returning();\\n```\\n\\n```json\\n[\\n  {\\n    id: 1,\\n    title: \\'The Beauty of Autumn\\',\\n    body: \\'Golden leaves cover the quiet streets as a crisp breeze fills the air, bringing the scent of rain and the promise of change\\',\\n    bodySearch: \"\\'air\\':13 \\'breez\\':10 \\'bring\\':14 \\'chang\\':23 \\'cover\\':3 \\'crisp\\':9 \\'fill\\':11 \\'golden\\':1 \\'leav\\':2 \\'promis\\':21 \\'quiet\\':5 \\'rain\\':18 \\'scent\\':16 \\'street\\':6\"\\n  }\\n]\\n```\\n</Section>\\n\\nThis is how you can implement full-text search with generated columns in PostgreSQL with Drizzle ORM.  The `@@` operator is used for direct matches:\\n\\n<Section>\\n```ts copy {6}\\nconst searchParam = \"bring\";\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`${posts.bodySearch} @@ to_tsquery(\\'english\\', ${searchParam})`);\\n```\\n\\n```sql\\nselect * from posts where body_search @@ to_tsquery(\\'english\\', \\'bring\\');\\n```\\n</Section>\\n\\nThis is more advanced schema with a generated column. The `search` column is generated from the `title` and `body` columns and `setweight()` function is used to assign different weights to the columns for full-text search.\\nThis is typically used to mark entries coming from different parts of a document, such as title versus body.\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {18,19,20,21,22,23,24,28}\\nimport { SQL, sql } from \\'drizzle-orm\\';\\nimport { index, pgTable, serial, text, customType } from \\'drizzle-orm/pg-core\\';\\n\\nexport const tsvector = customType<{\\n  data: string;\\n}>({\\n  dataType() {\\n    return `tsvector`;\\n  },\\n});\\n\\nexport const posts = pgTable(\\n \\'posts\\',\\n {\\n   id: serial(\\'id\\').primaryKey(),\\n   title: text(\\'title\\').notNull(),\\n   body: text(\\'body\\').notNull(),\\n   search: tsvector(\\'search\\')\\n     .notNull()\\n     .generatedAlwaysAs(\\n        (): SQL =>\\n         sql`setweight(to_tsvector(\\'english\\', ${posts.title}), \\'A\\')\\n          ||\\n          setweight(to_tsvector(\\'english\\', ${posts.body}), \\'B\\')`,\\n     ),\\n  },\\n  (t) => [\\n    index(\\'idx_search\\').using(\\'gin\\', t.search),\\n  ],\\n);\\n  ```\\n  </CodeTab>\\n  ```sql\\nCREATE TABLE \"posts\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"body\" text NOT NULL,\\n\\t\"search\" \"tsvector\" GENERATED ALWAYS AS (setweight(to_tsvector(\\'english\\', \"posts\".\"title\"), \\'A\\')\\n          ||\\n          setweight(to_tsvector(\\'english\\', \"posts\".\"body\"), \\'B\\')) STORED NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE INDEX \"idx_search\" ON \"posts\" USING gin (\"search\");\\n  ```\\n</CodeTabs>\\n\\nThis is how you can query the table with full-text search:\\n\\n<Section>\\n```ts copy {6}\\nconst search = \\'travel\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`${posts.search} @@ to_tsquery(\\'english\\', ${search})`);\\n```\\n\\n```sql\\nselect * from posts where search @@ to_tsquery(\\'english\\', \\'travel\\');\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/gel-ext-auth.mdx'), name='gel-ext-auth.mdx', displayName='gel-ext-auth.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Gel auth extension\\nslug: gel-ext-auth\\n---\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport Npx from \"@mdx/Npx.astro\";\\n\\n<Prerequisites>\\n- Get started with [Gel](/docs/get-started-gel)\\n- Using [drizzle-kit pull](/docs/drizzle-kit-pull)\\n</Prerequisites>\\n\\n#### Step 1 - Define Gel auth schema\\n\\nIn `dbschema/default.esdl` file add a Gel schema with an auth extension\\n\\n```esdl\\nusing extension auth;\\n\\nmodule default {\\n  global current_user := (\\n    assert_single((\\n      select User { id, username, email }\\n      filter .identity = global ext::auth::ClientTokenIdentity\\n    ))\\n  );\\n\\n  type User {\\n    required identity: ext::auth::Identity;\\n    required username: str;\\n    required email: str;\\n  }\\n}\\n```\\n\\n#### Step 2 - Push Gel schema to the database\\n\\nGenerate Gel migration file:\\n```bash\\ngel migration create\\n```\\n\\nApply Gel migrations to the database\\n```bash\\ngel migration apply\\n```\\n\\n#### Step 3 - Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'gel\\',\\n  // Enable auth schema for drizzle-kit\\n  schemaFilter: [\\'ext::auth\\', \\'public\\']\\n});\\n```\\n\\n#### Step 4 - Pull Gel types to Drizzle schema\\n\\nPull your database schema:\\n<Npx>\\ndrizzle-kit pull\\n</Npx>\\n\\nHere is an example of the generated schema.ts file:\\n\\n<Callout type=\"warning\">\\nYou\\'ll get more than just the `Identity` table from `ext::auth`. Drizzle will pull in all the \\n`auth` tables you can use. The example below showcases just one of them.\\n</Callout>\\n\\n```ts\\nimport { gelTable, uniqueIndex, uuid, text, gelSchema, timestamptz, foreignKey } from \"drizzle-orm/gel-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const extauth = gelSchema(\\'ext::auth\\');\\n\\nexport const identityInExtauth = extauth.table(\\'Identity\\', {\\n\\tid: uuid().default(sql`uuid_generate_v4()`).primaryKey().notNull(),\\n\\tcreatedAt: timestamptz(\\'created_at\\').default(sql`(clock_timestamp())`).notNull(),\\n\\tissuer: text().notNull(),\\n\\tmodifiedAt: timestamptz(\\'modified_at\\').notNull(),\\n\\tsubject: text().notNull(),\\n}, (table) => [\\n\\tuniqueIndex(\\'6bc2dd19-bce4-5810-bb1b-7007afe97a11;schemaconstr\\').using(\\n\\t\\t\\'btree\\',\\n\\t\\ttable.id.asc().nullsLast().op(\\'uuid_ops\\'),\\n\\t),\\n]);\\n\\nexport const user = gelTable(\\'User\\', {\\n\\tid: uuid().default(sql`uuid_generate_v4()`).primaryKey().notNull(),\\n\\temail: text().notNull(),\\n\\tidentityId: uuid(\\'identity_id\\').notNull(),\\n\\tusername: text().notNull(),\\n}, (table) => [\\n\\tuniqueIndex(\\'d504514c-26a7-11f0-b836-81aa188c0abe;schemaconstr\\').using(\\n\\t\\t\\'btree\\',\\n\\t\\ttable.id.asc().nullsLast().op(\\'uuid_ops\\'),\\n\\t),\\n\\tforeignKey({\\n\\t\\tcolumns: [table.identityId],\\n\\t\\tforeignColumns: [identityInExtauth.id],\\n\\t\\tname: \\'User_fk_identity\\',\\n\\t}),\\n]);\\n```\\n\\nðŸŽ‰ Now you can use the `auth` tables in your queries!', children=[]), DocItem(origPath=Path('guides/include-or-exclude-columns.mdx'), name='include-or-exclude-columns.mdx', displayName='include-or-exclude-columns.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Include or Exclude Columns in Query\\nslug: include-or-exclude-columns\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Select statement](/docs/select)\\n- [Get typed table columns](/docs/goodies#get-typed-table-columns)\\n- [Joins](/docs/joins)\\n- [Relational queries](/docs/rqb)\\n- [Partial select with relational queries](/docs/rqb#partial-fields-select)\\n</Prerequisites>\\n\\nDrizzle has flexible API for including or excluding columns in queries. To include all columns you can use `.select()` method like this:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n    ```ts copy {5}\\n    import { posts } from \\'./schema\\';\\n\\n    const db = drizzle(...);\\n\\n    await db.select().from(posts);\\n    ```\\n\\n    ```ts\\n    // result type\\n    type Result = {\\n      id: number;\\n      title: string;\\n      content: string;\\n      views: number;\\n    }[];\\n    ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    views: integer(\\'views\\').notNull().default(0),\\n  });\\n\\t```\\n</CodeTabs>\\n\\nTo include specific columns you can use `.select()` method like this:\\n\\n<Section>\\n  ```ts copy {1}\\n  await db.select({ title: posts.title }).from(posts);\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    title: string;\\n  }[];\\n  ```\\n</Section>\\n\\nTo include all columns with extra columns you can use `getTableColumns()` utility function like this:\\n\\n<Section>\\n  ```ts copy {5,6}\\n  import { getTableColumns, sql } from \\'drizzle-orm\\';\\n\\n  await db\\n    .select({\\n      ...getTableColumns(posts),\\n      titleLength: sql<number>`length(${posts.title})`,\\n    })\\n    .from(posts);\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    id: number;\\n    title: string;\\n    content: string;\\n    views: number;\\n    titleLength: number;\\n  }[];\\n  ```\\n</Section>\\n\\nTo exclude columns you can use `getTableColumns()` utility function like this:\\n\\n<Section>\\n  ```ts copy {3,5}\\n  import { getTableColumns } from \\'drizzle-orm\\';\\n\\n  const { content, ...rest } = getTableColumns(posts); // exclude \"content\" column\\n\\n  await db.select({ ...rest }).from(posts); // select all other columns\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    id: number;\\n    title: string;\\n    views: number;\\n  }[];\\n  ```\\n</Section>\\n\\nThis is how you can include or exclude columns with joins:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {5,9,10,11}\\n    import { eq, getTableColumns } from \\'drizzle-orm\\';\\n    import { comments, posts, users } from \\'./db/schema\\';\\n\\n    // exclude \"userId\" and \"postId\" columns from \"comments\"\\n    const { userId, postId, ...rest } = getTableColumns(comments);\\n\\n    await db\\n      .select({\\n        postId: posts.id, // include \"id\" column from \"posts\"\\n        comment: { ...rest }, // include all other columns\\n        user: users, // equivalent to getTableColumns(users)\\n      })\\n      .from(posts)\\n      .leftJoin(comments, eq(posts.id, comments.postId))\\n      .leftJoin(users, eq(users.id, posts.userId));\\n    ```\\n\\n    ```ts\\n    // result type\\n    type Result = {\\n      postId: number;\\n      comment: {\\n        id: number;\\n        content: string;\\n        createdAt: Date;\\n      } | null;\\n      user: {\\n        id: number;\\n        name: string;\\n        email: string;\\n      } | null;\\n    }[];\\n    ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n    email: text(\\'email\\').notNull(),\\n  });\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    views: integer(\\'views\\').notNull().default(0),\\n    userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n  });\\n\\n  export const comments = pgTable(\\'comments\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    postId: integer(\\'post_id\\').notNull().references(() => posts.id),\\n    userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n    content: text(\\'content\\').notNull(),\\n    createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  });\\n  ```\\n</CodeTabs>\\n\\nDrizzle has useful relational queries API, that lets you easily include or exclude columns in queries. This is how you can include all columns:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {5,7,8,9,12,13,14,17,18,19,20,21,22}\\n    import * as schema from \\'./schema\\';\\n\\n    const db = drizzle(..., { schema });\\n\\n    await db.query.posts.findMany();\\n    ```\\n\\n    ```ts\\n    // result type\\n    type Result = {\\n      id: number;\\n      title: string;\\n      content: string;\\n      views: number;\\n    }[]\\n    ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    views: integer(\\'views\\').notNull().default(0),\\n  });\\n\\t```\\n</CodeTabs>\\n\\nThis is how you can include specific columns using relational queries:\\n\\n<Section>\\n  ```ts copy {2,3,4}\\n  await db.query.posts.findMany({\\n    columns: {\\n      title: true,\\n    },\\n  });\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    title: string;\\n  }[]\\n  ```\\n</Section>\\n\\nThis is how you can include all columns with extra columns using relational queries:\\n\\n<Section>\\n  ```ts copy {4,5,6}\\n  import { sql } from \\'drizzle-orm\\';\\n\\n  await db.query.posts.findMany({\\n    extras: {\\n      titleLength: sql<number>`length(${posts.title})`.as(\\'title_length\\'),\\n    },\\n  });\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    id: number;\\n    title: string;\\n    content: string;\\n    views: number;\\n    titleLength: number;\\n  }[];\\n  ```\\n</Section>\\n\\nThis is how you can exclude columns using relational queries:\\n\\n<Section>\\n  ```ts copy {2,3,4}\\n  await db.query.posts.findMany({\\n    columns: {\\n      content: false,\\n    },\\n  });\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    id: number;\\n    title: string;\\n    views: number;\\n  }[]\\n  ```\\n</Section>\\n\\nThis is how you can include or exclude columns with relations using relational queries:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n  ```ts copy {7,12,13,16}\\n  import * as schema from \\'./schema\\';\\n\\n  const db = drizzle(..., { schema });\\n\\n  await db.query.posts.findMany({\\n    columns: {\\n      id: true, // include \"id\" column\\n    },\\n    with: {\\n      comments: {\\n        columns: {\\n          userId: false, // exclude \"userId\" column\\n          postId: false, // exclude \"postId\" column\\n        },\\n      },\\n      user: true, // include all columns from \"users\" table\\n    },\\n  });\\n  ```\\n\\n  ```ts\\n  // result type\\n  type Result = {\\n    id: number;\\n    user: {\\n      id: number;\\n      name: string;\\n      email: string;\\n    };\\n    comments: {\\n      id: number;\\n      content: string;\\n      createdAt: Date;\\n    }[];\\n  }[]\\n  ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { relations } from \\'drizzle-orm\\';\\n  import { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n    email: text(\\'email\\').notNull(),\\n  });\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    views: integer(\\'views\\').notNull().default(0),\\n    userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n  });\\n\\n  export const comments = pgTable(\\'comments\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    postId: integer(\\'post_id\\').notNull().references(() => posts.id),\\n    userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n    content: text(\\'content\\').notNull(),\\n    createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  });\\n\\n  export const usersRelations = relations(users, ({ many }) => ({\\n    posts: many(posts),\\n    comments: many(comments),\\n  }));\\n\\n  export const postsRelations = relations(posts, ({ many, one }) => ({\\n    comments: many(comments),\\n    user: one(users, { fields: [posts.userId], references: [users.id] }),\\n  }));\\n\\n  export const commentsRelations = relations(comments, ({ one }) => ({\\n    post: one(posts, { fields: [comments.postId], references: [posts.id] }),\\n    user: one(users, { fields: [comments.userId], references: [users.id] }),\\n  }));\\n  ```\\n</CodeTabs>\\n\\nThis is how you can create custom solution for conditional select:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {7}\\n    import { posts } from \\'./schema\\';\\n\\n    const searchPosts = async (withTitle = false) => {\\n      await db\\n        .select({\\n          id: posts.id,\\n          ...(withTitle && { title: posts.title }),\\n        })\\n        .from(posts);\\n    };\\n\\n    await searchPosts();\\n    await searchPosts(true);\\n    ```\\n\\n    ```ts\\n    // result type\\n    type Result = {\\n      id: number;\\n      title?: string | undefined;\\n    }[];\\n    ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    views: integer(\\'views\\').notNull().default(0),\\n  });\\n\\t```\\n</CodeTabs>\\n', children=[]), DocItem(origPath=Path('guides/incrementing-a-value.mdx'), name='incrementing-a-value.mdx', displayName='incrementing-a-value.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Increment value\\nslug: incrementing-a-value\\n---\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Update statement](/docs/update)\\n- [Filters](/docs/operators) and [sql operator](/docs/sql)\\n</Prerequisites>\\n\\nTo increment a column value you can use `update().set()` method like below:\\n\\n<Section>\\n```ts copy {8}\\nimport { eq, sql } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...)\\n  \\nawait db\\n  .update(table)\\n  .set({\\n    counter: sql`${table.counter} + 1`,\\n  })\\n  .where(eq(table.id, 1));\\n```\\n\\n```sql\\nupdate \"table\" set \"counter\" = \"counter\" + 1 where \"id\" = 1;\\n```\\n</Section>\\n\\nDrizzle has simple and flexible API, which lets you easily create custom solutions. This is how you do custom increment function:\\n\\n```ts copy {4,10,11}\\nimport { AnyColumn } from \\'drizzle-orm\\';\\n\\nconst increment = (column: AnyColumn, value = 1) => {\\n  return sql`${column} + ${value}`;\\n};\\n\\nawait db\\n  .update(table)\\n  .set({\\n    counter1: increment(table.counter1),\\n    counter2: increment(table.counter2, 10),\\n  })\\n  .where(eq(table.id, 1));\\n```\\n', children=[]), DocItem(origPath=Path('guides/limit-offset-pagination.mdx'), name='limit-offset-pagination.mdx', displayName='limit-offset-pagination.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Limit/Offset pagination\\nslug: limit-offset-pagination\\n---\\n\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Select statement](/docs/select) with [order by clause](/docs/select#order-by) and [limit & offset clauses](/docs/select#limit--offset)\\n- [Relational queries](/docs/rqb) with [order by clause](/docs/rqb#order-by) and [limit & offset clauses](/docs/rqb#limit--offset)\\n- [Dynamic query building](/docs/dynamic-query-building)\\n</Prerequisites>\\n\\nThis guide demonstrates how to implement `limit/offset` pagination in Drizzle:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {9,10,11}\\n    import { asc } from \\'drizzle-orm\\';\\n    import { users } from \\'./schema\\';\\n\\n    const db = drizzle(...);\\n\\n    await db\\n      .select()\\n      .from(users)\\n      .orderBy(asc(users.id)) // order by is mandatory\\n      .limit(4) // the number of rows to return\\n      .offset(4); // the number of rows to skip\\n    ```\\n\\n    ```sql\\n    select * from users order by id asc limit 4 offset 4;\\n    ```\\n\\n    ```ts\\n    // 5-8 rows returned\\n    [\\n      {\\n        id: 5,\\n        firstName: \\'Beth\\',\\n        lastName: \\'Davis\\',\\n        createdAt: 2024-03-11T20:51:46.787Z\\n      },\\n      {\\n        id: 6,\\n        firstName: \\'Charlie\\',\\n        lastName: \\'Miller\\',\\n        createdAt: 2024-03-11T21:15:46.787Z\\n      },\\n      {\\n        id: 7,\\n        firstName: \\'Clara\\',\\n        lastName: \\'Wilson\\',\\n        createdAt: 2024-03-11T21:33:46.787Z\\n      },\\n      {\\n        id: 8,\\n        firstName: \\'David\\',\\n        lastName: \\'Moore\\',\\n        createdAt: 2024-03-11T21:45:46.787Z\\n      }\\n    ]\\n    ```\\n  </CodeTab>\\n  <CodeTab>\\n    ```ts copy\\n    import { pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n    export const users = pgTable(\\'users\\', {\\n      id: serial(\\'id\\').primaryKey(),\\n      firstName: text(\\'first_name\\').notNull(),\\n      lastName: text(\\'last_name\\').notNull(),\\n      createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n    });\\n    ```\\n\\n    ```plaintext\\n    +----+------------+-----------+----------------------------+\\n    | id | first_name | last_name |         created_at         |\\n    +----+------------+-----------+----------------------------+\\n    |  1 | Alice      | Johnson   | 2024-03-08 12:23:55.251797 |\\n    +----+------------+-----------+----------------------------+\\n    |  2 | Alex       | Smith     | 2024-03-08 12:25:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  3 | Aaron      | Williams  | 2024-03-08 12:28:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  4 | Brian      | Brown     | 2024-03-08 12:34:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  5 | Beth       | Davis     | 2024-03-08 12:40:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  6 | Charlie    | Miller    | 2024-03-08 13:04:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  7 | Clara      | Wilson    | 2024-03-08 13:22:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    |  8 | David      | Moore     | 2024-03-08 13:34:55.182    |\\n    +----+------------+-----------+----------------------------+\\n    ```\\n  </CodeTab>\\n</CodeTabs>\\n\\nLimit is the number of rows to return `(page size)` and offset is the number of rows to skip `((page number - 1) * page size)`. \\nFor consistent pagination, ensure ordering by a unique column. Otherwise, the results can be inconsistent.\\n\\nIf you need to order by a non-unique column, you should also append a unique column to the ordering.\\n\\nThis is how you can implement `limit/offset` pagination with 2 columns:\\n\\n<Section>\\n```ts copy {5}\\nconst getUsers = async (page = 1, pageSize = 3) => {\\n  await db\\n    .select()\\n    .from(users)\\n    .orderBy(asc(users.firstName), asc(users.id)) // order by first_name (non-unique), id (pk)\\n    .limit(pageSize) \\n    .offset((page - 1) * pageSize);\\n}\\n\\nawait getUsers();\\n```\\n</Section>\\n\\nDrizzle has useful relational queries API, that lets you easily implement `limit/offset` pagination:\\n\\n<Section>\\n```ts copy {7,8,9}\\nimport * as schema from \\'./db/schema\\';\\n\\nconst db = drizzle({ schema });\\n\\nconst getUsers = async (page = 1, pageSize = 3) => {\\n  await db.query.users.findMany({\\n    orderBy: (users, { asc }) => asc(users.id),\\n    limit: pageSize,\\n    offset: (page - 1) * pageSize,\\n  });\\n};\\n\\nawait getUsers();\\n```\\n</Section>\\n\\nDrizzle has simple and flexible API, which lets you easily create custom solutions. This is how you can create custom function for pagination using `.$dynamic()` function:\\n\\n<Section>\\n```ts copy {11,12,13,16}\\nimport { SQL, asc } from \\'drizzle-orm\\';\\nimport { PgColumn, PgSelect } from \\'drizzle-orm/pg-core\\';\\n\\nfunction withPagination<T extends PgSelect>(\\n  qb: T,\\n  orderByColumn: PgColumn | SQL | SQL.Aliased,\\n  page = 1,\\n  pageSize = 3,\\n) {\\n  return qb\\n    .orderBy(orderByColumn)\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nconst query = db.select().from(users); // query that you want to execute with pagination\\n\\nawait withPagination(query.$dynamic(), asc(users.id));\\n```\\n\\n</Section>\\n\\nYou can improve performance of `limit/offset` pagination by using `deferred join` technique. This method performs the pagination on a subset of the data instead of the entire table.\\n\\nTo implement it you can do like this:\\n\\n```ts copy {10}\\nconst getUsers = async (page = 1, pageSize = 10) => {\\n   const sq = db\\n    .select({ id: users.id })\\n    .from(users)\\n    .orderBy(users.id)\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize)\\n    .as(\\'subquery\\');\\n\\n   await db.select().from(users).innerJoin(sq, eq(users.id, sq.id)).orderBy(users.id);\\n};\\n```\\n\\n**Benefits** of `limit/offset` pagination: it\\'s simple to implement and pages are easily reachable, which means that you can navigate to any page without having to save the state of the previous pages.\\n\\n**Drawbacks** of `limit/offset` pagination: degradation in query performance with increasing offset because database has to scan all rows before the offset to skip them, and inconsistency due to data shifts, which can lead to the same row being returned on different pages or rows being skipped.\\n\\nThis is how it works:\\n\\n<Section>\\n```ts copy\\nconst getUsers = async (page = 1, pageSize = 3) => {\\n  await db\\n    .select()\\n    .from(users)\\n    .orderBy(asc(users.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n};\\n\\n// user is browsing the first page\\nawait getUsers();\\n```\\n\\n```ts\\n// results for the first page\\n[\\n  {\\n    id: 1,\\n    firstName: \\'Alice\\',\\n    lastName: \\'Johnson\\',\\n    createdAt: 2024-03-10T17:17:06.148Z\\n  },\\n  {\\n    id: 2,\\n    firstName: \\'Alex\\',\\n    lastName: \\'Smith\\',\\n    createdAt: 2024-03-10T17:19:06.147Z\\n  },\\n  {\\n    id: 3,\\n    firstName: \\'Aaron\\',\\n    lastName: \\'Williams\\',\\n    createdAt: 2024-03-10T17:22:06.147Z\\n  }\\n]\\n```\\n\\n```ts\\n// while user is browsing the first page, a row with id 2 is deleted\\nawait db.delete(users).where(eq(users.id, 2));\\n\\n// user navigates to the second page\\nawait getUsers(2);\\n```\\n\\n```ts\\n// second page, row with id 3 was skipped\\n[\\n  {\\n    id: 5,\\n    firstName: \\'Beth\\',\\n    lastName: \\'Davis\\',\\n    createdAt: 2024-03-10T17:34:06.147Z\\n  },\\n  {\\n    id: 6,\\n    firstName: \\'Charlie\\',\\n    lastName: \\'Miller\\',\\n    createdAt: 2024-03-10T17:58:06.147Z\\n  },\\n  {\\n    id: 7,\\n    firstName: \\'Clara\\',\\n    lastName: \\'Wilson\\',\\n    createdAt: 2024-03-10T18:16:06.147Z\\n  }\\n]\\n```\\n</Section>\\n\\nSo, if your database experiences frequently insert and delete operations in real time or you need high performance to paginate large tables, you should consider using [cursor-based](/docs/guides/cursor-based-pagination) pagination instead.\\n\\nTo learn more about `deferred join` technique you should follow these guides: [Planetscale Pagination Guide](https://planetscale.com/blog/mysql-pagination) and [Efficient Pagination Guide by Aaron Francis](https://aaronfrancis.com/2022/efficient-pagination-using-deferred-joins).\\n', children=[]), DocItem(origPath=Path('guides/mysql-local-setup.mdx'), name='mysql-local-setup.mdx', displayName='mysql-local-setup.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: How to setup MySQL locally\\nslug: mysql-local-setup\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n<Prerequisites>\\n- Install latest [Docker Desktop](https://www.docker.com/products/docker-desktop/). Follow the instructions for your operating system.\\n</Prerequisites>\\n\\n<Steps>\\n\\n#### Pull the MySQL image\\n\\nPull the latest MySQL image from Docker Hub. In your terminal, run `docker pull mysql` to pull the latest MySQL version from Docker Hub:\\n\\n```bash copy\\ndocker pull mysql\\n```\\n\\nAlternatively, you can pull preferred version with a specific tag:\\n\\n```bash copy\\ndocker pull mysql:8.2\\n```\\n\\nWhen MySQL image is downloaded, you can check it in `Images` tab in Docker Desktop or by running `docker images`:\\n\\n<Section>\\n```bash copy\\ndocker images\\n```\\n\\n```plaintext\\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\\nmysql        latest    4e8a34aea708   2 months ago   609MB\\n```\\n</Section>\\n\\n#### Start a MySQL instance\\n\\nTo start a new MySQL container, run the following command:\\n\\n```bash copy\\ndocker run --name drizzle-mysql -e MYSQL_ROOT_PASSWORD=mypassword -d -p 3306:3306 mysql\\n```\\n\\n1. The `--name` option assigns the container the name `drizzle-mysql`.\\n2. The `-e MYSQL_ROOT_PASSWORD=` option sets the `MYSQL_ROOT_PASSWORD` environment variable with the specified value. This is password for the root user.\\n3. The `-d` flag runs the container in detached mode (in the background).\\n4. The `-p` option maps port `3306` on the container to port `3306` on your host machine, allowing MySQL to be accessed from your host system through this port.\\n5. The `mysql` argument specifies the image to use for the container. You can also specify other versions like `mysql:8.2`.\\n\\nYou can also specify other parameters like:\\n\\n1. `-e MYSQL_DATABASE=` to create a new database when the container is created. Default is `mysql`.\\n2. `-e MYSQL_USER=` and `-e MYSQL_PASSWORD=` to create a new user with a password when the container is created. But you still need to specify `MYSQL_ROOT_PASSWORD` for `root` user.\\n\\nTo check if the container is running, check `Containers` tab in Docker Desktop or use the `docker ps` command:\\n\\n```plaintext\\nCONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                               NAMES\\n19506a8dc12b   mysql         \"docker-entrypoint.sâ€¦\"   4 seconds ago    Up 3 seconds    33060/tcp, 0.0.0.0:3306->3306/tcp   drizzle-mysql\\n```\\n\\n#### Configure database url\\n\\nTo connect to the MySQL database, you need to provide the database URL. The URL format is:\\n\\n```plaintext\\nmysql://<user>:<password>@<host>:<port>/<database>\\n```\\n\\nYou should replace placeholders with your actual values. For example, for created container the url will be:\\n\\n```plaintext\\nmysql://root:mypassword@localhost:3306/mysql\\n```\\n\\nNow you can connect to the database using the URL in your application.\\n</Steps>\\n', children=[]), DocItem(origPath=Path('guides/point-datatype-psql.mdx'), name='point-datatype-psql.mdx', displayName='point-datatype-psql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Point datatype in PostgreSQL\\nslug: point-datatype-psql\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql)\\n- [Point datatype](/docs/column-types/pg#point)\\n- [Filtering in select statement](/docs/select#filtering)\\n- [sql operator](/docs/sql)\\n</Prerequisites>\\n\\nPostgreSQL has a special datatype to store geometric data called `point`. It is used to represent a point in a two-dimensional space. The point datatype is represented as a pair of `(x, y)` coordinates.\\nThe point expects to receive longitude first, followed by latitude.\\n\\n<Section>\\n```ts copy {6}\\nimport { sql } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...);\\n\\nawait db.execute(\\n  sql`select point(-90.9, 18.7)`,\\n);\\n```\\n\\n```json\\n[ \\n  { \\n    point: \\'(-90.9,18.7)\\' \\n  }\\n]\\n```\\n</Section>\\n\\nThis is how you can create table with `point` datatype in Drizzle:\\n\\n```ts {6}\\nimport { pgTable, point, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\nexport const stores = pgTable(\\'stores\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  location: point(\\'location\\', { mode: \\'xy\\' }).notNull(),\\n});\\n```\\n\\nThis is how you can insert point data into the table in Drizzle:\\n\\n```ts {4, 10, 16}\\n// mode: \\'xy\\'\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: { x: -90.9, y: 18.7 },\\n});\\n\\n// mode: \\'tuple\\'\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: [-90.9, 18.7],\\n});\\n\\n// sql raw\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: sql`point(-90.9, 18.7)`,\\n});\\n```\\n\\nTo compute the distance between the objects you can use `<->` operator. This is how you can query for the nearest location by coordinates in Drizzle:\\n\\n<Section>\\n```ts {9, 14, 17}\\nimport { getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { stores } from \\'./schema\\';\\n\\nconst point = {\\n  x: -73.935_242,\\n  y: 40.730_61,\\n};\\n\\nconst sqlDistance = sql`location <-> point(${point.x}, ${point.y})`;\\n\\nawait db\\n  .select({\\n    ...getTableColumns(stores),\\n    distance: sql`round((${sqlDistance})::numeric, 2)`,\\n  })\\n  .from(stores)\\n  .orderBy(sqlDistance)\\n  .limit(1);\\n```\\n\\n```sql\\nselect *, round((location <-> point(-73.935242, 40.73061))::numeric, 2)\\nfrom stores order by location <-> point(-73.935242, 40.73061)\\nlimit 1;\\n```\\n</Section>\\n\\nTo filter rows to include only those where a `point` type `location` falls within a specified rectangular boundary defined by two diagonal points you can user `<@` operator. It checks if the first object is contained in or on the second object:\\n\\n<Section>\\n```ts {12}\\nconst point = {\\n  x1: -88,\\n  x2: -73,\\n  y1: 40,\\n  y2: 43,\\n};\\n\\nawait db\\n  .select()\\n  .from(stores)\\n  .where(\\n    sql`${stores.location} <@ box(point(${point.x1}, ${point.y1}), point(${point.x2}, ${point.y2}))`\\n  );\\n```\\n\\n```sql\\nselect * from stores where location <@ box(point(-88, 40), point(-73, 43));\\n```\\n</Section>\\n\\n\\n\\n', children=[]), DocItem(origPath=Path('guides/postgis-geometry-point.mdx'), name='postgis-geometry-point.mdx', displayName='postgis-geometry-point.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: PostGIS geometry point\\nslug: postgis-geometry-point\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql)\\n- [Postgis extension](/docs/extensions/pg#postgis)\\n- [Indexes](/docs/indexes-constraints#indexes)\\n- [Filtering in select statement](/docs/select#filtering)\\n- [sql operator](/docs/sql)\\n</Prerequisites>\\n\\n`PostGIS` extends the capabilities of the PostgreSQL relational database by adding support for storing, indexing, and querying geospatial data. \\n\\nAs for now, Drizzle doesn\\'t create extension automatically, so you need to create it manually. Create an empty migration file and add SQL query:\\n\\n<Section>\\n```bash\\nnpx drizzle-kit generate --custom\\n```\\n\\n```sql\\nCREATE EXTENSION postgis;\\n```\\n</Section>\\n\\nThis is how you can create table with `geometry` datatype and spatial index in Drizzle:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {8, 11}\\n  import { geometry, index, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const stores = pgTable(\\n    \\'stores\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      name: text(\\'name\\').notNull(),\\n      location: geometry(\\'location\\', { type: \\'point\\', mode: \\'xy\\', srid: 4326 }).notNull(),\\n    },\\n    (t) => [\\n      index(\\'spatial_index\\').using(\\'gist\\', t.location),\\n    ]\\n  );\\n  ```\\n  </CodeTab>\\n  ```sql\\n  CREATE TABLE IF NOT EXISTS \"stores\" (\\n\\t  \"id\" serial PRIMARY KEY NOT NULL,\\n\\t  \"name\" text NOT NULL,\\n\\t  \"location\" geometry(point) NOT NULL\\n  );\\n  --> statement-breakpoint\\n  CREATE INDEX IF NOT EXISTS \"spatial_index\" ON \"stores\" USING gist (\"location\");\\n  ```\\n</CodeTabs>\\n \\nThis is how you can insert `geometry` data into the table in Drizzle. `ST_MakePoint()` in PostGIS creates a geometric object of type `point` using the specified coordinates.\\n`ST_SetSRID()` sets the `SRID` (unique identifier associated with a specific coordinate system, tolerance, and resolution) on a geometry to a particular integer value:\\n\\n```ts {4, 10, 16}\\n// mode: \\'xy\\'\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: { x: -90.9, y: 18.7 },\\n});\\n\\n// mode: \\'tuple\\'\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: [-90.9, 18.7],\\n});\\n\\n// sql raw\\nawait db.insert(stores).values({\\n  name: \\'Test\\',\\n  location: sql`ST_SetSRID(ST_MakePoint(-90.9, 18.7), 4326)`,\\n});\\n```\\n\\nTo compute the distance between the objects you can use `<->` operator and `ST_Distance()` function, which for `geometry types` returns the minimum planar distance between two geometries. This is how you can query for the nearest location by coordinates in Drizzle with PostGIS:\\n\\n<Section>\\n```ts copy {9, 14, 17}\\nimport { getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { stores } from \\'./schema\\';\\n\\nconst point = {\\n  x: -73.935_242,\\n  y: 40.730_61,\\n};\\n\\nconst sqlPoint = sql`ST_SetSRID(ST_MakePoint(${point.x}, ${point.y}), 4326)`;\\n\\nawait db\\n  .select({\\n    ...getTableColumns(stores),\\n    distance: sql`ST_Distance(${stores.location}, ${sqlPoint})`,\\n  })\\n  .from(stores)\\n  .orderBy(sql`${stores.location} <-> ${sqlPoint}`)\\n  .limit(1);\\n```\\n\\n```sql\\nselect *, ST_Distance(location, ST_SetSRID(ST_MakePoint(-73.935_242, 40.730_61), 4326))\\nfrom stores order by location <-> ST_SetSRID(ST_MakePoint(-73.935_242, 40.730_61), 4326)\\nlimit 1;\\n```\\n</Section>\\n\\nTo filter stores located within a specified rectangular area, you can use `ST_MakeEnvelope()` and `ST_Within()` functions. `ST_MakeEnvelope()` creates a rectangular Polygon from the minimum and maximum values for X and Y. `ST_Within()` Returns TRUE if geometry A is within geometry B.\\n\\n<Section>\\n```ts copy {13}\\nconst point = {\\n  x1: -88,\\n  x2: -73,\\n  y1: 40,\\n  y2: 43,\\n};\\n\\nawait db\\n  .select()\\n  .from(stores)\\n  .where(\\n    sql`ST_Within(\\n      ${stores.location}, ST_MakeEnvelope(${point.x1}, ${point.y1}, ${point.x2}, ${point.y2}, 4326)\\n    )`,\\n  );\\n```\\n\\n```sql\\nselect * from stores where ST_Within(location, ST_MakeEnvelope(-88, 40, -73, 43, 4326));\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/postgresql-full-text-search.mdx'), name='postgresql-full-text-search.mdx', displayName='postgresql-full-text-search.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: PostgreSQL full-text search\\nslug: postgresql-full-text-search\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql)\\n- [Select statement](/docs/select)\\n- [Indexes](/docs/indexes-constraints#indexes)\\n- [sql operator](/docs/sql)\\n- You should have `drizzle-orm@0.31.0` and `drizzle-kit@0.22.0` or higher.  \\n</Prerequisites>\\n\\nThis guide demonstrates how to implement full-text search in PostgreSQL with Drizzle ORM. Full-text search is a technique used to search for text within a document or a set of documents. A document is the unit of searching in a full text search system. PostgreSQL provides a set of functions to work with full-text search, such as `to_tsvector` and `to_tsquery`:\\n\\nThe `to_tsvector` function parses a textual document into tokens, reduces the tokens to lexemes, and returns a `tsvector` which lists the lexemes together with their positions in the document:\\n\\n<Section>\\n```ts copy {6}\\nimport { sql } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...);\\n\\nawait db.execute(\\n  sql`select to_tsvector(\\'english\\', \\'Guide to PostgreSQL full-text search with Drizzle ORM\\')`,\\n);\\n```\\n\\n```json\\n[\\n  {\\n    to_tsvector: \"\\'drizzl\\':9 \\'full\\':5 \\'full-text\\':4\\n    \\'guid\\':1 \\'orm\\':10 \\'postgresql\\':3 \\'search\\':7 \\'text\\':6\"\\n  }\\n]\\n```\\n</Section>\\n\\nThe `to_tsquery` function converts a keyword to normalized tokens and returns a `tsquery` that matches the lexemes in a `tsvector`. The `@@` operator is used for direct matches:\\n\\n<Section>\\n```ts copy {2, 3}\\nawait db.execute(\\n  sql`select to_tsvector(\\'english\\', \\'Guide to PostgreSQL full-text search with Drizzle ORM\\')\\n    @@ to_tsquery(\\'english\\', \\'Drizzle\\') as match`,\\n);\\n```\\n\\n```json\\n[ { match: true } ]\\n```\\n</Section>\\n\\nAs for now, Drizzle doesn\\'t support `tsvector` type natively, so you need to convert your data in the `text` column on the fly. To enhance the performance, you can create a `GIN` index on your column like this:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\", \"db_data\"]}>\\n  <CodeTab>\\n  ```ts copy {10, 11}\\n  import { index, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const posts = pgTable(\\n    \\'posts\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      title: text(\\'title\\').notNull(),\\n    },\\n    (table) => [\\n      index(\\'title_search_index\\').using(\\'gin\\', sql`to_tsvector(\\'english\\', ${table.title})`),\\n    ]\\n  );\\n  ```\\n  </CodeTab>\\n  <CodeTab>\\n  ```sql\\n  CREATE TABLE IF NOT EXISTS \"posts\" (\\n          \"id\" serial PRIMARY KEY NOT NULL,\\n          \"title\" text NOT NULL\\n  );\\n\\n  CREATE INDEX IF NOT EXISTS \"title_search_index\" ON \"posts\"\\n    USING gin (to_tsvector(\\'english\\', \"title\"));\\n  ```\\n  </CodeTab>\\n  ```json\\n  [\\n    { id: 1, title: \\'Planning Your First Trip to Europe\\' },\\n    { id: 2, title: \"Cultural Insights: Exploring Asia\\'s Heritage\" },\\n    { id: 3, title: \\'Top 5 Destinations for a Family Trip\\' },\\n    { id: 4, title: \\'Essential Hiking Gear for Mountain Enthusiasts\\' },\\n    { id: 5, title: \\'Trip Planning: Choosing Your Next Destination\\' },\\n    { id: 6, title: \\'Discovering Hidden Culinary Gems in Italy\\' },\\n    { id: 7, title: \\'The Ultimate Road Trip Guide for Explorers\\' },\\n  ];\\n  ```\\n</CodeTabs>\\n\\nTo implement full-text search in PostgreSQL with Drizzle ORM, you can use the `to_tsvector` and `to_tsquery` functions with `sql` operator:\\n\\n<Section>\\n```ts copy {9}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { posts } from \\'./schema\\';\\n\\nconst title = \\'trip\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`to_tsvector(\\'english\\', ${posts.title}) @@ to_tsquery(\\'english\\', ${title})`);\\n```\\n\\n```json\\n[\\n  { id: 1, title: \\'Planning Your First Trip to Europe\\' },\\n  { id: 3, title: \\'Top 5 Destinations for a Family Trip\\' },\\n  { id: 5, title: \\'Trip Planning: Choosing Your Next Destination\\' },\\n  { id: 7, title: \\'The Ultimate Road Trip Guide for Explorers\\' }\\n]\\n```\\n</Section>\\n\\nTo match by any of the keywords, you can use the `|` operator:\\n\\n<Section>\\n```ts copy {6}\\nconst title = \\'Europe | Asia\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`to_tsvector(\\'english\\', ${posts.title}) @@ to_tsquery(\\'english\\', ${title})`);\\n```\\n\\n```json\\n[\\n  { id: 1, title: \\'Planning Your First Trip to Europe\\' },\\n  { id: 2, title: \"Cultural Insights: Exploring Asia\\'s Heritage\" }\\n]\\n```\\n</Section>\\n\\nTo match multiple keywords, you can use the `plainto_tsquery` function:\\n\\n<Section>\\n```ts copy {7}\\n// \\'discover & Italy\\'\\nconst title = \\'discover Italy\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`to_tsvector(\\'english\\', ${posts.title}) @@ plainto_tsquery(\\'english\\', ${title})`);\\n```\\n\\n```sql\\nselect * from posts\\n  where to_tsvector(\\'english\\', title) @@ plainto_tsquery(\\'english\\', \\'discover Italy\\');\\n```\\n\\n```json\\n[ { id: 6, title: \\'Discovering Hidden Culinary Gems in Italy\\' } ]\\n```\\n</Section>\\n\\nTo match a phrase, you can use the `phraseto_tsquery` function:\\n\\n<Section>\\n```ts copy {8}\\n// if you query by \"trip family\", it will not return any result\\n// \\'family <-> trip\\'\\nconst title = \\'family trip\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`to_tsvector(\\'english\\', ${posts.title}) @@ phraseto_tsquery(\\'english\\', ${title})`);\\n```\\n\\n```sql\\nselect * from posts\\n  where to_tsvector(\\'english\\', title) @@ phraseto_tsquery(\\'english\\', \\'family trip\\');\\n```\\n\\n```json\\n[ { id: 3, title: \\'Top 5 Destinations for a Family Trip\\' } ]\\n```\\n</Section>\\n\\nYou can also use `websearch_to_tsquery` function which is a simplified version of `to_tsquery` with an alternative syntax, similar to the one used by web search engines:\\n\\n<Section>\\n```ts copy {7}\\n// \\'family | first & trip & europ | asia\\'\\nconst title = \\'family or first trip Europe or Asia\\';\\n\\nawait db\\n  .select()\\n  .from(posts)\\n  .where(sql`to_tsvector(\\'english\\', ${posts.title}) @@ websearch_to_tsquery(\\'english\\', ${title})`);\\n```\\n\\n```sql\\nselect * from posts\\n  where to_tsvector(\\'english\\', title)\\n  @@ websearch_to_tsquery(\\'english\\', \\'family or first trip Europe or Asia\\');\\n```\\n\\n```json\\n[\\n  { id: 1, title: \\'Planning Your First Trip to Europe\\' },\\n  { id: 2, title: \"Cultural Insights: Exploring Asia\\'s Heritage\" },\\n  { id: 3, title: \\'Top 5 Destinations for a Family Trip\\' }\\n]\\n```\\n</Section>\\n\\nTo implement full-text search on multiple columns, you can create index on multiple columns and concatenate the columns with `to_tsvector` function:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\", \"db_data\"]}>\\n  <CodeTab>\\n  ```ts copy {12-17}\\n  import { sql } from \\'drizzle-orm\\';\\n  import { index, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const posts = pgTable(\\n    \\'posts\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      title: text(\\'title\\').notNull(),\\n      description: text(\\'description\\').notNull(),\\n    },\\n    (table) => [\\n      index(\\'search_index\\').using(\\n        \\'gin\\',\\n        sql`(\\n            setweight(to_tsvector(\\'english\\', ${table.title}), \\'A\\') ||\\n            setweight(to_tsvector(\\'english\\', ${table.description}), \\'B\\')\\n        )`,\\n      ),\\n    ],\\n  );\\n  ```\\n  </CodeTab>\\n  <CodeTab>\\n  ```sql\\n  CREATE TABLE IF NOT EXISTS \"posts\" (\\n        \"id\" serial PRIMARY KEY NOT NULL,\\n        \"title\" text NOT NULL,\\n        \"description\" text NOT NULL\\n  );\\n\\n  CREATE INDEX IF NOT EXISTS \"search_index\" ON \"posts\"\\n    USING gin ((setweight(to_tsvector(\\'english\\', \"title\"), \\'A\\') ||\\n    setweight(to_tsvector(\\'english\\', \"description\"), \\'B\\')));\\n  ```\\n  </CodeTab>\\n  ```json\\n  [\\n    {\\n      id: 1,\\n      title: \\'Planning Your First Trip to Europe\\',\\n      description:\\n        \\'Get essential tips on budgeting, sightseeing, and cultural etiquette for your inaugural European adventure.\\',\\n    },\\n    {\\n      id: 2,\\n      title: \"Cultural Insights: Exploring Asia\\'s Heritage\",\\n      description:\\n        \\'Dive deep into the rich history and traditions of Asia through immersive experiences and local interactions.\\',\\n    },\\n    {\\n      id: 3,\\n      title: \\'Top 5 Destinations for a Family Trip\\',\\n      description:\\n        \\'Discover family-friendly destinations that offer fun, education, and relaxation for all ages.\\',\\n    },\\n    {\\n      id: 4,\\n      title: \\'Essential Hiking Gear for Mountain Enthusiasts\\',\\n      description:\\n        \\'Equip yourself with the latest and most reliable gear for your next mountain hiking expedition.\\',\\n    },\\n    {\\n      id: 5,\\n      title: \\'Trip Planning: Choosing Your Next Destination\\',\\n      description:\\n        \\'Learn how to select destinations that align with your travel goals, whether for leisure, adventure, or cultural exploration.\\',\\n    },\\n    {\\n      id: 6,\\n      title: \\'Discovering Hidden Culinary Gems in Italy\\',\\n      description:\\n        \"Unearth Italy\\'s lesser-known eateries and food markets that offer authentic and traditional flavors.\",\\n    },\\n    {\\n      id: 7,\\n      title: \\'The Ultimate Road Trip Guide for Explorers\\',\\n      description:\\n        \\'Plan your next great road trip with tips on route planning, packing, and discovering off-the-beaten-path attractions.\\',\\n    },\\n  ];\\n  ```\\n</CodeTabs>\\n\\nThe `setweight` function is used to label the entries of a tsvector with a given weight, where a weight is one of the letters A, B, C, or D. This is typically used to mark entries coming from different parts of a document, such as title versus body.\\n\\nThis is how you can query on multiple columns:\\n\\n<Section>\\n```ts copy {5-7}\\nconst title = \\'plan\\';\\n\\nawait db.select().from(posts)\\n  .where(sql`(\\n      setweight(to_tsvector(\\'english\\', ${posts.title}), \\'A\\') ||\\n      setweight(to_tsvector(\\'english\\', ${posts.description}), \\'B\\'))\\n      @@ to_tsquery(\\'english\\', ${title}\\n    )`\\n  );\\n```\\n\\n```json\\n[\\n  {\\n    id: 1,\\n    title: \\'Planning Your First Trip to Europe\\',\\n    description: \\'Get essential tips on budgeting, sightseeing, and cultural etiquette for your inaugural European adventure.\\'\\n  },\\n  {\\n    id: 5,\\n    title: \\'Trip Planning: Choosing Your Next Destination\\',\\n    description: \\'Learn how to select destinations that align with your travel goals, whether for leisure, adventure, or cultural exploration.\\'\\n  },\\n  {\\n    id: 7,\\n    title: \\'The Ultimate Road Trip Guide for Explorers\\',\\n    description: \\'Plan your next great road trip with tips on route planning, packing, and discovering off-the-beaten-path attractions.\\'\\n  }\\n]\\n```\\n</Section>\\n\\nTo rank the search results, you can use the `ts_rank` or `ts_rank_cd` functions and `orderBy` method:\\n\\n<Section>\\n```ts copy {6,7,12,13,18-20}\\nimport { desc, getTableColumns, sql } from \\'drizzle-orm\\';\\n\\nconst search = \\'culture | Europe | Italy | adventure\\';\\n\\nconst matchQuery = sql`(\\n  setweight(to_tsvector(\\'english\\', ${posts.title}), \\'A\\') ||\\n  setweight(to_tsvector(\\'english\\', ${posts.description}), \\'B\\')), to_tsquery(\\'english\\', ${search})`;\\n\\nawait db\\n  .select({\\n    ...getTableColumns(posts),\\n    rank: sql`ts_rank(${matchQuery})`,\\n    rankCd: sql`ts_rank_cd(${matchQuery})`,\\n  })\\n  .from(posts)\\n  .where(\\n    sql`(\\n      setweight(to_tsvector(\\'english\\', ${posts.title}), \\'A\\') ||\\n      setweight(to_tsvector(\\'english\\', ${posts.description}), \\'B\\')\\n      ) @@ to_tsquery(\\'english\\', ${search})`,\\n  )\\n  .orderBy((t) => desc(t.rank));\\n```\\n\\n```json\\n[\\n  {\\n    id: 1,\\n    title: \\'Planning Your First Trip to Europe\\',\\n    description: \\'Get essential tips on budgeting, sightseeing, and cultural etiquette for your inaugural European adventure.\\',\\n    rank: 0.2735672,\\n    rankCd: 1.8\\n  },\\n  {\\n    id: 6,\\n    title: \\'Discovering Hidden Culinary Gems in Italy\\',\\n    description: \"Unearth Italy\\'s lesser-known eateries and food markets that offer authentic and traditional flavors.\",\\n    rank: 0.16717994,\\n    rankCd: 1.4\\n  },\\n  {\\n    id: 2,\\n    title: \"Cultural Insights: Exploring Asia\\'s Heritage\",\\n    description: \\'Dive deep into the rich history and traditions of Asia through immersive experiences and local interactions.\\',\\n    rank: 0.15198177,\\n    rankCd: 1\\n  },\\n  {\\n    id: 5,\\n    title: \\'Trip Planning: Choosing Your Next Destination\\',\\n    description: \\'Learn how to select destinations that align with your travel goals, whether for leisure, adventure, or cultural exploration.\\',\\n    rank: 0.12158542,\\n    rankCd: 0.8\\n  }\\n]\\n```\\n</Section>\\n\\nThe `ts_rank` function focuses on the frequency of query terms throughout the document. The `ts_rank_cd` function focuses on the proximity of query terms within the document.\\n', children=[]), DocItem(origPath=Path('guides/postgresql-local-setup.mdx'), name='postgresql-local-setup.mdx', displayName='postgresql-local-setup.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: How to setup PostgreSQL locally\\nslug: postgresql-local-setup\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n<Prerequisites>\\n- Install latest [Docker Desktop](https://www.docker.com/products/docker-desktop/). Follow the instructions for your operating system.\\n</Prerequisites>\\n\\n<Steps>\\n\\n#### Pull the PostgreSQL image\\n\\nPull the latest PostgreSQL image from Docker Hub. In your terminal, run `docker pull postgres` to pull the latest Postgres version from Docker Hub:\\n\\n```bash copy\\ndocker pull postgres\\n```\\n\\nAlternatively, you can pull preferred version with a specific tag:\\n\\n```bash copy\\ndocker pull postgres:15\\n```\\n\\nWhen postgres image is downloaded, you can check it in `Images` tab in Docker Desktop or by running `docker images`:\\n\\n<Section>\\n```bash copy\\ndocker images\\n```\\n\\n```plaintext\\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\\npostgres     latest    75282fa229a1   6 weeks ago     453MB\\n```\\n</Section>\\n\\n#### Start a Postgres instance\\n\\nTo start a new PostgreSQL container, run the following command:\\n\\n```bash copy\\ndocker run --name drizzle-postgres -e POSTGRES_PASSWORD=mypassword -d -p 5432:5432 postgres\\n```\\n\\n1. The `--name` option assigns the container the name `drizzle-postgres`.\\n2. The `-e POSTGRES_PASSWORD=` option sets the `POSTGRES_PASSWORD` environment variable with the specified value.\\n3. The `-d` flag runs the container in detached mode (in the background).\\n4. The `-p` option maps port `5432` on the container to port `5432` on your host machine, allowing PostgreSQL to be accessed from your host system through this port.\\n5. The `postgres` argument specifies the image to use for the container. You can also specify other versions like `postgres:15`.\\n\\nYou can also specify other parameters like:\\n\\n1. The `-e POSTGRES_USER=` option sets the `POSTGRES_USER` environment variable with the specified value. Postgres uses the default user when this is empty. Most of the time, it is `postgres` and you can check it in the container logs in Docker Desktop or by running `docker logs <container_name>`.\\n2. The `-e POSTGRES_DB=` option sets the `POSTGRES_DB` environment variable with the specified value. Defaults to the `POSTGRES_USER` value when is empty.\\n\\nTo check if the container is running, check `Containers` tab in Docker Desktop or use the `docker ps` command:\\n\\n```plaintext\\nCONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS         PORTS                    NAMES\\ndf957c58a6a3   postgres   \"docker-entrypoint.sâ€¦\"   4 seconds ago   Up 3 seconds   0.0.0.0:5432->5432/tcp   drizzle-postgres\\n```\\n\\n#### Configure database url\\n\\nTo connect to the PostgreSQL database, you need to provide the database URL. The URL format is:\\n\\n```plaintext\\npostgres://<user>:<password>@<host>:<port>/<database>\\n```\\n\\nYou should replace placeholders with your actual values. For example, for created container the url will be:\\n\\n```plaintext\\npostgres://postgres:mypassword@localhost:5432/postgres\\n```\\n\\nNow you can connect to the database using the URL in your application.\\n</Steps>\\n', children=[]), DocItem(origPath=Path('guides/seeding-using-with-option.mdx'), name='seeding-using-with-option.mdx', displayName='seeding-using-with-option.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Seeding using \\'with\\' option\\nslug: seeding-using-with-option\\n---\\n\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) or [SQLite](/docs/get-started-sqlite)\\n- Get familiar with [One-to-many Relation](/docs/relations#one-to-many)\\n- Get familiar with [Drizzle Seed](/docs/seed-overview)\\n</Prerequisites>\\n\\n<Callout title=\\'Warning\\'>\\nUsing `with` implies tables to have a one-to-many relationship.\\n\\nTherefore, if `one` user has `many` posts, you can use `with` as follows:\\n```ts\\nusers: {\\n    count: 2,\\n    with: {\\n        posts: 3,\\n    },\\n},\\n```\\n</Callout>\\n\\n## Example 1\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts\\nimport { users, posts } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users, posts }).refine(() => ({\\n        users: {\\n            count: 2,\\n            with: {\\n                posts: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n\\n<CodeTab>\\n```ts\\nimport { serial, pgTable, integer, text } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\').notNull(),\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\nRunning the seeding script above will cause an error.\\n\\n```\\nError: \"posts\" table doesn\\'t have a reference to \"users\" table or\\nyou didn\\'t include your one-to-many relation in the seed function schema.\\nYou can\\'t specify \"posts\" as parameter in users.with object.\\n```\\n\\nYou will have several options to resolve an error:\\n- You can add reference to the `authorId` column in `posts` table in your schema\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n<Section>\\n```ts\\nimport { users, posts } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users, posts }).refine(() => ({\\n        users: {\\n            count: 2,\\n            with: {\\n                posts: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n// Running the seeding script above will fill you database with values shown below\\n```\\n\\n```mdx\\n`users`\\n\\n| id |   name   |   \\n| -- | -------- |\\n|  1 | \\'Melanny\\' | \\n|  2 | \\'Elvera\\' |\\n\\n`posts`\\n\\n| id |        content        | author_id |   \\n| -- | --------------------- | --------- |\\n|  1 | \\'tf02gUXb0LZIdEg6SL\\'  |     2     |\\n|  2 | \\'j15YdT7Sma\\'          |     2     |\\n|  3 | \\'LwwvWtLLAZzIpk\\'      |     1     |\\n|  4 | \\'mgyUnBKSrQw\\'         |     1     |\\n|  5 | \\'CjAJByKIqilHcPjkvEw\\' |     2     |\\n|  6 | \\'S5g0NzXs\\'            |     1     |\\n```\\n</Section>\\n</CodeTab>\\n<CodeTab>\\n```ts copy{11}\\nimport { serial, pgTable, integer, text } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\').notNull().references(() => users.id),\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n- You can add one-to-many relation to your schema and include it in the seed function schema\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n<Section>\\n```ts copy{1,5}\\nimport { users, posts, postsRelations } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users, posts, postsRelations }).refine(() => ({\\n        users: {\\n            count: 2,\\n            with: {\\n                posts: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n// Running the seeding script above will fill you database with values shown below\\n```\\n\\n```mdx\\n`users`\\n\\n| id |   name   |   \\n| -- | -------- |\\n|  1 | \\'Melanny\\' | \\n|  2 | \\'Elvera\\' |\\n\\n`posts`\\n\\n| id |        content        | author_id |   \\n| -- | --------------------- | --------- |\\n|  1 | \\'tf02gUXb0LZIdEg6SL\\'  |     2     |\\n|  2 | \\'j15YdT7Sma\\'          |     2     |\\n|  3 | \\'LwwvWtLLAZzIpk\\'      |     1     |\\n|  4 | \\'mgyUnBKSrQw\\'         |     1     |\\n|  5 | \\'CjAJByKIqilHcPjkvEw\\' |     2     |\\n|  6 | \\'S5g0NzXs\\'            |     1     |\\n```\\n</Section>\\n</CodeTab>\\n\\n<CodeTab>\\n```ts copy{2,15-20}\\nimport { serial, pgTable, integer, text } from \"drizzle-orm/pg-core\";\\nimport { relations } from \"drizzle-orm\";\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\').notNull(),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one }) => ({\\n\\tauthor: one(users, {\\n\\t\\tfields: [posts.authorId],\\n\\t\\treferences: [users.id],\\n\\t}),\\n}));\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n\\n## Example 2\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts\\nimport { users, posts } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users, posts }).refine(() => ({\\n        posts: {\\n            count: 2,\\n            with: {\\n                users: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n\\n<CodeTab>\\n```ts\\nimport { serial, pgTable, integer, text } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\').notNull().references(() => users.id),\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\nRunning the seeding script above will cause an error.\\n\\n```\\nError: \"posts\" table doesn\\'t have a reference to \"users\" table or\\nyou didn\\'t include your one-to-many relation in the seed function schema.\\nYou can\\'t specify \"posts\" as parameter in users.with object.\\n```\\n\\n<Callout title=\\'Why?\\'>\\nYou have a `posts` table referencing a `users` table in your schema, \\n```ts copy{7}\\n.\\n.\\n.\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\').notNull().references(() => users.id),\\n});\\n```\\nor in other words, you have one-to-many relation where `one` user can have `many` posts.\\n\\nHowever, in your seeding script, you\\'re attempting to generate 3 (`many`) users for `one` post.\\n```ts\\nposts: {\\n    count: 2,\\n    with: {\\n        users: 3,\\n    },\\n},\\n```\\n</Callout>\\n\\nTo resolve the error, you can modify your seeding script as follows:\\n<Section>\\n```ts copy{6-9}\\nimport { users, posts, postsRelations } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users, posts, postsRelations }).refine(() => ({\\n        users: {\\n            count: 2,\\n            with: {\\n                posts: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n// Running the seeding script above will fill you database with values shown below\\n```\\n\\n```mdx\\n`users`\\n\\n| id |   name   |   \\n| -- | -------- |\\n|  1 | \\'Melanny\\' | \\n|  2 | \\'Elvera\\' |\\n\\n`posts`\\n\\n| id |        content        | author_id |   \\n| -- | --------------------- | --------- |\\n|  1 | \\'tf02gUXb0LZIdEg6SL\\'  |     2     |\\n|  2 | \\'j15YdT7Sma\\'          |     2     |\\n|  3 | \\'LwwvWtLLAZzIpk\\'      |     1     |\\n|  4 | \\'mgyUnBKSrQw\\'         |     1     |\\n|  5 | \\'CjAJByKIqilHcPjkvEw\\' |     2     |\\n|  6 | \\'S5g0NzXs\\'            |     1     |\\n```\\n</Section>\\n\\n## Example 3\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts copy{6-9}\\nimport { users } from \\'./schema.ts\\';\\n\\nasync function main() {\\n    const db = drizzle(...);\\n    await seed(db, { users }).refine(() => ({\\n        users: {\\n            count: 2,\\n            with: {\\n                users: 3,\\n            },\\n        },\\n    }));\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n\\n<CodeTab>\\n```ts\\nimport { serial, pgTable, integer, text } from \"drizzle-orm/pg-core\";\\nimport type { AnyPgColumn } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n    reportsTo: integer(\\'reports_to\\').references((): AnyPgColumn => users.id),\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\nRunning the seeding script above will cause an error.\\n\\n```\\nError: \"users\" table has self reference.\\nYou can\\'t specify \"users\" as parameter in users.with object.\\n```\\n\\n<Callout title=\\'Why?\\'>\\nYou have a `users` table referencing a `users` table in your schema, \\n```ts copy{7}\\n.\\n.\\n.\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n    reportsTo: integer(\\'reports_to\\').references((): AnyPgColumn => users.id),\\n});\\n```\\nor in other words, you have one-to-one relation where `one` user can have only `one` user.\\n\\nHowever, in your seeding script, you\\'re attempting to generate 3 (`many`) users for `one` user, which is impossible.\\n```ts\\nusers: {\\n    count: 2,\\n    with: {\\n        users: 3,\\n    },\\n},\\n```\\n</Callout>', children=[]), DocItem(origPath=Path('guides/seeding-with-partially-exposed-schema.mdx'), name='seeding-with-partially-exposed-schema.mdx', displayName='seeding-with-partially-exposed-schema.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Seeding Partially Exposed Tables with Foreign Key\\nslug: seeding-with-partially-exposed-tables\\n---\\n\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) or [SQLite](/docs/get-started-sqlite)\\n- Get familiar with [Drizzle Seed](/docs/seed-overview)\\n</Prerequisites>\\n\\n## Example 1\\nLet\\'s assume you are trying to seed your database using the seeding script and schema shown below.\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts\\nimport { bloodPressure } from \\'./schema.ts\\';\\n\\nasync function main() {\\n  const db = drizzle(...);\\n  await seed(db, { bloodPressure });\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n\\n<CodeTab>\\n```ts copy {10}\\nimport { serial, pgTable, integer, doublePrecision } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\"users\", {\\n    id: serial(\"id\").primaryKey(),\\n});\\n\\nexport const bloodPressure = pgTable(\"bloodPressure\", {\\n\\tbloodPressureId: serial().primaryKey(),\\n\\tpressure: doublePrecision(),\\n\\tuserId: integer().references(() => users.id).notNull(),\\n})\\n```\\n</CodeTab>\\n</CodeTabs>\\nIf the `bloodPressure` table has a not-null constraint on the `userId` column, running the seeding script will cause an error.\\n\\n```\\nError: Column \\'userId\\' has not null constraint, \\nand you didn\\'t specify a table for foreign key on column \\'userId\\' in \\'bloodPressure\\' table.\\n```\\n\\n<Callout title=\\'What does it mean?\\'>\\nThis means we can\\'t fill the `userId` column with Null values due to the not-null constraint on that column. \\nAdditionally, you didn\\'t expose the `users` table to the `seed` function schema, so we can\\'t generate `users.id` to populate the `userId` column with these values.\\n</Callout>\\n\\n\\nAt this point, you have several options to resolve the error:\\n- You can remove the not-null constraint from the `userId` column;\\n- You can expose `users` table to `seed` function schema\\n```ts \\nawait seed(db, { bloodPressure, users });\\n```\\n- You can [refine](/docs/guides/seeding-with-partially-exposed-tables#refining-the-userid-column-generator) the `userId` column generator;\\n\\n## Example 2\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts\\nimport { bloodPressure } from \\'./schema.ts\\';\\n\\nasync function main() {\\n  const db = drizzle(...);\\n  await seed(db, { bloodPressure });\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n\\n<CodeTab>\\n```ts copy {10}\\nimport { serial, pgTable, integer, doublePrecision } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\"users\", {\\n    id: serial(\"id\").primaryKey(),\\n});\\n\\nexport const bloodPressure = pgTable(\"bloodPressure\", {\\n\\tbloodPressureId: serial().primaryKey(),\\n\\tpressure: doublePrecision(),\\n\\tuserId: integer().references(() => users.id),\\n})\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\nBy running the seeding script above you will see a warning\\n```\\nColumn \\'userId\\' in \\'bloodPressure\\' table will be filled with Null values\\nbecause you specified neither a table for foreign key on column \\'userId\\' \\nnor a function for \\'userId\\' column in refinements.\\n```\\n<Callout title=\\'What does it mean?\\'>\\nThis means you neither provided the `users` table to the `seed` function schema nor refined the `userId` column generator. \\nAs a result, the `userId` column will be filled with Null values.\\n</Callout>\\nThen you will have two choices:\\n- If you\\'re okay with filling the `userId` column with Null values, you can ignore the warning;\\n\\n- Otherwise, you can [refine](/docs/guides/seeding-with-partially-exposed-tables#refining-the-userid-column-generator) the `userId` column generator. \\n\\n## Refining the `userId` column generator\\nDoing so requires the `users` table to already have IDs such as 1 and 2 in the database.\\n<CodeTabs items={[\"index.ts\"]}>\\n<CodeTab>\\n```ts copy {8}\\nimport { bloodPressure } from \\'./schema.ts\\';\\n\\nasync function main() {\\n  const db = drizzle(...);\\n  await seed(db, { bloodPressure }).refine((funcs) => ({\\n    bloodPressure: {\\n      columns: {\\n        userId: funcs.valuesFromArray({ values: [1, 2] })\\n      }\\n    }\\n  }));\\n}\\nmain();\\n\\n```\\n</CodeTab>\\n</CodeTabs>', children=[]), DocItem(origPath=Path('guides/select-parent-rows-with-at-least-one-related-child-row.mdx'), name='select-parent-rows-with-at-least-one-related-child-row.mdx', displayName='select-parent-rows-with-at-least-one-related-child-row.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Select parent rows with at least one related child row\\nslug: select-parent-rows-with-at-least-one-related-child-row\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Select statement](/docs/select) and [select from subquery](/docs/select#select-from-subquery)\\n- [Inner join](/docs/joins#inner-join)\\n- [Filter operators](/docs/operators) and [exists function](/docs/operators#exists)\\n</Prerequisites>\\n\\nThis guide demonstrates how to select parent rows with the condition of having at least one related child row. Below, there are examples of schema definitions and the corresponding database data:\\n\\n  ```ts copy\\n  import { integer, pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n    email: text(\\'email\\').notNull(),\\n  });\\n\\n  export const posts = pgTable(\\'posts\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    content: text(\\'content\\').notNull(),\\n    userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n  });\\n  ```\\n\\n<CodeTabs items={[\"users.db\", \"posts.db\"]}>\\n  <CodeTab>\\n    ```plaintext\\n    +----+------------+----------------------+\\n    | id |    name    |        email         |\\n    +----+------------+----------------------+\\n    |  1 | John Doe   | john_doe@email.com   |\\n    +----+------------+----------------------+\\n    |  2 | Tom Brown  | tom_brown@email.com  |\\n    +----+------------+----------------------+\\n    |  3 | Nick Smith | nick_smith@email.com |\\n    +----+------------+----------------------+\\n    ```\\n  </CodeTab>\\n\\n  <CodeTab>\\n    ```plaintext\\n    +----+--------+-----------------------------+---------+\\n    | id | title  |          content            | user_id |\\n    +----+--------+-----------------------------+---------+\\n    |  1 | Post 1 | This is the text of post 1  |       1 |\\n    +----+--------+-----------------------------+---------+\\n    |  2 | Post 2 | This is the text of post 2  |       1 |\\n    +----+--------+-----------------------------+---------+\\n    |  3 | Post 3 | This is the text of post 3  |       3 |\\n    +----+--------+-----------------------------+---------+\\n    ```\\n  </CodeTab>\\n</CodeTabs>\\n\\nTo select parent rows with at least one related child row and retrieve child data you can use `.innerJoin()` method:\\n\\n<Section>\\n  ```ts copy {12}\\n  import { eq } from \\'drizzle-orm\\';\\n  import { users, posts } from \\'./schema\\';\\n\\n  const db = drizzle(...);\\n\\n  await db\\n    .select({\\n      user: users,\\n      post: posts,\\n    })\\n    .from(users)\\n    .innerJoin(posts, eq(users.id, posts.userId));\\n    .orderBy(users.id);\\n  ```\\n\\n  ```sql\\n  select users.*, posts.* from users\\n    inner join posts on users.id = posts.user_id\\n    order by users.id;\\n  ```\\n\\n  ```ts\\n  // result data, there is no user with id 2 because he has no posts\\n  [\\n    {\\n      user: { id: 1, name: \\'John Doe\\', email: \\'john_doe@email.com\\' },\\n      post: {\\n        id: 1,\\n        title: \\'Post 1\\',\\n        content: \\'This is the text of post 1\\',\\n        userId: 1\\n      }\\n    },\\n    {\\n      user: { id: 1, name: \\'John Doe\\', email: \\'john_doe@email.com\\' },\\n      post: {\\n        id: 2,\\n        title: \\'Post 2\\',\\n        content: \\'This is the text of post 2\\',\\n        userId: 1\\n      }\\n    },\\n    {\\n      user: { id: 3, name: \\'Nick Smith\\', email: \\'nick_smith@email.com\\' },\\n      post: {\\n        id: 3,\\n        title: \\'Post 3\\',\\n        content: \\'This is the text of post 3\\',\\n        userId: 3\\n      }\\n    }\\n  ]\\n  ```\\n</Section>\\n\\nTo only select parent rows with at least one related child row you can use subquery with `exists()` function like this:\\n\\n<Section>\\n```ts copy {8}\\nimport { eq, exists, sql } from \\'drizzle-orm\\';\\n\\nconst sq = db\\n  .select({ id: sql`1` })\\n  .from(posts)\\n  .where(eq(posts.userId, users.id));\\n\\nawait db.select().from(users).where(exists(sq));\\n```\\n\\n```sql\\nselect * from users where exists (select 1 from posts where posts.user_id = users.id);\\n```\\n\\n```ts\\n// result data, there is no user with id 2 because he has no posts\\n[\\n  { id: 1, name: \\'John Doe\\', email: \\'john_doe@email.com\\' },\\n  { id: 3, name: \\'Nick Smith\\', email: \\'nick_smith@email.com\\' }\\n]\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/timestamp-default-value.mdx'), name='timestamp-default-value.mdx', displayName='timestamp-default-value.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Timestamp as a default value\\nslug: timestamp-default-value\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- Learn about column data types for [PostgreSQL](/docs/column-types/pg), [MySQL](/docs/column-types/mysql) and [SQLite](/docs/column-types/sqlite)\\n- [sql operator](/docs/sql)\\n</Prerequisites>\\n\\n### PostgreSQL\\n\\nTo set current timestamp as a default value in PostgreSQL, you can use the `defaultNow()` method or `sql` operator with `now()` function which returns the current date and time with the time zone:\\n\\n<Section>\\n```ts copy {6,9}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { timestamp, pgTable, serial } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  timestamp1: timestamp(\\'timestamp1\\').notNull().defaultNow(),\\n  timestamp2: timestamp(\\'timestamp2\\', { mode: \\'string\\' })\\n    .notNull()\\n    .default(sql`now()`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"users\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"timestamp1\" timestamp DEFAULT now() NOT NULL,\\n\\t\"timestamp2\" timestamp DEFAULT now() NOT NULL\\n);\\n```\\n</Section>\\n\\nThe `mode` option defines how values are handled in the application. Values with `string` mode are treated as `string` in the application, but stored as timestamps in the database.\\n\\n<Section>\\n```plaintext\\n// Data stored in the database\\n+----+----------------------------+----------------------------+\\n| id |         timestamp1         |         timestamp2         |\\n+----+----------------------------+----------------------------+\\n| 1  | 2024-04-11 14:14:28.038697 | 2024-04-11 14:14:28.038697 |\\n+----+----------------------------+----------------------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[\\n  {\\n    id: 1,\\n    timestamp1: 2024-04-11T14:14:28.038Z, // Date object\\n    timestamp2: \\'2024-04-11 14:14:28.038697\\' // string\\n  }\\n]\\n```\\n</Section>\\n\\nTo set unix timestamp as a default value in PostgreSQL, you can use the `sql` operator and `extract(epoch from now())` function which returns the number of seconds since `1970-01-01 00:00:00 UTC`:\\n\\n<Section>\\n```ts copy {8}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, pgTable, serial } from \\'drizzle-orm/pg-core\\'\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  timestamp: integer(\\'timestamp\\')\\n    .notNull()\\n    .default(sql`extract(epoch from now())`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"users\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"timestamp\" integer DEFAULT extract(epoch from now()) NOT NULL\\n);\\n```\\n\\n```plaintext\\n// Data stored in the database\\n+----+------------+\\n| id | timestamp  |\\n+----+------------+\\n|  1 | 1712846784 |\\n+----+------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[ \\n  { \\n    id: 1, \\n    timestamp: 1712846784 // number\\n  } \\n]\\n```\\n</Section>\\n\\n\\n### MySQL\\n\\nTo set current timestamp as a default value in MySQL, you can use the `defaultNow()` method or `sql` operator with `now()` function which returns the current date and time `(YYYY-MM-DD HH-MM-SS)`:\\n\\n<Section>\\n```ts copy {6,9,12}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { mysqlTable, serial, timestamp } from \\'drizzle-orm/mysql-core\\';\\n\\nexport const users = mysqlTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  timestamp1: timestamp(\\'timestamp1\\').notNull().defaultNow(),\\n  timestamp2: timestamp(\\'timestamp2\\', { mode: \\'string\\' })\\n    .notNull()\\n    .default(sql`now()`),\\n  timestamp3: timestamp(\\'timestamp3\\', { fsp: 3 }) // fractional seconds part\\n    .notNull()\\n    .default(sql`now(3)`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` serial AUTO_INCREMENT NOT NULL,\\n\\t`timestamp1` timestamp NOT NULL DEFAULT now(),\\n\\t`timestamp2` timestamp NOT NULL DEFAULT now(),\\n\\t`timestamp3` timestamp(3) NOT NULL DEFAULT now(3),\\n\\tCONSTRAINT `users_id` PRIMARY KEY(`id`)\\n);\\n```\\n</Section>\\n\\n`fsp` option defines the number of fractional seconds to include in the timestamp. The default value is `0`.\\nThe `mode` option defines how values are handled in the application. Values with `string` mode are treated as `string` in the application, but stored as timestamps in the database.\\n\\n<Section>\\n```plaintext\\n// Data stored in the database\\n+----+---------------------+---------------------+-------------------------+\\n| id | timestamp1          | timestamp2          | timestamp3              |\\n+----+---------------------+---------------------+-------------------------+\\n|  1 | 2024-04-11 15:24:53 | 2024-04-11 15:24:53 | 2024-04-11 15:24:53.236 |\\n+----+---------------------+---------------------+-------------------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[\\n  {\\n    id: 1,\\n    timestamp1: 2024-04-11T15:24:53.000Z, // Date object\\n    timestamp2: \\'2024-04-11 15:24:53\\', // string\\n    timestamp3: 2024-04-11T15:24:53.236Z // Date object\\n  }\\n]\\n```\\n</Section>\\n\\nTo set unix timestamp as a default value in MySQL, you can use the `sql` operator and `unix_timestamp()` function which returns the number of seconds since `1970-01-01 00:00:00 UTC`:\\n\\n<Section>\\n```ts copy {8}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { mysqlTable, serial, int } from \\'drizzle-orm/mysql-core\\';\\n\\nexport const users = mysqlTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  timestamp: int(\\'timestamp\\')\\n    .notNull()\\n    .default(sql`(unix_timestamp())`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` serial AUTO_INCREMENT NOT NULL,\\n\\t`timestamp` int NOT NULL DEFAULT (unix_timestamp()),\\n\\tCONSTRAINT `users_id` PRIMARY KEY(`id`)\\n);\\n```\\n\\n```plaintext\\n// Data stored in the database\\n+----+------------+\\n| id | timestamp  |\\n+----+------------+\\n|  1 | 1712847986 |\\n+----+------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[ \\n  { \\n    id: 1, \\n    timestamp: 1712847986 // number\\n  } \\n]\\n```\\n</Section>\\n\\n### SQLite\\n\\nTo set current timestamp as a default value in SQLite, you can use `sql` operator with `current_timestamp` constant which returns text representation of the current UTC date and time `(YYYY-MM-DD HH:MM:SS)`:\\n\\n<Section>\\n```ts copy {8}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\n\\nexport const users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  timestamp: text(\\'timestamp\\')\\n    .notNull()\\n    .default(sql`(current_timestamp)`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`timestamp` text DEFAULT (current_timestamp) NOT NULL\\n);\\n```\\n\\n```plaintext\\n// Data stored in the database\\n+----+---------------------+\\n| id | timestamp           |\\n+----+---------------------+\\n|  1 | 2024-04-11 15:40:43 |\\n+----+---------------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[\\n  {\\n    id: 1,\\n    timestamp: \\'2024-04-11 15:40:43\\' // string\\n  }\\n]\\n```\\n</Section>\\n\\nTo set unix timestamp as a default value in SQLite, you can use the `sql` operator and `unixepoch()` function which returns the number of seconds since `1970-01-01 00:00:00 UTC`:\\n\\n<Section>\\n```ts copy {8,11,14}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, sqliteTable } from \\'drizzle-orm/sqlite-core\\';\\n\\nexport const users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  timestamp1: integer(\\'timestamp1\\', { mode: \\'timestamp\\' })\\n    .notNull()\\n    .default(sql`(unixepoch())`),\\n  timestamp2: integer(\\'timestamp2\\', { mode: \\'timestamp_ms\\' })\\n    .notNull()\\n    .default(sql`(unixepoch() * 1000)`),\\n  timestamp3: integer(\\'timestamp3\\', { mode: \\'number\\' })\\n    .notNull()\\n    .default(sql`(unixepoch())`),\\n});\\n```\\n\\n```sql\\nCREATE TABLE `users` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`timestamp1` integer DEFAULT (unixepoch()) NOT NULL,\\n\\t`timestamp2` integer DEFAULT (unixepoch() * 1000) NOT NULL,\\n\\t`timestamp3` integer DEFAULT (unixepoch()) NOT NULL\\n);\\n```\\n</Section>\\n\\nThe `mode` option defines how values are handled in the application. In the application, values with `timestamp` and `timestamp_ms` modes are treated as `Date` objects, but stored as integers in the database.\\nThe difference is that `timestamp` handles seconds, while `timestamp_ms` handles milliseconds.\\n\\n<Section>\\n```plaintext\\n// Data stored in the database\\n+------------+------------+---------------+------------+\\n| id         | timestamp1 | timestamp2    | timestamp3 |\\n+------------+------------+---------------+------------+\\n| 1          | 1712835640 | 1712835640000 | 1712835640 |\\n+------------+------------+---------------+------------+\\n```\\n\\n```ts\\n// Data returned by the application\\n[\\n  {\\n    id: 1,\\n    timestamp1: 2024-04-11T11:40:40.000Z, // Date object\\n    timestamp2: 2024-04-11T11:40:40.000Z, // Date object\\n    timestamp3: 1712835640 // number\\n  }\\n]\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/toggling-a-boolean-field.mdx'), name='toggling-a-boolean-field.mdx', displayName='toggling-a-boolean-field.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: SQL Toggle value\\nslug: toggling-a-boolean-field\\n---\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Update statement](/docs/update)\\n- [Filters](/docs/operators) and [not operator](/docs/operators#not)\\n- Boolean data type in [MySQL](/docs/column-types/mysql#boolean) and [SQLite](/docs/column-types/sqlite#boolean)\\n</Prerequisites>\\n\\nTo toggle a column value you can use `update().set()` method like below:\\n\\n<Section>\\n```tsx copy {8}\\nimport { eq, not } from \\'drizzle-orm\\';\\n\\nconst db = drizzle(...);\\n\\nawait db\\n  .update(table)\\n  .set({\\n    isActive: not(table.isActive),\\n  })\\n  .where(eq(table.id, 1));\\n```\\n\\n```sql\\nupdate \"table\" set \"is_active\" = not \"is_active\" where \"id\" = 1;\\n```\\n</Section>\\n\\nPlease note that there is no boolean type in MySQL and SQLite.\\nMySQL uses tinyint(1).\\nSQLite uses integers 0 (false) and 1 (true). \\n', children=[]), DocItem(origPath=Path('guides/unique-case-insensitive-email.mdx'), name='unique-case-insensitive-email.mdx', displayName='unique-case-insensitive-email.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Unique and Case-Insensitive Email Handling\\nslug: unique-case-insensitive-email\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Indexes](/docs/indexes-constraints#indexes)\\n- [Insert statement](/docs/insert) and [Select method](/docs/select)\\n- [sql operator](/docs/sql)\\n- You should have `drizzle-orm@0.31.0` and `drizzle-kit@0.22.0` or higher.\\n</Prerequisites>\\n\\n### PostgreSQL\\n\\nTo implement a unique and case-insensitive `email` handling in PostgreSQL with Drizzle, you can create a unique index on the lowercased `email` column. This way, you can ensure that the `email` is unique regardless of the case.\\n\\nDrizzle has simple and flexible API, which lets you easily create such an index using SQL-like syntax:\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {12,13}\\n  import { SQL, sql } from \\'drizzle-orm\\';\\n  import { AnyPgColumn, pgTable, serial, text, uniqueIndex } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\n    \\'users\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      name: text(\\'name\\').notNull(),\\n      email: text(\\'email\\').notNull(),\\n    },\\n    (table) => [\\n      // uniqueIndex(\\'emailUniqueIndex\\').on(sql`lower(${table.email})`),\\n      uniqueIndex(\\'emailUniqueIndex\\').on(lower(table.email)),\\n    ],\\n  );\\n\\n  // custom lower function\\n  export function lower(email: AnyPgColumn): SQL {\\n    return sql`lower(${email})`;\\n  }\\n  ```\\n  </CodeTab>\\n  ```sql\\n  CREATE TABLE IF NOT EXISTS \"users\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"email\" text NOT NULL\\n  );\\n  --> statement-breakpoint\\n  CREATE UNIQUE INDEX IF NOT EXISTS \"emailUniqueIndex\" ON \"users\" USING btree (lower(\"email\"));\\n  ```\\n</CodeTabs>\\n\\nThis is how you can select user by `email` with `lower` function:\\n\\n<Section>\\n```ts copy {10}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { lower, users } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst findUserByEmail = async (email: string) => {\\n  return await db\\n    .select()\\n    .from(users)\\n    .where(eq(lower(users.email), email.toLowerCase()));\\n};\\n```\\n\\n```sql\\nselect * from \"users\" where lower(email) = \\'john@email.com\\';\\n```\\n</Section>\\n\\n### MySQL\\n\\nIn MySQL, the default collation setting for string comparison is case-insensitive, which means that when performing operations like searching or comparing strings in SQL queries, the case of the characters does not affect the results. However, because collation settings can vary and may be configured to be case-sensitive, we will explicitly ensure that the `email` is unique regardless of case by creating a unique index on the lowercased `email` column.\\n\\nDrizzle has simple and flexible API, which lets you easily create such an index using SQL-like syntax:\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {12,13}\\n  import { SQL, sql } from \\'drizzle-orm\\';\\n  import { AnyMySqlColumn, mysqlTable, serial, uniqueIndex, varchar } from \\'drizzle-orm/mysql-core\\';\\n\\n  export const users = mysqlTable(\\n    \\'users\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      name: varchar(\\'name\\', { length: 255 }).notNull(),\\n      email: varchar(\\'email\\', { length: 255 }).notNull(),\\n    },\\n    (table) => [\\n      // uniqueIndex(\\'emailUniqueIndex\\').on(sql`(lower(${table.email}))`),\\n      uniqueIndex(\\'emailUniqueIndex\\').on(lower(table.email)),\\n    ]\\n  );\\n\\n  // custom lower function\\n  export function lower(email: AnyMySqlColumn): SQL {\\n    return sql`(lower(${email}))`;\\n  }\\n  ```\\n  </CodeTab>\\n  ```sql\\n  CREATE TABLE `users` (\\n\\t  `id` serial AUTO_INCREMENT NOT NULL,\\n\\t  `name` varchar(255) NOT NULL,\\n\\t  `email` varchar(255) NOT NULL,\\n\\t  CONSTRAINT `users_id` PRIMARY KEY(`id`),\\n\\t  CONSTRAINT `emailUniqueIndex` UNIQUE((lower(`email`)))\\n  );\\n  ```\\n</CodeTabs>\\n\\n<Callout type=\"warning\">\\nFunctional indexes are supported in MySQL starting from version `8.0.13`. For the correct syntax, the expression should be enclosed in parentheses, for example, `(lower(column))`.\\n</Callout>\\n\\nThis is how you can select user by `email` with `lower` function:\\n\\n<Section>\\n```ts copy {10}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { lower, users } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst findUserByEmail = async (email: string) => {\\n  return await db\\n    .select()\\n    .from(users)\\n    .where(eq(lower(users.email), email.toLowerCase()));\\n};\\n```\\n\\n```sql\\nselect * from `users` where lower(email) = \\'john@email.com\\';\\n```\\n</Section>\\n\\n### SQLite\\n\\nTo implement a unique and case-insensitive `email` handling in SQLite with Drizzle, you can create a unique index on the lowercased `email` column. This way, you can ensure that the `email` is unique regardless of the case.\\n\\nDrizzle has simple and flexible API, which lets you easily create such an index using SQL-like syntax:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {12,13}\\n  import { SQL, sql } from \\'drizzle-orm\\';\\n  import { AnySQLiteColumn, integer, sqliteTable, text, uniqueIndex } from \\'drizzle-orm/sqlite-core\\';\\n\\n  export const users = sqliteTable(\\n    \\'users\\',\\n    {\\n      id: integer(\\'id\\').primaryKey(),\\n      name: text(\\'name\\').notNull(),\\n      email: text(\\'email\\').notNull(),\\n    },\\n    (table) => [\\n      // uniqueIndex(\\'emailUniqueIndex\\').on(sql`lower(${table.email})`),\\n      uniqueIndex(\\'emailUniqueIndex\\').on(lower(table.email)),\\n    ]\\n  );\\n\\n  // custom lower function\\n  export function lower(email: AnySQLiteColumn): SQL {\\n    return sql`lower(${email})`;\\n  }\\n  ```\\n  </CodeTab>\\n  ```sql\\n  CREATE TABLE `users` (\\n\\t  `id` integer PRIMARY KEY NOT NULL,\\n\\t  `name` text NOT NULL,\\n\\t  `email` text NOT NULL\\n  );\\n  --> statement-breakpoint\\n  CREATE UNIQUE INDEX `emailUniqueIndex` ON `users` (lower(`email`));\\n  ```\\n</CodeTabs>\\n\\nThis is how you can select user by `email` with `lower` function:\\n\\n<Section>\\n```ts copy {10}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { lower, users } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst findUserByEmail = async (email: string) => {\\n  return await db\\n    .select()\\n    .from(users)\\n    .where(eq(lower(users.email), email.toLowerCase()));\\n};\\n```\\n\\n```sql\\nselect * from \"users\" where lower(email) = \\'john@email.com\\';\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/update-many-with-different-value.mdx'), name='update-many-with-different-value.mdx', displayName='update-many-with-different-value.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Update many with different values for each row\\nslug: update-many-with-different-value\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Update statement](/docs/update)\\n- [Filters](/docs/operators) and [sql operator](/docs/sql)\\n</Prerequisites>\\n\\nTo implement update many with different values for each row within 1 request you can use `sql` operator with `case` statement and `.update().set()` methods like this:\\n\\n<Section>\\n```ts {26, 29, 32, 36, 38, 40}\\nimport { SQL, inArray, sql } from \\'drizzle-orm\\';\\nimport { users } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst inputs = [\\n  {\\n    id: 1,\\n    city: \\'New York\\',\\n  },\\n  {\\n    id: 2,\\n    city: \\'Los Angeles\\',\\n  },\\n  {\\n    id: 3,\\n    city: \\'Chicago\\',\\n  },\\n];\\n\\n// You have to be sure that inputs array is not empty\\nif (inputs.length === 0) {\\n  return;\\n}\\n\\nconst sqlChunks: SQL[] = [];\\nconst ids: number[] = [];\\n\\nsqlChunks.push(sql`(case`);\\n\\nfor (const input of inputs) {\\n  sqlChunks.push(sql`when ${users.id} = ${input.id} then ${input.city}`);\\n  ids.push(input.id);\\n}\\n\\nsqlChunks.push(sql`end)`);\\n\\nconst finalSql: SQL = sql.join(sqlChunks, sql.raw(\\' \\'));\\n\\nawait db.update(users).set({ city: finalSql }).where(inArray(users.id, ids));\\n```\\n\\n```sql\\nupdate users set \"city\" = \\n  (case when id = 1 then \\'New York\\' when id = 2 then \\'Los Angeles\\' when id = 3 then \\'Chicago\\' end)\\nwhere id in (1, 2, 3)\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/upsert.mdx'), name='upsert.mdx', displayName='upsert.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Upsert Query\\nslug: upsert\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\n\\n<IsSupportedChipGroup chips={{PostgreSQL: true, MySQL: true, SQLite: true}}/>\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql), [MySQL](/docs/get-started-mysql) and [SQLite](/docs/get-started-sqlite)\\n- [Insert statement](/docs/insert), [onConflictDoUpdate method](/docs/insert#on-conflict-do-update) and [onDuplicateKeyUpdate method](/docs/insert#on-duplicate-key-update)\\n- [Composite primary key](/docs/indexes-constraints#composite-primary-key)\\n- [sql operator](/docs/sql)\\n</Prerequisites>\\n\\n### PostgreSQL and SQLite\\n\\nTo implement an upsert query in PostgreSQL and SQLite (skip to [MySQL](/docs/guides/upsert#mysql)) with Drizzle you can use `.onConflictDoUpdate()` method:\\n\\n<Section>\\n```ts copy {8,9,10,11}\\nimport { users } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nawait db\\n  .insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onConflictDoUpdate({\\n    target: users.id,\\n    set: { name: \\'Super John\\' },\\n  });\\n```\\n\\n```sql\\ninsert into users (\"id\", \"name\") values (1, \\'John\\')\\n  on conflict (\"id\") do update set name = \\'Super John\\';\\n```\\n</Section>\\n\\nTo upsert multiple rows in one query in PostgreSQL and SQLite you can use `sql operator` and `excluded` keyword. `excluded` is a special reference that refer to the row that was proposed for insertion, but wasn\\'t inserted because of the conflict.\\n\\nThis is how you can do it:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {21,24}\\n    import { sql } from \\'drizzle-orm\\';\\n    import { users } from \\'./schema\\';\\n\\n    const values = [\\n      {\\n        id: 1,\\n        lastLogin: new Date(),\\n      },\\n      {\\n        id: 2,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 60),\\n      },\\n      {\\n        id: 3,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 120),\\n      },\\n    ];\\n\\n    await db\\n      .insert(users)\\n      .values(values)\\n      .onConflictDoUpdate({\\n        target: users.id,\\n        set: { lastLogin: sql.raw(`excluded.${users.lastLogin.name}`) },\\n      });\\n    ```\\n\\n    ```sql\\n    insert into users (\"id\", \"last_login\") \\n      values \\n        (1, \\'2024-03-15T22:29:06.679Z\\'),\\n        (2, \\'2024-03-15T23:29:06.679Z\\'),\\n        (3, \\'2024-03-16T00:29:06.679Z\\')\\n      on conflict (\"id\") do update set last_login = excluded.last_login;\\n    ```\\n  </CodeTab>\\n  ```ts copy\\n  import { pgTable, serial, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    lastLogin: timestamp(\\'last_login\\', { mode: \\'date\\' }).notNull(),\\n  });\\n  ```\\n</CodeTabs>\\n\\nDrizzle has simple and flexible API, which lets you easily create custom solutions. This is how you do custom function for updating specific columns in multiple rows due to the conflict in PostgreSQL and SQLite:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {43,46}\\n    import { SQL, getTableColumns, sql } from \\'drizzle-orm\\';\\n    import { PgTable } from \\'drizzle-orm/pg-core\\';\\n    import { SQLiteTable } from \\'drizzle-orm/sqlite-core\\';\\n    import { users } from \\'./schema\\';\\n\\n    const buildConflictUpdateColumns = <\\n      T extends PgTable | SQLiteTable,\\n      Q extends keyof T[\\'_\\'][\\'columns\\']\\n    >(\\n      table: T,\\n      columns: Q[],\\n    ) => {\\n      const cls = getTableColumns(table);\\n\\n      return columns.reduce((acc, column) => {\\n        const colName = cls[column].name;\\n        acc[column] = sql.raw(`excluded.${colName}`);\\n\\n        return acc;\\n      }, {} as Record<Q, SQL>);\\n    };\\n\\n    const values = [\\n      {\\n        id: 1,\\n        lastLogin: new Date(),\\n        active: true,\\n      },\\n      {\\n        id: 2,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 60),\\n        active: true,\\n      },\\n      {\\n        id: 3,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 120),\\n        active: true,\\n      },\\n    ];\\n\\n    await db\\n      .insert(users)\\n      .values(values)\\n      .onConflictDoUpdate({\\n        target: users.id,\\n        set: buildConflictUpdateColumns(users, [\\'lastLogin\\', \\'active\\']),\\n      });\\n    ```\\n\\n    ```sql\\n    insert into users (\"id\", \"last_login\", \"active\")\\n    values\\n      (1, \\'2024-03-16T15:44:41.141Z\\', true),\\n      (2, \\'2024-03-16T16:44:41.141Z\\', true),\\n      (3, \\'2024-03-16T17:44:41.141Z\\', true)\\n    on conflict (\"id\") do update set last_login = excluded.last_login, active = excluded.active;\\n    ```\\n  </CodeTab>\\n  ```ts copy\\n  import { boolean, pgTable, serial, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const users = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    lastLogin: timestamp(\\'last_login\\', { mode: \\'date\\' }).notNull(),\\n    active: boolean(\\'active\\').notNull().default(false),\\n  });\\n  ```\\n</CodeTabs>\\n\\nThis is how you can implement an upsert query with multiple targets in PostgreSQL and SQLite:\\n\\n<Section>\\n```ts copy {8}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { inventory } from \\'./schema\\';\\n\\nawait db\\n  .insert(inventory)\\n  .values({ warehouseId: 1, productId: 1, quantity: 100 })\\n  .onConflictDoUpdate({\\n    target: [inventory.warehouseId, inventory.productId], // composite primary key\\n    set: { quantity: sql`${inventory.quantity} + 100` }, // add 100 to the existing quantity\\n  });\\n```\\n\\n```sql\\ninsert into inventory (\"warehouse_id\", \"product_id\", \"quantity\") values (1, 1, 100)\\n  on conflict (\"warehouse_id\",\"product_id\") do update set quantity = quantity + 100;\\n```\\n</Section>\\n\\nIf you want to implement upsert query with `where` clause for `update` statement, you can use `setWhere` property in `onConflictDoUpdate` method:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n  ```ts copy {25,26,27,28}\\n  import { or, sql } from \\'drizzle-orm\\';\\n  import { products } from \\'./schema\\';\\n\\n  const data = {\\n    id: 1,\\n    title: \\'Phone\\',\\n    price: \\'999.99\\',\\n    stock: 10,\\n    lastUpdated: new Date(),\\n  };\\n\\n  const excludedPrice = sql.raw(`excluded.${products.price.name}`);\\n  const excludedStock = sql.raw(`excluded.${products.stock.name}`);\\n\\n  await db\\n    .insert(products)\\n    .values(data)\\n    .onConflictDoUpdate({\\n      target: products.id,\\n      set: {\\n        price: excludedPrice,\\n        stock: excludedStock,\\n        lastUpdated: sql.raw(`excluded.${products.lastUpdated.name}`)\\n      },\\n      setWhere: or(\\n        sql`${products.stock} != ${excludedStock}`,\\n        sql`${products.price} != ${excludedPrice}`\\n      ),\\n    });\\n  ```\\n\\n  ```sql\\n  insert into products (\"id\", \"title\", \"stock\", \"price\", \"last_updated\")\\n    values (1, \\'Phone\\', 10, \\'999.99\\', \\'2024-04-29T21:56:55.563Z\\')\\n    on conflict (\"id\") do update\\n    set stock = excluded.stock, price = excluded.price, last_updated = excluded.last_updated\\n    where (stock != excluded.stock or price != excluded.price);\\n  ```\\n  </CodeTab>\\n\\n  ```ts copy\\n  import { integer, numeric, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n  export const products = pgTable(\\'products\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    title: text(\\'title\\').notNull(),\\n    stock: integer(\\'stock\\').notNull(),\\n    price: numeric(\\'price\\', { precision: 10, scale: 2 }).notNull(),\\n    lastUpdated: timestamp(\\'last_updated\\').notNull().defaultNow(),\\n  });\\n  ```\\n</CodeTabs>\\n\\n\\nIf you want to update all columns except of specific one, you can leave the previous value like this:\\n\\n<Section>\\n```ts copy {16}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { users } from \\'./schema\\';\\n\\nconst data = {\\n  id: 1,\\n  name: \\'John\\',\\n  email: \\'john@email.com\\',\\n  age: 29,\\n};\\n\\nawait db\\n  .insert(users)\\n  .values(data)\\n  .onConflictDoUpdate({\\n    target: users.id,\\n    set: { ...data, email: sql`${users.email}` }, // leave email as it was\\n});\\n```\\n\\n```sql\\ninsert into users (\"id\", \"name\", \"email\", \"age\") values (1, \\'John\\', \\'john@email.com\\', 29)\\n  on conflict (\"id\") do update set id = 1, name = \\'John\\', email = email, age = 29;\\n```\\n</Section>\\n\\n### MySQL\\n\\nTo implement an upsert query in MySQL with Drizzle you can use `.onDuplicateKeyUpdate()` method. MySQL will automatically determine the conflict target based on the primary key and unique indexes, and will update the row if any unique index conflicts.\\n\\nThis is how you can do it:\\n\\n<Section>\\n```ts copy {4}\\nawait db\\n  .insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onDuplicateKeyUpdate({ set: { name: \\'Super John\\' } });\\n```\\n\\n```sql\\ninsert into users (`id`, `first_name`) values (1, \\'John\\')\\n  on duplicate key update first_name = \\'Super John\\';\\n```\\n</Section>\\n\\nTo upsert multiple rows in one query in MySQL you can use `sql operator` and `values()` function. `values()` function refers to the value of column that would be inserted if duplicate-key conflict hadn\\'t occurred.  \\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {21,24}\\n    import { sql } from \\'drizzle-orm\\';\\n    import { users } from \\'./schema\\';\\n\\n    const values = [\\n      {\\n        id: 1,\\n        lastLogin: new Date(),\\n      },\\n      {\\n        id: 2,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 60),\\n      },\\n      {\\n        id: 3,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 120),\\n      },\\n    ];\\n\\n    await db\\n      .insert(users)\\n      .values(values)\\n      .onDuplicateKeyUpdate({\\n        set: {\\n          lastLogin: sql`values(${users.lastLogin})`,\\n        },\\n      });\\n    ```\\n\\n    ```sql\\n    insert into users (`id`, `last_login`)\\n      values\\n        (1, \\'2024-03-15 23:08:27.025\\'),\\n        (2, \\'2024-03-15 00:08:27.025\\'),\\n        (3, \\'2024-03-15 01:08:27.025\\')\\n      on duplicate key update last_login = values(last_login);\\n    ```\\n  </CodeTab>\\n  ```ts copy\\n  import { mysqlTable, serial, timestamp } from \\'drizzle-orm/mysql-core\\';\\n\\n  export const users = mysqlTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    lastLogin: timestamp(\\'last_login\\', { mode: \\'date\\' }).notNull(),\\n  });\\n  ```\\n</CodeTabs>\\n\\nDrizzle has simple and flexible API, which lets you easily create custom solutions. This is how you do custom function for updating specific columns in multiple rows due to the conflict in MySQL:\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n  <CodeTab>\\n    ```ts copy {36,38}\\n    import { SQL, getTableColumns, sql } from \\'drizzle-orm\\';\\n    import { MySqlTable } from \\'drizzle-orm/mysql-core\\';\\n    import { users } from \\'./schema\\';\\n\\n    const buildConflictUpdateColumns = <T extends MySqlTable, Q extends keyof T[\\'_\\'][\\'columns\\']>(\\n      table: T,\\n      columns: Q[],\\n    ) => {\\n      const cls = getTableColumns(table);\\n      return columns.reduce((acc, column) => {\\n        acc[column] = sql`values(${cls[column]})`;\\n        return acc;\\n      }, {} as Record<Q, SQL>);\\n    };\\n\\n    const values = [\\n      {\\n        id: 1,\\n        lastLogin: new Date(),\\n        active: true,\\n      },\\n      {\\n        id: 2,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 60),\\n        active: true,\\n      },\\n      {\\n        id: 3,\\n        lastLogin: new Date(Date.now() + 1000 * 60 * 120),\\n        active: true,\\n      },\\n    ];\\n\\n    await db\\n      .insert(users)\\n      .values(values)\\n      .onDuplicateKeyUpdate({\\n        set: buildConflictUpdateColumns(users, [\\'lastLogin\\', \\'active\\']),\\n      });\\n    ```\\n\\n    ```sql\\n    insert into users (`id`, `last_login`, `active`)\\n      values\\n        (1, \\'2024-03-16 15:23:28.013\\', true),\\n        (2, \\'2024-03-16 16:23:28.013\\', true),\\n        (3, \\'2024-03-16 17:23:28.013\\', true)\\n      on duplicate key update last_login = values(last_login), active = values(active);\\n    ```\\n  </CodeTab>\\n  ```ts copy\\n  import { boolean, mysqlTable, serial, timestamp } from \\'drizzle-orm/mysql-core\\';\\n\\n  export const users = mysqlTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    lastLogin: timestamp(\\'last_login\\', { mode: \\'date\\' }).notNull(),\\n    active: boolean(\\'active\\').notNull().default(false),\\n  });\\n  ```\\n</CodeTabs>\\n\\nIf you want to update all columns except of specific one, you can leave the previous value like this:\\n\\n<Section>\\n```ts copy {15}\\nimport { sql } from \\'drizzle-orm\\';\\nimport { users } from \\'./schema\\';\\n\\nconst data = {\\n  id: 1,\\n  name: \\'John\\',\\n  email: \\'john@email.com\\',\\n  age: 29,\\n};\\n\\nawait db\\n  .insert(users)\\n  .values(data)\\n  .onDuplicateKeyUpdate({\\n    set: { ...data, email: sql`${users.email}` }, // leave email as it was\\n});\\n```\\n\\n```sql\\ninsert into users (`id`, `name`, `email`, `age`) values (1, \\'John\\', \\'john@email.com\\', 29)\\n  on duplicate key update id = 1, name = \\'John\\', email = email, age = 29;\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('guides/vector-similarity-search.mdx'), name='vector-similarity-search.mdx', displayName='vector-similarity-search.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Vector similarity search with pgvector extension\\nslug:  vector-similarity-search\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Npm from \"@mdx/Npm.astro\";\\n\\n<Prerequisites>\\n- Get started with [PostgreSQL](/docs/get-started-postgresql)\\n- [Select statement](/docs/select)\\n- [Indexes](/docs/indexes-constraints#indexes)\\n- [sql operator](/docs/sql)\\n- [pgvector extension](/docs/extensions/pg#pg_vector)\\n- [Drizzle kit](/docs/kit-overview)\\n- You should have installed the `openai` [package](https://www.npmjs.com/package/openai) for generating embeddings. \\n<Npm>\\n  openai\\n</Npm>\\n- You should have `drizzle-orm@0.31.0` and `drizzle-kit@0.22.0` or higher.  \\n</Prerequisites>\\n\\nTo implement vector similarity search in PostgreSQL with Drizzle ORM, you can use the `pgvector` extension. This extension provides a set of functions to work with vectors and perform similarity search.\\n\\nAs for now, Drizzle doesn\\'t create extension automatically, so you need to create it manually. Create an empty migration file and add SQL query:\\n\\n<Section>\\n```bash\\nnpx drizzle-kit generate --custom\\n```\\n\\n```sql\\nCREATE EXTENSION vector;\\n```\\n</Section>\\n\\nTo perform similarity search, you need to create a table with a vector column and an `HNSW` or `IVFFlat` index on this column for better performance:\\n\\n<CodeTabs items={[\"schema.ts\", \"migration.sql\"]}>\\n  <CodeTab>\\n  ```ts copy {10, 13}\\n  import { index, pgTable, serial, text, vector } from \\'drizzle-orm/pg-core\\';\\n\\n  export const guides = pgTable(\\n    \\'guides\\',\\n    {\\n      id: serial(\\'id\\').primaryKey(),\\n      title: text(\\'title\\').notNull(),\\n      description: text(\\'description\\').notNull(),\\n      url: text(\\'url\\').notNull(),\\n      embedding: vector(\\'embedding\\', { dimensions: 1536 }),\\n    },\\n    (table) => [\\n      index(\\'embeddingIndex\\').using(\\'hnsw\\', table.embedding.op(\\'vector_cosine_ops\\')),\\n    ]\\n  );\\n  ```\\n  </CodeTab>\\n  ```sql\\n  CREATE TABLE IF NOT EXISTS \"guides\" (\\n    \"id\" serial PRIMARY KEY NOT NULL,\\n    \"title\" text NOT NULL,\\n    \"description\" text NOT NULL,\\n    \"url\" text NOT NULL,\\n    \"embedding\" vector(1536)\\n  );\\n  --> statement-breakpoint\\n  CREATE INDEX IF NOT EXISTS \"embeddingIndex\" ON \"guides\" USING hnsw (embedding vector_cosine_ops);\\n  ```\\n</CodeTabs>\\n\\nThe `embedding` column is used to store vector embeddings of the guide descriptions. Vector embedding is just a representation of some data. It converts different types of data into a common format (vectors) that language models can process. This allows us to perform mathematical operations, such as measuring the distance between two vectors, to determine how similar or different two data items are.\\n\\nIn this example we will use `OpenAI` model to generate [embeddings](https://platform.openai.com/docs/guides/embeddings) for the description:\\n```ts copy\\nimport OpenAI from \\'openai\\';\\n\\nconst openai = new OpenAI({\\n  apiKey: process.env[\\'OPENAI_API_KEY\\'],\\n});\\n\\nexport const generateEmbedding = async (value: string): Promise<number[]> => {\\n  const input = value.replaceAll(\\'\\\\n\\', \\' \\');\\n\\n  const { data } = await openai.embeddings.create({\\n    model: \\'text-embedding-ada-002\\',\\n    input,\\n  });\\n\\n  return data[0].embedding;\\n};\\n```\\n\\nTo search for similar guides by embedding, you can use `gt` and `sql` operators with `cosineDistance` function to calculate the similarity between the `embedding` column and the generated embedding:\\n\\n<Section>\\n```ts copy {10,15,16}\\nimport { cosineDistance, desc, gt, sql } from \\'drizzle-orm\\';\\nimport { generateEmbedding } from \\'./embedding\\';\\nimport { guides } from \\'./schema\\';\\n\\nconst db = drizzle(...);\\n\\nconst findSimilarGuides = async (description: string) => {\\n  const embedding = await generateEmbedding(description);\\n\\n  const similarity = sql<number>`1 - (${cosineDistance(guides.embedding, embedding)})`;\\n\\n  const similarGuides = await db\\n    .select({ name: guides.title, url: guides.url, similarity })\\n    .from(guides)\\n    .where(gt(similarity, 0.5))\\n    .orderBy((t) => desc(t.similarity))\\n    .limit(4);\\n\\n  return similarGuides;\\n};\\n```\\n\\n```ts\\nconst description = \\'Guides on using Drizzle ORM with different platforms\\';\\n\\nconst similarGuides = await findSimilarGuides(description);\\n```\\n\\n```json\\n[\\n  {\\n    name: \\'Drizzle with Turso\\',\\n    url: \\'/docs/tutorials/drizzle-with-turso\\',\\n    similarity: 0.8642314333984994\\n  },\\n  {\\n    name: \\'Drizzle with Supabase Database\\',\\n    url: \\'/docs/tutorials/drizzle-with-supabase\\',\\n    similarity: 0.8593631126014918\\n  },\\n  {\\n    name: \\'Drizzle with Neon Postgres\\',\\n    url: \\'/docs/tutorials/drizzle-with-neon\\',\\n    similarity: 0.8541051184461372\\n  },\\n  {\\n    name: \\'Drizzle with Vercel Edge Functions\\',\\n    url: \\'/docs/tutorials/drizzle-with-vercel-edge-functions\\',\\n    similarity: 0.8481551084241092\\n  }\\n]\\n```\\n</Section>\\n', children=[])]),\n",
       " DocItem(origPath=Path('guides.mdx'), name='guides.mdx', displayName='guides.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Guides from \"@components/Guides.astro\";\\n\\n<Guides/>', children=[]),\n",
       " DocItem(origPath=Path('indexes-constraints.mdx'), name='indexes-constraints.mdx', displayName='indexes-constraints.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# Indexes & Constraints\\n\\n## Constraints\\n\\nSQL constraints are the rules enforced on table columns. They are used to prevent invalid data from being entered into the database.\\n\\nThis ensures the accuracy and reliability of your data in the database.\\n\\n### Default\\n\\nThe `DEFAULT` clause specifies a default value to use for the column if no value provided by the user when doing an `INSERT`.\\nIf there is no explicit `DEFAULT` clause attached to a column definition,\\nthen the default value of the column is `NULL`.\\n\\nAn explicit `DEFAULT` clause may specify that the default value is `NULL`,\\na string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { integer, uuid, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    const table = pgTable(\\'table\\', {\\n      integer1: integer(\\'integer1\\').default(42),\\n      integer2: integer(\\'integer2\\').default(sql`\\'42\\'::integer`),\\n      uuid1: uuid(\\'uuid1\\').defaultRandom(),\\n      uuid2: uuid(\\'uuid2\\').default(sql`gen_random_uuid()`),\\n    });\\n    ```\\n\\n    ```sql\\n    CREATE TABLE IF NOT EXISTS \"table\" (\\n      \"integer1\" integer DEFAULT 42,\\n      \"integer2\" integer DEFAULT \\'42\\'::integer,\\n      \"uuid1\" uuid DEFAULT gen_random_uuid(),\\n      \"uuid2\" uuid DEFAULT gen_random_uuid()\\n    );\\n    ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { int, time, mysqlTable } from \"drizzle-orm/mysql-core\";\\n    \\n    const table = mysqlTable(\"table\", {\\n      int: int(\"int\").default(42),\\n      time: time(\"time\").default(sql`cast(\"14:06:10\" AS TIME)`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `table` (\\n      `int` int DEFAULT 42,\\n      `time` time DEFAULT cast(\"14:06:10\" AS TIME)\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n    const table = sqliteTable(\\'table\\', {\\n      int1: integer(\\'int1\\').default(42),\\n      int2: integer(\\'int2\\').default(sql`(abs(42))`)\\n    });\\n\\n    ```\\n    ```sql\\n    CREATE TABLE `table` (\\n      `int1` integer DEFAULT 42\\n      `int2` integer DEFAULT (abs(42))\\n    );\\n    ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { int, time, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n    \\n    const table = singlestoreTable(\"table\", {\\n      int: int(\"int\").default(42),\\n      time: time(\"time\").default(sql`cast(\"14:06:10\" AS TIME)`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `table` (\\n      `int` int DEFAULT 42,\\n      `time` time DEFAULT cast(\"14:06:10\" AS TIME)\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n\\n### Not null\\n\\nBy default, a column can hold **NULL** values. The `NOT NULL` constraint enforces a column to **NOT** accept **NULL** values.  \\n\\nThis enforces a field to always contain a value, which means that you cannot insert a new record,\\nor update a record without adding a value to this field.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n      ```typescript copy\\n      import { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\n      const table = pgTable(\\'table\\', {\\n        integer: integer(\\'integer\\').notNull(),\\n      });\\n      ```\\n\\n      ```sql\\n      CREATE TABLE IF NOT EXISTS \"table\" (\\n        \"integer\" integer NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n      const table = mysqlTable(\\'table\\', {\\n        int: int(\\'int\\').notNull(),\\n      });\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `table` (\\n        `int` int NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n   <Section>\\n      ```typescript copy\\n      const table = sqliteTable(\\'table\\', { \\n        numInt: integer(\\'numInt\\').notNull() \\n      });\\n      ```\\n\\n      ```sql\\n      CREATE TABLE table (\\n        `numInt` integer NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n    <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\n      const table = singlestoreTable(\\'table\\', {\\n        int: int(\\'int\\').notNull(),\\n      });\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `table` (\\n        `int` int NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n</Tabs>\\n\\n### Unique\\n\\nThe `UNIQUE` constraint ensures that all values in a column are different.  \\n\\nBoth the `UNIQUE` and `PRIMARY KEY` constraints provide a guarantee for uniqueness for a column or set of columns.\\n\\nA `PRIMARY KEY` constraint automatically has a `UNIQUE` constraint.  \\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n  You can have many `UNIQUE` constraints per table, but only one `PRIMARY KEY` constraint per table.\\n</Callout>\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n      ```typescript copy\\n      import { integer, text, unique, pgTable } from \"drizzle-orm/pg-core\";\\n\\n      export const user = pgTable(\\'user\\', {\\n        id: integer(\\'id\\').unique(),\\n      });\\n\\n      export const table = pgTable(\\'table\\', {\\n        id: integer(\\'id\\').unique(\\'custom_name\\'),\\n      });\\n\\n      export const composite = pgTable(\\'composite_example\\', {\\n        id: integer(\\'id\\'),\\n        name: text(\\'name\\'),\\n      }, (t) => [\\n        unique().on(t.id, t.name),\\n        unique(\\'custom_name\\').on(t.id, t.name)\\n      ]);\\n\\n      // In Postgres 15.0+ NULLS NOT DISTINCT is available\\n      // This example demonstrates both available usages\\n      export const userNulls = pgTable(\\'user_nulls_example\\', {\\n        id: integer(\\'id\\').unique(\"custom_name\", { nulls: \\'not distinct\\' }),\\n      }, (t) => [\\n        unique().on(t.id).nullsNotDistinct()\\n      ]);\\n      ```\\n\\n      ```sql\\n      CREATE TABLE IF NOT EXISTS \"composite_example\" (\\n\\t      \"id\" integer,\\n        \"name\" text,\\n        CONSTRAINT \"composite_example_id_name_unique\" UNIQUE(\"id\",\"name\"),\\n        CONSTRAINT \"custom_name\" UNIQUE(\"id\",\"name\")\\n      );\\n\\n      CREATE TABLE IF NOT EXISTS \"table\" (\\n      \\t\"id\" integer,\\n      \\tCONSTRAINT \"custom_name\" UNIQUE(\"id\")\\n      );\\n\\n      CREATE TABLE IF NOT EXISTS \"user\" (\\n      \\t\"id\" integer,\\n      \\tCONSTRAINT \"user_id_unique\" UNIQUE(\"id\")\\n      );\\n\\n      CREATE TABLE IF NOT EXISTS \"user_nulls_example\" (\\n        \"id\" integer,\\n        CONSTRAINT \"custom_name\" UNIQUE NULLS NOT DISTINCT(\"id\"),\\n        CONSTRAINT \"user_nulls_example_id_unique\" UNIQUE NULLS NOT DISTINCT(\"id\")\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, varchar, unique, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n      export const user = mysqlTable(\\'user\\', {\\n        id: int(\\'id\\').unique(),\\n      });\\n\\n      export const table = mysqlTable(\\'table\\', {\\n        id: int(\\'id\\').unique(\\'custom_name\\'),\\n      });\\n\\n      export const composite = mysqlTable(\\'composite_example\\', {\\n        id: int(\\'id\\'),\\n        name: varchar(\\'name\\', { length: 256 }),\\n      }, (t) => [\\n        unique().on(t.id, t.name),\\n        unique(\\'custom_name\\').on(t.id, t.name)\\n      ]);\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n      \\t`id` int,\\n      \\tCONSTRAINT `user_id_unique` UNIQUE(`id`)\\n      );\\n\\n      CREATE TABLE `table` (\\n      \\t`id` int,\\n      \\tCONSTRAINT `custom_name` UNIQUE(`id`)\\n      );\\n\\n      CREATE TABLE `composite_example` (\\n        `id` int,\\n        `name` varchar(256),\\n        CONSTRAINT `composite_example_id_name_unique` UNIQUE(`id`,`name`),\\n        CONSTRAINT `custom_name` UNIQUE(`id`,`name`)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n   <Section>\\n      ```typescript copy\\n      import { int, text, unique, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n      export const user = sqliteTable(\\'user\\', {\\n        id: int(\\'id\\').unique(),\\n      });\\n\\n      export const table = sqliteTable(\\'table\\', {\\n        id: int(\\'id\\').unique(\\'custom_name\\'),\\n      });\\n\\n      export const composite = sqliteTable(\\'composite_example\\', {\\n        id: int(\\'id\\'),\\n        name: text(\\'name\\'),\\n      }, (t) => [\\n        unique().on(t.id, t.name),\\n        unique(\\'custom_name\\').on(t.id, t.name)\\n      ]);\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n\\t      `id` integer\\n      );\\n\\n      CREATE TABLE `table` (\\n      \\t`id` integer\\n      );\\n\\n      CREATE TABLE `composite_example` (\\n      \\t`id` integer,\\n      \\t`name` text\\n      );\\n\\n      CREATE UNIQUE INDEX `composite_example_id_name_unique` ON `composite_example` (`id`,`name`);\\n      CREATE UNIQUE INDEX `custom_name` ON `composite_example` (`id`,`name`);\\n      CREATE UNIQUE INDEX `custom_name` ON `table` (`id`);\\n      CREATE UNIQUE INDEX `user_id_unique` ON `user` (`id`);\\n      ```\\n    </Section>\\n\\n  </Tab>\\n    <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, varchar, unique, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\n      export const user = singlestoreTable(\\'user\\', {\\n        id: int(\\'id\\').unique(),\\n      });\\n\\n      export const table = singlestoreTable(\\'table\\', {\\n        id: int(\\'id\\').unique(\\'custom_name\\'),\\n      });\\n\\n      export const composite = singlestoreTable(\\'composite_example\\', {\\n        id: int(\\'id\\'),\\n        name: varchar(\\'name\\', { length: 256 }),\\n      }, (t) => [\\n        unique().on(t.id, t.name),\\n        unique(\\'custom_name\\').on(t.id, t.name)\\n      ]);\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n      \\t`id` int,\\n      \\tCONSTRAINT `user_id_unique` UNIQUE(`id`)\\n      );\\n\\n      CREATE TABLE `table` (\\n      \\t`id` int,\\n      \\tCONSTRAINT `custom_name` UNIQUE(`id`)\\n      );\\n\\n      CREATE TABLE `composite_example` (\\n        `id` int,\\n        `name` varchar(256),\\n        CONSTRAINT `composite_example_id_name_unique` UNIQUE(`id`,`name`),\\n        CONSTRAINT `custom_name` UNIQUE(`id`,`name`)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n</Tabs>\\n\\n### Check\\n\\nThe `CHECK` constraint is used to limit the value range that can be placed in a column.\\n\\nIf you define a `CHECK` constraint on a column it will allow only certain values for this column.  \\n\\nIf you define a `CHECK` constraint on a table it can limit the values in certain columns based on values in other columns in the row.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n      ```typescript copy\\n      import { sql } from \"drizzle-orm\";\\n      import { check, integer, pgTable, text, uuid } from \"drizzle-orm/pg-core\";\\n\\n      export const users = pgTable(\\n        \"users\",\\n        {\\n          id: uuid().defaultRandom().primaryKey(),\\n          username: text().notNull(),\\n          age: integer(),\\n        },\\n        (table) => [\\n          check(\"age_check1\", sql`${table.age} > 21`),\\n        ]\\n      );\\n      ```\\n      ```sql\\n      CREATE TABLE IF NOT EXISTS \"users\" (\\n\\t      \"id\" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,\\n\\t      \"username\" text NOT NULL,\\n\\t      \"age\" integer,\\n\\t      CONSTRAINT \"age_check1\" CHECK (\"users\".\"age\" > 21)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n      ```typescript copy\\n      import { sql } from \"drizzle-orm\";\\n      import { check, int, mysqlTable, text } from \"drizzle-orm/mysql-core\";\\n\\n      export const users = mysqlTable(\\n        \"users\",\\n        {\\n          id: int().primaryKey(),\\n          username: text().notNull(),\\n          age: int(),\\n        },\\n        (table) => [\\n          check(\"age_check1\", sql`${table.age} > 21`)\\n        ]\\n      );\\n      ```\\n      ```sql\\n      CREATE TABLE `users` (\\n\\t      `id` int NOT NULL,\\n\\t      `username` text NOT NULL,\\n\\t      `age` int,\\n\\t      CONSTRAINT `users_id` PRIMARY KEY(`id`),\\n\\t      CONSTRAINT `age_check1` CHECK(`users`.`age` > 21)\\n      );\\n      ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n   <Section>\\n      ```typescript copy\\n      import { sql } from \"drizzle-orm\";\\n      import { check, int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\n      export const users = sqliteTable(\\n        \"users\",\\n        {\\n          id: int().primaryKey(),\\n          username: text().notNull(),\\n          age: int(),\\n        },\\n        (table) => [\\n          check(\"age_check1\", sql`${table.age} > 21`)\\n        ]\\n      );\\n      ```\\n      ```sql\\n      CREATE TABLE `users` (\\n\\t      `id` integer PRIMARY KEY NOT NULL,\\n\\t      `username` text NOT NULL,\\n\\t      `age` integer,\\n\\t      CONSTRAINT \"age_check1\" CHECK(\"users\".\"age\" > 21)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n    Currently not supported in SingleStore\\n  </Tab>\\n</Tabs>\\n\\n### Primary Key\\n\\nThe `PRIMARY KEY` constraint uniquely identifies each record in a table.  \\nPrimary keys must contain `UNIQUE` values, and cannot contain `NULL` values.  \\n\\nA table can have only **ONE** primary key; and in the table, this primary key can consist of single or multiple columns (fields).\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n      ```typescript copy\\n      import { serial, text, pgTable } from \"drizzle-orm/pg-core\";\\n\\n      const user = pgTable(\\'user\\', {\\n        id: serial(\\'id\\').primaryKey(),\\n      });\\n\\n      const table = pgTable(\\'table\\', {\\n        id: text(\\'cuid\\').primaryKey(),\\n      });\\n      ```\\n\\n      ```sql\\n      CREATE TABLE IF NOT EXISTS \"user\" (\\n        \"id\" serial PRIMARY KEY\\n      );\\n\\n      CREATE TABLE IF NOT EXISTS \"table\" (\\n        \"cuid\" text PRIMARY KEY\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, text, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n      export const user = mysqlTable(\"user\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n      })\\n\\n      export const table = mysqlTable(\"table\", {\\n        cuid: text(\"cuid\").primaryKey(),\\n      })\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n        `id` int AUTO_INCREMENT PRIMARY KEY NOT NULL\\n      );\\n\\n      CREATE TABLE `table` (\\n        `cuid` text PRIMARY KEY NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n   <Section>\\n      ```typescript copy\\n      import { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n      export const user = sqliteTable(\"user\", {\\n        id: integer(\"id\").primaryKey(),\\n      })\\n\\n      export const pet = sqliteTable(\"pet\", {\\n        id: integer(\"id\").primaryKey(),\\n      })\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n        `id` integer PRIMARY KEY AUTOINCREMENT NOT NULL\\n      );\\n\\n      CREATE TABLE `pet` (\\n        `id` integer PRIMARY KEY AUTOINCREMENT\\n      )\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```typescript\\n      import { int, text, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\n      export const user = singlestoreTable(\"user\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n      })\\n\\n      export const table = singlestoreTable(\"table\", {\\n        cuid: text(\"cuid\").primaryKey(),\\n      })\\n      ```\\n\\n      ```sql\\n      CREATE TABLE `user` (\\n        `id` int AUTO_INCREMENT PRIMARY KEY NOT NULL\\n      );\\n\\n      CREATE TABLE `table` (\\n        `cuid` text PRIMARY KEY NOT NULL\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n</Tabs>\\n\\n### Composite Primary Key\\n\\nJust like `PRIMARY KEY`, composite primary key uniquely identifies each record in a table using multiple fields.\\n\\nDrizzle ORM provides a standalone `primaryKey` operator for that:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n      ```typescript copy {18, 19}\\n      import { serial, text, integer, primaryKey, pgTable } from \"drizzle-orm/pg-core\";\\n\\n      export const user = pgTable(\"user\", {\\n        id: serial(\"id\").primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const book = pgTable(\"book\", {\\n        id: serial(\"id\").primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const booksToAuthors = pgTable(\"books_to_authors\", {\\n        authorId: integer(\"author_id\"),\\n        bookId: integer(\"book_id\"),\\n      }, (table) => [\\n        primaryKey({ columns: [table.bookId, table.authorId] }),\\n        // Or PK with custom name\\n        primaryKey({ name: \\'custom_name\\', columns: [table.bookId, table.authorId] }),\\n      ]);\\n      ```\\n\\n      ```sql {6, 9}\\n      ...\\n\\n      CREATE TABLE IF NOT EXISTS \"books_to_authors\" (\\n        \"author_id\" integer,\\n        \"book_id\" integer,\\n        PRIMARY KEY(\"book_id\",\"author_id\")\\n      );\\n\\n      ALTER TABLE \"books_to_authors\" ADD CONSTRAINT \"custom_name\" PRIMARY KEY(\"book_id\",\"author_id\");\\n      ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n      ```typescript {18, 19}\\n      import { int, text, primaryKey, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n      export const user = mysqlTable(\"user\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const book = mysqlTable(\"book\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const booksToAuthors = mysqlTable(\"books_to_authors\", {\\n        authorId: int(\"author_id\"),\\n        bookId: int(\"book_id\"),\\n      }, (table) => [\\n        primaryKey({ columns: [table.bookId, table.authorId] }),\\n        // Or PK with custom name\\n        primaryKey({ name: \\'custom_name\\', columns: [table.bookId, table.authorId] })\\n      ]);\\n      ```\\n\\n      ```sql {6}\\n      ...\\n\\n      CREATE TABLE `books_to_authors` (\\n        `author_id` int,\\n        `book_id` int,\\n        PRIMARY KEY(`book_id`,`author_id`)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n   <Section>\\n      ```typescript copy {18, 19}\\n      import { integer, text, primaryKey, sqliteTable} from \"drizzle-orm/sqlite-core\";\\n\\n      export const user = sqliteTable(\"user\", {\\n        id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n        name: text(\"name\"),\\n      });\\n\\n      export const book = sqliteTable(\"book\", {\\n        id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n        name: text(\"name\"),\\n      });\\n\\n      export const bookToAuthor = sqliteTable(\"book_to_author\", {\\n        authorId: integer(\"author_id\"),\\n        bookId: integer(\"book_id\"),\\n      }, (table) => [\\n        primaryKey({ columns: [table.bookId, table.authorId] }),\\n        // Or PK with custom name\\n        primaryKey({ name: \\'custom_name\\', columns: [table.bookId, table.authorId] })\\n      ]);\\n      ```\\n      ```sql {6}\\n      ...\\n\\n      CREATE TABLE `book_to_author` (\\n        `author_id` integer,\\n        `book_id` integer,\\n        PRIMARY KEY(`book_id`, `author_id`)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```typescript {18, 19}\\n      import { int, text, primaryKey, mysqlTable } from \"drizzle-orm/singlestore-core\";\\n\\n      export const user = singlestoreTable(\"user\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const book = singlestoreTable(\"book\", {\\n        id: int(\"id\").autoincrement().primaryKey(),\\n        name: text(\"name\"),\\n      });\\n\\n      export const booksToAuthors = singlestoreTable(\"books_to_authors\", {\\n        authorId: int(\"author_id\"),\\n        bookId: int(\"book_id\"),\\n      }, (table) => [\\n        primaryKey({ columns: [table.bookId, table.authorId] }),\\n        // Or PK with custom name\\n        primaryKey({ name: \\'custom_name\\', columns: [table.bookId, table.authorId] }),\\n      ]);\\n      ```\\n\\n      ```sql {6}\\n      ...\\n\\n      CREATE TABLE `books_to_authors` (\\n        `author_id` int,\\n        `book_id` int,\\n        PRIMARY KEY(`book_id`,`author_id`)\\n      );\\n      ```\\n    </Section>\\n\\n  </Tab>\\n</Tabs>\\n\\n### Foreign key\\n\\nThe `FOREIGN KEY` constraint is used to prevent actions that would destroy links between tables.\\nA `FOREIGN KEY` is a field (or collection of fields) in one table, that refers to the `PRIMARY KEY` in another table.\\nThe table with the foreign key is called the child table, and the table with the primary key is called the referenced or parent table.\\n\\nDrizzle ORM provides several ways to declare foreign keys.\\nYou can declare them in a column declaration statement:\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    ```typescript copy {11}\\n    import { serial, text, integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    export const user = pgTable(\"user\", {\\n      id: serial(\"id\"),\\n      name: text(\"name\"),\\n    });\\n\\n    export const book = pgTable(\"book\", {\\n      id: serial(\"id\"),\\n      name: text(\"name\"),\\n      authorId: integer(\"author_id\").references(() => user.id)\\n    });\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript {11}\\n    import { int, text, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n    export const user = mysqlTable(\"user\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n    });\\n\\n    export const book = mysqlTable(\"book\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n      authorId: int(\"author_id\").references(() => user.id)\\n    });\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript {11}\\n    import { integer, text, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n    export const user = sqliteTable(\"user\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      name: text(\"name\"),\\n    });\\n\\n    export const book = sqliteTable(\"book\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      name: text(\"name\"),\\n      authorId: integer(\"author_id\").references(() => user.id)\\n    });\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    Currently not supported in SingleStore\\n  </Tab>\\n</Tabs>\\n\\nIf you want to do a self reference, due to a TypeScript limitations you will have to either explicitly\\nset return type for reference callback or use a standalone `foreignKey` operator.\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    ```typescript copy {6,16-19}\\n    import { serial, text, integer, foreignKey, pgTable, AnyPgColumn } from \"drizzle-orm/pg-core\";\\n\\n    export const user = pgTable(\"user\", {\\n      id: serial(\"id\"),\\n      name: text(\"name\"),\\n      parentId: integer(\"parent_id\").references((): AnyPgColumn => user.id)\\n    });\\n\\n    // or\\n    export const user = pgTable(\"user\", {\\n      id: serial(\"id\"),\\n      name: text(\"name\"),\\n      parentId: integer(\"parent_id\"),\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.parentId],\\n        foreignColumns: [table.id],\\n        name: \"custom_fk\"\\n      })\\n    ]);\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript {6,16-19}\\n    import { int, text, foreignKey, AnyMySqlColumn, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n    export const user = mysqlTable(\"user\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n      parentId: int(\"parent_id\").references((): AnyMySqlColumn => user.id),\\n    });\\n\\n    // or\\n    export const user = mysqlTable(\"user\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n      parentId: int(\"parent_id\")\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.parentId],\\n        foreignColumns: [table.id],\\n        name: \"custom_fk\"\\n      })\\n    ]);\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript {6,16-19}\\n    import { integer, text, foreignKey, sqliteTable, AnySQLiteColumn } from \"drizzle-orm/sqlite-core\";\\n\\n    export const user = sqliteTable(\"user\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      name: text(\"name\"),\\n      parentId: integer(\"parent_id\").references((): AnySQLiteColumn => user.id)\\n    });\\n\\n    //or\\n    export const user = sqliteTable(\"user\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      name: text(\"name\"),\\n      parentId: integer(\"parent_id\"),\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.parentId],\\n        foreignColumns: [table.id],\\n        name: \"custom_fk\"\\n      })\\n    ]);\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    Currently not supported in SingleStore\\n  </Tab>\\n</Tabs>\\nTo declare multicolumn foreign keys you can use a dedicated `foreignKey` operator:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    ```typescript copy {4-5,14-15,18-21}\\n    import { serial, text, foreignKey, pgTable, AnyPgColumn } from \"drizzle-orm/pg-core\";\\n\\n    export const user = pgTable(\"user\", {\\n      firstName: text(\"firstName\"),\\n      lastName: text(\"lastName\"),\\n    }, (table) => [\\n      primaryKey({ columns: [table.firstName, table.lastName]})\\n    ]);\\n\\n    export const profile = pgTable(\"profile\", {\\n      id: serial(\"id\").primaryKey(),\\n      userFirstName: text(\"user_first_name\"),\\n      userLastName: text(\"user_last_name\"),\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.userFirstName, table.userLastName],\\n        foreignColumns: [user.firstName, user.lastName],\\n        name: \"custom_fk\"\\n      })\\n    ])\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript copy {4-5,14-15,18-21}\\n    import { int, text, primaryKey, foreignKey, mysqlTable, AnyMySqlColumn } from \"drizzle-orm/mysql-core\";\\n\\n    export const user = mysqlTable(\"user\", {\\n      firstName: text(\"firstName\"),\\n      lastName: text(\"lastName\"),\\n    }, (table) => [\\n      primaryKey({ columns: [table.firstName, table.lastName]})\\n    ]);\\n\\n    export const profile = mysqlTable(\"profile\", {\\n      id: int(\"id\").autoincrement().primaryKey(),\\n      userFirstName: text(\"user_first_name\"),\\n      userLastName: text(\"user_last_name\"),\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.userFirstName, table.userLastName],\\n        foreignColumns: [user.firstName, user.lastName],\\n        name: \"custom_name\"\\n      })\\n    ]);\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    ```typescript {4-5,14-15,18-21}\\n    import { integer, text, primaryKey, foreignKey, sqliteTable, AnySQLiteColumn } from \"drizzle-orm/sqlite-core\";\\n\\n    export const user = sqliteTable(\"user\", {\\n      firstName: text(\"firstName\"),\\n      lastName: text(\"lastName\"),\\n    }, (table) => [\\n      primaryKey({ columns: [table.firstName, table.lastName]})\\n    ]);\\n\\n    export const profile = sqliteTable(\"profile\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      userFirstName: text(\"user_first_name\"),\\n      userLastName: text(\"user_last_name\"),\\n    }, (table) => [\\n      foreignKey({\\n        columns: [table.userFirstName, table.userLastName],\\n        foreignColumns: [user.firstName, user.lastName],\\n        name: \"custom_name\"\\n      })\\n    ]);\\n    ```\\n\\n  </Tab>\\n  <Tab>\\n    Currently not supported in SingleStore\\n  </Tab>\\n</Tabs>\\n\\n## Indexes\\n\\nDrizzle ORM provides API for both `index` and `unique index` declaration:\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n  <Tab>\\n    <Section>\\n    ```typescript copy {9-10}\\n    import { serial, text, index, uniqueIndex, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    export const user = pgTable(\"user\", {\\n      id: serial(\"id\").primaryKey(),\\n      name: text(\"name\"),\\n      email: text(\"email\"),\\n    }, (table) => [\\n      index(\"name_idx\").on(table.name),\\n      uniqueIndex(\"email_idx\").on(table.email)\\n    ]);\\n    ```\\n    ```sql {5-6}\\n    CREATE TABLE \"user\" (\\n      ...\\n    );\\n\\n    CREATE INDEX \"name_idx\" ON \"user\" (\"name\");\\n    CREATE UNIQUE INDEX \"email_idx\" ON \"user\" (\"email\");\\n    ```\\n    </Section>\\n    <Callout type=\"warning\" emoji=\"âš ï¸\">\\n      For versions before `drizzle-kit@0.22.0` and `drizzle-orm@0.31.0` `drizzle-kit` only supports index `name` and `on()` param.\\n\\n      After versions `drizzle-kit@0.22.0` and `drizzle-orm@0.31.0` all fields are supported in drizzle-kit!\\n    </Callout>\\n\\n\\n    Starting from 0.31.0 a new index api for Drizzle ORM provides set of all params for index creation:\\n\\n```ts\\n// First example, with `.on()`\\nindex(\\'name\\')\\n  .on(table.column1.asc(), table.column2.nullsFirst(), ...) or .onOnly(table.column1.desc().nullsLast(), table.column2, ...)\\n  .concurrently()\\n  .where(sql``)\\n  .with({ fillfactor: \\'70\\' })\\n\\n// Second Example, with `.using()`\\nindex(\\'name\\')\\n  .using(\\'btree\\', table.column1.asc(), sql`lower(${table.column2})`, table.column1.op(\\'text_ops\\'))\\n  .where(sql``) // sql expression\\n  .with({ fillfactor: \\'70\\' })\\n```\\n\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript copy {9-10}\\n    import { int, text, index, uniqueIndex, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n    export const user = mysqlTable(\"user\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n      email: text(\"email\"),\\n    }, (table) => [\\n      index(\"name_idx\").on(table.name),\\n      uniqueIndex(\"email_idx\").on(table.email),\\n    ]);\\n    ```\\n    ```sql {5-6}\\n    CREATE TABLE `user` (\\n      ...\\n    );\\n\\n    CREATE INDEX `name_idx` ON `user` (`name`);\\n    CREATE UNIQUE INDEX `email_idx` ON `user` (`email`);\\n    ```\\n    </Section>\\n    <Callout type=\"warning\" emoji=\"âš ï¸\">\\n      As of now `drizzle-kit` only supports index `name` and `on()` param.\\n    </Callout>\\n\\n     Drizzle ORM provides set of all params for index creation:\\n\\n    ```typescript\\n    // Index declaration reference\\n    index(\"name\")\\n      .on(table.name)\\n      .algorythm(\"default\") // \"default\" | \"copy\" | \"inplace\"\\n      .using(\"btree\") // \"btree\" | \"hash\"\\n      .lock(\"default\") // \"none\" | \"default\" | \"exclusive\" | \"shared\"\\n    ```\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript {9-10}\\n    import { integer, text, index, uniqueIndex, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n    export const user = sqliteTable(\"user\", {\\n      id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n      name: text(\"name\"),\\n      email: text(\"email\"),\\n    }, (table) => [\\n      index(\"name_idx\").on(table.name),\\n      uniqueIndex(\"email_idx\").on(table.email),\\n    ]);\\n    ```\\n    ```sql {5-6}\\n    CREATE TABLE `user` (\\n      ...\\n    );\\n\\n    CREATE INDEX `name_idx` ON `user` (`name`);\\n    CREATE UNIQUE INDEX `email_idx` ON `user` (`email`);\\n    ```\\n    </Section>\\n\\n     Drizzle ORM provides set of all params for index creation:\\n     \\n    ```typescript\\n    // Index declaration reference\\n    index(\"name\")\\n      .on(table.name)\\n      .where(sql`...`)\\n    ```\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript copy {9-10}\\n    import { int, text, index, uniqueIndex, singlestoreTable } from \"drizzle-orm/singlestore-core\";\\n\\n    export const user = singlestoreTable(\"user\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n      email: text(\"email\"),\\n    }, (table) => [\\n      index(\"name_idx\").on(table.name),\\n      uniqueIndex(\"email_idx\").on(table.email),\\n    ]);\\n    ```\\n    ```sql {5-6}\\n    CREATE TABLE `user` (\\n      ...\\n    );\\n\\n    CREATE INDEX `name_idx` ON `user` (`name`);\\n    CREATE UNIQUE INDEX `email_idx` ON `user` (`email`);\\n    ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n', children=[]),\n",
       " DocItem(origPath=Path('insert.mdx'), name='insert.mdx', displayName='insert.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\n\\n# SQL Insert\\nDrizzle ORM provides you the most SQL-like way to insert rows into the database tables.\\n\\n## Insert one row\\nInserting data with Drizzle is extremely straightforward and sql-like. See for yourself:\\n\\n<Section>\\n```typescript copy \\nawait db.insert(users).values({ name: \\'Andrew\\' });\\n```\\n```sql\\ninsert into \"users\" (\"name\") values (\"Andrew\");\\n```\\n</Section>\\n\\nIf you need insert type for a particular table you can use `typeof usersTable.$inferInsert` syntax. \\n```typescript copy \\ntype NewUser = typeof users.$inferInsert;\\n\\nconst insertUser = async (user: NewUser) => {\\n  return db.insert(users).values(user);\\n}\\n\\nconst newUser: NewUser = { name: \"Alef\" };\\nawait insertUser(newUser);\\n```\\n\\n## Insert returning\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': false, \\'SingleStore\\': false}} />\\nYou can insert a row and get it back in PostgreSQL and SQLite like such:\\n```typescript copy\\nawait db.insert(users).values({ name: \"Dan\" }).returning();\\n\\n// partial return\\nawait db.insert(users).values({ name: \"Partial Dan\" }).returning({ insertedId: users.id });\\n```\\n\\n## Insert $returningId\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': false, \\'SQLite\\': false, \\'MySQL\\': true, \\'SingleStore\\': true }} />\\n\\nMySQL itself doesn\\'t have native support for `RETURNING` after using `INSERT`. There is only one way to do it for `primary keys` with `autoincrement` (or `serial`) types, where you can access `insertId` and `affectedRows` fields. We\\'ve prepared an automatic way for you to handle such cases with Drizzle and automatically receive all inserted IDs as separate objects\\n\\n```ts\\nimport { boolean, int, text, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\n\\nconst usersTable = mysqlTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  verified: boolean(\\'verified\\').notNull().default(false),\\n});\\n\\n\\nconst result = await db.insert(usersTable).values([{ name: \\'John\\' }, { name: \\'John1\\' }]).$returningId();\\n//    ^? { id: number }[]\\n```\\n\\nAlso with Drizzle, you can specify a `primary key` with `$default` function that will generate custom primary keys at runtime. We will also return those generated keys for you in the `$returningId()` call\\n\\n```ts\\nimport { varchar, text, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst usersTableDefFn = mysqlTable(\\'users_default_fn\\', {\\n  customId: varchar(\\'id\\', { length: 256 }).primaryKey().$defaultFn(createId),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\n\\nconst result = await db.insert(usersTableDefFn).values([{ name: \\'John\\' }, { name: \\'John1\\' }]).$returningId();\\n//  ^? { customId: string }[]\\n```\\n\\n> If there is no primary keys -> type will be `{}[]` for such queries\\n\\n## Insert multiple rows\\n```typescript copy\\nawait db.insert(users).values([{ name: \\'Andrew\\' }, { name: \\'Dan\\' }]);\\n```\\n\\n## Upserts and conflicts\\nDrizzle ORM provides simple interfaces for handling upserts and conflicts.\\n\\n### On conflict do nothing\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': false, \\'SingleStore\\': false }} />\\n\\n`onConflictDoNothing` will cancel the insert if there\\'s a conflict:\\n\\n```typescript copy\\nawait db.insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onConflictDoNothing();\\n\\n// explicitly specify conflict target\\nawait db.insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onConflictDoNothing({ target: users.id });\\n```\\n\\n### On conflict do update\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': false }} />\\n\\n`onConflictDoUpdate` will update the row if there\\'s a conflict:\\n```typescript\\nawait db.insert(users)\\n  .values({ id: 1, name: \\'Dan\\' })\\n  .onConflictDoUpdate({ target: users.id, set: { name: \\'John\\' } });\\n```\\n\\n#### `where` clauses\\n\\n`on conflict do update` can have a `where` clause in two different places -\\nas part of the conflict target (i.e. for partial indexes) or as part of the `update` clause:\\n\\n```sql\\ninsert into employees (employee_id, name)\\nvalues (123, \\'John Doe\\')\\non conflict (employee_id) where name <> \\'John Doe\\'\\ndo update set name = excluded.name\\n\\ninsert into employees (employee_id, name)\\nvalues (123, \\'John Doe\\')\\non conflict (employee_id) do update set name = excluded.name\\nwhere name <> \\'John Doe\\';\\n```\\n\\nTo specify these conditions in Drizzle, you can use `setWhere` and `targetWhere` clauses:\\n\\n```typescript\\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: \\'John Doe\\' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    targetWhere: sql`name <> \\'John Doe\\'`,\\n    set: { name: sql`excluded.name` }\\n  });\\n\\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: \\'John Doe\\' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    set: { name: \\'John Doe\\' },\\n    setWhere: sql`name <> \\'John Doe\\'`\\n  });\\n```\\n\\n<hr />\\n\\nUpsert with composite indexes, or composite primary keys for `onConflictDoUpdate`:\\n\\n```typescript\\nawait db.insert(users)\\n  .values({ firstName: \\'John\\', lastName: \\'Doe\\' })\\n  .onConflictDoUpdate({\\n    target: [users.firstName, users.lastName],\\n    set: { firstName: \\'John1\\' }\\n  });\\n```\\n\\n### On duplicate key update\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': false, \\'SQLite\\': false, \\'MySQL\\': true, \\'SingleStore\\': true }} />\\n\\nMySQL supports [`ON DUPLICATE KEY UPDATE`](https://dev.mysql.com/doc/refman/8.0/en/insert-on-duplicate.html) instead of `ON CONFLICT` clauses. MySQL will automatically determine the conflict target based on the primary key and unique indexes, and will update the row if *any* unique index conflicts.\\n\\nDrizzle supports this through the `onDuplicateKeyUpdate` method:\\n\\n```typescript\\n// Note that MySQL automatically determines targets based on the primary key and unique indexes\\nawait db.insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onDuplicateKeyUpdate({ set: { name: \\'John\\' } });\\n```\\n\\nWhile MySQL does not directly support doing nothing on conflict, you can perform a no-op by setting any column\\'s value to itself and achieve the same effect:\\n\\n```typescript\\nimport { sql } from \\'drizzle-orm\\';\\n\\nawait db.insert(users)\\n  .values({ id: 1, name: \\'John\\' })\\n  .onDuplicateKeyUpdate({ set: { id: sql`id` } });\\n```\\n\\n## `with insert` clause\\n\\n<Callout>\\n  Check how to use WITH statement with [select](/docs/select#with-clause), [update](/docs/update#with-update-clause), [delete](/docs/delete#with-delete-clause)\\n</Callout>\\n\\nUsing the `with` clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\\n<Section>\\n```typescript copy\\nconst userCount = db.$with(\\'user_count\\').as(\\n\\tdb.select({ value: sql`count(*)`.as(\\'value\\') }).from(users)\\n);\\n\\nconst result = await db.with(userCount)\\n\\t.insert(users)\\n\\t.values([\\n\\t\\t{ username: \\'user1\\', admin: sql`((select * from ${userCount}) = 0)` }\\n\\t])\\n\\t.returning({\\n\\t\\tadmin: users.admin\\n\\t});\\n```\\n```sql\\nwith \"user_count\" as (select count(*) as \"value\" from \"users\") \\ninsert into \"users\" (\"username\", \"admin\") \\nvalues ($1, ((select * from \"user_count\") = 0)) \\nreturning \"admin\"\\n```\\n</Section>\\n\\n\\n## Insert into ... select\\n\\nAs the SQLite documentation mentions:\\n\\n<Callout>\\nThe second form of the INSERT statement contains a SELECT statement instead of a VALUES clause. \\nA new entry is inserted into the table for each row of data returned by executing the SELECT statement. \\nIf a column-list is specified, the number of columns in the result of the SELECT must be the same as \\nthe number of items in the column-list. Otherwise, if no column-list is specified, the number of \\ncolumns in the result of the SELECT must be the same as the number of columns in the table. \\nAny SELECT statement, including compound SELECTs and SELECT statements with ORDER BY and/or LIMIT clauses, \\nmay be used in an INSERT statement of this form.\\n</Callout>\\n<Callout type=\\'warning\\'>\\nTo avoid a parsing ambiguity, the SELECT statement should always contain a WHERE clause, even if that clause is simply \"WHERE true\", if the upsert-clause is present. Without the WHERE clause, the parser does not know if the token \"ON\" is part of a join constraint on the SELECT, or the beginning of the upsert-clause.\\n</Callout>\\n\\nAs the PostgreSQL documentation mentions:\\n<Callout>\\nA query (SELECT statement) that supplies the rows to be inserted\\n</Callout>\\n\\nAnd as the MySQL documentation mentions:\\n\\n<Callout>\\nWith INSERT ... SELECT, you can quickly insert many rows into a table from the result of a SELECT statement, which can select from one or many tables\\n</Callout>\\n\\nDrizzle supports the current syntax for all dialects, and all of them share the same syntax. Let\\'s review some common scenarios and API usage. \\nThere are several ways to use select inside insert statements, allowing you to choose your preferred approach:\\n\\n- You can pass a query builder inside the select function.\\n- You can use a query builder inside a callback.\\n- You can pass an SQL template tag with any custom select query you want to use\\n\\n\\n<Tabs items={[\"Query Builder\", \"Callback\", \"SQL template tag\"]}>\\n<Tab>\\n<Section>\\n```ts\\nconst insertedEmployees = await db\\n  .insert(employees)\\n  .select(\\n    db.select({ name: users.name }).from(users).where(eq(users.role, \\'employee\\'))\\n  )\\n  .returning({\\n    id: employees.id,\\n    name: employees.name\\n  });\\n```\\n```ts\\nconst qb = new QueryBuilder();\\nawait db.insert(employees).select(\\n    qb.select({ name: users.name }).from(users).where(eq(users.role, \\'employee\\'))\\n);\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts\\nawait db.insert(employees).select(\\n    () => db.select({ name: users.name }).from(users).where(eq(users.role, \\'employee\\'))\\n);\\n```\\n```ts\\nawait db.insert(employees).select(\\n    (qb) => qb.select({ name: users.name }).from(users).where(eq(users.role, \\'employee\\'))\\n);\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts\\nawait db.insert(employees).select(\\n    sql`select \"users\".\"name\" as \"name\" from \"users\" where \"users\".\"role\" = \\'employee\\'`\\n);\\n```\\n```ts\\nawait db.insert(employees).select(\\n    () => sql`select \"users\".\"name\" as \"name\" from \"users\" where \"users\".\"role\" = \\'employee\\'`\\n);\\n```\\n</Section>\\n</Tab>\\n</Tabs>', children=[]),\n",
       " DocItem(origPath=Path('joins.mdx'), name='joins.mdx', displayName='joins.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# Joins [SQL]\\nJoin clause in SQL is used to combine 2 or more tables, based on related columns between them.\\nDrizzle ORM joins syntax is a balance between the SQL-likeness and type safety.\\n\\n## Join types\\nDrizzle ORM has APIs for `INNER JOIN [LATERAL]`, `FULL JOIN`, `LEFT JOIN [LATERAL]`, `RIGHT JOIN`, `CROSS JOIN [LATERAL]`.\\nLets have a quick look at examples based on below table schemas:\\n```typescript copy\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\nexport const pets = pgTable(\\'pets\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  ownerId: integer(\\'owner_id\\').notNull().references(() => users.id),\\n})\\n```\\n\\n### Left Join\\n<Section>\\n```typescript copy\\nconst result = await db.select().from(users).leftJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect ... from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    pets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    } | null;\\n}[];\\n```\\n</Section>\\n\\n### Left Join Lateral\\n<Section>\\n```typescript copy\\nconst subquery = db.select().from(pets).where(gte(users.age, 16)).as(\\'userPets\\')\\nconst result = await db.select().from(users).leftJoinLateral(subquery, sql`true`)\\n```\\n```sql\\nselect ... from \"users\" left join lateral (select ... from \"pets\" where \"users\".\"age\" >= 16) \"userPets\" on true\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    userPets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    } | null;\\n}[];\\n```\\n</Section>\\n\\n### Right Join\\n<Section>\\n```typescript copy\\nconst result = await db.select().from(users).rightJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect ... from \"users\" right join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    } | null;\\n    pets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    };\\n}[];\\n```\\n</Section>\\n\\n### Inner Join\\n<Section>\\n```typescript copy\\nconst result = await db.select().from(users).innerJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect ... from \"users\" inner join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    pets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    };\\n}[];\\n```\\n</Section>\\n\\n### Inner Join Lateral\\n<Section>\\n```typescript copy\\nconst subquery = db.select().from(pets).where(gte(users.age, 16)).as(\\'userPets\\')\\nconst result = await db.select().from(users).innerJoinLateral(subquery, sql`true`)\\n```\\n```sql\\nselect ... from \"users\" inner join lateral (select ... from \"pets\" where \"users\".\"age\" >= 16) \"userPets\" on true\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    userPets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    };\\n}[];\\n```\\n</Section>\\n\\n### Full Join\\n<Section>\\n```typescript copy\\nconst result = await db.select().from(users).fullJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect ... from \"users\" full join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    } | null;\\n    pets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    } | null;\\n}[];\\n```\\n</Section>\\n\\n### Cross Join\\n<Section>\\n```typescript copy\\nconst result = await db.select().from(users).crossJoin(pets)\\n```\\n```sql\\nselect ... from \"users\" cross join \"pets\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    pets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    };\\n}[];\\n```\\n</Section>\\n\\n### Cross Join Lateral\\n<Section>\\n```typescript copy\\nconst subquery = db.select().from(pets).where(gte(users.age, 16)).as(\\'userPets\\')\\nconst result = await db.select().from(users).crossJoinLateral(subquery)\\n```\\n```sql\\nselect ... from \"users\" cross join lateral (select ... from \"pets\" where \"users\".\"age\" >= 16) \"userPets\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n    };\\n    userPets: {\\n        id: number;\\n        name: string;\\n        ownerId: number;\\n    };\\n}[];\\n```\\n</Section>\\n\\n## Partial select\\nIf you need to select a particular subset of fields or to have a flat response type, Drizzle ORM\\nsupports joins with partial select and will automatically infer return type based on `.select({ ... })` structure.\\n<Section>\\n```typescript copy\\nawait db.select({\\n  userId: users.id,\\n  petId: pets.id,\\n}).from(user).leftJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect \"users\".\"id\", \"pets\".\"id\" from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n  userId: number;\\n  petId: number | null;\\n}[];\\n```\\n</Section>\\nYou might\\'ve noticed that `petId` can be null now, it\\'s because we\\'re left joining and there can be users without a pet.\\n\\nIt\\'s very important to keep in mind when using `sql` operator for partial selection fields and aggregations when needed,\\nyou should to use `sql<type | null>` for proper result type inference, that one is on you!\\n<Section>\\n```typescript copy\\nconst result = await db.select({\\n  userId: users.id,\\n  petId: pets.id,\\n  petName1: sql`upper(${pets.name})`,\\n  petName2: sql<string | null>`upper(${pets.name})`,\\n  //Ë„we should explicitly tell \\'string | null\\' in type, since we\\'re left joining that field\\n}).from(user).leftJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect \"users\".\"id\", \"pets\".\"id\", upper(\"pets\".\"name\")... from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n  userId: number;\\n  petId: number | null;\\n  petName1: unknown;\\n  petName2: string | null;\\n}[];\\n```\\n</Section>\\nTo avoid plethora of nullable fields when joining tables with lots of columns we can utilise our **nested select object syntax**,\\nour smart type inference will make whole object nullable instead of making all table fields nullable!\\n<Section>\\n```typescript copy\\nawait db.select({\\n  userId: users.id,\\n  userName: users.name,\\n  pet: {\\n    id: pets.id,\\n    name: pets.name,\\n    upperName: sql<string>`upper(${pets.name})`\\n  }\\n}).from(user).fullJoin(pets, eq(users.id, pets.ownerId))\\n```\\n```sql\\nselect ... from \"users\" full join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    userId: number | null;\\n    userName: string | null;\\n    pet: {\\n        id: number;\\n        name: string;\\n        upperName: string;\\n    } | null;\\n}[];\\n```\\n</Section>\\n\\n## Aliases & Selfjoins\\nDrizzle ORM supports table aliases which comes really handy when you need to do selfjoins.\\n\\nLets say you need to fetch users with their parents:\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```typescript copy\\nimport { user } from \"./schema\";\\n\\nconst parent = alias(user, \"parent\");\\nconst result = db\\n  .select()\\n  .from(user)\\n  .leftJoin(parent, eq(parent.id, user.parentId));\\n```\\n```sql\\nselect ... from \"user\" left join \"user\" \"parent\" on \"parent\".\"id\" = \"user\".\"parent_id\"\\n```\\n```typescript\\n// result type\\nconst result: {\\n    user: {\\n        id: number;\\n        name: string;\\n        parentId: number;\\n    };\\n    parent: {\\n        id: number;\\n        name: string;\\n        parentId: number;\\n    } | null;\\n}[];\\n```\\n</CodeTab>\\n\\n```typescript\\nexport const user = pgTable(\"user\", {\\n  id: integer(\"id\").primaryKey({ autoIncrement: true }),\\n  name: text(\"name\").notNull(),\\n  parentId: integer(\"parent_id\").notNull().references((): AnyPgColumn => user.id)\\n});\\n```\\n\\n</CodeTabs>\\n\\n## Aggregating results\\nDrizzle ORM delivers name-mapped results from the driver without changing the structure.\\n\\nYou\\'re free to operate with results the way you want, here\\'s an example of mapping many-one relational data:\\n```typescript\\ntype User = typeof users.$inferSelect;\\ntype Pet = typeof pets.$inferSelect;\\n\\nconst rows = db.select({\\n    user: users,\\n    pet: pets,\\n  }).from(users).leftJoin(pets, eq(users.id, pets.ownerId)).all();\\n\\nconst result = rows.reduce<Record<number, { user: User; pets: Pet[] }>>(\\n  (acc, row) => {\\n    const user = row.user;\\n    const pet = row.pet;\\n\\n    if (!acc[user.id]) {\\n      acc[user.id] = { user, pets: [] };\\n    }\\n\\n    if (pet) {\\n      acc[user.id].pets.push(pet);\\n    }\\n\\n    return acc;\\n  },\\n  {}\\n);\\n\\n// result type\\nconst result: Record<number, {\\n    user: User;\\n    pets: Pet[];\\n}>;\\n```\\n\\n## Many-to-one example\\n```typescript\\nimport { sqliteTable, text, integer } from \\'drizzle-orm/sqlite-core\\';\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\n\\nconst cities = sqliteTable(\\'cities\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n});\\n\\nconst users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n  cityId: integer(\\'city_id\\').references(() => cities.id)\\n});\\n\\nconst db = drizzle();\\n\\nconst result = db.select().from(cities).leftJoin(users, eq(cities.id, users.cityId)).all();\\n```\\n## Many-to-many example\\n```typescript\\nconst users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n});\\n\\nconst chatGroups = sqliteTable(\\'chat_groups\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n});\\n\\nconst usersToChatGroups = sqliteTable(\\'usersToChatGroups\\', {\\n  userId: integer(\\'user_id\\').notNull().references(() => users.id),\\n  groupId: integer(\\'group_id\\').notNull().references(() => chatGroups.id),\\n});\\n\\n\\n// querying user group with id 1 and all the participants(users)\\ndb.select()\\n  .from(usersToChatGroups)\\n  .leftJoin(users, eq(usersToChatGroups.userId, users.id))\\n  .leftJoin(chatGroups, eq(usersToChatGroups.groupId, chatGroups.id))\\n  .where(eq(chatGroups.id, 1))\\n  .all();\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('kit-custom-migrations.mdx'), name='kit-custom-migrations.mdx', displayName='kit-custom-migrations.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\n\\n# Migrations with Drizzle Kit\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n- Drizzle Kit [overview](/docs/kit-overview) and [config file](/docs/drizzle-config-file)\\n- `drizzle-kit generate` command - [read here](/docs/drizzle-kit-generate)\\n- `drizzle-kit migrate` command - [read here](/docs/drizzle-kit-migrate)\\n</Prerequisites>\\n\\nDrizzle lets you generate empty migration files to write your own custom SQL migrations \\nfor DDL alternations currently not supported by Drizzle Kit or data seeding, which you can then run with [`drizzle-kit migrate`](/docs/drizzle-kit-migrate) command.\\n\\n```shell\\ndrizzle-kit generate --custom --name=seed-users\\n```\\n<Section>\\n```plaintext {5}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”œ ðŸ“œ 0000_init.sql \\n â”‚ â”” ðŸ“œ 0001_seed-users.sql \\n â”œ ðŸ“‚ src\\n â”” â€¦\\n```\\n```sql\\n-- ./drizzle/0001_seed-users.sql\\n\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dan\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Andrew\\');\\nINSERT INTO \"users\" (\"name\") VALUES(\\'Dandrew\\');\\n```\\n</Section>\\n\\n### Running JavaScript and TypeScript migrations\\nWe will add ability to run custom JavaScript and TypeScript migration/seeding scripts in the upcoming release, you can follow [github discussion](https://github.com/drizzle-team/drizzle-orm/discussions/2832).', children=[]),\n",
       " DocItem(origPath=Path('kit-migrations-for-teams.mdx'), name='kit-migrations-for-teams.mdx', displayName='kit-migrations-for-teams.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='# Drizzle migrations for teams\\n\\nThis section will be updated right after our release of the next version of migrations folder structure. \\nYou can read an extended [github discussion](https://github.com/drizzle-team/drizzle-orm/discussions/2832) and subscribe to the updates!\\n', children=[]),\n",
       " DocItem(origPath=Path('kit-overview.mdx'), name='kit-overview.mdx', displayName='kit-overview.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\n\\n# Migrations with Drizzle Kit\\n<Prerequisites>\\n- Get started with Drizzle and `drizzle-kit` - [read here](/docs/get-started)\\n- Drizzle schema fundamentals - [read here](/docs/sql-schema-declaration)\\n- Database connection basics - [read here](/docs/connect-overview)\\n- Drizzle migrations fundamentals - [read here](/docs/migrations)\\n</Prerequisites>\\n\\n\\n**Drizzle Kit** is a CLI tool for managing SQL database migrations with Drizzle.\\n<Npm>\\n  -D drizzle-kit\\n</Npm>\\n<Callout type=\"warning\">\\nMake sure to first go through Drizzle [get started](/docs/get-started) and [migration fundamentals](/docs/migrations) and pick SQL migration flow that suits your business needs best. \\n</Callout>\\n\\nBased on your schema, Drizzle Kit let\\'s you generate and run SQL migration files, \\npush schema directly to the database, pull schema from database, spin up drizzle studio and has a couple of utility commands.\\n<Npx>\\ndrizzle-kit generate\\ndrizzle-kit migrate\\ndrizzle-kit push\\ndrizzle-kit pull\\ndrizzle-kit check\\ndrizzle-kit up\\ndrizzle-kit studio\\n</Npx>\\n\\n\\n|                                                      |                                                                                                                                                                    |\\n| :--------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| [`drizzle-kit generate`](/docs/drizzle-kit-generate) | lets you generate SQL migration files based on your Drizzle schema either upon declaration or on subsequent changes, [see here](/docs/drizzle-kit-generate).       |\\n| [`drizzle-kit migrate`](/docs/drizzle-kit-migrate)   | lets you apply generated SQL migration files to your database, [see here](/docs/drizzle-kit-migrate).                                                              |\\n| [`drizzle-kit pull`](/docs/drizzle-kit-pull)         | lets you pull(introspect) database schema, convert it to Drizzle schema and save it to your codebase, [see here](/docs/drizzle-kit-pull)                           |\\n| [`drizzle-kit push`](/docs/drizzle-kit-push)         | lets you push your Drizzle schema to database either upon declaration or on subsequent schema changes, [see here](/docs/drizzle-kit-push)                          |\\n| [`drizzle-kit studio`](/docs/drizzle-kit-studio)     | will connect to your database and spin up proxy server for Drizzle Studio which you can use for convenient database browsing, [see here](/docs/drizzle-kit-studio) |\\n| [`drizzle-kit check`](/docs/drizzle-kit-check)       | will walk through all generate migrations and check for any race conditions(collisions) of generated migrations, [see here](/docs/drizzle-kit-check)               |\\n| [`drizzle-kit up`](/docs/drizzle-kit-up)             | used to upgrade snapshots of previously generated migrations, [see here](/docs/drizzle-kit-up)                                                                     |\\n<br/>\\n\\nDrizzle Kit is configured through [drizzle.config.ts](/docs/drizzle-config-file) configuration file or via CLI params.<br/>\\nIt\\'s required to at least provide SQL `dialect` and `schema` path for Drizzle Kit to know how to generate migrations.\\n```\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts  <--- Drizzle config file\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n<CodeTabs items={[\"simple config\", \"extended config\"]}>\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n});\\n```\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  out: \"./drizzle\",\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n\\n  driver: \"pglite\",\\n  dbCredentials: {\\n    url: \"./database/\",\\n  },\\n\\n  extensionsFilters: [\"postgis\"],\\n  schemaFilter: \"public\",\\n  tablesFilter: \"*\",\\n\\n  introspect: {\\n    casing: \"camel\",\\n  },\\n\\n  migrations: {\\n    prefix: \"timestamp\",\\n    table: \"__drizzle_migrations__\",\\n    schema: \"public\",\\n  },\\n\\n  breakpoints: true,\\n  strict: true,\\n  verbose: true,\\n});\\n```\\n</CodeTabs>\\n\\nYou can provide Drizzle Kit config path via CLI param, it\\'s very useful when you have multiple database stages or multiple databases or different databases on the same project:\\n\\n<Npx>\\n  drizzle-kit push --config=drizzle-dev.drizzle.config\\n  drizzle-kit push --config=drizzle-prod.drizzle.config\\n</Npx>\\n```plaintext {5-6}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle-dev.config.ts\\n â”œ ðŸ“œ drizzle-prod.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('kit-seed-data.mdx'), name='kit-seed-data.mdx', displayName='kit-seed-data.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\n\\n# Drizzle Kit data seeding\\n\\nThis section will be updated right after our release of `drizzle-seed` package.', children=[]),\n",
       " DocItem(origPath=Path('kit-web-mobile.mdx'), name='kit-web-mobile.mdx', displayName='kit-web-mobile.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Npx from \\'@mdx/Npx.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Prerequisites from \"@mdx/Prerequisites.astro\"\\n\\n# Drizzle migrations in web and mobile environments\\n\\nThis section will be updated in the next release.\\n\\nFor **Expo SQLite**, **OP SQLite** and **React Native** migrations - please refer to our [Get Started](/docs/get-started/expo-new) guide.', children=[]),\n",
       " DocItem(origPath=Path('latest-releases'), name='latest-releases', displayName='latest-releases', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('latest-releases/drizzle-kit-v0232.mdx'), name='drizzle-kit-v0232.mdx', displayName='drizzle-kit-v0232.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: Drizzle Kit v0.23.2 release\\npubDate: 2024-08-05\\ndescription: Bug fixes\\n---\\n\\n- Fixed a bug in PostgreSQL with push and introspect where the `schemaFilter` object was passed. It was detecting enums even in schemas that were not defined in the schemaFilter.\\n- Fixed the `drizzle-kit up` command to work as expected, starting from the sequences release.', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0110.mdx'), name='drizzle-orm-v0110.mdx', displayName='drizzle-orm-v0110.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\npubDate: 2022-07-20\\ntitle: DrizzleORM v0.11.0 release\\ndescription: DrizzleORM - is an open source TypeScript ORM, supports PostgreSQL and about to have MySQL and SQLite support in couple of weeks. We\\'ve decided it\\'s time to share it with public.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\nDrizzleORM - is an open source TypeScript ORM, supports PostgreSQL and about to have MySQL and SQLite support in couple of weeks. We\\'ve decided it\\'s time to share it with public.\\n\\nWith drizzle you have a fully typed SQL schema in-code which benefits you in multiple different major ways, which I\\'ll cover later\\n\\n```ts\\n// declaring enum in database\\nexport const popularityEnum = createEnum({ alias: \\'popularity\\', values: [\\'unknown\\', \\'known\\', \\'popular\\'] });\\n\\nexport class CountriesTable extends PgTable<CountriesTable> {\\n  id = this.serial(\"id\").primaryKey();\\n  name = this.varchar(\"name\", { size: 256 })\\n\\n  // declaring index\\n  nameIndex = this.uniqueIndex(this.name)\\n\\n  public tableName(): string {\\n    return \\'countries\\';\\n  }\\n}\\n\\nexport class CitiesTable extends PgTable<CitiesTable> {\\n  id = this.serial(\"id\").primaryKey();\\n  name = this.varchar(\"name\", { size: 256 })\\n  countryId = this.int(\"country_id\").foreignKey(CountriesTable, (country) => country.id)\\n\\n  // declaring enum column in table\\n  popularity = this.type(popularityEnum, \"popularity\")\\n\\n  public tableName(): string {\\n    return \\'cities\\';\\n  }\\n}\\n```\\n\\nThis is quick start example of how you connect to the database and make your first query with typed result\\n\\n```ts\\nimport { drizzle, PgTable } from \\'drizzle-orm\\'\\n\\nexport class UsersTable extends PgTable<UsersTable> {\\n  public id = this.serial(\\'id\\').primaryKey();\\n  public fullName = this.text(\\'full_name\\');\\n  public phone = this.varchar(\\'phone\\', { size: 256 });\\n\\n  public tableName(): string {\\n    return \\'users\\';\\n  }\\n}\\nexport type User = InferType<UsersTable>\\n\\nconst db = await drizzle.connect(\"postgres://user:password@host:port/db\");\\nconst usersTable = new UsersTable(db);\\n\\nconst users: User[] = await usersTable.select().execute();\\n```\\n\\nThis is how you use `WHERE` statement with filters, run partial select queries, use `limit/offset` and `orderBy`\\n\\n```ts\\nawait table.select().where(\\n  eq(table.id, 42)\\n).execute();\\n\\n// you can combine filters with eq(...) or or(...)\\nawait table.select().where(\\n  and([eq(table.id, 42), eq(table.name, \"Dan\")])\\n).execute();\\n\\nawait table.select().where(\\n  or([eq(table.id, 42), eq(table.id, 1)])\\n).execute();\\n\\n// partial select\\nconst result = await table.select({\\n     mapped1: table.id,\\n     mapped2: table.name,\\n}).execute();\\nconst { mapped1, mapped2 } = result[0];\\n\\n// limit offset & order by\\nawait table.select().limit(10).offset(10).execute()\\nawait table.select().orderBy((table) => table.name, Order.ASC)\\nawait table.select().orderBy((table) => table.name, Order.DESC)\\n```\\n\\nThis is how you run `inserts`, `updates` and `deletes`\\n\\n```ts\\nconst result = await usersTable.insert({\\n  name: \"Andrew\",\\n  createdAt: new Date(),\\n}).execute();\\n\\nconst result = await usersTable.insertMany([{\\n  name: \"Andrew\",\\n  createdAt: new Date(),\\n}, {\\n  name: \"Dan\",\\n  createdAt: new Date(),\\n}]).execute();\\n\\nawait usersTable.update()\\n  .where(eq(usersTable.name, \\'Dan\\'))\\n  .set({ name: \\'Mr. Dan\\' })\\n  .execute();\\n\\nawait usersTable.delete()\\n  .where(eq(usersTable.name, \\'Dan\\'))\\n  .execute();\\n```\\n\\nOne of the most powerful features we have in our ORM are fully typed joins, compiler won\\'t let you make a mistake\\n\\n```ts\\nconst usersTable = new UsersTable(db);\\nconst citiesTable = new CitiesTable(db);\\n\\nconst result = await citiesTable.select()\\n  .leftJoin(usersTable, (cities, users) => eq(cities.userId, users.id))\\n  .where((cities, users) => eq(cities.id, 1))\\n  .execute();\\n\\nconst citiesWithUsers: { city: City, user: User }[] = result.map((city, user) => ({ city, user }));\\n```\\n\\nHere\\'s a `many to many` relationship example\\n\\n```ts\\nexport class UsersTable extends PgTable<UsersTable> {\\n  id = this.serial(\"id\").primaryKey();\\n    name = this.varchar(\"name\");\\n}\\n\\nexport class ChatGroupsTable extends PgTable<ChatGroupsTable> {\\n  id = this.serial(\"id\").primaryKey();\\n}\\n\\nexport class ManyToManyTable extends PgTable<ManyToManyTable> {\\n  userId = this.int(\\'user_id\\').foreignKey(UsersTable, (table) => table.id, { onDelete: \\'CASCADE\\' });\\n  groupId = this.int(\\'group_id\\').foreignKey(ChatGroupsTable, (table) => table.id, { onDelete: \\'CASCADE\\' });\\n}\\n\\n...\\nconst usersTable = new UsersTable(db);\\nconst chatGroupsTable = new ChatGroupsTable(db);\\nconst manyToManyTable = new ManyToManyTable(db);\\n\\n// querying user group with id 1 and all the participants(users)\\nconst usersWithUserGroups = await manyToManyTable.select()\\n  .leftJoin(usersTable, (manyToMany, users) => eq(manyToManyTable.userId, users.id))\\n  .leftJoin(chatGroupsTable, (manyToMany, _users, chatGroups) => eq(manyToManyTable.groupId, chatGroups.id))\\n  .where((manyToMany, _users, userGroups) => eq(userGroups.id, 1))\\n  .execute();\\n```\\n\\nLast but not least are migrations. We\\'ve implemented a CLI tool for automatic migrations generation, which does handle renames and deletes by prompting you to resolve.\\n\\nFor a typescript schema below\\n\\n<Section>\\n```ts\\nimport { PgTable } from \"drizzle-orm\";\\n\\nexport class UsersTable extends PgTable<UsersTable> {\\n  public id = this.serial(\"id\").primaryKey();\\n  public fullName = this.varchar(\"full_name\", { size: 256 });\\n\\n  public fullNameIndex = this.index(this.fullName);\\n\\n  public tableName(): string {\\n    return \"users\";\\n  }\\n}\\n\\nexport class AuthOtpTable extends PgTable<AuthOtpTable> {\\n  public id = this.serial(\"id\").primaryKey();\\n  public phone = this.varchar(\"phone\", { size: 256 });\\n  public userId = this.int(\"user_id\").foreignKey(UsersTable, (t) => t.id);\\n\\n  public tableName(): string {\\n    return \"auth_otp\";\\n  }\\n}\\n```\\n\\n```sql\\n-- SQL migration\\nCREATE TABLE IF NOT EXISTS auth_otp (\\n    \"id\" SERIAL PRIMARY KEY,\\n    \"phone\" character varying(256),\\n    \"user_id\" INT\\n);\\n\\nCREATE TABLE IF NOT EXISTS users (\\n    \"id\" SERIAL PRIMARY KEY,\\n    \"full_name\" character varying(256)\\n);\\n\\nDO $$ BEGIN\\n ALTER TABLE auth_otp ADD CONSTRAINT auth_otp_user_id_fkey FOREIGN KEY (\"user_id\") REFERENCES users(id);\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n\\nCREATE INDEX IF NOT EXISTS users_full_name_index ON users (full_name);\\n```\\n</Section>\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0162.mdx'), name='drizzle-orm-v0162.mdx', displayName='drizzle-orm-v0162.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.16.2 release\\npubDate: 2023-01-21\\ndescription: Drizzle ORM - is an idiomatic TypeScript ORM which can be used as query builder and as an ORM being the source of truth for SQL schema and CLI for automatic migrations generation.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\nDrizzle ORM - is an idiomatic TypeScript ORM which can be used as query builder and as an ORM being the source of truth for SQL schema and CLI for automatic migrations generation.\\n\\nSince last major update we\\'ve added numerous requested features ðŸš€\\n\\n### ðŸŽ‰ PostgreSQL schemas\\n\\nYou can now declare [PostgreSQL schemas](https://www.postgresql.org/docs/current/ddl-schemas.html) and tables to be created within this schema\\n\\n<Section>\\n```ts copy\\n// src/schema.ts\\nimport { pgSchema } from \"drizzle-orm-pg\";\\n\\nexport const mySchema = pgSchema(\"my_schema\");\\n\\nexport const users = mySchema(\"users\", {\\n  id: serial(\"id\").primaryKey(),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n});\\n```\\n```sql\\nCREATE SCHEMA \"my_schema\";\\n\\nCREATE TABLE IF NOT EXISTS \"my_schema\".\"users\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text,\\n\\t\"email\" text\\n);\\n```\\n</Section>\\n\\n[drizzle-kit](https://driz.link/kit) will automatically generate all needed SQL migrations\\n\\n ```shell \\ndrizzle-kit generate:pg --schema=src/schema.ts --out=migrations/ \\n ```\\n\\n### ðŸŽ‰ MySQL databases/schemas\\n\\nYou can now declare [MySQL databases/schemas](https://dev.mysql.com/doc/refman/8.0/en/create-database.html) and tables to be created within it\\n\\n```ts copy\\n// schema.ts\\nimport { mysqlSchema } from \"drizzle-orm-mysql\";\\n\\nconst mySchema = mysqlSchema(\"my_schema\");\\n\\nconst users = mySchema(\"users\", {\\n  id: serial(\"id\").primaryKey(),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n});\\n```\\n\\n[drizzle-kit](https://driz.link/kit) will automatically generate all needed SQL migrations ```shell drizzle-kit\\ngenerate:mysql --schema=src/schema.ts --out=migrations/ ```\\n\\nwhich will automatically generate you SQL migration\\n\\n```sql\\nCREATE DATABASE `my_schema`;\\n\\nCREATE TABLE `my_schema`.`users` (\\n\\t`id` serial PRIMARY KEY NOT NULL,\\n\\t`name` text,\\n\\t`email` text\\n);\\n```\\n\\n### ðŸŽ‰ PostgreSQL introspect\\n\\nYou can now pull database schema from your existing PostgreSQL database within seconds with [drizzle-kit](https://driz.link/kit), this vanishes mostly any friction for you to switch from any existing orm or vanilla SQL.\\nIt supports:\\n\\n- enums\\n- tables with all native and non-native columns\\n- indexes\\n- foreign keys, self references and cyclic fks\\n- schemas\\n\\n```shell\\ndrizzle-kit introspect:pg --out=migrations/ --connectionString=postgresql://user:pass@host:port/db_name\\n```\\n\\nit will print you `schema.ts`\\n\\n```ts copy\\nexport const myEnum = pgEnum(\"my_enum\", [\"one\", \"two\", \"three\"]);\\nexport const mySchema = pgSchema(\"my_schema\");\\n\\nexport const users = mySchema(\"users\", {\\n  id: serial(\"id\").primaryKey(),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n});\\n\\nexport const users2 = pgTable(\"users2\", {\\n  id: serial(\"id\").primaryKey(),\\n  name: varchar(\"name2\"),\\n  enum: myEnum(\"enum\"),\\n});\\n\\nexport const allColumns = pgTable(\"all_columns\", {\\n  sm: smallint(\"smallint\"),\\n  smdef: smallint(\"smallint_def\").default(10),\\n  int: integer(\"integer\"),\\n  intdef: integer(\"integer_def\").default(10),\\n  numeric: numeric(\"numeric\"),\\n  numeric2: numeric(\"numeric2\", { precision: 7 }),\\n  numeric3: numeric(\"numeric3\", { scale: 7 }),\\n  numeric4: numeric(\"numeric4\", { precision: 7, scale: 7 }),\\n  numericdef: numeric(\"numeridef\").default(\"100\"),\\n  bigint: bigint(\"bigint\", { mode: \"number\" }),\\n  bigintdef: bigint(\"bigint\", { mode: \"number\" }).default(100),\\n  bool: boolean(\"boolean\"),\\n  booldef: boolean(\"boolean_def\").default(true),\\n  text: text(\"text\"),\\n  textdef: text(\"textdef\").default(\"text\"),\\n  varchar: varchar(\"varchar\"),\\n  varchardef: varchar(\"varchardef\").default(\"text\"),\\n  serial: serial(\"serial\"),\\n  bigserial: bigserial(\"bigserial\", { mode: \"bigint\" }),\\n  decimal: decimal(\"decimal\", { precision: 100, scale: 2 }),\\n  decimaldef: decimal(\"decimaldef\", { precision: 100, scale: 2 }).default(\\n    \"100.0\",\\n  ),\\n  doublePrecision: doublePrecision(\"decimal\"),\\n  doublePrecisiondef: doublePrecision(\"decimaldef\").default(100.0),\\n  real: real(\"real\"),\\n  realdef: real(\"decimaldef\").default(100.0),\\n  json: json<{ attr: string }>(\"json\"),\\n  jsondef: json<{ attr: string }>(\"jsondef\").default({ attr: \"value\" }),\\n  jsonb: jsonb<{ attr: string }>(\"jsonb\"),\\n  jsonbdef: jsonb<{ attr: string }>(\"jsonbdef\").default({ attr: \"value\" }),\\n  time: time(\"time\"),\\n  time2: time(\"time2\", { precision: 6, withTimezone: true }),\\n  timedefnow: time(\"timedefnow\").defaultNow(),\\n  timestamp: timestamp(\"timestamp\"),\\n  timestamp2: timestamp(\"timestamp2\", { precision: 6, withTimezone: true }),\\n  timestamp3: timestamp(\"timestamp3\", { withTimezone: true }),\\n  timestamp4: timestamp(\"timestamp4\", { precision: 4 }),\\n  timestampdef: timestamp(\"timestampdef\").defaultNow(),\\n  date: date(\"date\", { mode: \"date\" }),\\n  datedef: date(\"datedef\").defaultNow(),\\n  interval: interval(\"interval\"),\\n  intervaldef: interval(\"intervaldef\").default(\"10 days\"),\\n});\\n\\nexport const cyclic1 = pgTable(\"cyclic1\", {\\n  id: serial(\"id\").primaryKey(),\\n  ext2: integer(\"ext2\").references(() => cyclic2.id),\\n});\\n\\nexport const cyclic2 = pgTable(\"cyclic2\", {\\n  id: serial(\"id\").primaryKey(),\\n  ext1: integer(\"ext1\").references((): AnyPgColumn => cyclic1.id),\\n});\\n\\nexport const example = pgTable(\\n  \"example\",\\n  {\\n    id: serial(\"id\").primaryKey(),\\n    reportsTo: integer(\"reports_to\"),\\n  },\\n  (table) => {\\n    return {\\n      reportsToFK: foreignKey({\\n        columns: [table.reportsTo],\\n        foreignColumns: [table.id],\\n      }),\\n    };\\n  },\\n);\\n```\\n\\n### ðŸŽ‰ Postgres.js driver support\\n\\nWe\\'ve added full support for [postgres.js](https://github.com/porsager/postgres), it is lightweight and it is fast ðŸš€\\n\\n```ts copy\\n// schema.ts\\nimport { pgTable, serial, text, varchar } from \"drizzle-orm-pg\";\\nexport const users = pgTable(\"users\", {\\n  id: serial(\"id\").primaryKey(),\\n  fullName: text(\"full_name\"),\\n  phone: varchar(\"phone\", { length: 256 }),\\n});\\n\\n// index.ts\\nimport { drizzle, PostgresJsDatabase } from \"drizzle-orm-pg/postgres.js\";\\nimport postgres from \"postgres\";\\nimport { users } from \"./schema\";\\n\\nconst client = postgres(connectionString);\\nconst db: PostgresJsDatabase = drizzle(client);\\n\\nconst allUsers = await db.select(users);\\n```\\n\\nFull PostgreSQL docs see [here](https://github.com/drizzle-team/drizzle-orm/tree/main/drizzle-orm-pg)\\n\\n### ðŸŽ‰ PostgreSQL and MySQL types\\n\\nWe\\'ve added useful operators for you to create any needed non-native PostgreSQL or MySQL types\\n\\n```ts copy\\n// PostgreSQL\\nconst customText = customType<{ data: string }>({\\n  dataType() {\\n    return \"text\";\\n  },\\n});\\n\\nconst usersTable = pgTable(\"users\", {\\n  name: customText(\"name\").notNull(),\\n});\\n\\n// MySQL\\nconst customText = customType<{ data: string }>({\\n  dataType() {\\n    return \"text\";\\n  },\\n});\\n\\nconst usersTable = mysqlTable(\"users\", {\\n  name: customText(\"name\").notNull(),\\n});\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0272.mdx'), name='drizzle-orm-v0272.mdx', displayName='drizzle-orm-v0272.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.27.2 release\\npubDate: 2023-07-12\\ndescription: Added support for unique constraints in PostgreSQL, MySQL, SQLite.\\n---\\n\\n## ðŸŽ‰ Added support for `UNIQUE` constraints in PostgreSQL, MySQL, SQLite\\n\\nFor PostgreSQL, unique constraints can be defined at the column level for single-column constraints, and in the third parameter for multi-column constraints. In both cases, it will be possible to define a custom name for the constraint. Additionally, PostgreSQL will receive the `NULLS NOT DISTINCT` option to restrict having more than one NULL value in a table. [Reference](https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-UNIQUE-CONSTRAINTS)\\n\\nExamples that just shows a different `unique` usage. Please don't search a real usage for those tables\\n\\n```ts copy\\n// single column\\nconst table = pgTable('table', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull().unique(),\\n  state: char('state', { length: 2 }).unique('custom'),\\n  field: char('field', { length: 2 }).unique('custom_field', { nulls: 'not distinct' }),\\n});\\n// multiple columns\\nconst table = pgTable('table', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull(),\\n  state: char('state', { length: 2 }),\\n}, (t) => ({\\n  first: unique('custom_name').on(t.name, t.state).nullsNotDistinct(),\\n  second: unique('custom_name1').on(t.name, t.state),\\n}));\\n```\\n\\nFor MySQL, everything will be the same except for the `NULLS NOT DISTINCT` option. It appears that MySQL does not support it\\n\\nExamples that just shows a different `unique` usage. Please don't search a real usage for those tables\\n\\n```ts copy\\n// single column\\nconst table = mysqlTable('table', {\\n    id: serial('id').primaryKey(),\\n    name: text('name').notNull().unique(),\\n    state: text('state').unique('custom'),\\n    field: text('field').unique('custom_field'),\\n});\\n// multiple columns\\nconst table = mysqlTable('cities1', {\\n    id: serial('id').primaryKey(),\\n    name: text('name').notNull(),\\n    state: text('state'),\\n}, (t) => ({\\n    first: unique().on(t.name, t.state),\\n    second: unique('custom_name1').on(t.name, t.state),\\n}));\\n```\\n\\nIn SQLite unique constraints are the same as unique indexes. As long as you can specify a name for the unique index in SQLite - we will treat all unique constraints as unique indexes in internal implementation\\n\\n```ts copy\\n// single column\\nconst table = sqliteTable('table', {\\n    id: int('id').primaryKey(),\\n    name: text('name').notNull().unique(),\\n    state: text('state').unique('custom'),\\n    field: text('field').unique(),\\n});\\n// multiple columns\\nconst table = sqliteTable('table', {\\n    id: int('id').primaryKey(),\\n    name: text('name').notNull(),\\n    state: text('state'),\\n}, (t) => ({\\n    first: unique().on(t.name, t.state),\\n    second: unique('custom').on(t.name, t.state),\\n}));\\n```\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0280.mdx'), name='drizzle-orm-v0280.mdx', displayName='drizzle-orm-v0280.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.28.0 release\\npubDate: 2023-08-06\\ndescription: Removed support for filtering by nested relations, Added Relational Queries mode config for mysql2 driver, improved IntelliSense performance for large schemas, improved Relational Queries Permormance and Read Usage. Added possibility to insert rows with default values for all columns.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\n## Breaking changes\\n\\n### Removed support for filtering by nested relations\\n\\nCurrent example won\\'t work in `0.28.0`:\\n\\n```ts\\nconst usersWithPosts = await db.query.users.findMany({\\n  where: (table, { sql }) => (sql`json_array_length(${table.posts}) > 0`),\\n  with: {\\n    posts: true,\\n  },\\n});\\n```\\n\\nThe `table` object in the `where` callback won\\'t have fields from `with` and `extras`. We removed them to be able to build more efficient relational queries, which improved row reads and performance.\\n\\nIf you have used those fields in the `where` callback before, there are several workarounds:\\n\\n1. Applying those filters manually on the code level after the rows are fetched;\\n2. Using the core API.\\n\\n### Added Relational Queries `mode` config for `mysql2` driver\\n\\nDrizzle relational queries always generate exactly one SQL statement to run on the database and it has certain caveats. To have best in class support for every database out there we\\'ve introduced modes.\\n\\nDrizzle relational queries use lateral joins of subqueries under the hood and for now PlanetScale does not support them.\\n\\nWhen using `mysql2` driver with regular MySQL database - you should specify mode: \"default\".\\nWhen using `mysql2` driver with PlanetScale - you need to specify mode: \"planetscale\".\\n\\n```ts copy {9}\\nimport { drizzle } from \\'drizzle-orm/mysql2\\';\\nimport mysql from \\'mysql2/promise\\';\\nimport * as schema from \\'./schema\\';\\n\\nconst client = await mysql.createConnection({\\n  uri: process.env.PLANETSCALE_DATABASE_URL,\\n});\\n\\nconst db = drizzle({ client, schema, mode: \\'planetscale\\' });\\n```\\n\\n## Improved IntelliSense performance for large schemas\\n\\nWe\\'ve run the diagnostics on a database schema with 85 tables, 666 columns, 26 enums, 172 indexes and 133 foreign keys. We\\'ve optimized internal types which resulted in **430%** speed up in IntelliSense.\\n\\n## Improved Relational Queries Permormance and Read Usage\\n\\nIn this release we\\'ve fully changed a way query is generated for Relational Queri API.\\n\\nAs a summary we\\'ve made current set of changes in query generation startegy:\\n\\n1. Lateral Joins: In the new version we\\'re utilizing lateral joins, denoted by the \"LEFT JOIN LATERAL\" clauses, to retrieve specific data from related tables efficiently For MySQL in PlanetScale and SQLite, we\\'ve used simple subquery selects, which improved a query plan and overall performance\\n\\n2. Selective Data Retrieval: In the new version we\\'re retrieving only the necessary data from tables. This targeted data retrieval reduces the amount of unnecessary information fetched, resulting in a smaller dataset to process and faster execution.\\n\\n3. Reduced Aggregations: In the new version we\\'ve reduced the number of aggregation functions (e.g., COUNT, json_agg). By using json_build_array directly within the lateral joins, drizzle is aggregating the data in a more streamlined manner, leading to improved query performance.\\n\\n4. Simplified Grouping: In the new version the GROUP BY clause is removed, as the lateral joins and subqueries already handle data aggregation more efficiently.\\n\\nFor this drizzle query\\n\\n<Section>\\n```ts copy\\nconst items = await db.query.comments.findMany({\\n  limit,\\n  orderBy: comments.id,\\n  with: {\\n    user: {\\n      columns: { name: true },\\n    },\\n    post: {\\n      columns: { title: true },\\n      with: {\\n        user: {\\n          columns: { name: true },\\n        },\\n      },\\n    },\\n  },\\n});\\n```\\n\\n```sql\\n-- Query generated now\\nselect \"comments\".\"id\",\\n       \"comments\".\"user_id\",\\n       \"comments\".\"post_id\",\\n       \"comments\".\"content\",\\n       \"comments_user\".\"data\" as \"user\",\\n       \"comments_post\".\"data\" as \"post\"\\nfrom \"comments\"\\n         left join lateral (select json_build_array(\"comments_user\".\"name\") as \"data\"\\n                            from (select *\\n                                  from \"users\" \"comments_user\"\\n                                  where \"comments_user\".\"id\" = \"comments\".\"user_id\"\\n                                  limit 1) \"comments_user\") \"comments_user\" on true\\n         left join lateral (select json_build_array(\"comments_post\".\"title\", \"comments_post_user\".\"data\") as \"data\"\\n                            from (select *\\n                                  from \"posts\" \"comments_post\"\\n                                  where \"comments_post\".\"id\" = \"comments\".\"post_id\"\\n                                  limit 1) \"comments_post\"\\n                                     left join lateral (select json_build_array(\"comments_post_user\".\"name\") as \"data\"\\n                                                        from (select *\\n                                                              from \"users\" \"comments_post_user\"\\n                                                              where \"comments_post_user\".\"id\" = \"comments_post\".\"user_id\"\\n                                                              limit 1) \"comments_post_user\") \"comments_post_user\"\\n                                               on true) \"comments_post\" on true\\norder by \"comments\".\"id\"\\nlimit 1\\n```\\n\\n```sql\\n-- Query generated before\\nSELECT \"id\",\\n       \"user_id\",\\n       \"post_id\",\\n       \"content\",\\n       \"user\"::JSON,\\n       \"post\"::JSON\\nFROM\\n  (SELECT \"comments\".*,\\n          CASE\\n              WHEN count(\"comments_post\".\"id\") = 0 THEN \\'[]\\'\\n              ELSE json_agg(json_build_array(\"comments_post\".\"title\", \"comments_post\".\"user\"::JSON))::text\\n          END AS \"post\"\\n   FROM\\n     (SELECT \"comments\".*,\\n             CASE\\n                 WHEN count(\"comments_user\".\"id\") = 0 THEN \\'[]\\'\\n                 ELSE json_agg(json_build_array(\"comments_user\".\"name\"))::text\\n             END AS \"user\"\\n      FROM \"comments\"\\n      LEFT JOIN\\n        (SELECT \"comments_user\".*\\n         FROM \"users\" \"comments_user\") \"comments_user\" ON \"comments\".\"user_id\" = \"comments_user\".\"id\"\\n      GROUP BY \"comments\".\"id\",\\n               \"comments\".\"user_id\",\\n               \"comments\".\"post_id\",\\n               \"comments\".\"content\") \"comments\"\\n   LEFT JOIN\\n     (SELECT \"comments_post\".*\\n      FROM\\n        (SELECT \"comments_post\".*,\\n                CASE\\n                    WHEN count(\"comments_post_user\".\"id\") = 0 THEN \\'[]\\'\\n                    ELSE json_agg(json_build_array(\"comments_post_user\".\"name\"))\\n                END AS \"user\"\\n         FROM \"posts\" \"comments_post\"\\n         LEFT JOIN\\n           (SELECT \"comments_post_user\".*\\n            FROM \"users\" \"comments_post_user\") \"comments_post_user\" ON \"comments_post\".\"user_id\" = \"comments_post_user\".\"id\"\\n         GROUP BY \"comments_post\".\"id\") \"comments_post\") \"comments_post\" ON \"comments\".\"post_id\" = \"comments_post\".\"id\"\\n   GROUP BY \"comments\".\"id\",\\n            \"comments\".\"user_id\",\\n            \"comments\".\"post_id\",\\n            \"comments\".\"content\",\\n            \"comments\".\"user\") \"comments\"\\nLIMIT 1\\n```\\n</Section>\\n\\nRead more about [Relational Queries](/docs/rqb) in the documentation.\\n\\n## Possibility to insert rows with default values for all columns\\n\\nYou can now provide an empty object or an array of empty objects, and Drizzle will insert all defaults into the database.\\n\\n```ts copy {2,5}\\n// Insert 1 row with all defaults\\nawait db.insert(usersTable).values({});\\n\\n// Insert 2 rows with all defaults\\nawait db.insert(usersTable).values([{}, {}]);\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0281.mdx'), name='drizzle-orm-v0281.mdx', displayName='drizzle-orm-v0281.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.28.1 release\\npubDate: 2023-08-07\\ndescription: Fixed Postgres array-related issues introduced by 0.28.0.\\n---\\n\\n## Fixes\\n\\n- Fixed Postgres array-related issues introduced by 0.28.0 ([#983](https://github.com/drizzle-team/drizzle-orm/issues/983), [#992](https://github.com/drizzle-team/drizzle-orm/issues/992))\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0282.mdx'), name='drizzle-orm-v0282.mdx', displayName='drizzle-orm-v0282.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.28.2 release\\npubDate: 2023-08-10\\ndescription: Added a set of tests for d1, fixed issues in internal documentation, resolved the issue of truncating timestamp milliseconds for MySQL, corrected the type of the '.get()' method for sqlite-based dialects, rectified the sqlite-proxy bug that caused the query to execute twice. Added a support for Typebox package.\\n---\\n\\n## The community contributions release ðŸŽ‰\\n\\n### Internal Features and Changes\\n- Added a set of tests for d1\\n- Fixed issues in internal documentation\\n\\n### Fixes\\n- Resolved the issue of truncating timestamp milliseconds for MySQL\\n- Corrected the type of the `.get()` method for sqlite-based dialects ([#565](https://github.com/drizzle-team/drizzle-orm/issues/565))\\n- Rectified the sqlite-proxy bug that caused the query to execute twice\\n\\n### New packages ðŸŽ‰\\n\\nAdded a support for [Typebox](https://github.com/sinclairzx81/typebox) in [drizzle-typebox](/docs/typebox) package.\\n\\nPlease check documentation page for more usage examples: /docs/typebox\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0283.mdx'), name='drizzle-orm-v0283.mdx', displayName='drizzle-orm-v0283.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.28.3 release\\npubDate: 2023-08-22\\ndescription: Added SQLite simplified query API, added methods to column builders and to table model type inference. Fixed sqlite-proxy and SQL.js response from \\'.get()\\' when the result is empty.\\n---\\n\\n## Fixes\\n\\n- Fixed sqlite-proxy and SQL.js response from `.get()` when the result is empty\\n\\n## New Features\\n\\n### ðŸŽ‰ Added SQLite simplified query API\\n\\n### ðŸŽ‰ Added `.$defaultFn()` / `.$default()` methods to column builders\\n\\nFor more information check docs for [PostgreSQL](/docs/column-types/pg#default-value), [MySQL](/docs/column-types/mysql#default-value) and [SQLite](/docs/column-types/sqlite#default-value).\\n\\nYou can specify any logic and any implementation for a function like `cuid()` for runtime defaults. Drizzle won\\'t limit you in the number of implementations you can add.\\n\\n> Note: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`\\n\\n```ts copy {5}\\nimport { varchar, mysqlTable } from \"drizzle-orm/mysql-core\";\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst table = mysqlTable(\\'table\\', {\\n\\tid: varchar(\\'id\\', { length: 128 }).$defaultFn(() => createId()),\\n});\\n```\\n\\n### ðŸŽ‰ Added `table.$inferSelect` / `table._.inferSelect` and `table.$inferInsert` / `table._.inferInsert` for more convenient table model type inference\\n\\n- ðŸ›  Deprecated `InferModel` type in favor of more explicit `InferSelectModel` and `InferInsertModel`\\n\\n```ts copy {11,12,14,15}\\nimport { InferSelectModel, InferInsertModel } from \\'drizzle-orm\\'\\n\\nconst usersTable = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  verified: boolean(\\'verified\\').notNull().default(false),\\n  jsonb: jsonb(\\'jsonb\\').$type<string[]>(),\\n  createdAt: timestamp(\\'created_at\\', { withTimezone: true }).notNull().defaultNow(),\\n});\\n\\ntype SelectUser = typeof usersTable.$inferSelect;\\ntype InsertUser = typeof usersTable.$inferInsert;\\n\\ntype SelectUser2 = InferSelectModel<typeof usersTable>;\\ntype InsertUser2 = InferInsertModel<typeof usersTable>;\\n```\\n\\n- ðŸ›  Disabled `.d.ts` files bundling\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0284.mdx'), name='drizzle-orm-v0284.mdx', displayName='drizzle-orm-v0284.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.28.4 release\\npubDate: 2023-08-24\\ndescription: Fixed imports in ESM-based projects and type error on Postgres table definitions.\\n---\\n\\n## Fixes: \\n\\n- Fixed imports in ESM-based projects ([#1088](https://github.com/drizzle-team/drizzle-orm/issues/1088))\\n- Fixed type error on Postgres table definitions ([#1089](https://github.com/drizzle-team/drizzle-orm/issues/1089))\\n\\nâš  If you are facing a `Cannot find package '@opentelemetry/api'` error, please update to `0.28.5`, it's fixed there.\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0285.mdx'), name='drizzle-orm-v0285.mdx', displayName='drizzle-orm-v0285.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.28.5 release\\npubDate: 2023-08-24 12:00:00\\ndescription: Fixed incorrect OpenTelemetry type import that caused a runtime error.\\n---\\n\\n## Fixes\\n\\n- Fixed incorrect OpenTelemetry type import that caused a runtime error\\n\\nThe OpenTelemetry logic currently present in the ORM isn't meant to be used by Drizzle and no stats have ever been collected by Drizzle using drizzle-orm. OpenTelemetry is simply a protocol. If you take a look at the actual code that utilizes it in drizzle-orm, it simply uses the tracer to collect the query stats and doesn't send it anywhere. It was designed for the ORM users to be able to send those stats to their own telemetry consumers.\\n\\nThe important thing is - the OpenTelemetry logic is disabled on the current version. It literally does nothing. We experimented with it at some point in the past, but disabled it before the release.\\n\\nAs to the reason of the issue in the last release: it happened because of an incorrect type import on [this line](https://github.com/drizzle-team/drizzle-orm/blob/594e96538e588fee5748e372884dbaf32c331524/drizzle-orm/src/tracing.ts#L1). We've used `import { type ... }` syntax instead of `import type { ... }`, which resulted in the `import '@opentelemetry/api'` line leaking to the runtime.\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0286.mdx'), name='drizzle-orm-v0286.mdx', displayName='drizzle-orm-v0286.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.28.6 release\\npubDate: 2023-09-06\\ndescription: Changed datetime mapping for MySQL, added LibSQL batch API support, added JSON mode for text in SQLite, added \\'.toSQL()\\' to Relational Query API calls, added new PostgreSQL operators for Arrays, added more SQL operators for the \\'where\\' function in Relational Queries, and fixed bugs.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\n## Changes\\n\\n> **Note**:\\n> MySQL `datetime` with `mode: \\'date\\'` will now store dates in UTC strings and retrieve data in UTC as well to align with MySQL behavior for `datetime`. If you need a different behavior and want to handle `datetime` mapping in a different way, please use `mode: \\'string\\'` or [Custom Types](/docs/custom-types) implementation\\n\\nCheck [Fix Datetime mapping for MySQL](https://github.com/drizzle-team/drizzle-orm/pull/1082) for implementation details\\n\\n## New Features\\n\\n### ðŸŽ‰ `LibSQL` batch api support\\n\\nReference: https://docs.turso.tech/reference/client-access/javascript-typescript-sdk#execute-a-batch-of-statements\\n\\nBatch API usage example:\\n\\n<Section>\\n```ts copy {1}\\nconst batchResponse = await db.batch([\\n\\tdb.insert(usersTable).values({ id: 1, name: \\'John\\' }).returning({\\n\\t\\tid: usersTable.id,\\n\\t}),\\n\\tdb.update(usersTable).set({ name: \\'Dan\\' }).where(eq(usersTable.id, 1)),\\n\\tdb.query.usersTable.findMany({}),\\n\\tdb.select().from(usersTable).where(eq(usersTable.id, 1)),\\n\\tdb.select({ id: usersTable.id, invitedBy: usersTable.invitedBy }).from(\\n\\t\\tusersTable,\\n\\t),\\n]);\\n```\\n\\n```ts\\ntype BatchResponse = [\\n\\t{\\n\\t\\tid: number;\\n\\t}[],\\n\\tResultSet,\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n];\\n```\\n</Section>\\n\\nAll possible builders that can be used inside `db.batch`:\\n\\n```ts\\n`db.all()`,\\n`db.get()`,\\n`db.values()`,\\n`db.run()`,\\n`db.query.<table>.findMany()`,\\n`db.query.<table>.findFirst()`,\\n`db.select()...`,\\n`db.update()...`,\\n`db.delete()...`,\\n`db.insert()...`,\\n```\\n\\nMore usage examples here: [integration-tests/tests/libsql-batch.test.ts](https://github.com/drizzle-team/drizzle-orm/pull/1161/files#diff-17253895532e520545027dd48dcdbac2d69a5a49d594974e6d55d7502f89b838R248) and in [docs](/docs/batch-api)\\n\\n### ðŸŽ‰ Add json mode for text in SQLite\\n\\nRead more in [docs](/docs/get-started-postgresql#http-proxy)\\n\\n```ts copy {2}\\nconst test = sqliteTable(\\'test\\', {\\n\\tdataTyped: text(\\'data_typed\\', { mode: \\'json\\' }).$type<{ a: 1 }>().notNull(),\\n});\\n```\\n\\n### ðŸŽ‰ Add `.toSQL()` to Relational Query API calls\\n\\n```ts copy {1}\\nconst query = db.query.usersTable.findFirst().toSQL();\\n```\\n\\n### ðŸŽ‰ Added new PostgreSQL operators for Arrays\\n\\nList of operators and usage examples\\n`arrayContains`, `arrayContained`, `arrayOverlaps`\\n\\nRead more in [docs](/docs/get-started-postgresql#http-proxy)\\n\\n```ts copy {2,5,8,11,12,13,14}\\nconst contains = await db.select({ id: posts.id }).from(posts)\\n\\t.where(arrayContains(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n\\nconst contained = await db.select({ id: posts.id }).from(posts)\\n\\t.where(arrayContained(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n\\nconst overlaps = await db.select({ id: posts.id }).from(posts)\\n\\t.where(arrayOverlaps(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n\\nconst withSubQuery = await db.select({ id: posts.id }).from(posts)\\n\\t.where(arrayContains(\\n\\t\\tposts.tags,\\n\\t\\tdb.select({ tags: posts.tags }).from(posts).where(eq(posts.id, 1)),\\n\\t));\\n```\\n\\n### ðŸŽ‰ Add more SQL operators for where filter function in Relational Queries\\n\\nYou can find more examples in [docs](/docs/rqb#select-filters)\\n\\n<Section>\\n```ts\\n// Before\\nimport { inArray } from \"drizzle-orm/pg-core\";\\n\\nawait db.users.findFirst({\\n  where: (table, _) => inArray(table.id, [ ... ])\\n})\\n```\\n\\n```ts copy {3}\\n// After\\nawait db.users.findFirst({\\n  where: (table, { inArray }) => inArray(table.id, [ ... ])\\n})\\n```\\n</Section>\\n\\n## Fixes\\n\\n- Correct where in on conflict in sqlite ([#1076](https://github.com/drizzle-team/drizzle-orm/pull/1076))\\n- Fix libsql/client type import ([#1122](https://github.com/drizzle-team/drizzle-orm/pull/1122))\\n- Fix: raw sql query not being mapped properly on RDS ([#1071](https://github.com/drizzle-team/drizzle-orm/pull/1071))\\n- Fix Datetime mapping for MySQL ([#1082](https://github.com/drizzle-team/drizzle-orm/pull/1082))\\n- Fix smallserial generating as serial ([#1127](https://github.com/drizzle-team/drizzle-orm/pull/1127))\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0290.mdx'), name='drizzle-orm-v0290.mdx', displayName='drizzle-orm-v0290.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.29.0 release\\npubDate: 2023-11-09\\ndescription: Added new features like unsigned option for bigint in MySQL, improved query builder types, added possibility to specify name for primary keys and foreign keys, read replicas support, set operators support, new MySQL and PostgreSQL proxy drivers, D1 Batch API support.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\n> Drizzle ORM version `0.29.0` will require a minimum Drizzle Kit version of `0.20.0`, and vice versa. Therefore, when upgrading to a newer version of Drizzle ORM, you will also need to upgrade Drizzle Kit. This may result in some breaking changes throughout the versions, especially if you need to upgrade Drizzle Kit and your Drizzle ORM version is older than `<0.28.0`\\n\\n## New Features\\n\\n### ðŸŽ‰ MySQL `unsigned` option for bigint\\n\\nYou can now specify `bigint unsigned` type\\n\\n```ts copy {2}\\nconst table = mysqlTable(\\'table\\', {\\n  id: bigint(\\'id\\', { mode: \\'number\\', unsigned: true }),\\n});\\n```\\n\\nRead more in [docs](/docs/column-types/mysql#bigint)\\n\\n### ðŸŽ‰ Improved query builder types\\n\\nStarting from `0.29.0` by default, as all the query builders in Drizzle try to conform to SQL as much as possible, you can only invoke most of the methods once. For example, in a SELECT statement there might only be one WHERE clause, so you can only invoke .where() once:\\n\\n```ts copy {5}\\nconst query = db\\n  .select()\\n  .from(users)\\n  .where(eq(users.id, 1))\\n  .where(eq(users.name, \\'John\\')); // âŒ Type error - where() can only be invoked once\\n```\\n\\nThis behavior is useful for conventional query building, i.e. when you create the whole query at once. However, it becomes a problem when you want to build a query dynamically, i.e. if you have a shared function that takes a query builder and enhances it. To solve this problem, Drizzle provides a special \\'dynamic\\' mode for query builders, which removes the restriction of invoking methods only once. To enable it, you need to call .$dynamic() on a query builder.\\n\\nLet\\'s see how it works by implementing a simple withPagination function that adds LIMIT and OFFSET clauses to a query based on the provided page number and an optional page size:\\n\\n```ts copy {12,13}\\nfunction withPagination<T extends PgSelect>(\\n  qb: T,\\n  page: number,\\n  pageSize: number = 10,\\n) {\\n  return qb.limit(pageSize).offset(page * pageSize);\\n}\\n\\nconst query = db.select().from(users).where(eq(users.id, 1));\\nwithPagination(query, 1); // âŒ Type error - the query builder is not in dynamic mode\\n\\nconst dynamicQuery = query.$dynamic();\\nwithPagination(dynamicQuery, 1); // âœ… OK\\n```\\n\\nNote that the withPagination function is generic, which allows you to modify the result type of the query builder inside it, for example by adding a join:\\n\\n```ts copy {2}\\nfunction withFriends<T extends PgSelect>(qb: T) {\\n  return qb.leftJoin(friends, eq(friends.userId, users.id));\\n}\\n\\nlet query = db.select().from(users).where(eq(users.id, 1)).$dynamic();\\nquery = withFriends(query);\\n```\\n\\nRead more in [docs](/docs/dynamic-query-building)\\n\\n### ðŸŽ‰ Possibility to specify name for primary keys and foreign keys\\n\\nThere is an issue when constraint names exceed the 64-character limit of the database. This causes the database engine to truncate the name, potentially leading to issues. Starting from `0.29.0`, you have the option to specify custom names for both `primaryKey()` and `foreignKey()`. We have also deprecated the old `primaryKey()` syntax, which can still be used but will be removed in future releases\\n\\n```ts copy {5,7}\\nconst table = pgTable(\\'table\\', {\\n  id: integer(\\'id\\'),\\n  name: text(\\'name\\'),\\n}, (table) => ({\\n  cpk: primaryKey({ name: \\'composite_key\\', columns: [table.id, table.name] }),\\n  cfk: foreignKey({\\n    name: \\'fkName\\',\\n    columns: [table.id],\\n    foreignColumns: [table.name],\\n  }),\\n}));\\n```\\n\\nRead more in [docs](/docs/indexes-constraints#composite-primary-key)\\n\\n### ðŸŽ‰ Read Replicas Support\\n\\nYou can now use the Drizzle `withReplica` function to specify different database connections for read replicas and the main instance for write operations. By default, `withReplicas` will use a random read replica for read operations and the main instance for all other data modification operations. You can also specify custom logic for choosing which read replica connection to use. You have the freedom to make any weighted, custom decision for that. Here are some usage examples:\\n\\n```ts copy {5}\\nconst primaryDb = drizzle({ client });\\nconst read1 = drizzle({ client });\\nconst read2 = drizzle({ client });\\n\\nconst db = withReplicas(primaryDb, [read1, read2]);\\n\\n// read from primary\\ndb.$primary.select().from(usersTable);\\n\\n// read from either read1 connection or read2 connection\\ndb.select().from(usersTable)\\n\\n// use primary database for delete operation\\ndb.delete(usersTable).where(eq(usersTable.id, 1))\\n```\\n\\nImplementation example of custom logic for selecting read replicas, where the first replica has a 70% chance of being chosen, and the second replica has a 30% chance of being chosen. Note that you can implement any type of random selection for read replicas\\n\\n```ts copy\\nconst db = withReplicas(primaryDb, [read1, read2], (replicas) => {\\n    const weight = [0.7, 0.3];\\n    let cumulativeProbability = 0;\\n    const rand = Math.random();\\n\\n    for (const [i, replica] of replicas.entries()) {\\n      cumulativeProbability += weight[i]!;\\n      if (rand < cumulativeProbability) return replica;\\n    }\\n    return replicas[0]!\\n});\\n```\\n\\n`withReplicas` function is available for all dialects in Drizzle ORM\\n\\nRead more in [docs](/docs/read-replicas)\\n\\n### ðŸŽ‰ Set operators support (UNION, UNION ALL, INTERSECT, INTERSECT ALL, EXCEPT, EXCEPT ALL)\\n\\nHuge thanks to @Angelelz for the significant contribution he made, from API discussions to proper type checks and runtime logic, along with an extensive set of tests. This greatly assisted us in delivering this feature in this release\\n\\nUsage examples:\\nAll set operators can be used in a two ways: `import approach` or `builder approach`\\n\\n<Section>\\n```ts copy {2,7}\\n// Import approach\\nimport { union } from \\'drizzle-orm/pg-core\\'\\n\\nconst allUsersQuery = db.select().from(users);\\nconst allCustomersQuery = db.select().from(customers);\\n\\nconst result = await union(allUsersQuery, allCustomersQuery)\\n```\\n\\n```ts copy {2}\\n// Builder approach\\nconst result = await db.select().from(users).union(db.select().from(customers));\\n```\\n</Section>\\n\\nRead more in [docs](/docs/set-operations)\\n\\n### ðŸŽ‰ New MySQL Proxy Driver\\n\\nA new driver has been released, allowing you to create your own implementation for an HTTP driver using a MySQL database. You can find usage examples in the `./examples/mysql-proxy` folder\\n\\nYou need to implement two endpoints on your server that will be used for queries and migrations(Migrate endpoint is optional and only if you want to use drizzle migrations). Both the server and driver implementation are up to you, so you are not restricted in any way. You can add custom mappings, logging, and much more\\n\\nYou can find both server and driver implementation examples in the `./examples/mysql-proxy` folder\\n\\n```ts copy {4,9}\\n// Driver\\nimport axios from \\'axios\\';\\nimport { eq } from \\'drizzle-orm/expressions\\';\\nimport { drizzle } from \\'drizzle-orm/mysql-proxy\\';\\nimport { migrate } from \\'drizzle-orm/mysql-proxy/migrator\\';\\nimport { cities, users } from \\'./schema\\';\\n\\nasync function main() {\\n  const db = drizzle(async (sql, params, method) => {\\n    try {\\n      const rows = await axios.post(`${process.env.REMOTE_DRIVER}/query`, {\\n        sql,\\n        params,\\n        method,\\n      });\\n\\n      return { rows: rows.data };\\n    } catch (e: any) {\\n      console.error(\\'Error from pg proxy server:\\', e.response.data);\\n      return { rows: [] };\\n    }\\n  });\\n\\n  await migrate(db, async (queries) => {\\n    try {\\n      await axios.post(`${process.env.REMOTE_DRIVER}/migrate`, { queries });\\n    } catch (e) {\\n      console.log(e);\\n      throw new Error(\\'Proxy server cannot run migrations\\');\\n    }\\n  }, { migrationsFolder: \\'drizzle\\' });\\n\\n  await db.insert(cities).values({ id: 1, name: \\'name\\' });\\n\\n  await db.insert(users).values({\\n    id: 1,\\n    name: \\'name\\',\\n    email: \\'email\\',\\n    cityId: 1,\\n  });\\n\\n  const usersToCityResponse = await db.select().from(users).leftJoin(\\n    cities,\\n    eq(users.cityId, cities.id),\\n  );\\n}\\n```\\n\\nRead more in [docs](/docs/get-started-mysql#http-proxy)\\n\\n### ðŸŽ‰ New PostgreSQL Proxy Driver\\n\\nSame as MySQL you can now implement your own http driver for PostgreSQL database. You can find usage examples in the `./examples/pg-proxy` folder\\n\\nYou need to implement two endpoints on your server that will be used for queries and migrations (Migrate endpoint is optional and only if you want to use drizzle migrations). Both the server and driver implementation are up to you, so you are not restricted in any way. You can add custom mappings, logging, and much more\\n\\nYou can find both server and driver implementation examples in the `./examples/pg-proxy` folder\\n\\n```ts copy {3,8}\\nimport axios from \\'axios\\';\\nimport { eq } from \\'drizzle-orm/expressions\\';\\nimport { drizzle } from \\'drizzle-orm/pg-proxy\\';\\nimport { migrate } from \\'drizzle-orm/pg-proxy/migrator\\';\\nimport { cities, users } from \\'./schema\\';\\n\\nasync function main() {\\n  const db = drizzle(async (sql, params, method) => {\\n    try {\\n      const rows = await axios.post(`${process.env.REMOTE_DRIVER}/query`, { sql, params, method });\\n\\n      return { rows: rows.data };\\n    } catch (e: any) {\\n      console.error(\\'Error from pg proxy server:\\', e.response.data);\\n      return { rows: [] };\\n    }\\n  });\\n\\n  await migrate(db, async (queries) => {\\n    try {\\n      await axios.post(`${process.env.REMOTE_DRIVER}/query`, { queries });\\n    } catch (e) {\\n      console.log(e);\\n      throw new Error(\\'Proxy server cannot run migrations\\');\\n    }\\n  }, { migrationsFolder: \\'drizzle\\' });\\n\\n  const insertedCity = await db.insert(cities).values({ id: 1, name: \\'name\\' }).returning();\\n  const insertedUser = await db.insert(users).values({ id: 1, name: \\'name\\', email: \\'email\\', cityId: 1 });\\n  const usersToCityResponse = await db.select().from(users).leftJoin(cities, eq(users.cityId, cities.id));\\n}\\n```\\n\\nRead more in [docs](/docs/get-started-postgresql#http-proxy)\\n\\n### ðŸŽ‰ `D1` Batch API support\\n\\nReference: https://developers.cloudflare.com/d1/platform/client-api/#dbbatch\\n\\nBatch API usage example:\\n\\n<Section>\\n```ts copy {1}\\nconst batchResponse = await db.batch([\\n  db.insert(usersTable).values({ id: 1, name: \\'John\\' }).returning({\\n    id: usersTable.id,\\n  }),\\n  db.update(usersTable).set({ name: \\'Dan\\' }).where(eq(usersTable.id, 1)),\\n  db.query.usersTable.findMany({}),\\n  db.select().from(usersTable).where(eq(usersTable.id, 1)),\\n  db.select({ id: usersTable.id, invitedBy: usersTable.invitedBy }).from(\\n    usersTable,\\n  ),\\n]);\\n```\\n\\n```ts\\ntype BatchResponse = [\\n  {\\n    id: number;\\n  }[],\\n  D1Result,\\n  {\\n    id: number;\\n    name: string;\\n    verified: number;\\n    invitedBy: number | null;\\n  }[],\\n  {\\n    id: number;\\n    name: string;\\n    verified: number;\\n    invitedBy: number | null;\\n  }[],\\n  {\\n    id: number;\\n    invitedBy: number | null;\\n  }[],\\n];\\n```\\n</Section>\\n\\nAll possible builders that can be used inside `db.batch`:\\n\\n```ts\\n`db.all()`,\\n`db.get()`,\\n`db.values()`,\\n`db.run()`,\\n`db.query.<table>.findMany()`,\\n`db.query.<table>.findFirst()`,\\n`db.select()...`,\\n`db.update()...`,\\n`db.delete()...`,\\n`db.insert()...`,\\n```\\n\\nMore usage examples here: [integration-tests/tests/d1-batch.test.ts](https://github.com/drizzle-team/drizzle-orm/blob/beta/integration-tests/tests/d1-batch.test.ts) and in [docs](/docs/batch-api)\\n\\n---\\n## Drizzle Kit 0.20.0\\n\\n1. New way to define drizzle.config using `defineConfig` function\\n2. Possibility to access Cloudflare D1 with Drizzle Studio using wrangler.toml file\\n3. Drizzle Studio is migrating to https://local.drizzle.studio/\\n4. `bigint unsigned` support\\n5. `primaryKeys` and `foreignKeys` now can have custom names\\n6. Environment variables are now automatically fetched \\n7. Some bug fixes and improvements\\n\\nYou can read more about drizzle-kit updates [here](https://github.com/drizzle-team/drizzle-kit-mirror/releases/tag/v0.20.0)\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0291.mdx'), name='drizzle-orm-v0291.mdx', displayName='drizzle-orm-v0291.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\npubDate: 2023-11-29\\ntitle: DrizzleORM v0.29.1 release\\ndescription: Fixed issues include forwarding arguments correctly when using the withReplica feature, resolving the selectDistinctOn not working with multiple columns problem, and providing detailed JSDoc for all query builders in all dialects. Additionally, introduced new helpers for aggregate functions in SQL and a new ESLint Drizzle Plugin package.\\n---\\nimport Npm from \"@mdx/Npm.astro\";\\n\\n## Fixes\\n\\n- Forward args correctly when using withReplica feature ([#1536](https://github.com/drizzle-team/drizzle-orm/pull/1536))\\n- Fix selectDistinctOn not working with multiple columns ([#1466](https://github.com/drizzle-team/drizzle-orm/pull/1466))\\n\\n## New Features/Helpers\\n\\n### Detailed JSDoc for all query builders in all dialects\\n\\nYou can now access more information, hints, documentation links, etc. while developing and using JSDoc right in your IDE. Previously, we had them only for filter expressions, but now you can see them for all parts of the Drizzle query builder\\n\\n### New helpers for aggregate functions in SQL\\n\\n> Remember, aggregation functions are often used with the GROUP BY clause of the SELECT statement. So if you are selecting using aggregating functions and other columns in one query,\\nbe sure to use the `.groupBy` clause\\n\\nHere is a list of functions and equivalent using `sql` template:\\n\\ncount\\n\\n```ts copy {1,2,6,9}\\nawait db.select({ value: count() }).from(users);\\nawait db.select({ value: count(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`count(\\'*\\'))`.mapWith(Number) \\n}).from(users);\\nawait db.select({ \\n  value: sql`count(${users.id})`.mapWith(Number) \\n}).from(users);\\n```\\n\\ncountDistinct\\n\\n```ts copy {1,5}\\nawait db.select({ value: countDistinct(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`count(${users.id})`.mapWith(Number) \\n}).from(users);\\n```\\n\\navg\\n\\n```ts copy {1,5}\\nawait db.select({ value: avg(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`avg(${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n\\navgDistinct\\n\\n```ts copy {1,5}\\nawait db.select({ value: avgDistinct(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`avg(distinct ${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n\\nsum\\n\\n```ts copy {1,5}\\nawait db.select({ value: sum(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`sum(${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n\\nsumDistinct\\n\\n```ts copy {1,5}\\nawait db.select({ value: sumDistinct(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`sum(distinct ${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n\\nmax\\n\\n```ts copy {1,5}\\nawait db.select({ value: max(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`max(${expression})`.mapWith(users.id) \\n}).from(users);\\n```\\n\\nmin\\n\\n```ts copy {1,5}\\nawait db.select({ value: min(users.id) }).from(users);\\n\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`min(${users.id})`.mapWith(users.id) \\n}).from(users);\\n```\\n\\nTo find more information check docs: [aggregation helpers](/docs/select#aggregations-helpers)\\n\\n## New Packages\\n\\n### Drizzle ESLint Plugin\\n\\nFor cases where it\\'s impossible to perform type checks for specific scenarios, or where it\\'s possible but error messages would be challenging to understand, we\\'ve decided to create an ESLint package with recommended rules. This package aims to assist developers in handling crucial scenarios during development. For more information you can check [docs](/docs/eslint-plugin).\\n\\n### Install\\n\\n<Npm>\\neslint eslint-plugin-drizzle\\n</Npm>\\n\\nYou can install those packages for typescript support in your IDE\\n\\n<Npm>\\n@typescript-eslint/eslint-plugin @typescript-eslint/parser\\n</Npm>\\n\\n### Usage\\n\\nCreate a `.eslintrc.yml` file, add `drizzle` to the `plugins`, and specify the rules you want to use. You can find a list of all existing rules below\\n\\n```yaml copy {6,8,9}\\nroot: true\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\nrules:\\n  \\'drizzle/enforce-delete-with-where\\': \"error\"\\n  \\'drizzle/enforce-update-with-where\\': \"error\"\\n```\\n\\n#### All config\\n\\nThis plugin exports an all config that makes use of all rules (except for deprecated ones).\\n\\n```yaml copy\\nroot: true\\nextends:\\n  - \"plugin:drizzle/all\"\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\n```\\n\\nAt the moment, `all` is equivalent to `recommended`\\n\\n```yaml copy\\nroot: true\\nextends:\\n  - \"plugin:drizzle/recommended\"\\nparser: \\'@typescript-eslint/parser\\'\\nparserOptions:\\n  project: \\'./tsconfig.json\\'\\nplugins:\\n  - drizzle\\n```\\n\\n### Rules\\n\\n**enforce-delete-with-where**: Enforce using `delete` with `the.where()` clause in the `.delete()` statement. Most of the time, you don\\'t need to delete all rows in the table and require some kind of `WHERE` statements.\\n\\nError Message:\\n\\n```plaintext\\nWithout `.where(...)` you will delete all the rows in a table. If you didn\\'t want to do it, please use `db.delete(...).where(...)` instead. Otherwise you can ignore this rule here\\n```\\n\\nOptionally, you can define a `drizzleObjectName` in the plugin options that accept a `string` or `string[]`. This is useful when you have objects or classes with a delete method that\\'s not from Drizzle. Such a `delete` method will trigger the ESLint rule. To avoid that, you can define the name of the Drizzle object that you use in your codebase (like db) so that the rule would only trigger if the delete method comes from this object:\\n\\nExample, config 1:\\n\\n```json copy\\n\"rules\": {\\n  \"drizzle/enforce-delete-with-where\": [\"error\"]\\n}\\n```\\n\\n```ts copy\\nclass MyClass {\\n  public delete() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will be triggered by ESLint Rule\\nmyClassObj.delete()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.delete()\\n```\\n\\nExample, config 2:\\n\\n```json copy\\n\"rules\": {\\n  \"drizzle/enforce-delete-with-where\": [\"error\", { \"drizzleObjectName\": [\"db\"] }],\\n}\\n```\\n\\n```ts copy\\nclass MyClass {\\n  public delete() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will NOT be triggered by ESLint Rule\\nmyClassObj.delete()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.delete()\\n```\\n\\n**enforce-update-with-where**: Enforce using `update` with `the.where()` clause in the `.update()` statement. Most of the time, you don\\'t need to update all rows in the table and require some kind of `WHERE` statements.\\n\\nError Message:\\n\\n```plaintext\\nWithout `.where(...)` you will update all the rows in a table. If you didn\\'t want to do it, please use `db.update(...).set(...).where(...)` instead. Otherwise you can ignore this rule here\\n```\\n\\nOptionally, you can define a `drizzleObjectName` in the plugin options that accept a `string` or `string[]`. This is useful when you have objects or classes with a delete method that\\'s not from Drizzle. Such as `update` method will trigger the ESLint rule. To avoid that, you can define the name of the Drizzle object that you use in your codebase (like db) so that the rule would only trigger if the delete method comes from this object:\\n\\nExample, config 1:\\n\\n```json copy\\n\"rules\": {\\n  \"drizzle/enforce-update-with-where\": [\"error\"]\\n}\\n```\\n\\n```ts copy\\nclass MyClass {\\n  public update() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will be triggered by ESLint Rule\\nmyClassObj.update()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.update()\\n```\\n\\nExample, config 2:\\n\\n```json copy\\n\"rules\": {\\n  \"drizzle/enforce-update-with-where\": [\"error\", { \"drizzleObjectName\": [\"db\"] }],\\n}\\n```\\n\\n```ts copy\\nclass MyClass {\\n  public update() {\\n    return {}\\n  }\\n}\\n\\nconst myClassObj = new MyClass();\\n\\n// ---> Will NOT be triggered by ESLint Rule\\nmyClassObj.update()\\n\\nconst db = drizzle(...)\\n// ---> Will be triggered by ESLint Rule\\ndb.update()\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0292.mdx'), name='drizzle-orm-v0292.mdx', displayName='drizzle-orm-v0292.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.29.2 release\\npubDate: 2023-12-25\\ndescription: Implemented enhancements in the planescale relational tests. Corrected string escaping for empty PgArrays. Rectified syntax error for the exists function in SQLite. Ensured proper handling of dates in AWS Data API. Resolved the Hermes mixins constructor issue.\\n---\\n\\n## Fixes: \\n\\n- Added improvements to the planescale relational tests ([#1579](https://github.com/drizzle-team/drizzle-orm/pull/1579))\\n- FIX: correct string escaping for empty PgArrays ([#1640](https://github.com/drizzle-team/drizzle-orm/pull/1640))\\n- Fix wrong syntax for exists fn in sqlite ([#1647](https://github.com/drizzle-team/drizzle-orm/pull/1647))\\n- Properly handle dates in AWS Data API\\n- Fix Hermes mixins constructor issue\\n\\n## ESLint Drizzle Plugin, v0.2.3\\n\\n```bash copy\\nnpm i eslint-plugin-drizzle@0.2.3\\n```\\n\\nðŸŽ‰ [ESLint] Add support for functions and improve error messages\\n\\n- Allowed Drizzle object to be or to be retrieved from a function, e.g.\\n- Added better context to the suggestion in the error message.\\n\\nFor more info you can check [docs](/docs/eslint-plugin)\\n## New Drivers\\n\\n**ðŸŽ‰ Expo SQLite Driver is available**\\n\\nFor starting with [Expo SQLite Driver](/docs/get-started-sqlite#expo-sqlite), you need to install `expo-sqlite` and `drizzle-orm` packages.\\n\\n```bash copy\\nnpm install drizzle-orm expo-sqlite@next\\n```\\n\\nThen, you can use it like this:\\n\\n```ts copy {4,6}\\nimport { drizzle } from \"drizzle-orm/expo-sqlite\";\\nimport { openDatabaseSync } from \"expo-sqlite\";\\n\\nconst expoDb = openDatabaseSync(\"db.db\");\\n\\nconst db = drizzle(expoDb);\\n\\nawait db.select().from(...)...\\n\\n// or\\n\\ndb.select().from(...).then(...);\\n\\n// or\\n\\ndb.select().from(...).all();\\n```\\n\\nIf you want to use Drizzle Migrations, you need to update babel and metro configuration files.\\n\\n1. Install `babel-plugin-inline-import` package.\\n\\n```bash copy\\nnpm install babel-plugin-inline-import\\n```\\n\\n2. Update `babel.config.js` and `metro.config.js` files.\\n\\n```ts filename=\"babel.config.js\" copy {6}\\nmodule.exports = function(api) {\\n  api.cache(true);\\n\\n  return {\\n    presets: [\\'babel-preset-expo\\'],\\n+   plugins: [[\"inline-import\", { \"extensions\": [\".sql\"] }]]\\n  };\\n};\\n```\\n\\n```ts filename=\"metro.config.js\" copy {6}\\nconst { getDefaultConfig } = require(\\'expo/metro-config\\');\\n\\n/** @type {import(\\'expo/metro-config\\').MetroConfig} */\\nconst config = getDefaultConfig(__dirname);\\n\\n+config.resolver.sourceExts.push(\\'sql\\');\\n\\nmodule.exports = config;\\n```\\n\\n3. Create `drizzle.config.ts` file in your project root folder.\\n\\n```ts copy\\nimport type { Config } from \\'drizzle-kit\\';\\n\\nexport default {\\n\\tschema: \\'./db/schema.ts\\',\\n\\tout: \\'./drizzle\\',\\n    dialect: \\'sqlite\\',\\n\\tdriver: \\'expo\\',\\n} satisfies Config;\\n```\\n\\nAfter creating schema file and drizzle.config.ts file, you can generate migrations like this:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThen you need to import `migrations.js` file in your `App.tsx` file from `./drizzle` folder and use hook `useMigrations` or `migrate` function.\\n\\n```ts copy {4,11}\\nimport { drizzle } from \"drizzle-orm/expo-sqlite\";\\nimport { openDatabaseSync } from \"expo-sqlite\";\\nimport { useMigrations } from \\'drizzle-orm/expo-sqlite/migrator\\';\\nimport migrations from \\'./drizzle/migrations\\';\\n\\nconst expoDb = openDatabaseSync(\"db.db\");\\n\\nconst db = drizzle(expoDb);\\n\\nexport default function App() {\\n    const { success, error } = useMigrations(db, migrations);\\n\\n    if (error) {\\n        return (\\n            <View>\\n                <Text>Migration error: {error.message}</Text>\\n            </View>\\n        );\\n    }\\n\\n    if (!success) {\\n        return (\\n            <View>\\n                <Text>Migration is in progress...</Text>\\n            </View>\\n        );\\n    }\\n\\n    return ...your application component;\\n}\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0293.mdx'), name='drizzle-orm-v0293.mdx', displayName='drizzle-orm-v0293.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.29.3 release\\npubDate: 2024-01-02\\ndescription: Fixed expo peer dependencies.\\n---\\n\\n## Fixes: \\n\\n- Make expo peer dependencies optional ([#1714](https://github.com/drizzle-team/drizzle-orm/pull/1714))\\n\\nFor more info you can check [Expo docs](https://expo.dev/) and [Get started with Expo SQLite and Drizzle](/docs/get-started-sqlite#expo-sqlite).\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0294.mdx'), name='drizzle-orm-v0294.mdx', displayName='drizzle-orm-v0294.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.29.4 release\\npubDate: 2024-02-22\\ndescription: Added Neon HTTP Batch support and updated the default behavior and instances of database-js.\\n---\\nimport Section from \"@mdx/Section.astro\";\\n\\n## New Features\\n\\n### ðŸŽ‰ Neon HTTP Batch\\n\\nFor more info you can check [Neon docs](https://neon.tech/docs/serverless/serverless-driver#issue-multiple-queries-with-the-transaction-function) and [Get started with Neon and Drizzle](/docs/get-started-postgresql#neon).\\n\\n<Section>\\n```ts copy {8}\\nimport { neon } from \\'@neondatabase/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/neon-http\\';\\nimport { usersTable } from \\'./schema\\';\\n\\nconst sql = neon(process.env.DRIZZLE_DATABASE_URL!);\\nconst db = drizzle(sql);\\n\\nconst batchResponse: BatchType = await db.batch([\\n\\tdb.insert(usersTable).values({ id: 1, name: \\'John\\' }).returning({\\n\\t\\tid: usersTable.id,\\n\\t}),\\n\\tdb.insert(usersTable).values({ id: 2, name: \\'Dan\\' }),\\n\\tdb.query.usersTable.findMany({}),\\n\\tdb.query.usersTable.findFirst({}),\\n]);\\n```\\n\\n```ts\\ntype BatchType = [\\n\\t{\\n\\t\\tid: number;\\n\\t}[],\\n\\tNeonHttpQueryResult<never>,\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t}[],\\n\\t{\\n\\t\\tid: number;\\n\\t\\tname: string;\\n\\t\\tverified: number;\\n\\t\\tinvitedBy: number | null;\\n\\t} | undefined,\\n];\\n```\\n</Section>\\n\\n## Improvements\\n\\nThanks to the `database-js` and `PlanetScale` teams, we have updated the default behavior and instances of `database-js`.\\n\\nAs suggested by the `database-js` core team, you should use the `Client` instance instead of `connect()`:\\n\\n```ts copy {1,5}\\nimport { Client } from \\'@planetscale/database\\';\\nimport { drizzle } from \\'drizzle-orm/planetscale-serverless\\';\\n\\n// create the connection\\nconst client = new Client({\\n\\thost: process.env[\\'DATABASE_HOST\\'],\\n\\tusername: process.env[\\'DATABASE_USERNAME\\'],\\n\\tpassword: process.env[\\'DATABASE_PASSWORD\\'],\\n});\\n\\nconst db = drizzle(client);\\n```\\n\\n> Warning: In this version, there are no breaking changes, but starting from version `0.30.0`, you will encounter an error if you attempt to use anything other than a `Client` instance.\\n>\\n> We suggest starting to change connections to PlanetScale now to prevent any runtime errors in the future.\\n\\nPreviously our docs stated to use `connect()` and only this function was can be passed to drizzle. In this realase we are adding support for `new Client()` and deprecating `connect()`, by suggesting from `database-js` team. In this release you will see a `warning` when trying to pass `connect()` function result:\\n\\n**Warning text**\\n\\n```mdx\\nWarning: You need to pass an instance of Client:\\n\\nimport { Client } from \"@planetscale/database\";\\n\\nconst client = new Client({\\n  host: process.env[\"DATABASE_HOST\"],\\n  username: process.env[\"DATABASE_USERNAME\"],\\n  password: process.env[\"DATABASE_PASSWORD\"],\\n});\\n\\nconst db = drizzle(client);\\n\\nStarting from version 0.30.0, you will encounter an error if you attempt to use anything other than a Client instance.\\n\\nPlease make the necessary changes now to prevent any runtime errors in the future\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0295.mdx'), name='drizzle-orm-v0295.mdx', displayName='drizzle-orm-v0295.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.29.5 release\\npubDate: 2024-03-06\\ndescription: Added with update, with delete, with insert, possibility to specify custom schema and custom name for migrations table, sqlite proxy batch and relational queries support.\\n---\\n\\nimport Section from \"@mdx/Section.astro\";\\n\\n## New Features\\n\\n### ðŸŽ‰ WITH UPDATE, WITH DELETE, WITH INSERT\\n\\nYou can now use `WITH` statements with [INSERT](/docs/insert#with-insert-clause), [UPDATE](/docs/update#with-update-clause) and [DELETE](/docs/delete#with-delete-clause) statements\\n\\nUsage examples\\n\\n<Section>\\n```ts copy {6,7}\\nconst averageAmount = db.$with(\\'average_amount\\').as(\\n\\tdb.select({ value: sql`avg(${orders.amount})`.as(\\'value\\') }).from(orders),\\n);\\n\\nconst result = await db\\n\\t.with(averageAmount)\\n\\t.delete(orders)\\n\\t.where(gt(orders.amount, sql`(select * from ${averageAmount})`))\\n\\t.returning({\\n\\t\\tid: orders.id,\\n\\t});\\n```\\n\\n```sql\\nwith \"average_amount\" as (select avg(\"amount\") as \"value\" from \"orders\") \\ndelete from \"orders\" \\nwhere \"orders\".\"amount\" > (select * from \"average_amount\") \\nreturning \"id\";\\n```\\n</Section>\\n\\nFor more examples for all statements, check docs:\\n\\n- [with insert docs](/docs/insert#with-insert-clause)\\n- [with update docs](/docs/update#with-update-clause)\\n- [with delete docs](/docs/delete#with-delete-clause)\\n\\n### ðŸŽ‰ Possibility to specify custom schema and custom name for migrations table\\n\\n- **Custom table for migrations**\\n\\nBy default, all information about executed migrations will be stored in the database inside the `__drizzle_migrations` table,\\nand for PostgreSQL, inside the `drizzle` schema. However, you can configure where to store those records.\\n\\nTo add a custom table name for migrations stored inside your database, you should use the `migrationsTable` option\\n\\nUsage example\\n\\n```ts copy {3}\\nawait migrate(db, {\\n\\tmigrationsFolder: \\'./drizzle\\',\\n\\tmigrationsTable: \\'my_migrations\\',\\n});\\n```\\n\\n- **Custom schema for migrations**\\n\\n> Works only with PostgreSQL databases\\n\\nTo add a custom schema name for migrations stored inside your database, you should use the `migrationsSchema` option\\n\\nUsage example\\n\\n```ts copy {3}\\nawait migrate(db, {\\n\\tmigrationsFolder: \\'./drizzle\\',\\n\\tmigrationsSchema: \\'custom\\',\\n});\\n```\\n\\n### ðŸŽ‰ SQLite Proxy bacth and Relational Queries support\\n\\nYou can find more information about SQLite proxy in [docs](/docs/get-started-sqlite#http-proxy).\\n\\n- You can now use `.query.findFirst` and `.query.findMany` syntax with sqlite proxy driver\\n\\n- SQLite Proxy supports batch requests, the same as it\\'s done for all other drivers. Check full [docs](/docs/batch-api)\\n\\n  You will need to specify a specific callback for batch queries and handle requests to proxy server:\\n\\n```ts\\nimport { drizzle } from \\'drizzle-orm/sqlite-proxy\\';\\n\\ntype ResponseType = { rows: any[][] | any[] }[];\\n\\nconst db = drizzle(\\n\\tasync (sql, params, method) => {\\n\\t\\t// single query logic\\n\\t},\\n\\t// new batch callback\\n\\tasync (\\n\\t\\tqueries: {\\n\\t\\t\\tsql: string;\\n\\t\\t\\tparams: any[];\\n\\t\\t\\tmethod: \\'all\\' | \\'run\\' | \\'get\\' | \\'values\\';\\n\\t\\t}[],\\n\\t) => {\\n\\t\\ttry {\\n\\t\\t\\tconst result: ResponseType = await axios.post(\\n\\t\\t\\t\\t\\'http://localhost:3000/batch\\',\\n\\t\\t\\t\\t{ queries },\\n\\t\\t\\t);\\n\\n\\t\\t\\treturn result;\\n\\t\\t} catch (e: any) {\\n\\t\\t\\tconsole.error(\\'Error from sqlite proxy server:\\', e);\\n\\t\\t\\tthrow e;\\n\\t\\t}\\n\\t},\\n);\\n```\\n\\nAnd then you can use `db.batch([])` method, that will proxy all queries\\n\\n> Response from the batch should be an array of raw values (an array within an array), in the same order as they were sent to the proxy server\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0300.mdx'), name='drizzle-orm-v0300.mdx', displayName='drizzle-orm-v0300.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.0 release\\npubDate: 2024-03-07\\ndescription: Modified the 'postgres.js' driver instance to always return strings for dates, and then Drizzle will provide you with either strings of mapped dates, depending on the selected 'mode'. Fixed many bugs related to timestamps and dates. \\n---\\n\\n## Breaking Changes\\n\\nThe Postgres timestamp mapping has been changed to align all drivers with the same behavior.\\n\\nâ— We've modified the `postgres.js` driver instance to always return strings for dates, and then Drizzle will provide you with either strings of mapped dates, depending on the selected `mode`. The only issue you may encounter is that once you provide the `postgres.js`` driver instance inside Drizzle, the behavior of this object will change for dates, which will always be strings.\\n\\nWe've made this change as a minor release, just as a warning, that:\\n\\n- If you were using timestamps and were waiting for a specific response, the behavior will now be changed.\\n  When mapping to the driver, we will always use `.toISOString` for both timestamps with timezone and without timezone.\\n\\n- If you were using the `postgres.js` driver outside of Drizzle, all `postgres.js` clients passed to Drizzle will have mutated behavior for dates. All dates will be strings in the response.\\n\\nParsers that were changed for `postgres.js`.\\n\\n```ts\\nconst transparentParser = (val: any) => val;\\n\\n// Override postgres.js default date parsers: https://github.com/porsager/postgres/discussions/761\\nfor (const type of ['1184', '1082', '1083', '1114']) {\\n\\tclient.options.parsers[type as any] = transparentParser;\\n\\tclient.options.serializers[type as any] = transparentParser;\\n}\\n```\\n\\nIdeally, as is the case with almost all other drivers, we should have the possibility to mutate mappings on a per-query basis, which means that the driver client won't be mutated. We will be reaching out to the creator of the `postgres.js` library to inquire about the possibility of specifying per-query mapping interceptors and making this flow even better for all users.\\n\\nIf we've overlooked this capability and it is already available with `postgres.js``, please ping us in our Discord!\\n\\nA few more references for timestamps without and with timezones can be found in our [docs](http://orm.drizzle.team/docs/column-types/pg#timestamp)\\n\\nCheck docs for getting started with `postgres.js` driver and Drizzle [here](/docs/get-started-postgresql#postgresjs)\\n\\n## Fixes\\n\\n- timestamp with mode string is returned as Date object instead of string - ([#806](https://github.com/drizzle-team/drizzle-orm/issues/806))\\n- Dates are always dates ([#971](https://github.com/drizzle-team/drizzle-orm/issues/971))\\n- Inconsistencies when working with timestamps and corresponding datetime objects in javascript. ([#1176](https://github.com/drizzle-team/drizzle-orm/issues/1176))\\n- timestamp columns showing string type, however actually returning a Date object. ([#1185](https://github.com/drizzle-team/drizzle-orm/issues/1185))\\n- Wrong data type for postgres date colum ([#1407](https://github.com/drizzle-team/drizzle-orm/issues/1407))\\n- invalid timestamp conversion when using PostgreSQL with TimeZone set to UTC ([#1587](https://github.com/drizzle-team/drizzle-orm/issues/1587))\\n- Postgres insert into timestamp with time zone removes milliseconds ([#1061](https://github.com/drizzle-team/drizzle-orm/issues/1061))\\n- update timestamp field (using AWS Data API) ([#1164](https://github.com/drizzle-team/drizzle-orm/issues/1164))\\n- Invalid date from relational queries ([#895](https://github.com/drizzle-team/drizzle-orm/issues/895))\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0301.mdx'), name='drizzle-orm-v0301.mdx', displayName='drizzle-orm-v0301.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.1 release\\npubDate: 2024-03-08\\ndescription: Added support for op-sqlite driver and fixed migration hook for Expo driver. \\n---\\n\\n## New Features\\n\\n### ðŸŽ‰ OP-SQLite driver Support\\n\\nUsage Example\\n\\n```ts copy {4,5,6,8}\\nimport { open } from '@op-engineering/op-sqlite';\\nimport { drizzle } from 'drizzle-orm/op-sqlite';\\n\\nconst opsqlite = open({\\n\\tname: 'myDB',\\n});\\n\\nconst db = drizzle(opsqlite);\\n\\nawait db.select().from(users);\\n```\\n\\nFor more usage and setup details, please check our [op-sqlite docs](http://orm.drizzle.team/docs/get-started-sqlite#op-sqlite)\\n\\n## Fixes\\n\\n- Migration hook fixed for Expo driver\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v03010.mdx'), name='drizzle-orm-v03010.mdx', displayName='drizzle-orm-v03010.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.10 release\\npubDate: 2024-05-01\\ndescription: Added '.if()' function to all WHERE expressions and fixed internal mappings for sessions '.all', '.values', '.execute' functions in AWS DataAPI.\\n---\\n\\n## New Features\\n\\n### ðŸŽ‰ `.if()` function added to all WHERE expressions\\n\\n#### Select all posts with views greater than 100\\n\\n```ts {5}\\nasync function someFunction(views = 0) {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(gt(posts.views, views).if(views > 100));\\n}\\n```\\n\\n## Bug Fixes\\n\\n- Fixed internal mappings for sessions `.all`, `.values`, `.execute` functions in AWS DataAPI\\n\\nRead get started guide with AWS DataAPI in the [documentation](/docs/get-started-postgresql#aws-data-api).\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0302.mdx'), name='drizzle-orm-v0302.mdx', displayName='drizzle-orm-v0302.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.30.2 release\\npubDate: 2024-03-14\\ndescription: Updated LibSQL migrations to utilize batch execution instead of transactions and fixed findFirst query for bun:sqlite.\\n---\\n\\n## Improvements\\n\\nLibSQL migrations have been updated to utilize batch execution instead of transactions. As stated in the [documentation](https://docs.turso.tech/sdk/ts/reference#batch-transactions), LibSQL now supports batch operations\\n\\n> A batch consists of multiple SQL statements executed sequentially within an implicit transaction. The backend handles the transaction: success commits all changes, while any failure results in a full rollback with no modifications.\\n\\nTo get started with Turso and Drizzle follow the [documentation](/docs/get-started-sqlite#turso)\\n\\n## Fixes\\n\\n- [Sqlite] Fix findFirst query for bun:sqlite ([#1885](https://github.com/drizzle-team/drizzle-orm/pull/1885))\\n\\nTo get started with Bun SQLite and Drizzle follow the [documentation](/docs/get-started-sqlite#bun-sqlite)\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0303.mdx'), name='drizzle-orm-v0303.mdx', displayName='drizzle-orm-v0303.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.3 release\\npubDate: 2024-03-19\\ndescription: Added raw query support to batch API in Neon HTTP driver, fixed '@neondatabase/serverless' HTTP driver types issue, and fixed sqlite-proxy driver '.run()' result.\\n---\\n\\n## New Features\\n\\n- Added raw query support (`db.execute(...)`) to batch API in Neon HTTP driver\\n\\nTo get started with Neon and Drizzle follow the [documentation](/docs/get-started-postgresql#neon)\\n\\n## Fixes\\n\\n- Fixed `@neondatabase/serverless` HTTP driver types issue ([#1945](https://github.com/drizzle-team/drizzle-orm/issues/1945), [neondatabase/serverless#66](https://github.com/neondatabase/serverless/issues/66))\\n- Fixed sqlite-proxy driver `.run()` result\\n\\nTo get started with SQLite proxy driver and Drizzle follow the [documentation](/docs/get-started-sqlite#http-proxy)\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0304.mdx'), name='drizzle-orm-v0304.mdx', displayName='drizzle-orm-v0304.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.30.4 release\\npubDate: 2024-03-19 12:00:00\\ndescription: Added support for Xata driver. \\n---\\n\\nimport Npm from \"@mdx/Npm.astro\";\\n\\n## New Features\\n\\n### ðŸŽ‰ xata-http driver support\\n\\nAccording their **[official website](https://xata.io)**, Xata is a Postgres data platform with a focus on reliability, scalability, and developer experience. The Xata Postgres service is currently in beta, please see the [Xata docs](https://xata.io/docs/postgres) on how to enable it in your account.\\n\\nDrizzle ORM natively supports both the `xata` driver with `drizzle-orm/xata` package and the **`postgres`** or **`pg`** drivers for accessing a Xata Postgres database.\\n\\nThe following example use the Xata generated client, which you obtain by running the [xata init](https://xata.io/docs/getting-started/installation) CLI command.\\n\\n<Npm>\\ndrizzle-orm @xata.io/client\\n-D drizzle-kit\\n</Npm>\\n\\n```ts\\nimport { drizzle } from \\'drizzle-orm/xata-http\\';\\nimport { getXataClient } from \\'./xata\\'; // Generated client\\n\\nconst xata = getXataClient();\\nconst db = drizzle(xata);\\n\\nconst result = await db.select().from(...);\\n```\\n\\nYou can also connect to Xata using `pg` or `postgres.js` drivers\\n\\nTo get started with Xata and Drizzle follow the [documentation](/docs/get-started-postgresql#xata).\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0305.mdx'), name='drizzle-orm-v0305.mdx', displayName='drizzle-orm-v0305.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.5 release\\npubDate: 2024-03-27\\ndescription: Added '$onUpdate' functionality for PostgreSQL, MySQL and SQLite and fixed insertions on columns with the smallserial datatype.\\n---\\n\\n## New Features\\n\\n### `$onUpdate` functionality for PostgreSQL, MySQL and SQLite\\n\\nAdds a dynamic update value to the column.\\nThe function will be called when the row is updated, and the returned value will be used as the column value if none is provided.\\nIf no `default` (or `$defaultFn`) value is provided, the function will be called when the row is inserted as well, and the returned value will be used as the column value.\\n\\n> Note: This value does not affect the `drizzle-kit` behavior, it is only used at runtime in `drizzle-orm`.\\n\\n```ts copy {4,5,6}\\nconst usersOnUpdate = pgTable('users_on_update', {\\n  id: serial('id').primaryKey(),\\n  name: text('name').notNull(),\\n  updateCounter: integer('update_counter').default(sql`1`).$onUpdateFn(() => sql`update_counter + 1`),\\n  updatedAt: timestamp('updated_at', { mode: 'date', precision: 3 }).$onUpdate(() => new Date()),\\n  alwaysNull: text('always_null').$type<string | null>().$onUpdate(() => null),\\n});\\n```\\n\\n## Fixes\\n\\n- Insertions on columns with the smallserial datatype are not optional - [#1848](https://github.com/drizzle-team/drizzle-orm/issues/1848)\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0306.mdx'), name='drizzle-orm-v0306.mdx', displayName='drizzle-orm-v0306.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.30.6 release\\npubDate: 2024-03-28\\ndescription: Added support for PGlite driver.\\n---\\n\\n## New Features\\n\\n### PGlite driver Support\\n\\n[PGlite](https://github.com/electric-sql/pglite) is a WASM Postgres build packaged into a TypeScript client library that enables you to run Postgres in the browser, Node.js and Bun, with no need to install any other dependencies. It is only 2.6mb gzipped.\\n\\nIt can be used as an ephemeral in-memory database, or with persistence either to the file system (Node/Bun) or indexedDB (Browser).\\n\\nUnlike previous \"Postgres in the browser\" projects, PGlite does not use a Linux virtual machine - it is simply Postgres in WASM.\\n\\n\\nRead get started with Drizzle and PGlite guide [here](/docs/get-started-postgresql#pglite).\\n\\nUsage Example\\n```ts copy {1,6}\\nimport { PGlite } from \\'@electric-sql/pglite\\';\\nimport { drizzle } from \\'drizzle-orm/pglite\\';\\nimport { users } from \\'./schema\\';\\n\\n// In-memory Postgres\\nconst client = new PGlite();\\nconst db = drizzle(client);\\n\\nawait db.select().from(users);\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0307.mdx'), name='drizzle-orm-v0307.mdx', displayName='drizzle-orm-v0307.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.7 release\\npubDate: 2024-04-03\\ndescription: Added mappings for '@vercel/postgres' package and fixed interval mapping for neon drivers.\\n---\\n\\n## Fixes\\n\\n- Add mappings for `@vercel/postgres` package\\n\\nRead more about Vercel Postgres [here](https://vercel.com/docs/storage/vercel-postgres). To get started with Drizzle and Vercel Postgres follow the [documentation](/docs/get-started-postgresql#vercel-postgres).\\n\\n- Fix interval mapping for `neon` drivers - [#1542](https://github.com/drizzle-team/drizzle-orm/issues/1542)\\n\\nRead more about Neon [here](https://neon.tech/). To get started with Drizzle and Neon follow the [documentation](/docs/get-started-postgresql#neon).\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0308.mdx'), name='drizzle-orm-v0308.mdx', displayName='drizzle-orm-v0308.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.8 release\\npubDate: 2024-04-11\\ndescription: Added custom schema support to enums in Postgres, changed D1 'migrate()' function to use batch API, updated '.onConflictDoUpdate' method, fixed query generation for 'where' clause in Postgres '.onConflictDoNothing' method and fixed various bugs related to AWS Data API.\\n---\\n\\n## New Features\\n\\n- Added custom schema support to enums in Postgres (fixes [#669](https://github.com/drizzle-team/drizzle-orm/issues/669) via [#2048](https://github.com/drizzle-team/drizzle-orm/pull/2048)):\\n\\n```ts copy {3,4}\\nimport { pgSchema } from 'drizzle-orm/pg-core';\\n\\nconst mySchema = pgSchema('mySchema');\\nconst colors = mySchema.enum('colors', ['red', 'green', 'blue']);\\n```\\n\\nLearn more about Postgres [schemas](/docs/schemas) and [enums](/docs/column-types/pg#enum).\\n\\n## Fixes\\n\\n- Changed D1 `migrate()` function to use batch API ([#2137](https://github.com/drizzle-team/drizzle-orm/pull/2137))\\n\\nTo get started with Drizzle and D1 follow the [documentation](/docs/get-started-sqlite#cloudflare-d1).\\n\\n- Split `where` clause in Postgres `.onConflictDoUpdate` method into `setWhere` and `targetWhere` clauses, to support both `where` cases in `on conflict ...` clause (fixes [#1628](https://github.com/drizzle-team/drizzle-orm/issues/1628), [#1302](https://github.com/drizzle-team/drizzle-orm/issues/1302) via [#2056](https://github.com/drizzle-team/drizzle-orm/pull/2056)). \\n\\n```ts copy\\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: 'John Doe' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    targetWhere: sql`name <> 'John Doe'`,\\n    set: { name: sql`excluded.name` }\\n  });\\n  \\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: 'John Doe' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    set: { name: 'John Doe' },\\n    setWhere: sql`name <> 'John Doe'`\\n  });\\n```\\n\\nLearn more about `.onConflictDoUpdate` method [here](/docs/insert#on-conflict-do-update).\\n- Fixed query generation for `where` clause in Postgres `.onConflictDoNothing` method, as it was placed in a wrong spot (fixes [#1628](https://github.com/drizzle-team/drizzle-orm/issues/1628) via [#2056](https://github.com/drizzle-team/drizzle-orm/pull/2056)).\\n\\nLearn more about `.onConflictDoNothing` method [here](/docs/insert#on-conflict-do-nothing).\\n\\n- Fixed multiple issues with AWS Data API driver (fixes [#1931](https://github.com/drizzle-team/drizzle-orm/pull/1931), [#1932](https://github.com/drizzle-team/drizzle-orm/issues/1932), [#1934](https://github.com/drizzle-team/drizzle-orm/issues/1934), [#1936](https://github.com/drizzle-team/drizzle-orm/issues/1936) via [#2119](https://github.com/drizzle-team/drizzle-orm/pull/2119))\\n- Fix inserting and updating array values in AWS Data API (fixes [#1912](https://github.com/drizzle-team/drizzle-orm/issues/1912) via [#1911](https://github.com/drizzle-team/drizzle-orm/pull/1911))\\n\\nTo get started with Drizzle and AWS Data API follow the [documentation](/docs/get-started-postgresql#aws-data-api).\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0309.mdx'), name='drizzle-orm-v0309.mdx', displayName='drizzle-orm-v0309.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.30.9 release\\npubDate: 2024-04-22\\ndescription: Added 'setWhere' and 'targetWhere' fields to '.onConflictDoUpdate()' config in SQLite, added schema information to Drizzle instances via 'db._.fullSchema' and fixed migrator in AWS Data API.\\n---\\n\\n## New Features\\n\\n- Added `setWhere` and `targetWhere` fields to `.onConflictDoUpdate()` config in SQLite instead of single `where` field:\\n\\n```ts copy\\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: 'John Doe' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    targetWhere: sql`name <> 'John Doe'`,\\n    set: { name: sql`excluded.name` }\\n  });\\n  \\nawait db.insert(employees)\\n  .values({ employeeId: 123, name: 'John Doe' })\\n  .onConflictDoUpdate({\\n    target: employees.employeeId,\\n    set: { name: 'John Doe' },\\n    setWhere: sql`name <> 'John Doe'`\\n  });\\n```\\n\\nRead more about `.onConflictDoUpdate()` method [here](/docs/insert#on-conflict-do-update).\\n\\n- ðŸ› ï¸ Added schema information to Drizzle instances via `db._.fullSchema`\\n\\n## Fixes\\n\\n- Fixed migrator in AWS Data API\\n\\nTo get started with Drizzle and AWS Data API follow the [documentation](/docs/get-started-postgresql#aws-data-api).\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0310.mdx'), name='drizzle-orm-v0310.mdx', displayName='drizzle-orm-v0310.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.31.0 release\\npubDate: 2024-05-31\\ndescription: PostgreSQL indexes API changes\\n---\\n\\n## Breaking changes\\n\\n> Note: `drizzle-orm@0.31.0` can be used with `drizzle-kit@0.22.0` or higher. The same applies to Drizzle Kit. If you run a Drizzle Kit command, it will check and prompt you for an upgrade (if needed). You can check for Drizzle Kit updates. [below](#drizzle-kit-updates-drizzle-kit0220)\\n\\n### PostgreSQL indexes API was changed\\n\\nThe previous Drizzle+PostgreSQL indexes API was incorrect and was not aligned with the PostgreSQL documentation. The good thing is that it was not used in queries, and drizzle-kit didn\\'t support all properties for indexes. This means we can now change the API to the correct one and provide full support for it in drizzle-kit\\n\\nPrevious API\\n\\n- No way to define SQL expressions inside `.on`.\\n- `.using` and `.on` in our case are the same thing, so the API is incorrect here.\\n- `.asc()`, `.desc()`, `.nullsFirst()`, and `.nullsLast()` should be specified for each column or expression on indexes, but not on an index itself.\\n\\n```ts\\n// Index declaration reference\\nindex(\\'name\\')\\n  .on(table.column1, table.column2, ...) or .onOnly(table.column1, table.column2, ...)\\n  .concurrently()\\n  .using(sql``) // sql expression\\n  .asc() or .desc()\\n  .nullsFirst() or .nullsLast()\\n  .where(sql``) // sql expression\\n```\\n\\nCurrent API\\n\\n```ts\\n// First example, with `.on()`\\nindex(\\'name\\')\\n  .on(table.column1.asc(), table.column2.nullsFirst(), ...) or .onOnly(table.column1.desc().nullsLast(), table.column2, ...)\\n  .concurrently()\\n  .where(sql``)\\n  .with({ fillfactor: \\'70\\' })\\n\\n// Second Example, with `.using()`\\nindex(\\'name\\')\\n  .using(\\'btree\\', table.column1.asc(), sql`lower(${table.column2})`, table.column1.op(\\'text_ops\\'))\\n  .where(sql``) // sql expression\\n  .with({ fillfactor: \\'70\\' })\\n```\\n\\n## New Features\\n\\n### ðŸŽ‰ \"pg_vector\" extension support\\n\\n> There is no specific code to create an extension inside the Drizzle schema. We assume that if you are using vector types, indexes, and queries, you have a PostgreSQL database with the `pg_vector` extension installed.\\n\\nYou can now specify indexes for `pg_vector` and utilize `pg_vector` functions for querying, ordering, etc.\\n\\nLet\\'s take a few examples of `pg_vector` indexes from the `pg_vector` docs and translate them to Drizzle\\n\\n#### L2 distance, Inner product and Cosine distance\\n\\n```ts\\n// CREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\\n// CREATE INDEX ON items USING hnsw (embedding vector_ip_ops);\\n// CREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\\n\\nconst table = pgTable(\\'items\\', {\\n    embedding: vector(\\'embedding\\', { dimensions: 3 })\\n}, (table) => ({\\n    l2: index(\\'l2_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_l2_ops\\'))\\n    ip: index(\\'ip_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_ip_ops\\'))\\n    cosine: index(\\'cosine_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_cosine_ops\\'))\\n}))\\n```\\n\\n#### L1 distance, Hamming distance and Jaccard distance - added in pg_vector 0.7.0 version\\n\\n```ts\\n// CREATE INDEX ON items USING hnsw (embedding vector_l1_ops);\\n// CREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);\\n// CREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);\\n\\nconst table = pgTable(\\'table\\', {\\n    embedding: vector(\\'embedding\\', { dimensions: 3 })\\n}, (table) => ({\\n    l1: index(\\'l1_index\\').using(\\'hnsw\\', table.embedding.op(\\'vector_l1_ops\\'))\\n    hamming: index(\\'hamming_index\\').using(\\'hnsw\\', table.embedding.op(\\'bit_hamming_ops\\'))\\n    bit: index(\\'bit_jaccard_index\\').using(\\'hnsw\\', table.embedding.op(\\'bit_jaccard_ops\\'))\\n}))\\n```\\n\\nFor queries, you can use predefined functions for vectors or create custom ones using the SQL template operator.\\n\\nYou can also use the following helpers:\\n\\n```ts\\nimport { l2Distance, l1Distance, innerProduct, \\n          cosineDistance, hammingDistance, jaccardDistance } from \\'drizzle-orm\\'\\n\\nl2Distance(table.column, [3, 1, 2]) // table.column <-> \\'[3, 1, 2]\\'\\nl1Distance(table.column, [3, 1, 2]) // table.column <+> \\'[3, 1, 2]\\'\\n\\ninnerProduct(table.column, [3, 1, 2]) // table.column <#> \\'[3, 1, 2]\\'\\ncosineDistance(table.column, [3, 1, 2]) // table.column <=> \\'[3, 1, 2]\\'\\n\\nhammingDistance(table.column, \\'101\\') // table.column <~> \\'101\\'\\njaccardDistance(table.column, \\'101\\') // table.column <%> \\'101\\'\\n```\\n\\nIf `pg_vector` has some other functions to use, you can replicate implimentation from existing one we have. Here is how it can be done\\n\\n```ts\\nexport function l2Distance(\\n  column: SQLWrapper | AnyColumn,\\n  value: number[] | string[] | TypedQueryBuilder<any> | string,\\n): SQL {\\n  if (is(value, TypedQueryBuilder<any>) || typeof value === \\'string\\') {\\n    return sql`${column} <-> ${value}`;\\n  }\\n  return sql`${column} <-> ${JSON.stringify(value)}`;\\n}\\n```\\n\\nName it as you wish and change the operator. This example allows for a numbers array, strings array, string, or even a select query. Feel free to create any other type you want or even contribute and submit a PR\\n\\n#### Examples\\n\\nLet\\'s take a few examples of `pg_vector` queries from the `pg_vector` docs and translate them to Drizzle\\n\\n```ts\\nimport { l2Distance } from \\'drizzle-orm\\';\\n\\n// SELECT * FROM items ORDER BY embedding <-> \\'[3,1,2]\\' LIMIT 5;\\ndb.select().from(items).orderBy(l2Distance(items.embedding, [3,1,2]))\\n\\n// SELECT embedding <-> \\'[3,1,2]\\' AS distance FROM items;\\ndb.select({ distance: l2Distance(items.embedding, [3,1,2]) })\\n\\n// SELECT * FROM items ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\\nconst subquery = db.select({ embedding: items.embedding }).from(items).where(eq(items.id, 1));\\ndb.select().from(items).orderBy(l2Distance(items.embedding, subquery)).limit(5)\\n\\n// SELECT (embedding <#> \\'[3,1,2]\\') * -1 AS inner_product FROM items;\\ndb.select({ innerProduct: sql`(${maxInnerProduct(items.embedding, [3,1,2])}) * -1` }).from(items)\\n\\n// and more!\\n```\\n\\n## ðŸŽ‰ New PostgreSQL types: `point`, `line`\\n\\nYou can now use `point` and `line` from [PostgreSQL Geometric Types](https://www.postgresql.org/docs/current/datatype-geometric.html)\\n\\nType `point` has 2 modes for mappings from the database: `tuple` and `xy`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database Point(1,2) will be typed as [1,2] with drizzle.\\n\\n- `xy` will be accepted for insert and mapped on select to an object with x, y coordinates. So, the database Point(1,2) will be typed as `{ x: 1, y: 2 }` with drizzle\\n\\n```ts\\nconst items = pgTable(\\'items\\', {\\n point: point(\\'point\\'),\\n pointObj: point(\\'point_xy\\', { mode: \\'xy\\' }),\\n});\\n```\\n\\nType `line` has 2 modes for mappings from the database: `tuple` and `abc`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database Line{1,2,3} will be typed as [1,2,3] with drizzle.\\n\\n- `abc` will be accepted for insert and mapped on select to an object with a, b, and c constants from the equation `Ax + By + C = 0`. So, the database Line{1,2,3} will be typed as `{ a: 1, b: 2, c: 3 }` with drizzle.\\n\\n```ts\\nconst items = pgTable(\\'items\\', {\\n line: line(\\'line\\'),\\n lineObj: line(\\'line_abc\\', { mode: \\'abc\\' }),\\n});\\n```\\n\\n## ðŸŽ‰ Basic \"postgis\" extension support\\n\\n> There is no specific code to create an extension inside the Drizzle schema. We assume that if you are using postgis types, indexes, and queries, you have a PostgreSQL database with the `postgis` extension installed.\\n\\n`geometry` type from postgis extension:\\n\\n```ts\\nconst items = pgTable(\\'items\\', {\\n  geo: geometry(\\'geo\\', { type: \\'point\\' }),\\n  geoObj: geometry(\\'geo_obj\\', { type: \\'point\\', mode: \\'xy\\' }),\\n  geoSrid: geometry(\\'geo_options\\', { type: \\'point\\', mode: \\'xy\\', srid: 4000 }),\\n});\\n```\\n\\n**mode**\\nType `geometry` has 2 modes for mappings from the database: `tuple` and `xy`.\\n\\n- `tuple` will be accepted for insert and mapped on select to a tuple. So, the database geometry will be typed as [1,2] with drizzle.\\n- `xy` will be accepted for insert and mapped on select to an object with x, y coordinates. So, the database geometry will be typed as `{ x: 1, y: 2 }` with drizzle\\n\\n**type**\\n\\nThe current release has a predefined type: `point`, which is the `geometry(Point)` type in the PostgreSQL PostGIS extension. You can specify any string there if you want to use some other type\\n\\n# Drizzle Kit updates: `drizzle-kit@0.22.0`\\n\\n> Release notes here are partially duplicated from [drizzle-kit@0.22.0](https://github.com/drizzle-team/drizzle-kit-mirror/releases/tag/v0.22.0)\\n\\n## New Features\\n\\n### ðŸŽ‰ Support for new types\\n\\nDrizzle Kit can now handle:\\n\\n- `point` and `line` from PostgreSQL\\n- `vector` from the PostgreSQL `pg_vector` extension\\n- `geometry` from the PostgreSQL `PostGIS` extension\\n\\n### ðŸŽ‰ New param in drizzle.config - `extensionsFilters`\\n\\nThe PostGIS extension creates a few internal tables in the `public` schema. This means that if you have a database with the PostGIS extension and use `push` or `introspect`, all those tables will be included in `diff` operations. In this case, you would need to specify `tablesFilter`, find all tables created by the extension, and list them in this parameter.\\n\\nWe have addressed this issue so that you won\\'t need to take all these steps. Simply specify `extensionsFilters` with the name of the extension used, and Drizzle will skip all the necessary tables.\\n\\nCurrently, we only support the `postgis` option, but we plan to add more extensions if they create tables in the `public` schema.\\n\\nThe `postgis` option will skip the `geography_columns`, `geometry_columns`, and `spatial_ref_sys` tables\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defaultConfig({\\n  dialect: \"postgresql\",\\n  extensionsFilters: [\"postgis\"],\\n})\\n```\\n\\n## Improvements\\n\\n### Update zod schemas for database credentials and write tests to all the positive/negative cases\\n\\n- support full set of SSL params in kit config, provide types from node:tls connection\\n\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defaultConfig({\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    ssl: true, //\"require\" | \"allow\" | \"prefer\" | \"verify-full\" | options from node:tls\\n  }\\n})\\n```\\n\\n```ts\\nimport { defineConfig } from \\'drizzle-kit\\'\\n\\nexport default defaultConfig({\\n  dialect: \"mysql\",\\n  dbCredentials: {\\n    ssl: \"\", // string | SslOptions (ssl options from mysql2 package)\\n  }\\n})\\n```\\n\\n### Normilized SQLite urls for `libsql` and `better-sqlite3` drivers\\n\\nThose drivers have different file path patterns, and Drizzle Kit will accept both and create a proper file path format for each\\n\\n### Updated MySQL and SQLite index-as-expression behavior\\n\\nIn this release MySQL and SQLite will properly map expressions into SQL query. Expressions won\\'t be escaped in string but columns will be\\n\\n```ts\\nexport const users = sqliteTable(\\n  \\'users\\',\\n  {\\n    id: integer(\\'id\\').primaryKey(),\\n    email: text(\\'email\\').notNull(),\\n  },\\n  (table) => ({\\n    emailUniqueIndex: uniqueIndex(\\'emailUniqueIndex\\').on(sql`lower(${table.email})`),\\n  }),\\n);\\n\\n```\\n```sql\\n-- before\\nCREATE UNIQUE INDEX `emailUniqueIndex` ON `users` (`lower(\"users\".\"email\")`);\\n\\n-- now\\nCREATE UNIQUE INDEX `emailUniqueIndex` ON `users` (lower(\"email\"));\\n```\\n\\n## Bug Fixes\\n\\n- [BUG]: multiple constraints not added (only the first one is generated) - [#2341](https://github.com/drizzle-team/drizzle-orm/issues/2341) \\n- Drizzle Studio: Error: Connection terminated unexpectedly - [#435](https://github.com/drizzle-team/drizzle-kit-mirror/issues/435)\\n- Unable to run sqlite migrations local - [#432](https://github.com/drizzle-team/drizzle-kit-mirror/issues/432)\\n- error: unknown option \\'--config\\' - [#423](https://github.com/drizzle-team/drizzle-kit-mirror/issues/423)\\n\\n\\n## How `push` and `generate` works for indexes\\n\\n### Limitations\\n\\n#### You should specify a name for your index manually if you have an index on at least one expression\\n\\nExample\\n\\n```ts\\nindex().on(table.id, table.email) // will work well and name will be autogeneretaed\\nindex(\\'my_name\\').on(table.id, table.email) // will work well\\n\\n// but\\n\\nindex().on(sql`lower(${table.email})`) // error\\nindex(\\'my_name\\').on(sql`lower(${table.email})`) // will work well\\n```\\n\\n#### Push won\\'t generate statements if these fields(list below) were changed in an existing index:\\n\\n- expressions inside `.on()` and `.using()`\\n- `.where()` statements\\n- operator classes `.op()` on columns\\n\\nIf you are using `push` workflows and want to change these fields in the index, you would need to:\\n\\n- Comment out the index\\n- Push\\n- Uncomment the index and change those fields\\n- Push again\\n\\nFor the `generate` command, `drizzle-kit` will be triggered by any changes in the index for any property in the new drizzle indexes API, so there are no limitations here.\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0311.mdx'), name='drizzle-orm-v0311.mdx', displayName='drizzle-orm-v0311.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.31.1 release\\npubDate: 2024-06-04\\ndescription: React Live Queries ðŸŽ‰\\n---\\n\\n# New Features\\n\\n## Live Queries ðŸŽ‰\\n\\n> ### For a full explanation about Drizzle + Expo welcome to [discussions](https://github.com/drizzle-team/drizzle-orm/discussions/2447)\\n\\nAs of `v0.31.1` Drizzle ORM now has native support for Expo SQLite Live Queries!\\nWe've implemented a native `useLiveQuery` React Hook which observes necessary database changes and automatically re-runs database queries. It works with both SQL-like and Drizzle Queries:\\n\\n```tsx\\nimport { useLiveQuery, drizzle } from 'drizzle-orm/expo-sqlite';\\nimport { openDatabaseSync } from 'expo-sqlite';\\nimport { users } from './schema';\\nimport { Text } from 'react-native';\\n\\nconst expo = openDatabaseSync('db.db', { enableChangeListener: true }); // <-- enable change listeners\\nconst db = drizzle(expo);\\n\\nconst App = () => {\\n  // Re-renders automatically when data changes\\n  const { data } = useLiveQuery(db.select().from(users));\\n\\n  // const { data, error, updatedAt } = useLiveQuery(db.query.users.findFirst());\\n  // const { data, error, updatedAt } = useLiveQuery(db.query.users.findMany());\\n\\n\\n  return <Text>{JSON.stringify(data)}</Text>;\\n};\\n\\nexport default App;\\n```\\n\\nWe've intentionally not changed the API of ORM itself to stay with conventional React Hook API, so we have `useLiveQuery(databaseQuery)` as opposed to `db.select().from(users).useLive()` or `db.query.users.useFindMany()`\\n\\nWe've also decided to provide `data`, `error` and `updatedAt` fields as a result of hook for concise explicit error handling following practices of `React Query` and `Electric SQL`\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0312.mdx'), name='drizzle-orm-v0312.mdx', displayName='drizzle-orm-v0312.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.31.2 release\\npubDate: 2024-06-07\\ndescription: Added support for TiDB Cloud Serverless driver\\n---\\n\\n- ðŸŽ‰ Added support for TiDB Cloud Serverless driver:\\n\\n```ts\\nimport { connect } from '@tidbcloud/serverless';\\nimport { drizzle } from 'drizzle-orm/tidb-serverless';\\n\\nconst client = connect({ url: '...' });\\nconst db = drizzle(client);\\nawait db.select().from(...);\\n```\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0313.mdx'), name='drizzle-orm-v0313.mdx', displayName='drizzle-orm-v0313.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"---\\ntitle: DrizzleORM v0.31.3 release\\npubDate: 2024-07-08\\ndescription: Prisma-Drizzle extension  \\n---\\n\\n### Bug fixed\\n\\n- ðŸ› ï¸ Fixed RQB behavior for tables with same names in different schemas\\n- ðŸ› ï¸ Fixed [BUG]: Mismatched type hints when using RDS Data API - #2097\\n\\n### New Prisma-Drizzle extension  \\n\\n```ts\\nimport { PrismaClient } from '@prisma/client';\\nimport { drizzle } from 'drizzle-orm/prisma/pg';\\nimport { User } from './drizzle';\\n\\nconst prisma = new PrismaClient().$extends(drizzle());\\nconst users = await prisma.$drizzle.select().from(User);\\n```\\n\\nFor more info, check docs: /docs/prisma\\n\", children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0314.mdx'), name='drizzle-orm-v0314.mdx', displayName='drizzle-orm-v0314.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.31.4 release\\npubDate: 2024-07-08\\ndescription: Mark prisma clients package as optional\\n---\\n\\n- Mark prisma clients package as optional - thanks @Cherry', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0320.mdx'), name='drizzle-orm-v0320.mdx', displayName='drizzle-orm-v0320.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.32.0 release\\npubDate: 2024-07-10\\ndescription: Generated columns, identity columns, sequences and more\\n---\\n\\n# Release notes for `drizzle-orm@0.32.0` and `drizzle-kit@0.23.0`\\n\\n> It\\'s not mandatory to upgrade both packages, but if you want to use the new features in both queries and migrations, you will need to upgrade both packages\\n\\n## New Features\\n\\n### ðŸŽ‰ MySQL `$returningId()` function\\n\\nMySQL itself doesn\\'t have native support for `RETURNING` after using `INSERT`. There is only one way to do it for `primary keys` with `autoincrement` (or `serial`) types, where you can access `insertId` and `affectedRows` fields. We\\'ve prepared an automatic way for you to handle such cases with Drizzle and automatically receive all inserted IDs as separate objects\\n\\n```ts\\nimport { boolean, int, text, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\n\\nconst usersTable = mysqlTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  verified: boolean(\\'verified\\').notNull().default(false),\\n});\\n\\n\\nconst result = await db.insert(usersTable).values([{ name: \\'John\\' }, { name: \\'John1\\' }]).$returningId();\\n//    ^? { id: number }[]\\n```\\n\\nAlso with Drizzle, you can specify a `primary key` with `$default` function that will generate custom primary keys at runtime. We will also return those generated keys for you in the `$returningId()` call\\n\\n```ts\\nimport { varchar, text, mysqlTable } from \\'drizzle-orm/mysql-core\\';\\nimport { createId } from \\'@paralleldrive/cuid2\\';\\n\\nconst usersTableDefFn = mysqlTable(\\'users_default_fn\\', {\\n  customId: varchar(\\'id\\', { length: 256 }).primaryKey().$defaultFn(createId),\\n  name: text(\\'name\\').notNull(),\\n});\\n\\n\\nconst result = await db.insert(usersTableDefFn).values([{ name: \\'John\\' }, { name: \\'John1\\' }]).$returningId();\\n//  ^? { customId: string }[]\\n```\\n\\n> If there is no primary keys -> type will be `{}[]` for such queries\\n\\n### ðŸŽ‰ PostgreSQL Sequences\\n\\nYou can now specify sequences in Postgres within any schema you need and define all the available properties\\n\\n##### **Example**\\n\\n```ts\\nimport { pgSchema, pgSequence } from \"drizzle-orm/pg-core\";\\n\\n// No params specified\\nexport const customSequence = pgSequence(\"name\");\\n\\n// Sequence with params\\nexport const customSequence = pgSequence(\"name\", {\\n      startWith: 100,\\n      maxValue: 10000,\\n      minValue: 100,\\n      cycle: true,\\n      cache: 10,\\n      increment: 2\\n});\\n\\n// Sequence in custom schema\\nexport const customSchema = pgSchema(\\'custom_schema\\');\\n\\nexport const customSequence = customSchema.sequence(\"name\");\\n```\\n\\n### ðŸŽ‰ PostgreSQL Identity Columns\\n\\n[Source](https://wiki.postgresql.org/wiki/Don%27t_Do_This#Don.27t_use_serial): As mentioned, the `serial` type in Postgres is outdated and should be deprecated. Ideally, you should not use it. `Identity columns` are the recommended way to specify sequences in your schema, which is why we are introducing the `identity columns` feature\\n\\n##### **Example**\\n\\n```ts\\nimport { pgTable, integer, text } from \\'drizzle-orm/pg-core\\' \\n\\nexport const ingredients = pgTable(\"ingredients\", {\\n  id: integer(\"id\").primaryKey().generatedAlwaysAsIdentity({ startWith: 1000 }),\\n  name: text(\"name\").notNull(),\\n  description: text(\"description\"),\\n});\\n```\\n\\nYou can specify all properties available for sequences in the `.generatedAlwaysAsIdentity()` function. Additionally, you can specify custom names for these sequences\\n\\nPostgreSQL docs [reference](https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-PARMS-GENERATED-IDENTITY).\\n\\n### ðŸŽ‰ PostgreSQL Generated Columns\\n\\nYou can now specify generated columns on any column supported by PostgreSQL to use with generated columns\\n\\n##### **Example** with generated column for `tsvector`\\n\\n> Note: we will add `tsVector` column type before latest release\\n\\n```ts\\nimport { SQL, sql } from \"drizzle-orm\";\\nimport { customType, index, integer, pgTable, text } from \"drizzle-orm/pg-core\";\\n\\nconst tsVector = customType<{ data: string }>({\\n  dataType() {\\n    return \"tsvector\";\\n  },\\n});\\n\\nexport const test = pgTable(\\n  \"test\",\\n  {\\n    id: integer(\"id\").primaryKey().generatedAlwaysAsIdentity(),\\n    content: text(\"content\"),\\n    contentSearch: tsVector(\"content_search\", {\\n      dimensions: 3,\\n    }).generatedAlwaysAs(\\n      (): SQL => sql`to_tsvector(\\'english\\', ${test.content})`\\n    ),\\n  },\\n  (t) => ({\\n    idx: index(\"idx_content_search\").using(\"gin\", t.contentSearch),\\n  })\\n);\\n```\\n\\nIn case you don\\'t need to reference any columns from your table, you can use just `sql` template or a `string`\\n\\n```ts\\nexport const users = pgTable(\"users\", {\\n  id: integer(\"id\"),\\n  name: text(\"name\"),\\n  generatedName: text(\"gen_name\").generatedAlwaysAs(sql`hello world!`),\\n  generatedName1: text(\"gen_name1\").generatedAlwaysAs(\"hello world!\"),\\n}),\\n```\\n\\n### ðŸŽ‰ MySQL Generated Columns\\n\\nYou can now specify generated columns on any column supported by MySQL to use with generated columns\\n\\nYou can specify both `stored` and `virtual` options, for more info you can check [MySQL docs](https://dev.mysql.com/doc/refman/8.4/en/create-table-generated-columns.html)\\n\\nAlso MySQL has a few limitation for such columns usage, which is described [here](https://dev.mysql.com/doc/refman/8.4/en/alter-table-generated-columns.html)\\n\\nDrizzle Kit will also have limitations for `push` command:\\n\\n1. You can\\'t change the generated constraint expression and type using `push`. Drizzle-kit will ignore this change. To make it work, you would need to `drop the column`, `push`, and then `add a column with a new expression`. This was done due to the complex mapping from the database side, where the schema expression will be modified on the database side and, on introspection, we will get a different string. We can\\'t be sure if you changed this expression or if it was changed and formatted by the database. As long as these are generated columns and `push` is mostly used for prototyping on a local database, it should be fast to `drop` and `create` generated columns. Since these columns are `generated`, all the data will be restored\\n\\n2. `generate` should have no limitations\\n\\n##### **Example**\\n\\n```ts\\nexport const users = mysqlTable(\"users\", {\\n  id: int(\"id\"),\\n  id2: int(\"id2\"),\\n  name: text(\"name\"),\\n  generatedName: text(\"gen_name\").generatedAlwaysAs(\\n    (): SQL => sql`${schema2.users.name} || \\'hello\\'`,\\n    { mode: \"stored\" }\\n  ),\\n  generatedName1: text(\"gen_name1\").generatedAlwaysAs(\\n    (): SQL => sql`${schema2.users.name} || \\'hello\\'`,\\n    { mode: \"virtual\" }\\n  ),\\n}),\\n```\\n\\nIn case you don\\'t need to reference any columns from your table, you can use just `sql` template or a `string` in `.generatedAlwaysAs()`\\n\\n### ðŸŽ‰ SQLite Generated Columns\\n\\nYou can now specify generated columns on any column supported by SQLite to use with generated columns\\n\\nYou can specify both `stored` and `virtual` options, for more info you can check [SQLite docs](https://www.sqlite.org/gencol.html)\\n\\nAlso SQLite has a few limitation for such columns usage, which is described [here](https://www.sqlite.org/gencol.html)\\n\\nDrizzle Kit will also have limitations for `push` and `generate` command:\\n\\n1. You can\\'t change the generated constraint expression with the stored type in an existing table. You would need to delete this table and create it again. This is due to SQLite limitations for such actions. We will handle this case in future releases (it will involve the creation of a new table with data migration).\\n\\n2. You can\\'t add a `stored` generated expression to an existing column for the same reason as above. However, you can add a `virtual` expression to an existing column.\\n\\n3. You can\\'t change a `stored` generated expression in an existing column for the same reason as above. However, you can change a `virtual` expression.\\n\\n4. You can\\'t change the generated constraint type from `virtual` to `stored` for the same reason as above. However, you can change from `stored` to `virtual`.\\n\\n## New Drizzle Kit features\\n\\n### ðŸŽ‰ Migrations support for all the new orm features\\n\\nPostgreSQL sequences, identity columns and generated columns for all dialects\\n\\n### ðŸŽ‰ New flag `--force` for `drizzle-kit push`\\n\\nYou can auto-accept all data-loss statements using the push command. It\\'s only available in CLI parameters. Make sure you always use it if you are fine with running data-loss statements on your database\\n\\n### ðŸŽ‰ New `migrations` flag `prefix`\\n\\nYou can now customize migration file prefixes to make the format suitable for your migration tools:\\n\\n- `index` is the default type and will result in `0001_name.sql` file names;\\n- `supabase` and `timestamp` are equal and will result in `20240627123900_name.sql` file names;\\n- `unix` will result in unix seconds prefixes `1719481298_name.sql` file names;\\n- `none` will omit the prefix completely;\\n\\n\\n##### **Example**: Supabase migrations format\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  migrations: {\\n    prefix: \\'supabase\\'\\n  }\\n});\\n\\n```\\n', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0321.mdx'), name='drizzle-orm-v0321.mdx', displayName='drizzle-orm-v0321.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.32.1 release\\npubDate: 2024-07-23\\ndescription: Bug fixes\\n---\\n\\n- Fix typings for indexes and allow creating indexes on 3+ columns mixing columns and expressions\\n- Added support for \"limit 0\" in all dialects - closes [#2011](https://github.com/drizzle-team/drizzle-orm/issues/2011)\\n- Make inArray and notInArray accept empty list, closes [#1295](https://github.com/drizzle-team/drizzle-orm/issues/1295)\\n- fix typo in lt typedoc\\n- fix wrong example in README.md', children=[]), DocItem(origPath=Path('latest-releases/drizzle-orm-v0322.mdx'), name='drizzle-orm-v0322.mdx', displayName='drizzle-orm-v0322.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: DrizzleORM v0.32.2 release\\npubDate: 2024-08-05\\ndescription: Bug fixes\\n---\\n\\n- Fix AWS Data API type hints bugs in RQB\\n- Fix set transactions in MySQL bug\\n- Add forwaring dependencies within useLiveQuery, fixes [#2651](https://github.com/drizzle-team/drizzle-orm/issues/2651)\\n- Export additional types from SQLite package, like `AnySQLiteUpdate`', children=[])]),\n",
       " DocItem(origPath=Path('latest-releases.mdx'), name='latest-releases.mdx', displayName='latest-releases.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import LatestReleases from \"@components/LatestReleases.astro\";\\n\\n<LatestReleases/>', children=[]),\n",
       " DocItem(origPath=Path('migrate'), name='migrate', displayName='migrate', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('migrate/components.mdx'), name='components.mdx', displayName='components.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport AnchorCards from \"@mdx/AnchorCards.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport CodeTab from \"@mdx/CodeTab.astro\";\\nimport IsSupportedChipGroup from \"@mdx/IsSupportedChipGroup.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport SimpleLinkCards from \"@mdx/SimpleLinkCards.astro\";\\nimport Steps from \"@mdx/Steps.astro\";\\nimport YoutubeCards from \"@mdx/YoutubeCards.astro\";\\n\\n## Npm\\n\\n<Npm>drizzle-orm</Npm>\\n\\n<Npm>drizzle-orm -D drizzle-kit</Npm>\\n\\n## AnchorCards\\n\\n<AnchorCards\\n  cards={{\\n    Anchor1: \"#anchor1\",\\n    Anchor2: \"#anchor2\",\\n    Anchor3: \"#anchor3\",\\n    Anchor4: \"#anchor4\",\\n  }}\\n/>\\n\\n## Callout\\n\\n<Callout emoji={\"ðŸ˜€\"}>Callout example</Callout>\\n\\n<Callout>Callout example</Callout>\\n\\n<Callout type={\"info\"}>Callout example</Callout>\\n\\n<Callout type={\"warning\"}>Callout example</Callout>\\n\\n<Callout type={\"error\"}>Callout example</Callout>\\n\\n## CodeTabs with CodeTab\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy /schema/3\\n\\timport * as schema from \\'./schema\\';\\n\\timport { drizzle } from \\'drizzle-orm/...\\';\\n\\n    const db = drizzle(client, { schema });\\n\\n    const result = await db.query.users.findMany({\\n    \\twith: {\\n    \\t\\tposts: true\\n    \\t},\\n    });\\n    ```\\n\\n    ```ts\\n    [{\\n    \\tid: 10,\\n    \\tname: \"Dan\",\\n    \\tposts: [\\n    \\t\\t{\\n    \\t\\t\\tid: 1,\\n    \\t\\t\\tcontent: \"SQL is awesome\",\\n    \\t\\t\\tauthorId: 10,\\n    \\t\\t},\\n    \\t\\t{\\n    \\t\\t\\tid: 2,\\n    \\t\\t\\tcontent: \"But check relational queries\",\\n    \\t\\t\\tauthorId: 10,\\n    \\t\\t}\\n    \\t]\\n    }]\\n    ```\\n    </CodeTab>\\n\\n    ```typescript copy\\n    import { integer, serial, text, pgTable } from \\'drizzle-orm/pg-core\\';\\n    import { relations } from \\'drizzle-orm\\';\\n\\n    export const users = pgTable(\\'users\\', {\\n    \\tid: serial(\\'id\\').primaryKey(),\\n    \\tname: text(\\'name\\').notNull(),\\n    });\\n\\n    export const usersRelations = relations(users, ({ many }) => ({\\n    \\tposts: many(posts),\\n    }));\\n\\n    export const posts = pgTable(\\'posts\\', {\\n    \\tid: serial(\\'id\\').primaryKey(),\\n    \\tcontent: text(\\'content\\').notNull(),\\n    \\tauthorId: integer(\\'author_id\\').notNull(),\\n    });\\n\\n    export const postsRelations = relations(posts, ({ one }) => ({\\n    \\tauthor: one(users, { fields: [posts.authorId], references: [users.id] }),\\n    }));\\n    ```\\n\\n</CodeTabs>\\n\\n## IsSupportedChipGroup\\n\\n<IsSupportedChipGroup\\n  chips={{ PostgreSQL: true, SQLite: true, MySQL: false }}\\n/>\\n\\n## Section\\n\\nFor codeblocks connection\\n\\n<Section>\\n```typescript\\nimport { sql } from \"drizzle-orm\";\\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\nconst table = sqliteTable(\\'table\\', {\\nint1: integer(\\'int1\\').default(42),\\nint2: integer(\\'int2\\').default(sql`(abs(42))`)\\n});\\n\\n```\\n```sql\\nCREATE TABLE `table` (\\n  `int1` integer DEFAULT 42,\\n  `int2` integer DEFAULT (abs(42))\\n);\\n```\\n\\n</Section>\\n\\n## Tabs with Tab and Section\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { integer, uuid, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    const table = pgTable(\\'table\\', {\\n      integer1: integer(\\'integer1\\').default(42),\\n      integer2: integer(\\'integer2\\').default(sql`\\'42\\'::integer`),\\n      uuid1: uuid(\\'uuid1\\').defaultRandom(),\\n      uuid2: uuid(\\'uuid2\\').default(sql`gen_random_uuid()`),\\n    });\\n    ```\\n\\n    ```sql\\n    CREATE TABLE IF NOT EXISTS \"table\" (\\n      \"integer1\" integer DEFAULT 42,\\n      \"integer2\" integer DEFAULT \\'42\\'::integer,\\n      \"uuid1\" uuid DEFAULT gen_random_uuid(),\\n      \"uuid2\" uuid DEFAULT gen_random_uuid()\\n    );\\n    ```\\n    </Section>\\n\\n  </Tab> \\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { int, time, mysqlTable } from \"drizzle-orm/mysql-core\";\\n    \\n    const table = mysqlTable(\"table\", {\\n      int: int(\"int\").default(42),\\n      time: time(\"time\").default(sql`cast(\"14:06:10\" AS TIME)`),\\n    });\\n    ```\\n    ```sql\\n    CREATE TABLE `table` (\\n      `int` int DEFAULT 42,\\n      `time` time DEFAULT cast(\"14:06:10\" AS TIME)\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```typescript\\n    import { sql } from \"drizzle-orm\";\\n    import { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n    const table = sqliteTable(\\'table\\', {\\n      int1: integer(\\'int1\\').default(42),\\n      int2: integer(\\'int2\\').default(sql`(abs(42))`)\\n    });\\n\\n    ```\\n    ```sql\\n    CREATE TABLE `table` (\\n      `int1` integer DEFAULT 42,\\n      `int2` integer DEFAULT (abs(42))\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n\\n## SimpleLinkCards\\n\\n<SimpleLinkCards\\n  cards={{\\n    \"PostgreSQL column types\": \"/docs/column-types/pg\",\\n    \"MySQL column types\": \"/docs/column-types/mysql\",\\n    \"SQLite column types\": \"/docs/column-types/sqlite\",\\n  }}\\n/>\\n\\n## Steps\\n\\nWith h4 headers\\n\\n<Steps>\\n\\n#### Install babel plugin\\n\\nIt\\'s necessary to bundle SQL migration files as string directly to your bundle.\\n\\n```shell\\nnpm install babel-plugin-inline-import\\n```\\n\\n#### Update config files.\\n\\nYou will need to update `babel.config.js`, `metro.config.js` and `drizzle.config.ts` files\\n\\n```js filename=\\'babel.config.js\\'\\nmodule.exports = function (api) {\\n  api.cache(true);\\n\\n  return {\\n    presets: [\"babel-preset-expo\"],\\n    plugins: [[\"inline-import\", { extensions: [\".sql\"] }]], // <-- add this\\n  };\\n};\\n```\\n</Steps>\\n\\n## YoutubeCards\\n\\n<YoutubeCards cards={[\\n\\t{\\n\\t\\tid: \"4ZhtoOFKFP8\",\\n\\t\\ttitle: \"Easiest Database Setup in Next.js&nbsp;14 with Turso&nbsp;&&nbsp;Drizzle\",\\n\\t\\tdescription: \"Sam Meech-Ward\",\\n\\t\\ttime: \\'38:08\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"NfVELsEZFsA\",\\n\\t\\ttitle: \"Next.js Project with Vercel, Neon, Drizzle, TailwindCSS, FlowBite and more!\",\\n\\t\\tdescription: \"CodingEntrepreneurs\",\\n\\t\\ttime: \\'5:46:28\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"_SLxGYzv6jo\",\\n\\t\\ttitle: \"I Have A New Favorite Database&nbsp;Tool\",\\n\\t\\tdescription: \"Theo - t3.gg\",\\n\\t\\ttime: \\'5:46\\'\\n\\t}\\n]}/>\\n\\n\\n## Collapsable code block\\n\\n```prisma  copy filename=\"prisma/schema.prisma\" collapsable\\ngenerator client {\\n  provider = \"prisma-client-js\"\\n}\\n\\ndatasource db {\\n  provider = \"postgresql\"\\n  url      = env(\"DATABASE_URL\")\\n}\\n\\n\\nmodel Product {\\n  id              Int           @id @default(autoincrement())\\n  name            String\\n  supplierId      Int\\n  unitPrice       Decimal       @db.Decimal(10, 4)\\n  unitsInStock    Int\\n\\n  supplier        Supplier?     @relation(fields: [supplierId], references: [id])\\n  orderDetails    OrderDetail[]\\n\\n  @@map(\"products\")\\n}\\n\\nmodel Supplier {\\n  id           Int       @id @default(autoincrement())\\n  companyName  String\\n  city         String\\n  country      String\\n\\n  products     Product[]\\n\\n  @@map(\"suppliers\")\\n}\\n\\nmodel OrderDetail {\\n  orderId   Int\\n  productId Int\\n  quantity  Int\\n\\n  order   Order   @relation(fields: [orderId], references: [id])\\n  product Product @relation(fields: [productId], references: [id])\\n\\n  @@id([orderId, productId])\\n  @@map(\"order_details\")\\n}\\n\\nmodel Order {\\n  id             Int       @id @default(autoincrement())\\n  orderDate      DateTime  @db.Date\\n  shippedDate    DateTime? @db.Date\\n  shipAddress    String\\n  shipPostalCode String?\\n  shipCountry    String\\n\\n  orderDetails OrderDetail[]\\n\\n  @@map(\"orders\")\\n}\\n```', children=[]), DocItem(origPath=Path('migrate/migrate-from-prisma.mdx'), name='migrate-from-prisma.mdx', displayName='migrate-from-prisma.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Migrate from Prisma to Drizzle\"\\n---\\nimport Steps from \"@mdx/Steps.astro\";\\nimport Npm from \"@mdx/Npm.astro\";\\n\\n## Getting Started\\n\\nThis guide provides a straightforward approach to migrating a basic **Prisma** project to **Drizzle ORM**. Although the example focuses on `PostgreSQL`, the process is similar for other supported databases.\\n\\n### Overview of the migration process\\n\\nRegardless of your application type or API layer, the steps to transition from **Prisma** to **Drizzle ORM** remain consistent:\\n\\n1. Install **Drizzle ORM** & **Drizzle Kit**\\n2. Setup **Drizzle config** file\\n3. Introspect your database\\n4. Connect **Drizzle ORM** to your database\\n5. Transition your **Prisma** queries to **Drizzle ORM** queries\\n\\nThese steps are applicable whether you\\'re developing a REST API (for example, with Express, Koa, or NestJS) or any other type of application that utilizes **Prisma** for database interactions.\\n\\n## Overview of the Prisma project\\n\\nFor this guide, we\\'ll use a REST API built with `Express` as a sample project to migrate to **Drizzle ORM**. It has four entities:\\n\\n```prisma  copy filename=\"prisma/schema.prisma\" collapsable\\ngenerator client {\\n  provider = \"prisma-client-js\"\\n}\\n\\ndatasource db {\\n  provider = \"postgresql\"\\n  url      = env(\"DATABASE_URL\")\\n}\\n\\n\\nmodel Product {\\n  id              Int           @id @default(autoincrement())\\n  name            String\\n  supplierId      Int\\n  unitPrice       Decimal       @db.Decimal(10, 4)\\n  unitsInStock    Int\\n\\n  supplier        Supplier?     @relation(fields: [supplierId], references: [id])\\n  orderDetails    OrderDetail[]\\n\\n  @@map(\"products\")\\n}\\n\\nmodel Supplier {\\n  id           Int       @id @default(autoincrement())\\n  companyName  String\\n  city         String\\n  country      String\\n\\n  products     Product[]\\n\\n  @@map(\"suppliers\")\\n}\\n\\nmodel OrderDetail {\\n  orderId   Int\\n  productId Int\\n  quantity  Int\\n\\n  order   Order   @relation(fields: [orderId], references: [id])\\n  product Product @relation(fields: [productId], references: [id])\\n\\n  @@id([orderId, productId])\\n  @@map(\"order_details\")\\n}\\n\\nmodel Order {\\n  id             Int       @id @default(autoincrement())\\n  orderDate      DateTime  @db.Date\\n  shippedDate    DateTime? @db.Date\\n  shipAddress    String\\n  shipPostalCode String?\\n  shipCountry    String\\n\\n  orderDetails OrderDetail[]\\n\\n  @@map(\"orders\")\\n}\\n```\\n\\nThe models have the following relations:\\n\\n1. `one-to-many` between `Supplier` and `Product`\\n2. `many-to-many` between `Order` and `Product`\\n\\nFor `many-to-many` relation we will create a join table `order_details`, so `Order` and `Product` entities will have `one-to-many` relations with `OrderDetail` entity.\\n\\nThe corresponding tables have been created using a generated Prisma migration.\\n\\n\\n```sql copy filename=\"prisma/migrations/20240101200233_init/migration.sql\" collapsable\\n-- CreateTable\\nCREATE TABLE \"products\" (\\n    \"id\" SERIAL NOT NULL,\\n    \"name\" TEXT NOT NULL,\\n    \"supplierId\" INTEGER NOT NULL,\\n    \"unitPrice\" DECIMAL(10,4) NOT NULL,\\n    \"unitsInStock\" INTEGER NOT NULL,\\n\\n    CONSTRAINT \"products_pkey\" PRIMARY KEY (\"id\")\\n);\\n\\n-- CreateTable\\nCREATE TABLE \"suppliers\" (\\n    \"id\" SERIAL NOT NULL,\\n    \"companyName\" TEXT NOT NULL,\\n    \"city\" TEXT NOT NULL,\\n    \"country\" TEXT NOT NULL,\\n\\n    CONSTRAINT \"suppliers_pkey\" PRIMARY KEY (\"id\")\\n);\\n\\n-- CreateTable\\nCREATE TABLE \"order_details\" (\\n    \"orderId\" INTEGER NOT NULL,\\n    \"productId\" INTEGER NOT NULL,\\n    \"quantity\" INTEGER NOT NULL,\\n\\n    CONSTRAINT \"order_details_pkey\" PRIMARY KEY (\"orderId\",\"productId\")\\n);\\n\\n-- CreateTable\\nCREATE TABLE \"orders\" (\\n    \"id\" SERIAL NOT NULL,\\n    \"orderDate\" DATE NOT NULL,\\n    \"shippedDate\" DATE,\\n    \"shipAddress\" TEXT NOT NULL,\\n    \"shipPostalCode\" TEXT,\\n    \"shipCountry\" TEXT NOT NULL,\\n\\n    CONSTRAINT \"orders_pkey\" PRIMARY KEY (\"id\")\\n);\\n\\n-- AddForeignKey\\nALTER TABLE \"products\" ADD CONSTRAINT \"products_supplierId_fkey\" FOREIGN KEY (\"supplierId\") REFERENCES \"suppliers\"(\"id\") ON DELETE RESTRICT ON UPDATE CASCADE;\\n\\n-- AddForeignKey\\nALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_orderId_fkey\" FOREIGN KEY (\"orderId\") REFERENCES \"orders\"(\"id\") ON DELETE RESTRICT ON UPDATE CASCADE;\\n\\n-- AddForeignKey\\nALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_productId_fkey\" FOREIGN KEY (\"productId\") REFERENCES \"products\"(\"id\") ON DELETE RESTRICT ON UPDATE CASCADE;\\n```\\n\\nThis guide uses the following file structure:\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ prisma\\n â”‚  â”œ ðŸ“‚ migrations\\n â”‚  â”‚  â”œ ðŸ“‚ 20240101200233_init\\n â”‚  â”‚  â”‚  â”” ðŸ“œ migration.sql\\n â”‚  â”‚  â”” ðŸ“œ migration_lock.toml\\n â”‚  â”” ðŸ“œ schema.prisma\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ db\\n â”‚  â”‚  â”” ðŸ“œ db.ts\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n<Steps>\\n\\n#### Install Drizzle ORM & Drizzle Kit\\n\\nThe first step is to install **Drizzle ORM** and `pg` package which we will use as a driver. The second step is to install **Drizzle Kit** and types for `pg`. [Drizzle Kit](/docs/kit-overview) - CLI companion for automatic SQL migrations generation and rapid prototyping. \\n\\n<Npm>\\ndrizzle-orm pg\\n-D drizzle-kit @types/pg\\n</Npm>\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by **Drizzle Kit** and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\'; // make sure to install dotenv package\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\',\\n  out: \\'./src/drizzle\\',\\n  schema: \\'./src/drizzle/schema.ts\\',\\n  dbCredentials: {\\n    host: process.env.DB_HOST!,\\n    port: Number(process.env.DB_PORT!),\\n    user: process.env.DB_USERNAME!,\\n    password: process.env.DB_PASSWORD!,\\n    database: process.env.DB_NAME!,\\n  },\\n  // Print all statements\\n  verbose: true,\\n  // Always ask for confirmation\\n  strict: true,\\n});\\n```\\n\\n#### Introspect your database\\n\\n**Drizzle Kit** provides a CLI command to introspect your database and generate a schema file. The schema file contains all the information about your database tables, columns, relations, and indices.\\n\\n```bash\\nnpx drizzle-kit introspect\\n```\\n\\nThis command will generate a schema.ts file, along with snapshots and migrations in the src/drizzle folder.\\n\\n```typescript collapsable copy filename=\"src/drizzle/schema.ts\"\\nimport {\\n  pgTable,\\n  varchar,\\n  timestamp,\\n  text,\\n  integer,\\n  serial,\\n  foreignKey,\\n  numeric,\\n  date,\\n  primaryKey,\\n} from \\'drizzle-orm/pg-core\\';\\nimport { sql } from \\'drizzle-orm\\';\\n\\nexport const prismaMigrations = pgTable(\\'_prisma_migrations\\', {\\n  id: varchar(\\'id\\', { length: 36 }).primaryKey().notNull(),\\n  checksum: varchar(\\'checksum\\', { length: 64 }).notNull(),\\n  finishedAt: timestamp(\\'finished_at\\', { withTimezone: true, mode: \\'string\\' }),\\n  migrationName: varchar(\\'migration_name\\', { length: 255 }).notNull(),\\n  logs: text(\\'logs\\'),\\n  rolledBackAt: timestamp(\\'rolled_back_at\\', { withTimezone: true, mode: \\'string\\' }),\\n  startedAt: timestamp(\\'started_at\\', { withTimezone: true, mode: \\'string\\' }).defaultNow().notNull(),\\n  appliedStepsCount: integer(\\'applied_steps_count\\').default(0).notNull(),\\n});\\n\\nexport const suppliers = pgTable(\\'suppliers\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  companyName: text(\\'companyName\\').notNull(),\\n  city: text(\\'city\\').notNull(),\\n  country: text(\\'country\\').notNull(),\\n});\\n\\nexport const products = pgTable(\\'products\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  name: text(\\'name\\').notNull(),\\n  supplierId: integer(\\'supplierId\\')\\n    .notNull()\\n    .references(() => suppliers.id, { onDelete: \\'restrict\\', onUpdate: \\'cascade\\' }),\\n  unitPrice: numeric(\\'unitPrice\\', { precision: 10, scale: 4 }).notNull(),\\n  unitsInStock: integer(\\'unitsInStock\\').notNull(),\\n});\\n\\nexport const orders = pgTable(\\'orders\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  orderDate: date(\\'orderDate\\').notNull(),\\n  shippedDate: date(\\'shippedDate\\'),\\n  shipAddress: text(\\'shipAddress\\').notNull(),\\n  shipPostalCode: text(\\'shipPostalCode\\'),\\n  shipCountry: text(\\'shipCountry\\').notNull(),\\n});\\n\\nexport const orderDetails = pgTable(\\n  \\'order_details\\',\\n  {\\n    orderId: integer(\\'orderId\\')\\n      .notNull()\\n      .references(() => orders.id, { onDelete: \\'restrict\\', onUpdate: \\'cascade\\' }),\\n    productId: integer(\\'productId\\')\\n      .notNull()\\n      .references(() => products.id, { onDelete: \\'restrict\\', onUpdate: \\'cascade\\' }),\\n    quantity: integer(\\'quantity\\').notNull(),\\n  },\\n  (table) => [\\n    primaryKey({ columns: [table.orderId, table.productId], name: \\'order_details_pkey\\' })\\n  ]\\n);\\n```\\n\\n```sql collapsable copy filename=\"src/drizzle/0000_cool_puff_adder.sql\"\\nCREATE TABLE IF NOT EXISTS \"_prisma_migrations\" (\\n\\t\"id\" varchar(36) PRIMARY KEY NOT NULL,\\n\\t\"checksum\" varchar(64) NOT NULL,\\n\\t\"finished_at\" timestamp with time zone,\\n\\t\"migration_name\" varchar(255) NOT NULL,\\n\\t\"logs\" text,\\n\\t\"rolled_back_at\" timestamp with time zone,\\n\\t\"started_at\" timestamp with time zone DEFAULT now() NOT NULL,\\n\\t\"applied_steps_count\" integer DEFAULT 0 NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"suppliers\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"companyName\" text NOT NULL,\\n\\t\"city\" text NOT NULL,\\n\\t\"country\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"products\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"supplierId\" integer NOT NULL,\\n\\t\"unitPrice\" numeric(10, 4) NOT NULL,\\n\\t\"unitsInStock\" integer NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"orders\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"orderDate\" date NOT NULL,\\n\\t\"shippedDate\" date,\\n\\t\"shipAddress\" text NOT NULL,\\n\\t\"shipPostalCode\" text,\\n\\t\"shipCountry\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"order_details\" (\\n\\t\"orderId\" integer NOT NULL,\\n\\t\"productId\" integer NOT NULL,\\n\\t\"quantity\" integer NOT NULL,\\n\\tCONSTRAINT order_details_pkey PRIMARY KEY(\"orderId\",\"productId\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"products\" ADD CONSTRAINT \"products_supplierId_fkey\" FOREIGN KEY (\"supplierId\") REFERENCES \"suppliers\"(\"id\") ON DELETE restrict ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_orderId_fkey\" FOREIGN KEY (\"orderId\") REFERENCES \"orders\"(\"id\") ON DELETE restrict ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_productId_fkey\" FOREIGN KEY (\"productId\") REFERENCES \"products\"(\"id\") ON DELETE restrict ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nAlso, if you want to use relational queries, you have to update your schema file with relational tables:\\n\\n```typescript copy filename=\"src/drizzle/schema.ts\"\\n// ...other imports\\nimport { relations } from \\'drizzle-orm\\';\\n\\n// ...other tables\\nexport const suppliersRelations = relations(suppliers, ({ many }) => ({\\n  products: many(products),\\n}));\\n\\nexport const productsRelations = relations(products, ({ one, many }) => ({\\n  supplier: one(suppliers, { fields: [products.supplierId], references: [suppliers.id] }),\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const ordersRelations = relations(orders, ({ many }) => ({\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const orderDetailsRelations = relations(orderDetails, ({ one }) => ({\\n  order: one(orders, { fields: [orderDetails.orderId], references: [orders.id] }),\\n  product: one(products, { fields: [orderDetails.productId], references: [products.id] }),\\n}));\\n```\\n\\nNow we have the following file structure:\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ drizzle\\n â”‚  â”‚  â”œ ðŸ“‚ meta\\n |  |  |  â”œ ðŸ“œ _journal.json\\n â”‚  â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚  â”‚  â”œ ðŸ“œ 0000_cool_puff_adder.sql\\n â”‚  â”‚  â”” ðŸ“œ schema.ts\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ package.json\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `db.ts` file in the `src/drizzle` folder and set up your database configuration:\\n\\n```typescript copy filename=\"src/drizzle/db.ts\"\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport { Client } from \\'pg\\';\\nimport * as schema from \\'./schema\\';\\n\\nexport const client = new Client({\\n  host: process.env.DB_HOST!,\\n  port: Number(process.env.DB_PORT!),\\n  user: process.env.DB_USERNAME!,\\n  password: process.env.DB_PASSWORD!,\\n  database: process.env.DB_NAME!,\\n});\\n\\n// { schema } is used for relational queries\\nexport const db = drizzle({ client, schema });\\n```\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { client, db } from \\'./drizzle/db\\';\\nimport { resolve } from \\'node:path\\';\\nimport { migrate } from \\'drizzle-orm/node-postgres/migrator\\';\\n\\n\\n(async () => {\\n  await client.connect();\\n\\n  // This command run all migrations from the migrations folder and apply changes to the database\\n  await migrate(db, { migrationsFolder: resolve(__dirname, \\'./drizzle\\') });\\n\\n  // ... start your application\\n})();\\n```\\n\\n#### Transition your Prisma queries to Drizzle ORM queries\\n\\nIn this section, we will show you how to replace several queries from **Prisma** with **Drizzle ORM**.\\n\\n##### Replace insert queries\\n\\nWe will show how to insert new rows into `suppliers` and `products` tables.\\n\\n1. `POST /suppliers`\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nawait prisma.supplier.createMany({\\n  data: [\\n    { companyName: \\'TestCompanyName1\\', city: \\'TestCity1\\', country: \\'TestCountry1\\' },\\n    { companyName: \\'TestCompanyName2\\', city: \\'TestCity2\\', country: \\'TestCountry2\\' },\\n  ],\\n});\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nawait db.insert(suppliers).values([\\n  {\\n    companyName: \\'TestCompanyName1\\',\\n    city: \\'TestCity1\\',\\n    country: \\'TestCountry1\\',\\n  },\\n  {\\n    companyName: \\'TestCompanyName2\\',\\n    city: \\'TestCity2\\',\\n    country: \\'TestCountry2\\',\\n  },\\n]);\\n```\\n\\n2. `POST /products`\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nawait prisma.product.createMany({\\n  data: [\\n    { \\n      name: \\'TestProductName1\\',\\n      supplierId: 1,\\n      unitPrice: 10,\\n      unitsInStock: 20,\\n    },\\n    {\\n      name: \\'TestProductName2\\',\\n      supplierId: 1,\\n      unitPrice: 25,\\n      unitsInStock: 7,\\n    },\\n    {\\n      name: \\'TestProductName3\\',\\n      supplierId: 2,\\n      unitPrice: 50,\\n      unitsInStock: 17,\\n    },\\n    {\\n      name: \\'TestProductName4\\',\\n      supplierId: 2,\\n      unitPrice: 100,\\n      unitsInStock: 2,\\n    },\\n  ],\\n});\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\nBe careful with the `unitPrice` field. In **Prisma** it\\'s a `number` type, but in **Drizzle ORM** it\\'s a `string` type, which can handle more than 16383 digits after the decimal point, unlike the `number` type.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nawait db.insert(products).values([\\n  {\\n    name: \\'TestProductName1\\',\\n    supplierId: 1,\\n    unitPrice: \\'10\\',\\n    unitsInStock: 20,\\n  },\\n  {\\n    name: \\'TestProductName2\\',\\n    supplierId: 1,\\n    unitPrice: \\'25\\',\\n    unitsInStock: 7,\\n  },\\n  {\\n    name: \\'TestProductName3\\',\\n    supplierId: 2,\\n    unitPrice: \\'50\\',\\n    unitsInStock: 17,\\n  },\\n  {\\n    name: \\'TestProductName4\\',\\n    supplierId: 2,\\n    unitPrice: \\'100\\',\\n    unitsInStock: 2,\\n  },\\n]);\\n```\\n\\n##### Replace select queries\\n\\nIn this section we will show how to select one row, multiple rows, count rows, filter rows, join tables and paginate results.\\n\\n1. `GET /products/:id`\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await prisma.product.findUnique({\\n  where: { id },\\n  include: {\\n    supplier: true,\\n  },\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products, suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n  .select({\\n    product: products,\\n    supplier: suppliers,\\n  })\\n  .from(products)\\n  .where(eq(products.id, id))\\n  .leftJoin(suppliers, eq(suppliers.id, products.supplierId));\\n\\n// or you can use relational queries\\nconst response = await db.query.products.findFirst({\\n  where: (products, { eq }) => eq(products.id, id),\\n  with: {\\n    supplier: true,\\n  },\\n});\\n```\\n\\nResponse will be type-safe with both ORMs.\\n\\n```typescript\\n// response type for Drizzle ORM\\nconst response: {\\n  product: {\\n    name: string;\\n    id: number;\\n    supplierId: number;\\n    unitPrice: string;\\n    unitsInStock: number;\\n  };\\n  supplier: {\\n    id: number;\\n    companyName: string;\\n    city: string | null;\\n    country: string;\\n  } | null;\\n}[]\\n```\\n\\n2. `GET /products`\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { Prisma } from \\'@prisma/client\\';\\nimport { prisma } from \\'../db/db\\';\\n\\nconst whereOptions: Prisma.ProductWhereInput = {\\n  name: { contains: \\'test\\', mode: \\'insensitive\\' },\\n};\\n\\nconst [response, count] = await Promise.all([\\n  prisma.product.findMany({\\n    where: whereOptions,\\n    take: 10,\\n    skip: 0,\\n    select: {\\n      id: true,\\n      name: true,\\n      unitPrice: true,\\n      unitsInStock: true,\\n    },\\n  }),\\n  prisma.product.count({ where: whereOptions }),\\n]);\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript collapsable copy filename=\"src/controllers/product.controller.ts\"\\nimport { ilike, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products } from \\'../drizzle/schema\\';\\n\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db\\n    .select({\\n      id: products.id,\\n      name: products.name,\\n      unitPrice: products.unitPrice,\\n      unitsInStock: products.unitsInStock,\\n    })\\n    .from(products)\\n    .where(whereOptions)\\n    .offset(0)\\n    .limit(10),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n\\n// or you can use relational queries\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db.query.products.findMany({\\n    where: whereOptions,\\n    columns: {\\n      id: true,\\n      name: true,\\n      unitPrice: true,\\n      unitsInStock: true,\\n    },\\n    offset: 0,\\n    limit: 10,\\n  }),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n```\\n\\nResponse will be type-safe with both ORMs.\\n\\n```typescript\\n// response type for Drizzle ORM\\nconst response: {\\n  id: number;\\n  name: string;\\n  unitPrice: string;\\n  unitsInStock: number;\\n}[]\\n```\\n\\n3. `GET /orders/:id`\\n\\nIn **Prisma**, aggregate functions require using the `aggregate` method. For complex queries, the `$queryRaw` method is used, which is not type-safe.\\n\\nWe want to select `id`, `orderDate` and `shipCountry` fields from `orders` table and by using `aggregation functions` sum `totalPrice` of order, `totalQuantity` of products in the order and count `totalProducts` in the order.\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nconst { id } = req.params;\\n\\nconst order = await prisma.order.findFirst({\\n  where: { id },\\n  select: {\\n    id: true,\\n    orderDate: true,\\n    shipCountry: true,\\n  },\\n});\\nif (!order) {\\n  throw new Error(\\'Order not found\\');\\n}\\n\\nconst { _count, _sum } = await prisma.orderDetail.aggregate({\\n  where: { orderId: id },\\n  _sum: {\\n    quantity: true,\\n  },\\n  _count: {\\n    orderId: true,\\n  },\\n});\\n\\nconst totalPrice: Array<{ totalPrice: number }> = await prisma.$queryRaw<number>`\\n  SELECT SUM(unitPrice * quantity) as \"totalPrice\"\\n  FROM order_details\\n  WHERE \"orderId\" = ${id}\\n`;\\n\\nconst response = {\\n  ...order,\\n  totalPrice: totalPrice[0].totalPrice,\\n  totalQuantity: _sum.quantity,\\n  totalProducts: _count.orderId,\\n};\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orders, orderDetails, products } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n      .select({\\n        id: orders.id,\\n        shipCountry: orders.shipCountry,\\n        orderDate: orders.orderDate,\\n        totalPrice: sql<number>`cast(sum(${orderDetails.quantity} * ${products.unitPrice}) as float)`,\\n        totalQuantity: sql<number>`cast(sum(${orderDetails.quantity}) as int)`,\\n        totalProducts: sql<number>`cast(count(${orderDetails.productId}) as int)`,\\n      })\\n      .from(orders)\\n      .where(eq(orders.id, id))\\n      .groupBy(orders.id)\\n      .leftJoin(orderDetails, eq(orderDetails.orderId, orders.id))\\n      .leftJoin(products, eq(products.id, orderDetails.productId));\\n```\\n\\nIn **Drizzle ORM**, the result will be type-safe with aggregations too.\\n\\n```typescript\\n// response type\\nconst response: {\\n  id: number;\\n  shipCountry: string;\\n  orderDate: string;\\n  totalPrice: number;\\n  totalQuantity: number;\\n  totalProducts: number;\\n}[]\\n```\\n\\n**Note:** as of now aggregations are not supported in relational queries, so you have to use `core queries`.\\n\\n##### Replace update queries\\n\\nIn this section, we will show you how to update multiple rows.\\n\\n1. `PATCH /suppliers/:id`\\n  \\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nconst { id } = req.params;\\n\\nconst supplier = await prisma.supplier.update({\\n  where: { id },\\n  data: { city: \\'TestCity1Updated\\', country: \\'TestCountry1Updated\\' },\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nawait db\\n    .update(suppliers)\\n    .set({\\n      city: \\'TestCity1Updated\\',\\n      country: \\'TestCountry1Updated\\',\\n    })\\n    .where(eq(suppliers.id, id));\\n```\\n\\n##### Replace delete queries\\n\\nIn this section, we will show you how to delete a single row and multiple rows using transactions.\\n\\n1. `DELETE /orders/:id`\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { prisma } from \\'../db/db\\';\\n\\nconst { id } = req.params;\\n\\nconst orderDetailQuery = prisma.orderDetail.deleteMany({\\n  where: { orderId: id },\\n});\\n\\nconst orderQuery = prisma.order.deleteMany({\\n  where: { id },\\n});\\n\\nawait prisma.$transaction([orderDetailQuery, orderQuery]);\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orderDetails, orders } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\ntry {\\n  await db.transaction(async (tx) => {\\n    await tx.delete(orderDetails).where(eq(orderDetails.orderId, id));\\n\\n    await tx.delete(orders).where(eq(orders.id, id));\\n  });\\n} catch (e) {\\n  console.error(e);\\n}\\n```\\n</Steps>\\n', children=[]), DocItem(origPath=Path('migrate/migrate-from-sequelize.mdx'), name='migrate-from-sequelize.mdx', displayName='migrate-from-sequelize.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Migrate from Sequelize to Drizzle\"\\n---\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Steps from \"@mdx/Steps.astro\";\\n\\n## Getting Started\\n\\nThis guide provides a straightforward approach to migrating a basic **Sequelize** project to **Drizzle ORM**. Although the example focuses on `PostgreSQL`, the process is similar for other supported databases.\\n\\n### Overview of the migration process\\n\\nRegardless of your application type or API layer, the steps to transition from **Sequelize** to **Drizzle ORM** remain consistent:\\n\\n1. Install **Drizzle ORM** & **Drizzle Kit**\\n2. Setup **Drizzle config** file\\n3. Introspect your database\\n4. Connect **Drizzle ORM** to your database\\n5. Transition your **Sequelize** queries to **Drizzle ORM** queries\\n\\nThese steps are applicable whether you\\'re developing a REST API (for example, with Express, Koa, or NestJS) or any other type of application that utilizes **Sequelize** for database interactions.\\n\\n## Overview of the Sequelize project\\n\\nFor this guide, we\\'ll use a REST API built with `Express` as a sample project to migrate to **Drizzle ORM**. It has four entities:\\n\\n```typescript collapsable copy filename=\"src/db/models/supplier.ts\"\\nimport { DataTypes, Model } from \\'sequelize\\';\\nimport { Product } from \\'./product\\';\\nimport { sequelize } from \\'../db\\';\\n\\nexport class Supplier extends Model {}\\n\\nSupplier.init(\\n  {\\n    id: {\\n      type: DataTypes.INTEGER,\\n      autoIncrement: true,\\n      primaryKey: true,\\n    },\\n    companyName: {\\n      type: DataTypes.TEXT,\\n      allowNull: false,\\n    },\\n    city: {\\n      type: DataTypes.TEXT,\\n      allowNull: true,\\n    },\\n    country: {\\n      type: DataTypes.TEXT,\\n      allowNull: false,\\n    },\\n  },\\n  {\\n    sequelize,\\n    tableName: \\'suppliers\\',\\n    modelName: \\'Supplier\\',\\n    timestamps: false,\\n  },\\n);\\n\\nSupplier.hasMany(Product, {\\n  foreignKey: \\'supplierId\\',\\n});\\n\\nProduct.belongsTo(Supplier, {\\n  foreignKey: \\'supplierId\\',\\n  targetKey: \\'id\\',\\n});\\n```\\n\\n```typescript collapsable copy filename=\"src/db/models/product.ts\"\\nimport { DataTypes, Model } from \\'sequelize\\';\\nimport { sequelize } from \\'../db\\';\\n\\nexport class Product extends Model {}\\n\\nProduct.init(\\n  {\\n    id: {\\n      type: DataTypes.INTEGER,\\n      autoIncrement: true,\\n      primaryKey: true,\\n    },\\n    name: {\\n      type: DataTypes.TEXT,\\n      allowNull: false,\\n    },\\n    supplierId: {\\n      type: DataTypes.INTEGER,\\n      allowNull: false,\\n      references: {\\n        model: \\'suppliers\\',\\n        key: \\'id\\',\\n      },\\n      field: \\'supplierId\\',\\n    },\\n    unitPrice: {\\n      type: DataTypes.DECIMAL,\\n      allowNull: false,\\n    },\\n    unitsInStock: {\\n      type: DataTypes.INTEGER,\\n      allowNull: false,\\n    },\\n  },\\n  {\\n    sequelize,\\n    tableName: \\'products\\',\\n    modelName: \\'Product\\',\\n    timestamps: false,\\n  },\\n);\\n```\\n\\n```typescript collapsable copy filename=\"src/db/models/order.ts\"\\nimport { DataTypes, Model } from \\'sequelize\\';\\nimport { sequelize } from \\'../db\\';\\n\\nexport class Order extends Model {}\\n\\nOrder.init(\\n  {\\n    id: {\\n      type: DataTypes.INTEGER,\\n      autoIncrement: true,\\n      primaryKey: true,\\n    },\\n    orderDate: {\\n      type: DataTypes.DATE,\\n      allowNull: false,\\n    },\\n    shippedDate: {\\n      type: DataTypes.DATE,\\n      allowNull: true,\\n    },\\n    shipAddress: {\\n      type: DataTypes.TEXT,\\n      allowNull: false,\\n    },\\n    shipPostalCode: {\\n      type: DataTypes.TEXT,\\n      allowNull: true,\\n    },\\n    shipCountry: {\\n      type: DataTypes.TEXT,\\n      allowNull: false,\\n    },\\n  },\\n  {\\n    sequelize,\\n    tableName: \\'orders\\',\\n    modelName: \\'Order\\',\\n    timestamps: false,\\n  },\\n);\\n```\\n\\n```typescript collapsable copy filename=\"src/db/models/order-detail.ts\"\\nimport { DataTypes, Model } from \\'sequelize\\';\\nimport { sequelize } from \\'../db\\';\\nimport { Order } from \\'./order\\';\\nimport { Product } from \\'./product\\';\\n\\nexport class OrderDetail extends Model {}\\n\\nOrderDetail.init(\\n  {\\n    orderId: {\\n      type: DataTypes.INTEGER,\\n      primaryKey: true,\\n      references: {\\n        model: Order,\\n        key: \\'id\\',\\n      },\\n      field: \\'orderId\\',\\n    },\\n    productId: {\\n      type: DataTypes.INTEGER,\\n      primaryKey: true,\\n      references: {\\n        model: Product,\\n        key: \\'id\\',\\n      },\\n      field: \\'productId\\',\\n    },\\n    quantity: {\\n      type: DataTypes.INTEGER,\\n      allowNull: false,\\n    },\\n  },\\n  {\\n    sequelize,\\n    tableName: \\'order_details\\',\\n    modelName: \\'OrderDetail\\',\\n    timestamps: false,\\n  },\\n);\\n\\nOrder.hasMany(OrderDetail, { foreignKey: \\'orderId\\', as: \\'details\\' });\\nOrderDetail.belongsTo(Order, { foreignKey: \\'orderId\\' });\\n\\nProduct.hasMany(OrderDetail, { foreignKey: \\'productId\\', as: \\'details\\' });\\nOrderDetail.belongsTo(Product, { foreignKey: \\'productId\\' });\\n\\nOrder.belongsToMany(Product, {\\n  through: OrderDetail,\\n  foreignKey: \\'orderId\\',\\n  as: \\'products\\',\\n  targetKey: \\'id\\',\\n});\\nProduct.belongsToMany(Order, {\\n  through: OrderDetail,\\n  foreignKey: \\'productId\\',\\n  as: \\'orders\\',\\n  targetKey: \\'id\\',\\n});\\n```\\n\\nThe models have the following relations:\\n\\n1. `one-to-many` between `Supplier` and `Product`\\n2. `many-to-many` between `Order` and `Product`\\n\\nFor `many-to-many` relation we will create a join table `order_details`, so `Order` and `Product` entities will have `one-to-many` relations with `OrderDetail` entity.\\n\\nThe corresponding tables have been created using Sequelize migration. Sequelize doesn\\'t support auto generation of migrations, so you have to write them manually.\\n\\n```javascript collapsable copy filename=\"src/db/migrations/20231220152726-init.js\"\\n\\'use strict\\';\\n\\nmodule.exports = {\\n  async up(queryInterface, Sequelize) {\\n    await queryInterface.createTable(\\'suppliers\\', {\\n      id: {\\n        type: Sequelize.INTEGER,\\n        autoIncrement: true,\\n        primaryKey: true,\\n      },\\n      companyName: {\\n        type: Sequelize.TEXT,\\n        allowNull: false,\\n      },\\n      city: {\\n        type: Sequelize.TEXT,\\n        allowNull: true,\\n      },\\n      country: {\\n        type: Sequelize.TEXT,\\n        allowNull: false,\\n      },\\n    });\\n\\n    await queryInterface.createTable(\\'products\\', {\\n      id: {\\n        type: Sequelize.INTEGER,\\n        autoIncrement: true,\\n        primaryKey: true,\\n      },\\n      name: {\\n        type: Sequelize.TEXT,\\n        allowNull: false,\\n      },\\n      supplierId: {\\n        type: Sequelize.INTEGER,\\n        allowNull: false,\\n        references: {\\n          model: \\'suppliers\\',\\n          key: \\'id\\',\\n        },\\n        onUpdate: \\'CASCADE\\',\\n        onDelete: \\'SET NULL\\',\\n      },\\n      unitPrice: {\\n        type: Sequelize.DECIMAL,\\n        allowNull: false,\\n      },\\n      unitsInStock: {\\n        type: Sequelize.INTEGER,\\n        allowNull: false,\\n      },\\n    });\\n\\n    await queryInterface.createTable(\\'orders\\', {\\n      id: {\\n        type: Sequelize.INTEGER,\\n        autoIncrement: true,\\n        primaryKey: true,\\n      },\\n      orderDate: {\\n        type: Sequelize.DATE,\\n        allowNull: false,\\n      },\\n      shippedDate: {\\n        type: Sequelize.DATE,\\n        allowNull: true,\\n      },\\n      shipAddress: {\\n        type: Sequelize.TEXT,\\n        allowNull: false,\\n      },\\n      shipPostalCode: {\\n        type: Sequelize.TEXT,\\n        allowNull: true,\\n      },\\n      shipCountry: {\\n        type: Sequelize.TEXT,\\n        allowNull: false,\\n      },\\n    });\\n\\n    await queryInterface.createTable(\\'order_details\\', {\\n      orderId: {\\n        type: Sequelize.INTEGER,\\n        primaryKey: true,\\n        references: {\\n          model: \\'orders\\',\\n          key: \\'id\\',\\n        },\\n        onUpdate: \\'CASCADE\\',\\n        onDelete: \\'CASCADE\\',\\n      },\\n      productId: {\\n        type: Sequelize.INTEGER,\\n        primaryKey: true,\\n        references: {\\n          model: \\'products\\',\\n          key: \\'id\\',\\n        },\\n        onUpdate: \\'CASCADE\\',\\n        onDelete: \\'CASCADE\\',\\n      },\\n      quantity: {\\n        type: Sequelize.INTEGER,\\n        allowNull: false,\\n      },\\n    });\\n  },\\n\\n  async down(queryInterface, Sequelize) {\\n    await queryInterface.dropTable(\\'order_details\\');\\n    await queryInterface.dropTable(\\'orders\\');\\n    await queryInterface.dropTable(\\'products\\');\\n    await queryInterface.dropTable(\\'suppliers\\');\\n  },\\n};\\n```\\n\\nThis guide uses the following file structure:\\n\\n```text\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ db\\n â”‚  â”‚  â”œ ðŸ“‚ migrations\\n â”‚  â”‚  â”‚  â”” ðŸ“œ 20231220152726-init.js\\n â”‚  â”‚  â”œ ðŸ“‚ models\\n â”‚  â”‚  â”‚  â”œ ðŸ“œ order-detail.ts\\n â”‚  â”‚  â”‚  â”œ ðŸ“œ order.ts\\n â”‚  â”‚  â”‚  â”œ ðŸ“œ product.ts\\n â”‚  â”‚  â”‚  â”” ðŸ“œ supplier.ts\\n â”‚  â”‚  â”œ ðŸ“œ db.ts\\n â”‚  â”‚  â”” ðŸ“œ config.js\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ .sequelizerc\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n<Steps>\\n\\n#### Install Drizzle ORM & Drizzle Kit\\n\\nThe first step is to install **Drizzle ORM** and `pg` package which we will use as a driver. The second step is to install **Drizzle Kit** and types for `pg`. [Drizzle Kit](/docs/kit-overview) - CLI companion for automatic SQL migrations generation and rapid prototyping. \\n\\n<Npm>\\ndrizzle-orm pg\\n-D drizzle-kit @types/pg\\n</Npm>\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by **Drizzle Kit** and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\'; // make sure to install dotenv package\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\',\\n  out: \\'./src/drizzle\\',\\n  schema: \\'./src/drizzle/schema.ts\\',\\n  dbCredentials: {\\n    host: process.env.DB_HOST!,\\n    port: Number(process.env.DB_PORT!),\\n    user: process.env.DB_USERNAME!,\\n    password: process.env.DB_PASSWORD!,\\n    database: process.env.DB_NAME!,\\n  },\\n  // Print all statements\\n  verbose: true,\\n  // Always ask for confirmation\\n  strict: true,\\n});\\n```\\n\\n#### Introspect your database\\n\\n**Drizzle Kit** provides a CLI command to introspect your database and generate a schema file. The schema file contains all the information about your database tables, columns, relations, and indices.\\n\\n```bash\\nnpx drizzle-kit introspect\\n```\\n\\nThis command will generate a schema.ts file, along with snapshots and migrations in the src/drizzle folder.\\n\\n```typescript collapsable copy filename=\"src/drizzle/schema.ts\"\\nimport {\\n  pgTable,\\n  varchar,\\n  serial,\\n  text,\\n  foreignKey,\\n  integer,\\n  numeric,\\n  timestamp,\\n  primaryKey,\\n} from \\'drizzle-orm/pg-core\\';\\nimport { relations, sql } from \\'drizzle-orm\\';\\n\\nexport const sequelizeMeta = pgTable(\\'SequelizeMeta\\', {\\n  name: varchar(\\'name\\', { length: 255 }).primaryKey().notNull(),\\n});\\n\\nexport const suppliers = pgTable(\\'suppliers\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  companyName: text(\\'companyName\\').notNull(),\\n  city: text(\\'city\\'),\\n  country: text(\\'country\\').notNull(),\\n});\\n\\nexport const products = pgTable(\\'products\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  name: text(\\'name\\').notNull(),\\n  supplierId: integer(\\'supplierId\\')\\n    .notNull()\\n    .references(() => suppliers.id, { onDelete: \\'set null\\', onUpdate: \\'cascade\\' }),\\n  unitPrice: numeric(\\'unitPrice\\').notNull(),\\n  unitsInStock: integer(\\'unitsInStock\\').notNull(),\\n});\\n\\nexport const orders = pgTable(\\'orders\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  orderDate: timestamp(\\'orderDate\\', { withTimezone: true, mode: \\'string\\' }).notNull(),\\n  shippedDate: timestamp(\\'shippedDate\\', { withTimezone: true, mode: \\'string\\' }),\\n  shipAddress: text(\\'shipAddress\\').notNull(),\\n  shipPostalCode: text(\\'shipPostalCode\\'),\\n  shipCountry: text(\\'shipCountry\\').notNull(),\\n});\\n\\nexport const orderDetails = pgTable(\\n  \\'order_details\\',\\n  {\\n    orderId: integer(\\'orderId\\')\\n      .notNull()\\n      .references(() => orders.id, { onDelete: \\'cascade\\', onUpdate: \\'cascade\\' }),\\n    productId: integer(\\'productId\\')\\n      .notNull()\\n      .references(() => products.id, { onDelete: \\'cascade\\', onUpdate: \\'cascade\\' }),\\n    quantity: integer(\\'quantity\\').notNull(),\\n  },\\n  (table) => [\\n    primaryKey({ columns: [table.orderId, table.productId], name: \\'order_details_pkey\\' })\\n  ]\\n);\\n```\\n\\n```sql collapsable copy filename=\"src/drizzle/0000_high_rhodey.sql\"\\n-- Current sql file was generated after introspecting the database\\n\\nCREATE TABLE IF NOT EXISTS \"SequelizeMeta\" (\\n\\t\"name\" varchar(255) PRIMARY KEY NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"suppliers\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"companyName\" text NOT NULL,\\n\\t\"city\" text,\\n\\t\"country\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"products\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"supplierId\" integer NOT NULL,\\n\\t\"unitPrice\" numeric NOT NULL,\\n\\t\"unitsInStock\" integer NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"orders\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"orderDate\" timestamp with time zone NOT NULL,\\n\\t\"shippedDate\" timestamp with time zone,\\n\\t\"shipAddress\" text NOT NULL,\\n\\t\"shipPostalCode\" text,\\n\\t\"shipCountry\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"order_details\" (\\n\\t\"orderId\" integer NOT NULL,\\n\\t\"productId\" integer NOT NULL,\\n\\t\"quantity\" integer NOT NULL,\\n\\tCONSTRAINT order_details_pkey PRIMARY KEY(\"orderId\",\"productId\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"products\" ADD CONSTRAINT \"products_supplierId_fkey\" FOREIGN KEY (\"supplierId\") REFERENCES \"suppliers\"(\"id\") ON DELETE set null ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_orderId_fkey\" FOREIGN KEY (\"orderId\") REFERENCES \"orders\"(\"id\") ON DELETE cascade ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"order_details_productId_fkey\" FOREIGN KEY (\"productId\") REFERENCES \"products\"(\"id\") ON DELETE cascade ON UPDATE cascade;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nAlso, if you want to use relational queries, you have to update your schema file with relational tables:\\n\\n```typescript copy filename=\"src/drizzle/schema.ts\"\\n// ...other imports\\nimport { relations } from \\'drizzle-orm\\';\\n\\n// ...other tables \\nexport const suppliersRelations = relations(suppliers, ({ many }) => ({\\n  products: many(products),\\n}));\\n\\nexport const productsRelations = relations(products, ({ one, many }) => ({\\n  supplier: one(suppliers, { fields: [products.supplierId], references: [suppliers.id] }),\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const ordersRelations = relations(orders, ({ many }) => ({\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const orderDetailsRelations = relations(orderDetails, ({ one }) => ({\\n  order: one(orders, { fields: [orderDetails.orderId], references: [orders.id] }),\\n  product: one(products, { fields: [orderDetails.productId], references: [products.id] }),\\n}));\\n```\\n\\nNow we have the following file structure:\\n\\n```text\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ drizzle\\n â”‚  â”‚  â”œ ðŸ“‚ meta\\n |  |  |  â”œ ðŸ“œ _journal.json\\n â”‚  â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚  â”‚  â”œ ðŸ“œ 0000_lush_lenny_balinger.sql\\n â”‚  â”‚  â”” ðŸ“œ schema.ts\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ package.json\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `db.ts` file in the `src/drizzle` folder and set up your database configuration:\\n\\n```typescript copy filename=\"src/drizzle/db.ts\"\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport { Client } from \\'pg\\';\\nimport * as schema from \\'./schema\\';\\n\\nexport const client = new Client({\\n  host: process.env.DB_HOST!,\\n  port: Number(process.env.DB_PORT!),\\n  user: process.env.DB_USERNAME!,\\n  password: process.env.DB_PASSWORD!,\\n  database: process.env.DB_NAME!,\\n});\\n\\n// { schema } is used for relational queries\\nexport const db = drizzle({ client, schema });\\n```\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { client, db } from \\'./drizzle/db\\';\\nimport { resolve } from \\'node:path\\';\\nimport { migrate } from \\'drizzle-orm/node-postgres/migrator\\';\\n\\n\\n(async () => {\\n  await client.connect();\\n\\n  // This command run all migrations from the migrations folder and apply changes to the database\\n  await migrate(db, { migrationsFolder: resolve(__dirname, \\'./drizzle\\') });\\n\\n  // ... start your application\\n})();\\n```\\n\\n#### Transition your Sequelize queries to Drizzle ORM queries\\n\\nIn this section, we will show you how to replace several queries from **Sequelize** with **Drizzle ORM**.\\n\\n##### Replace insert queries\\n\\nWe will show how to insert new rows into `suppliers` and `products` tables.\\n\\n1. `POST /suppliers`\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { Supplier } from \\'../db/models/supplier\\';\\n\\nconst suppliers = await Supplier.bulkCreate([\\n  {\\n    companyName: \\'TestCompanyName1\\',\\n    city: \\'TestCity1\\',\\n    country: \\'TestCountry1\\',\\n  },\\n  {\\n    companyName: \\'TestCompanyName2\\',\\n    city: \\'TestCity2\\',\\n    country: \\'TestCountry2\\',\\n  },\\n]);\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nawait db.insert(suppliers).values([\\n  {\\n    companyName: \\'TestCompanyName1\\',\\n    city: \\'TestCity1\\',\\n    country: \\'TestCountry1\\',\\n  },\\n  {\\n    companyName: \\'TestCompanyName2\\',\\n    city: \\'TestCity2\\',\\n    country: \\'TestCountry2\\',\\n  },\\n]);\\n```\\n\\n2. `POST /products`\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { Product } from \\'../db/models/product\\';\\n\\nconst products = await Product.bulkCreate([\\n  {\\n    name: \\'TestProductName1\\',\\n    supplierId: 1,\\n    unitPrice: 10,\\n    unitsInStock: 20,\\n  },\\n  {\\n    name: \\'TestProductName2\\',\\n    supplierId: 1,\\n    unitPrice: 25,\\n    unitsInStock: 7,\\n  },\\n  {\\n    name: \\'TestProductName3\\',\\n    supplierId: 2,\\n    unitPrice: 50,\\n    unitsInStock: 17,\\n  },\\n  {\\n    name: \\'TestProductName4\\',\\n    supplierId: 2,\\n    unitPrice: 100,\\n    unitsInStock: 2,\\n  },\\n]);\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\nBe careful with the `unitPrice` field. In **Sequelize** it\\'s a `number` type, but in **Drizzle ORM** it\\'s a `string` type, which can handle more than 16383 digits after the decimal point, unlike the `number` type.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nawait db.insert(products).values([\\n  {\\n    name: \\'TestProductName1\\',\\n    supplierId: 1,\\n    unitPrice: \\'10\\',\\n    unitsInStock: 20,\\n  },\\n  {\\n    name: \\'TestProductName2\\',\\n    supplierId: 1,\\n    unitPrice: \\'25\\',\\n    unitsInStock: 7,\\n  },\\n  {\\n    name: \\'TestProductName3\\',\\n    supplierId: 2,\\n    unitPrice: \\'50\\',\\n    unitsInStock: 17,\\n  },\\n  {\\n    name: \\'TestProductName4\\',\\n    supplierId: 2,\\n    unitPrice: \\'100\\',\\n    unitsInStock: 2,\\n  },\\n]);\\n```\\n\\n##### Replace select queries\\n\\nIn this section we will show how to select one row, multiple rows, count rows, filter rows, join tables and paginate results.\\n\\n1. `GET /products/:id`\\n\\nIn **Sequelize**, the response type is not strictly typed. For example, if you choose to include a relation or select only a few fields instead of all, these modifications will not be reflected in the response type.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { Product } from \\'../db/models/product\\';\\nimport { Supplier } from \\'../db/models/supplier\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await Product.findByPk(id, {\\n  include: Supplier,\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products, suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n  .select({\\n    product: products,\\n    supplier: suppliers,\\n  })\\n  .from(products)\\n  .where(eq(products.id, id))\\n  .leftJoin(suppliers, eq(suppliers.id, products.supplierId));\\n\\n// or you can use relational queries\\nconst response = await db.query.products.findFirst({\\n  where: (products, { eq }) => eq(products.id, id),\\n  with: {\\n    supplier: true,\\n  },\\n});\\n```\\n\\nIn **Drizzle ORM**, the response type will match precisely what is specified in the select object, so including the `supplier` relation is fully type-safe.\\n\\n```typescript\\n// response type\\nconst response: {\\n  product: {\\n    name: string;\\n    id: number;\\n    supplierId: number;\\n    unitPrice: string;\\n    unitsInStock: number;\\n  };\\n  supplier: {\\n    id: number;\\n    companyName: string;\\n    city: string | null;\\n    country: string;\\n  } | null;\\n}[]\\n```\\n\\n2. `GET /products`\\n\\nIn **Sequelize**, the result is not type-safe as it doesn\\'t specify the fields you want to select.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { Product } from \\'../db/models/product\\';\\nimport { Op } from \\'sequelize\\';\\n\\nconst { rows, count } = await Product.findAndCountAll({\\n  limit: 10,\\n  offset: 0,\\n  attributes: [\\'id\\', \\'name\\', \\'unitPrice\\', \\'unitsInStock\\'],\\n  where: {\\n    name: {\\n      [Op.iLike]: `%test%`,\\n    },\\n  },\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript collapsable copy filename=\"src/controllers/product.controller.ts\"\\nimport { ilike, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products } from \\'../drizzle/schema\\';\\n\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db\\n    .select({\\n      id: products.id,\\n      name: products.name,\\n      unitPrice: products.unitPrice,\\n      unitsInStock: products.unitsInStock,\\n    })\\n    .from(products)\\n    .where(whereOptions)\\n    .offset(0)\\n    .limit(10),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n\\n// or you can use relational queries\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db.query.products.findMany({\\n    where: whereOptions,\\n    columns: {\\n      id: true,\\n      name: true,\\n      unitPrice: true,\\n      unitsInStock: true,\\n    },\\n    offset: 0,\\n    limit: 10,\\n  }),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n```\\n\\nIn **Drizzle ORM**, the result is strictly type-safe, meaning the fields you select are explicitly defined.\\n\\n```typescript\\n// response type\\nconst response: {\\n  id: number;\\n  name: string;\\n  unitPrice: string;\\n  unitsInStock: number;\\n}[]\\n```\\n\\n3. `GET /orders/:id`\\n\\nIn **Sequelize** you can\\'t implement complicated queries with methods like `findByPk`. So, you have to use raw queries, which are not type-safe as well.\\n\\nWe want to select `id`, `orderDate` and `shipCountry` fields from `orders` table and by using `aggregation functions` sum `totalPrice` of order, `totalQuantity` of products in the order and count `totalProducts` in the order.\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { sequelize } from \\'../db/db\\';\\nimport { QueryTypes } from \\'sequelize\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await sequelize.query(\\n      `\\nSELECT \\n  orders.id,\\n  orders.\"orderDate\",\\n  orders.\"shipCountry\",\\n  SUM(products.\"unitPrice\" * order_details.quantity)::float AS \"totalPrice\",\\n  SUM(order_details.quantity)::int AS \"totalQuantity\",\\n  COUNT(order_details.\"productId\")::int AS \"totalProducts\"\\nFROM orders\\nLEFT JOIN order_details ON orders.id = order_details.\"orderId\"\\nLEFT JOIN products ON order_details.\"productId\" = products.id\\nWHERE orders.id = :orderId\\nGROUP BY orders.id\\n`,\\n      {\\n        replacements: { orderId: id },\\n        type: QueryTypes.SELECT,\\n      },\\n    );\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orders, orderDetails, products } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n      .select({\\n        id: orders.id,\\n        shipCountry: orders.shipCountry,\\n        orderDate: orders.orderDate,\\n        totalPrice: sql<number>`cast(sum(${orderDetails.quantity} * ${products.unitPrice}) as float)`,\\n        totalQuantity: sql<number>`cast(sum(${orderDetails.quantity}) as int)`,\\n        totalProducts: sql<number>`cast(count(${orderDetails.productId}) as int)`,\\n      })\\n      .from(orders)\\n      .where(eq(orders.id, id))\\n      .groupBy(orders.id)\\n      .leftJoin(orderDetails, eq(orderDetails.orderId, orders.id))\\n      .leftJoin(products, eq(products.id, orderDetails.productId));\\n```\\n\\nIn **Drizzle ORM**, the result will be type-safe with aggregations too.\\n\\n```typescript\\n// response type\\nconst response: {\\n  id: number;\\n  shipCountry: string;\\n  orderDate: string;\\n  totalPrice: number;\\n  totalQuantity: number;\\n  totalProducts: number;\\n}[]\\n```\\n\\n**Note:** as of now aggregations are not supported in relational queries, so you have to use `core queries`.\\n\\n##### Replace update queries\\n\\nIn this section, we will show you how to update multiple rows.\\n\\n1. `PATCH /suppliers/:id`\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { Supplier } from \\'../db/models/supplier\\';\\n\\nconst { id } = req.params;\\n\\nconst supplier = await Supplier.findByPk(1);\\nif (!supplier) {\\n  throw new Error(\\'Supplier not found\\');\\n}\\n\\nsupplier.set({\\n  city: \\'TestCity1Updated\\',\\n  country: \\'TestCountry1Updated\\',\\n});\\n\\nawait supplier.save();\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nawait db\\n    .update(suppliers)\\n    .set({\\n      city: \\'TestCity1Updated\\',\\n      country: \\'TestCountry1Updated\\',\\n    })\\n    .where(eq(suppliers.id, id));\\n```\\n\\n##### Replace delete queries\\n\\nIn this section, we will show you how to delete a single row and multiple rows using transactions.\\n\\n1. `DELETE /orders/:id`\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { Order } from \\'../db/models/order\\';\\nimport { OrderDetail } from \\'../db/models/order-detail\\';\\nimport { sequelize } from \\'../db/db\\';\\n\\nconst { id } = req.params;\\n\\ntry {\\n  const order = await Order.findByPk(id);\\n  if (!order) {\\n    throw new Error(\\'Order not found\\');\\n  }\\n\\n  await sequelize.transaction(async (t) => {\\n    await OrderDetail.destroy({\\n      where: {\\n        orderId: id,\\n      },\\n      transaction: t,\\n    });\\n\\n    await order.destroy({ transaction: t });\\n  });\\n} catch (e) {\\n  console.error(e);\\n}\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orderDetails, orders } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\ntry {\\n  await db.transaction(async (tx) => {\\n    await tx.delete(orderDetails).where(eq(orderDetails.orderId, id));\\n\\n    await tx.delete(orders).where(eq(orders.id, id));\\n  });\\n} catch (e) {\\n  console.error(e);\\n}\\n```\\n\\n</Steps>\\n', children=[]), DocItem(origPath=Path('migrate/migrate-from-typeorm.mdx'), name='migrate-from-typeorm.mdx', displayName='migrate-from-typeorm.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Migrate from TypeORM to Drizzle\"\\n---\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Steps from \"@mdx/Steps.astro\";\\n\\n## Getting Started\\n\\nThis guide provides a straightforward approach to migrating a basic **TypeORM** project to **Drizzle ORM**. Although the example focuses on `PostgreSQL`, the process is similar for other supported databases.\\n\\n### Overview of the migration process\\n\\nRegardless of your application type or API layer, the steps to transition from **TypeORM** to **Drizzle ORM** remain consistent:\\n\\n1. Install **Drizzle ORM** & **Drizzle Kit**\\n2. Setup **Drizzle config** file\\n3. Introspect your database\\n4. Connect **Drizzle ORM** to your database\\n5. Transition your **TypeORM** queries to **Drizzle ORM** queries\\n\\nThese steps are applicable whether you\\'re developing a REST API (for example, with Express, Koa, or NestJS) or any other type of application that utilizes **TypeORM** for database interactions.\\n\\n## Overview of the TypeORM project\\n\\nFor this guide, we\\'ll use a REST API built with `Express` as a sample project to migrate to **Drizzle ORM**. It has four entities:\\n\\n```typescript collapsable copy filename=\"src/entities/supplier.entity.ts\"\\nimport { Column, Entity, OneToMany, PrimaryGeneratedColumn } from \\'typeorm\\';\\nimport { Product } from \\'./product.entity\\';\\n\\n@Entity({ name: \\'suppliers\\' })\\nexport class Supplier {\\n  @PrimaryGeneratedColumn(\\'increment\\')\\n  public id: number;\\n\\n  @Column({ type: \\'text\\' })\\n  public companyName: string;\\n\\n  @Column({ type: \\'text\\', nullable: true })\\n  public city: string;\\n\\n  @Column({ type: \\'text\\' })\\n  public country: string;\\n\\n  @OneToMany(() => Product, (product) => product.supplier)\\n  public products: Product[];\\n}\\n```\\n\\n```typescript collapsable copy filename=\"src/entities/product.entity.ts\"\\nimport { Column, Entity, JoinColumn, ManyToOne, OneToMany, PrimaryGeneratedColumn } from \\'typeorm\\';\\nimport { OrderDetail } from \\'./order-detail.entity\\';\\nimport { Supplier } from \\'./supplier.entity\\';\\n\\n@Entity({ name: \\'products\\' })\\nexport class Product {\\n  @PrimaryGeneratedColumn(\\'increment\\')\\n  public id: number;\\n\\n  @Column({ type: \\'text\\' })\\n  public name: string;\\n\\n  @Column({ type: \\'integer\\' })\\n  public supplierId: number;\\n\\n  @Column({ type: \\'decimal\\', precision: 10, scale: 4 })\\n  public unitPrice: number;\\n\\n  @Column({ type: \\'integer\\' })\\n  public unitsInStock: number;\\n\\n  @OneToMany(() => OrderDetail, (orderDetail) => orderDetail.product)\\n  public orderDetails: OrderDetail[];\\n\\n  @ManyToOne(() => Supplier, (supplier) => supplier.products)\\n  @JoinColumn({ name: \\'supplierId\\', referencedColumnName: \\'id\\' })\\n  public supplier: Supplier;\\n}\\n```\\n\\n```typescript collapsable copy filename=\"src/entities/order.entity.ts\"\\nimport { Column, Entity, OneToMany, PrimaryGeneratedColumn } from \\'typeorm\\';\\nimport { OrderDetail } from \\'./order-detail.entity\\';\\n\\n@Entity({ name: \\'orders\\' })\\nexport class Order {\\n  @PrimaryGeneratedColumn(\\'increment\\')\\n  public id: number;\\n\\n  @Column({ type: \\'date\\' })\\n  public orderDate: Date;\\n\\n  @Column({ type: \\'date\\', nullable: true })\\n  public shippedDate: Date;\\n\\n  @Column({ type: \\'text\\' })\\n  public shipAddress: string;\\n\\n  @Column({ type: \\'text\\', nullable: true })\\n  public shipPostalCode: string;\\n\\n  @Column({ type: \\'text\\' })\\n  public shipCountry: string;\\n\\n  @OneToMany(() => OrderDetail, (orderDetail) => orderDetail.order)\\n  public orderDetails: OrderDetail[];\\n}\\n```\\n\\n```typescript collapsable copy filename=\"src/entities/order-detail.entity.ts\"\\nimport { Column, Entity, JoinColumn, ManyToOne, PrimaryColumn } from \\'typeorm\\';\\nimport { Order } from \\'./order.entity\\';\\nimport { Product } from \\'./product.entity\\';\\n\\n@Entity({ name: \\'order_details\\' })\\nexport class OrderDetail {\\n  @PrimaryColumn({ type: \\'integer\\' })\\n  public orderId: number;\\n\\n  @PrimaryColumn({ type: \\'integer\\' })\\n  public productId: number;\\n\\n  @Column({ type: \\'integer\\' })\\n  public quantity: number;\\n\\n  @ManyToOne(() => Order, (order) => order.orderDetails)\\n  @JoinColumn({ name: \\'orderId\\', referencedColumnName: \\'id\\' })\\n  public order: Order;\\n\\n  @ManyToOne(() => Product, (product) => product.orderDetails)\\n  @JoinColumn({ name: \\'productId\\', referencedColumnName: \\'id\\' })\\n  public product: Product;\\n}\\n```\\n\\nThe models have the following relations:\\n\\n1. `one-to-many` between `Supplier` and `Product`\\n2. `many-to-many` between `Order` and `Product`\\n\\nFor `many-to-many` relation we will create a join table `order_details`, so `Order` and `Product` entities will have `one-to-many` relations with `OrderDetail` entity.\\n\\nThe corresponding tables have been created using a generated TypeORM migration.\\n\\n```typescript copy filename=\"src/db/migrations/1702216840703-init.ts\"\\nimport { MigrationInterface, QueryRunner } from \"typeorm\";\\n\\nexport class Init1702216840703 implements MigrationInterface {\\n    name = \\'Init1702216840703\\'\\n\\n    public async up(queryRunner: QueryRunner): Promise<void> {\\n        await queryRunner.query(`CREATE TABLE \"orders\" (\"id\" SERIAL NOT NULL, \"orderDate\" date NOT NULL, \"shippedDate\" date, \"shipAddress\" text NOT NULL, \"shipPostalCode\" text, \"shipCountry\" text NOT NULL, CONSTRAINT \"PK_710e2d4957aa5878dfe94e4ac2f\" PRIMARY KEY (\"id\"))`);\\n        await queryRunner.query(`CREATE TABLE \"suppliers\" (\"id\" SERIAL NOT NULL, \"companyName\" text NOT NULL, \"city\" text, \"country\" text NOT NULL, CONSTRAINT \"PK_b70ac51766a9e3144f778cfe81e\" PRIMARY KEY (\"id\"))`);\\n        await queryRunner.query(`CREATE TABLE \"products\" (\"id\" SERIAL NOT NULL, \"name\" text NOT NULL, \"supplierId\" integer NOT NULL, \"unitPrice\" numeric(10,4) NOT NULL, \"unitsInStock\" integer NOT NULL, CONSTRAINT \"PK_0806c755e0aca124e67c0cf6d7d\" PRIMARY KEY (\"id\"))`);\\n        await queryRunner.query(`CREATE TABLE \"order_details\" (\"orderId\" integer NOT NULL, \"productId\" integer NOT NULL, \"quantity\" integer NOT NULL, CONSTRAINT \"PK_e08ee153eb9c98ee497c1d1287e\" PRIMARY KEY (\"orderId\", \"productId\"))`);\\n        await queryRunner.query(`ALTER TABLE \"products\" ADD CONSTRAINT \"FK_c143cbc0299e1f9220c4b5debd8\" FOREIGN KEY (\"supplierId\") REFERENCES \"suppliers\"(\"id\") ON DELETE NO ACTION ON UPDATE NO ACTION`);\\n        await queryRunner.query(`ALTER TABLE \"order_details\" ADD CONSTRAINT \"FK_147bc15de4304f89a93c7eee969\" FOREIGN KEY (\"orderId\") REFERENCES \"orders\"(\"id\") ON DELETE NO ACTION ON UPDATE NO ACTION`);\\n        await queryRunner.query(`ALTER TABLE \"order_details\" ADD CONSTRAINT \"FK_c67ebaba3e5085b6401911acc70\" FOREIGN KEY (\"productId\") REFERENCES \"products\"(\"id\") ON DELETE NO ACTION ON UPDATE NO ACTION`);\\n    }\\n\\n    public async down(queryRunner: QueryRunner): Promise<void> {\\n        await queryRunner.query(`ALTER TABLE \"order_details\" DROP CONSTRAINT \"FK_c67ebaba3e5085b6401911acc70\"`);\\n        await queryRunner.query(`ALTER TABLE \"order_details\" DROP CONSTRAINT \"FK_147bc15de4304f89a93c7eee969\"`);\\n        await queryRunner.query(`ALTER TABLE \"products\" DROP CONSTRAINT \"FK_c143cbc0299e1f9220c4b5debd8\"`);\\n        await queryRunner.query(`DROP TABLE \"order_details\"`);\\n        await queryRunner.query(`DROP TABLE \"products\"`);\\n        await queryRunner.query(`DROP TABLE \"suppliers\"`);\\n        await queryRunner.query(`DROP TABLE \"orders\"`);\\n    }\\n\\n}\\n```\\n\\nThis guide uses the following file structure:\\n\\n```text\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ db\\n â”‚  â”‚  â”œ ðŸ“‚ migrations\\n â”‚  â”‚  â”‚  â”” ðŸ“œ 1702216840703-init.ts\\n â”‚  â”‚  â”” ðŸ“œ typeorm.config.ts\\n â”‚  â”œ ðŸ“‚ entities\\n â”‚  â”‚  â”œ ðŸ“œ order-detail.entity.ts\\n â”‚  â”‚  â”œ ðŸ“œ order.entity.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.entity.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.entity.ts\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n<Steps>\\n\\n#### Install Drizzle ORM & Drizzle Kit\\n\\nThe first step is to install **Drizzle ORM** and `pg` package which we will use as a driver. The second step is to install **Drizzle Kit** and types for `pg`. [Drizzle Kit](/docs/kit-overview) - CLI companion for automatic SQL migrations generation and rapid prototyping. \\n\\n<Npm>\\ndrizzle-orm pg\\n-D drizzle-kit @types/pg\\n</Npm>\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by **Drizzle Kit** and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\'; // make sure to install dotenv package\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\',\\n  out: \\'./src/drizzle\\',\\n  schema: \\'./src/drizzle/schema.ts\\',\\n  dbCredentials: {\\n    host: process.env.DB_HOST!,\\n    port: Number(process.env.DB_PORT!),\\n    user: process.env.DB_USERNAME!,\\n    password: process.env.DB_PASSWORD!,\\n    database: process.env.DB_NAME!,\\n  },\\n  // Print all statements\\n  verbose: true,\\n  // Always ask for confirmation\\n  strict: true,\\n});\\n```\\n\\n#### Introspect your database\\n\\n**Drizzle Kit** provides a CLI command to introspect your database and generate a schema file. The schema file contains all the information about your database tables, columns, relations, and indices.\\n\\n```bash\\nnpx drizzle-kit introspect\\n```\\n\\nThis command will generate a schema.ts file, along with snapshots and migrations in the src/drizzle folder.\\n\\n```typescript collapsable copy filename=\"src/drizzle/schema.ts\" \\nimport {\\n  pgTable,\\n  serial,\\n  bigint,\\n  varchar,\\n  text,\\n  foreignKey,\\n  integer,\\n  numeric,\\n  date,\\n  primaryKey,\\n} from \\'drizzle-orm/pg-core\\';\\nimport { sql } from \\'drizzle-orm\\';\\n\\nexport const migrations = pgTable(\\'migrations\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  // You can use { mode: \"bigint\" } if numbers are exceeding js number limitations\\n  timestamp: bigint(\\'timestamp\\', { mode: \\'number\\' }).notNull(),\\n  name: varchar(\\'name\\').notNull(),\\n});\\n\\nexport const suppliers = pgTable(\\'suppliers\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  companyName: text(\\'companyName\\').notNull(),\\n  city: text(\\'city\\'),\\n  country: text(\\'country\\').notNull(),\\n});\\n\\nexport const products = pgTable(\\'products\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  name: text(\\'name\\').notNull(),\\n  supplierId: integer(\\'supplierId\\')\\n    .notNull()\\n    .references(() => suppliers.id),\\n  unitPrice: numeric(\\'unitPrice\\', { precision: 10, scale: 4 }).notNull(),\\n  unitsInStock: integer(\\'unitsInStock\\').notNull(),\\n});\\n\\nexport const orders = pgTable(\\'orders\\', {\\n  id: serial(\\'id\\').primaryKey().notNull(),\\n  orderDate: date(\\'orderDate\\').notNull(),\\n  shippedDate: date(\\'shippedDate\\'),\\n  shipAddress: text(\\'shipAddress\\').notNull(),\\n  shipPostalCode: text(\\'shipPostalCode\\'),\\n  shipCountry: text(\\'shipCountry\\').notNull(),\\n});\\n\\nexport const orderDetails = pgTable(\\n  \\'order_details\\',\\n  {\\n    orderId: integer(\\'orderId\\')\\n      .notNull()\\n      .references(() => orders.id),\\n    productId: integer(\\'productId\\')\\n      .notNull()\\n      .references(() => products.id),\\n    quantity: integer(\\'quantity\\').notNull(),\\n  },\\n  (table) => [\\n    primaryKey({\\n      columns: [table.orderId, table.productId],\\n      name: \\'PK_e08ee153eb9c98ee497c1d1287e\\',\\n    })\\n  ],\\n);\\n```\\n\\n```sql collapsable copy filename=\"src/drizzle/0000_lush_lenny_balinger.sql\"\\n-- Current sql file was generated after introspecting the database\\n\\nCREATE TABLE IF NOT EXISTS \"migrations\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"timestamp\" bigint NOT NULL,\\n\\t\"name\" varchar NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"suppliers\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"companyName\" text NOT NULL,\\n\\t\"city\" text,\\n\\t\"country\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"products\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"supplierId\" integer NOT NULL,\\n\\t\"unitPrice\" numeric(10, 4) NOT NULL,\\n\\t\"unitsInStock\" integer NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"orders\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"orderDate\" date NOT NULL,\\n\\t\"shippedDate\" date,\\n\\t\"shipAddress\" text NOT NULL,\\n\\t\"shipPostalCode\" text,\\n\\t\"shipCountry\" text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"order_details\" (\\n\\t\"orderId\" integer NOT NULL,\\n\\t\"productId\" integer NOT NULL,\\n\\t\"quantity\" integer NOT NULL,\\n\\tCONSTRAINT PK_e08ee153eb9c98ee497c1d1287e PRIMARY KEY(\"orderId\",\"productId\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"products\" ADD CONSTRAINT \"FK_c143cbc0299e1f9220c4b5debd8\" FOREIGN KEY (\"supplierId\") REFERENCES \"suppliers\"(\"id\") ON DELETE no action ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"FK_147bc15de4304f89a93c7eee969\" FOREIGN KEY (\"orderId\") REFERENCES \"orders\"(\"id\") ON DELETE no action ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"order_details\" ADD CONSTRAINT \"FK_c67ebaba3e5085b6401911acc70\" FOREIGN KEY (\"productId\") REFERENCES \"products\"(\"id\") ON DELETE no action ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nAlso, if you want to use relational queries, you have to update your schema file with relational tables:\\n\\n```typescript copy filename=\"src/drizzle/schema.ts\"\\n// ...other imports\\nimport { relations } from \\'drizzle-orm\\';\\n\\n// ...other tables \\nexport const suppliersRelations = relations(suppliers, ({ many }) => ({\\n  products: many(products),\\n}));\\n\\nexport const productsRelations = relations(products, ({ one, many }) => ({\\n  supplier: one(suppliers, { fields: [products.supplierId], references: [suppliers.id] }),\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const ordersRelations = relations(orders, ({ many }) => ({\\n  orderDetails: many(orderDetails),\\n}));\\n\\nexport const orderDetailsRelations = relations(orderDetails, ({ one }) => ({\\n  order: one(orders, { fields: [orderDetails.orderId], references: [orders.id] }),\\n  product: one(products, { fields: [orderDetails.productId], references: [products.id] }),\\n}));\\n```\\n\\nNow we have the following file structure:\\n\\n```text\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ drizzle\\n â”‚  â”‚  â”œ ðŸ“‚ meta\\n |  |  |  â”œ ðŸ“œ _journal.json\\n â”‚  â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚  â”‚  â”œ ðŸ“œ 0000_lush_lenny_balinger.sql\\n â”‚  â”‚  â”” ðŸ“œ schema.ts\\n â”‚  â”œ ðŸ“‚ routers\\n â”‚  â”‚  â”œ ðŸ“œ order.router.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.router.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.router.ts\\n â”‚  â”œ ðŸ“‚ controllers\\n â”‚  â”‚  â”œ ðŸ“œ order.controller.ts\\n â”‚  â”‚  â”œ ðŸ“œ product.controller.ts\\n â”‚  â”‚  â”” ðŸ“œ supplier.controller.ts\\n â”‚  â”œ ðŸ“œ index.ts\\n â”‚  â”” ðŸ“œ server.ts\\n â”œ ðŸ“œ package.json\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `db.ts` file in the `src/drizzle` folder and set up your database configuration:\\n\\n```typescript copy filename=\"src/drizzle/db.ts\"\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport { Client } from \\'pg\\';\\nimport * as schema from \\'./schema\\';\\n\\nexport const client = new Client({\\n  host: process.env.DB_HOST!,\\n  port: Number(process.env.DB_PORT!),\\n  user: process.env.DB_USERNAME!,\\n  password: process.env.DB_PASSWORD!,\\n  database: process.env.DB_NAME!,\\n});\\n\\n// { schema } is used for relational queries\\nexport const db = drizzle({ client, schema });\\n```\\n\\n```typescript copy filename=\"src/index.ts\"\\nimport \\'dotenv/config\\';\\nimport { client, db } from \\'./drizzle/db\\';\\nimport { resolve } from \\'node:path\\';\\nimport { migrate } from \\'drizzle-orm/node-postgres/migrator\\';\\n\\n\\n(async () => {\\n  await client.connect();\\n\\n  // This command run all migrations from the migrations folder and apply changes to the database\\n  await migrate(db, { migrationsFolder: resolve(__dirname, \\'./drizzle\\') });\\n\\n  // ... start your application\\n})();\\n```\\n\\n#### Transition your TypeORM queries to Drizzle ORM queries\\n\\nIn this section, we will show you how to replace several queries from **TypeORM** with **Drizzle ORM**.\\n\\n##### Replace insert queries\\n\\nWe will show how to insert new rows into `suppliers` and `products` tables.\\n\\n1. `POST /suppliers`\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Supplier } from \\'../entities/supplier.entity\\';\\n\\nconst repository = dataSource.getRepository(Supplier);\\n\\nconst suppliers = repository.create([\\n  {\\n    companyName: \\'TestCompanyName1\\',\\n    city: \\'TestCity1\\',\\n    country: \\'TestCountry1\\',\\n  },\\n  {\\n    companyName: \\'TestCompanyName2\\',\\n    city: \\'TestCity2\\',\\n    country: \\'TestCountry2\\',\\n  },\\n]);\\n\\nawait repository.save(suppliers);\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nawait db.insert(suppliers).values([\\n  {\\n    companyName: \\'TestCompanyName1\\',\\n    city: \\'TestCity1\\',\\n    country: \\'TestCountry1\\',\\n  },\\n  {\\n    companyName: \\'TestCompanyName2\\',\\n    city: \\'TestCity2\\',\\n    country: \\'TestCountry2\\',\\n  },\\n]);\\n```\\n\\n2. `POST /products`\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Product } from \\'../entities/product.entity\\';\\n\\nconst repository = dataSource.getRepository(Product);\\n\\nconst products = repository.create([\\n  {\\n    name: \\'TestProductName1\\',\\n    supplierId: 1,\\n    unitPrice: 10,\\n    unitsInStock: 20,\\n  },\\n  {\\n    name: \\'TestProductName2\\',\\n    supplierId: 1,\\n    unitPrice: 25,\\n    unitsInStock: 7,\\n  },\\n  {\\n    name: \\'TestProductName3\\',\\n    supplierId: 2,\\n    unitPrice: 50,\\n    unitsInStock: 17,\\n  },\\n  {\\n    name: \\'TestProductName4\\',\\n    supplierId: 2,\\n    unitPrice: 100,\\n    unitsInStock: 2,\\n  },\\n]);\\n\\nawait repository.save(products);\\n```\\n\\nWith **Drizzle ORM**, the query is implemented as follows:\\n\\nBe careful with the `unitPrice` field. In **TypeORM** it\\'s a `number` type, but in **Drizzle ORM** it\\'s a `string` type, which can handle more than 16383 digits after the decimal point, unlike the `number` type.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nawait db.insert(products).values([\\n  {\\n    name: \\'TestProductName1\\',\\n    supplierId: 1,\\n    unitPrice: \\'10\\',\\n    unitsInStock: 20,\\n  },\\n  {\\n    name: \\'TestProductName2\\',\\n    supplierId: 1,\\n    unitPrice: \\'25\\',\\n    unitsInStock: 7,\\n  },\\n  {\\n    name: \\'TestProductName3\\',\\n    supplierId: 2,\\n    unitPrice: \\'50\\',\\n    unitsInStock: 17,\\n  },\\n  {\\n    name: \\'TestProductName4\\',\\n    supplierId: 2,\\n    unitPrice: \\'100\\',\\n    unitsInStock: 2,\\n  },\\n]);\\n```\\n\\n##### Replace select queries\\n\\nIn this section we will show how to select one row, multiple rows, count rows, filter rows, join tables and paginate results.\\n\\n1. `GET /products/:id`\\n\\nIn **TypeORM**, the response type is not strictly typed. For example, if you choose to include a relation or select only a few fields instead of all, these modifications will not be reflected in the response type.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Product } from \\'../entities/product.entity\\';\\n\\nconst { id } = req.params;\\n\\nconst repository = dataSource.getRepository(Product);\\n\\nconst response = await repostitory.findOne({\\n  where: { id },\\n  relations: [\\'supplier\\'],\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products, suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n  .select({\\n    product: products,\\n    supplier: suppliers,\\n  })\\n  .from(products)\\n  .where(eq(products.id, id))\\n  .leftJoin(suppliers, eq(suppliers.id, products.supplierId));\\n\\n// or you can use relational queries\\nconst response = await db.query.products.findFirst({\\n  where: (products, { eq }) => eq(products.id, id),\\n  with: {\\n    supplier: true,\\n  },\\n});\\n```\\n\\nIn **Drizzle ORM**, the response type will match precisely what is specified in the select object, so including the `supplier` relation is fully type-safe.\\n\\n```typescript\\n// response type\\nconst response: {\\n  product: {\\n    name: string;\\n    id: number;\\n    supplierId: number;\\n    unitPrice: string;\\n    unitsInStock: number;\\n  };\\n  supplier: {\\n    id: number;\\n    companyName: string;\\n    city: string | null;\\n    country: string;\\n  } | null;\\n}[]\\n```\\n\\n2. `GET /products`\\n\\nIn **TypeORM**, the result is not type-safe as it doesn\\'t specify the fields you want to select.\\n\\n```typescript copy filename=\"src/controllers/product.controller.ts\"\\nimport { ILike } from \\'typeorm\\';\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Product } from \\'../entities/product.entity\\';\\n\\nconst repository = dataSource.getRepository(Product);\\n\\nconst response = await repostitory.findAndCount({\\n  skip: 0,\\n  take: 10,\\n  where: {\\n    name: ILike(`%test%`),\\n  },\\n  select: [\\'id\\', \\'name\\', \\'unitPrice\\', \\'unitsInStock\\'],\\n});\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript collapsable copy filename=\"src/controllers/product.controller.ts\"\\nimport { ilike, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { products } from \\'../drizzle/schema\\';\\n\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db\\n    .select({\\n      id: products.id,\\n      name: products.name,\\n      unitPrice: products.unitPrice,\\n      unitsInStock: products.unitsInStock,\\n    })\\n    .from(products)\\n    .where(whereOptions)\\n    .offset(0)\\n    .limit(10),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n\\n// or you can use relational queries\\nconst whereOptions = ilike(products.name, `%test%`);\\n\\nconst [response, count] = await Promise.all([\\n  db.query.products.findMany({\\n    where: whereOptions,\\n    columns: {\\n      id: true,\\n      name: true,\\n      unitPrice: true,\\n      unitsInStock: true,\\n    },\\n    offset: 0,\\n    limit: 10,\\n  }),\\n  db\\n    .select({ count: sql<number>`cast(count(${products.id}) as integer)` })\\n    .from(products)\\n    .where(whereOptions),\\n]);\\n```\\n\\nIn **Drizzle ORM**, the result is strictly type-safe, meaning the fields you select are explicitly defined.\\n\\n```typescript\\n// response type\\nconst response: {\\n  id: number;\\n  name: string;\\n  unitPrice: string;\\n  unitsInStock: number;\\n}[]\\n```\\n\\n3. `GET /orders/:id`\\n\\nIn **TypeORM** you can\\'t use `aggregation functions` with relations and select specific fields using method `findOne`. So, you have to use `querybuilder`, which is not type-safe as well.\\n\\nWe want to select `id`, `orderDate` and `shipCountry` fields from `orders` table and by using `aggregation functions` sum `totalPrice` of order, `totalQuantity` of products in the order and count `totalProducts` in the order.\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Order } from \\'../entities/order.entity\\';\\n\\nconst { id } = req.params;\\n\\nconst orderRepository = dataSource.getRepository(Order);\\n\\nconst orderQueryBuilder = orderRepository.createQueryBuilder(\\'order\\');\\n\\nconst response = await orderQueryBuilder\\n  .select([\\n    \\'order.id as id\\',\\n    \\'order.orderDate as \"orderDate\"\\',\\n    \\'order.shipCountry as \"shipCountry\"\\',\\n    \\'SUM(product.unitPrice * detail.quantity)::float as \"totalPrice\"\\',\\n    \\'SUM(detail.quantity)::int as \"totalQuantity\"\\',\\n    \\'COUNT(detail.productId)::int as \"totalProducts\"\\',\\n  ])\\n  .leftJoin(\\'order.orderDetails\\', \\'detail\\')\\n  .leftJoin(\\'detail.product\\', \\'product\\')\\n  .groupBy(\\'order.id\\')\\n  .where(\\'order.id = :id\\', { id })\\n  .getRawOne();\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orders, orderDetails, products } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nconst response = await db\\n      .select({\\n        id: orders.id,\\n        shipCountry: orders.shipCountry,\\n        orderDate: orders.orderDate,\\n        totalPrice: sql<number>`cast(sum(${orderDetails.quantity} * ${products.unitPrice}) as float)`,\\n        totalQuantity: sql<number>`cast(sum(${orderDetails.quantity}) as int)`,\\n        totalProducts: sql<number>`cast(count(${orderDetails.productId}) as int)`,\\n      })\\n      .from(orders)\\n      .where(eq(orders.id, id))\\n      .groupBy(orders.id)\\n      .leftJoin(orderDetails, eq(orderDetails.orderId, orders.id))\\n      .leftJoin(products, eq(products.id, orderDetails.productId));\\n```\\n\\nIn **Drizzle ORM**, the result will be type-safe with aggregations too.\\n\\n```typescript\\n// response type\\nconst response: {\\n  id: number;\\n  shipCountry: string;\\n  orderDate: string;\\n  totalPrice: number;\\n  totalQuantity: number;\\n  totalProducts: number;\\n}[]\\n```\\n\\n**Note:** as of now aggregations are not supported in relational queries, so you have to use `core queries`.\\n\\n##### Replace update queries\\n\\nIn this section, we will show you how to update multiple rows.\\n\\n1. `PATCH /suppliers/:id`\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { Supplier } from \\'../entities/supplier.entity\\';\\n\\nconst { id } = req.params;\\n\\nconst repository = dataSource.getRepository(Supplier);\\n\\nconst supplier = await repository.findOneBy({ id });\\nif (!supplier) {\\n  throw new Error(\\'Supplier not found\\');\\n}\\n\\nsupplier.city = \\'TestCity1Updated\\';\\nsupplier.country = \\'TestCountry1Updated\\';\\n\\nawait repository.save(supplier);\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/supplier.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { suppliers } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\nawait db\\n    .update(suppliers)\\n    .set({\\n      city: \\'TestCity1Updated\\',\\n      country: \\'TestCountry1Updated\\',\\n    })\\n    .where(eq(suppliers.id, id));\\n```\\n\\n##### Replace delete queries\\n\\nIn this section, we will show you how to delete a single row and multiple rows using transactions.\\n\\n1. `DELETE /orders/:id`\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport dataSource from \\'../db/typeorm.config\\';\\nimport { OrderDetail } from \\'../entities/order-detail.entity\\';\\nimport { Order } from \\'../entities/order.entity\\';\\n\\nconst { id } = req.params;\\n\\nconst queryRunner = dataSource.createQueryRunner();\\n\\nawait queryRunner.connect();\\n\\nawait queryRunner.startTransaction();\\n\\ntry {\\n  await queryRunner.manager.delete(OrderDetail, { orderId: id });\\n\\n  await queryRunner.manager.delete(Order, { id });\\n\\n  await queryRunner.commitTransaction();\\n} catch (e) {\\n  await queryRunner.rollbackTransaction();\\n\\n  console.error(e);\\n} finally {\\n  await queryRunner.release();\\n}\\n```\\n\\nIn **Drizzle ORM**, the query is implemented as follows:\\n\\n```typescript copy filename=\"src/controllers/order.controller.ts\"\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../drizzle/db\\';\\nimport { orderDetails, orders } from \\'../drizzle/schema\\';\\n\\nconst { id } = req.params;\\n\\ntry {\\n  await db.transaction(async (tx) => {\\n    await tx.delete(orderDetails).where(eq(orderDetails.orderId, id));\\n\\n    await tx.delete(orders).where(eq(orders.id, id));\\n  });\\n} catch (e) {\\n  console.error(e);\\n}\\n```\\n\\n</Steps>\\n', children=[])]),\n",
       " DocItem(origPath=Path('migrations.mdx'), name='migrations.mdx', displayName='migrations.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntest: 10\\n---\\nexport const a = 10;\\n\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Tag from \\'@mdx/Tag.astro\\'\\n\\n\\n# Drizzle migrations fundamentals\\n\\nSQL databases require you to specify a **strict schema** of entities you\\'re going to store upfront \\nand if (when) you need to change the shape of those entities - you will need to do it via **schema migrations**.\\n\\nThere\\'re multiple production grade ways of managing database migrations. \\nDrizzle is designed to perfectly suits all of them, regardless of you going **database first** or **codebase first**.\\n\\n**Database first** is when your database schema is a source of truth. You manage your database schema either directly on the database or \\nvia database migration tools and then you pull your database schema to your codebase application level entities.  \\n \\n**Codebase first** is when database schema in your codebase is a source of truth and is under version control. You declare and manage your database schema in JavaScript/TypeScript\\nand then you apply that schema to the database itself either with Drizzle, directly or via external migration tools. \\n\\n#### How can Drizzle help?\\nWe\\'ve built [**drizzle-kit**](/docs/kit-overview) - CLI app for managing migrations with Drizzle. \\n```shell\\ndrizzle-kit migrate\\ndrizzle-kit generate\\ndrizzle-kit push\\ndrizzle-kit pull\\n```\\nIt is designed to let you choose how to approach migrations based on your current business demands. \\n\\nIt fits in both database and codebase first approaches, it lets you **push your schema** or **generate SQL migration** files or **pull the schema** from database. \\nIt is perfect wether you work alone or in a team.\\n<br/>\\n\\n<hr/>\\n<rem/>\\n\\n**Now let\\'s pick the best option for your project:**\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 1**</Tag>\\n> I manage database schema myself using external migration tools or by running SQL migrations directly on my database.\\n> From Drizzle I just need to get current state of the schema from my database and save it as TypeScript schema file.\\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **database first** approach. You have your database schema as a **source of truth** and \\nDrizzle lets you pull database schema to TypeScript using [`drizzle-kit pull`](/docs/drizzle-kit-pull) command.\\n\\n<Section>\\n```\\n                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \\n                                  â”‚                        â”‚ <---  CREATE TABLE \"users\" (\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                        â”‚        \"id\" SERIAL PRIMARY KEY,\\nâ”‚ ~ drizzle-kit pull       â”‚      â”‚                        â”‚        \"name\" TEXT,\\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚        DATABASE        â”‚        \"email\" TEXT UNIQUE\\n  â”‚                               â”‚                        â”‚       );\\n  â”” Pull datatabase schema -----> â”‚                        â”‚\\n  â”Œ Generate Drizzle       <----- â”‚                        â”‚\\n  â”‚ schema TypeScript file        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n  â”‚\\n  v\\n```\\n```typescript\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(),\\n});\\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 2**</Tag>\\n> I want to have database schema in my TypeScript codebase, \\n> I don\\'t wanna deal with SQL migration files.  \\n> I want Drizzle to \"push\" my schema directly to the database\\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **codebase first** approach. You have your TypeScript Drizzle schema as a **source of truth** and \\nDrizzle lets you push schema changes to the database using [`drizzle-kit push`](/docs/drizzle-kit-push) command.\\n\\nThat\\'s the best approach for rapid prototyping and we\\'ve seen dozens of teams \\nand solo developers successfully using it as a primary migrations flow in their production applications.\\n\\n<Section>\\n```typescript {6} filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(), // <--- added column\\n});\\n```\\n```\\nAdd column to `users` table                                                                          \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ + email: text().unique() â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  v                                           \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ ~ drizzle-kit push       â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n  â”” Pull current datatabase schema ---------> â”‚                          â”‚\\n                                              â”‚                          â”‚\\n  â”Œ Generate alternations based on diff <---- â”‚         DATABASE         â”‚\\n  â”‚                                           â”‚                          â”‚\\n  â”” Apply migrations to the database -------> â”‚                          â”‚\\n                                       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n                                       â”‚\\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n   ALTER TABLE `users` ADD COLUMN `email` TEXT UNIQUE; \\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 3**</Tag>\\n> I want to have database schema in my TypeScript codebase, \\n> I want Drizzle to generate SQL migration files for me and apply them to my database\\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **codebase first** approach. You have your TypeScript Drizzle schema as a source of truth and \\nDrizzle lets you generate SQL migration files based on your schema changes with [`drizzle-kit generate`](/docs/drizzle-kit-generate)\\nand then apply them to the database with [`drizzle-kit migrate`](/docs/drizzle-kit-migrate) commands. \\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(),\\n});\\n```\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit generate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  â”” 1. read previous migration folders\\n    2. find diff between current and previous schema\\n    3. prompt developer for renames if necessary\\n  â”Œ 4. generate SQL migration and persist to file\\n  â”‚    â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  \\n  â”‚      ðŸ“‚ drizzle       \\n  â”‚      â”” ðŸ“‚ 20242409125510_premium_mister_fear\\n  â”‚        â”œ ðŸ“œ snapshot.json\\n  â”‚        â”” ðŸ“œ migration.sql\\n  v\\n```\\n```sql\\n-- drizzle/20242409125510_premium_mister_fear/migration.sql\\n\\nCREATE TABLE \"users\" (\\n \"id\" SERIAL PRIMARY KEY,\\n \"name\" TEXT,\\n \"email\" TEXT UNIQUE\\n);\\n```\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit migrate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         \\n  â”” 1. read migration.sql files in migrations folder        â”‚                          â”‚\\n    2. fetch migration history from database -------------> â”‚                          â”‚\\n  â”Œ 3. pick previously unapplied migrations <-------------- â”‚         DATABASE         â”‚\\n  â”” 4. apply new migration to the database ---------------> â”‚                          â”‚\\n                                                            â”‚                          â”‚\\n                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n[âœ“] done!                                                 \\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 4**</Tag>\\n> I want to have database schema in my TypeScript codebase,\\n> I want Drizzle to generate SQL migration files for me and I want Drizzle to apply them during runtime\\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **codebase first** approach. You have your TypeScript Drizzle schema as a source of truth and \\nDrizzle lets you generate SQL migration files based on your schema changes with [`drizzle-kit generate`](/docs/drizzle-kit-generate) and then \\nyou can apply them to the database during runtime of your application.\\n\\nThis approach is widely used for **monolithic** applications when you apply database migrations \\nduring zero downtime deployment and rollback DDL changes if something fails. \\nThis is also used in **serverless** deployments with migrations running in **custom resource** once during deployment process.\\n\\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(),\\n});\\n```\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit generate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  â”” 1. read previous migration folders\\n    2. find diff between current and previous schema\\n    3. prompt developer for renames if necessary\\n  â”Œ 4. generate SQL migration and persist to file\\n  â”‚    â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  \\n  â”‚      ðŸ“‚ drizzle       \\n  â”‚      â”” ðŸ“‚ 20242409125510_premium_mister_fear\\n  â”‚        â”œ ðŸ“œ snapshot.json\\n  â”‚        â”” ðŸ“œ migration.sql\\n  v\\n```\\n```sql\\n-- drizzle/20242409125510_premium_mister_fear/migration.sql\\n\\nCREATE TABLE \"users\" (\\n \"id\" SERIAL PRIMARY KEY,\\n \"name\" TEXT,\\n \"email\" TEXT UNIQUE\\n);\\n```\\n```ts\\n// index.ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\"\\nimport { migrate } from \\'drizzle-orm/node-postgres/migrator\\';\\n\\nconst db = drizzle(process.env.DATABASE_URL);\\n\\nawait migrate(db);\\n```\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ npx tsx src/index.ts  â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                                      \\n  â”œ 1. init database connection                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         \\n  â”” 2. read migration.sql files in migrations folder        â”‚                          â”‚\\n    3. fetch migration history from database -------------> â”‚                          â”‚\\n  â”Œ 4. pick previously unapplied migrations <-------------- â”‚         DATABASE         â”‚\\n  â”” 5. apply new migration to the database ---------------> â”‚                          â”‚\\n                                                            â”‚                          â”‚\\n                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n[âœ“] done!                                                 \\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 5**</Tag>\\n> I want to have database schema in my TypeScript codebase,\\n> I want Drizzle to generate SQL migration files for me,\\n> but I will apply them to my database myself or via external migration tools \\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **codebase first** approach. You have your TypeScript Drizzle schema as a source of truth and \\nDrizzle lets you generate SQL migration files based on your schema changes with [`drizzle-kit generate`](/docs/drizzle-kit-generate) and then \\nyou can apply them to the database either directly or via external migration tools.\\n\\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(),\\n});\\n```\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit generate â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  â”” 1. read previous migration folders\\n    2. find diff between current and previous scheama\\n    3. prompt developer for renames if necessary\\n  â”Œ 4. generate SQL migration and persist to file\\n  â”‚    â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  \\n  â”‚      ðŸ“‚ drizzle       \\n  â”‚      â”” ðŸ“‚ 20242409125510_premium_mister_fear\\n  â”‚        â”œ ðŸ“œ snapshot.json\\n  â”‚        â”” ðŸ“œ migration.sql\\n  v\\n```\\n```sql\\n-- drizzle/20242409125510_premium_mister_fear/migration.sql\\n\\nCREATE TABLE \"users\" (\\n \"id\" SERIAL PRIMARY KEY,\\n \"name\" TEXT,\\n \"email\" TEXT UNIQUE\\n);\\n```\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ (._.) now you run your migrations â”‚           \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  \\n  â”‚\\n directly to the database\\n  â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€>â”‚                    â”‚  \\n  â”‚                                    â”‚    â”‚      Database      â”‚           \\n or via external tools                 â”‚    â”‚                    â”‚   \\n  â”‚                                    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚      \\n  â””â”€â”€â”‚ Bytebase           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         \\n     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  \\n     â”‚ Liquibase          â”‚\\n     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ \\n     â”‚ Atlas              â”‚\\n     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ \\n     â”‚ etcâ€¦               â”‚\\n     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\\n[âœ“] done!                                                 \\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n<rem/>\\n\\n<Tag style=\"font-size: 12px\">**Option 6**</Tag>\\n> I want to have database schema in my TypeScript codebase,\\n> I want Drizzle to output the SQL representation of my Drizzle schema to the console,\\n> and I will apply them to my database via [Atlas](https://atlasgo.io/guides/orms/drizzle)\\n\\n<Callout collapsed=\"Expand details\">\\nThat\\'s a **codebase first** approach. You have your TypeScript Drizzle schema as a source of truth and \\nDrizzle lets you export SQL statements based on your schema changes with [`drizzle-kit export`](/docs/drizzle-kit-generate) and then \\nyou can apply them to the database via [Atlas](https://atlasgo.io/guides/orms/drizzle) or other external SQL migration tools.\\n\\n<Section>\\n```typescript filename=\"src/schema.ts\"\\nimport * as p from \"drizzle-orm/pg-core\";\\n\\nexport const users = p.pgTable(\"users\", {\\n  id: p.serial().primaryKey(),\\n  name: p.text(),\\n  email: p.text().unique(),\\n});\\n```\\n```                                  \\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ $ drizzle-kit export   â”‚                  \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  \\n  â”‚                                           \\n  â”” 1. read your drizzle schema\\n    2. generated SQL representation of your schema\\n  â”Œ 3. outputs to console\\n  â”‚    \\n  â”‚        \\n  v\\n```\\n```sql\\nCREATE TABLE \"users\" (\\n \"id\" SERIAL PRIMARY KEY,\\n \"name\" TEXT,\\n \"email\" TEXT UNIQUE\\n);\\n```\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  \\nâ”‚ (._.) now you run your migrations â”‚           \\nâ””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  \\n  â”‚\\n via Atlas\\n  â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚              â”‚\\n  â””â”€â”€â”‚ Atlas              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Database    â”‚      \\n     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚              â”‚       \\n                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\\n[âœ“] done!                                                 \\n```\\n</Section>\\n</Callout>\\n\\n<rem/>\\n<rem/>\\n', children=[]),\n",
       " DocItem(origPath=Path('operators.mdx'), name='operators.mdx', displayName='operators.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# Filter and conditional operators\\nWe natively support all dialect specific filter and conditional operators.\\n\\nYou can import all filter & conditional from `drizzle-orm`:\\n```typescript copy\\nimport { eq, ne, gt, gte, ... } from \"drizzle-orm\";\\n```\\n\\n### eq\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue equal to `n`\\n<Section>\\n```typescript copy\\nimport { eq } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(eq(table.column, 5));\\n```\\n\\n```sql copy\\nSELECT * FROM table WHERE table.column = 5\\n```\\n</Section>\\n\\n\\n<Section>\\n```typescript\\nimport { eq } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(eq(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 = table.column2\\n```\\n</Section>\\n\\n\\n### ne\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is not equal to `n`  \\n<Section>\\n```typescript\\nimport { ne } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(ne(table.column, 5));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column <> 5\\n```\\n</Section>\\n\\n\\n<Section>\\n```typescript\\nimport { ne } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(ne(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 <> table.column2\\n```\\n</Section>\\n\\n## ---\\n\\n### gt\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} /> \\n  \\nValue is greater than `n`\\n<Section>\\n```typescript\\nimport { gt } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(gt(table.column, 5));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column > 5\\n```\\n</Section>\\n\\n\\n<Section>\\n```typescript\\nimport { gt } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(gt(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 > table.column2\\n```\\n</Section>\\n\\n### gte\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is greater than or equal to `n`\\n<Section>\\n```typescript\\nimport { gte } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(gte(table.column, 5));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column >= 5\\n```\\n</Section>\\n\\n\\n<Section>\\n```typescript\\nimport { gte } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(gte(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 >= table.column2\\n```\\n</Section>\\n\\n### lt\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is less than `n`\\n<Section>\\n```typescript\\nimport { lt } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(lt(table.column, 5));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column < 5\\n```\\n</Section>\\n\\n\\n<Section>\\n```typescript\\nimport { lt } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(lt(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 < table.column2\\n```\\n</Section>\\n\\n### lte\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is less than or equal to `n`.\\n\\n<Section>\\n```typescript\\nimport { lte } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(lte(table.column, 5));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column <= 5\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { lte } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(lte(table.column1, table.column2));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column1 <= table.column2\\n```\\n</Section>\\n\\n## ---\\n\\n### exists\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue exists\\n<Section>\\n```typescript\\nimport { exists } from \"drizzle-orm\";\\n\\nconst query = db.select().from(table2)\\ndb.select().from(table).where(exists(query));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE EXISTS (SELECT * from table2)\\n```\\n</Section>\\n\\n### notExists\\n\\n<Section>\\n```typescript\\nimport { notExists } from \"drizzle-orm\";\\n\\nconst query = db.select().from(table2)\\ndb.select().from(table).where(notExists(query));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE NOT EXISTS (SELECT * from table2)\\n```\\n</Section>\\n\\n### isNull\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is `null`\\n<Section>\\n```typescript\\nimport { isNull } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(isNull(table.column));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column IS NULL\\n```\\n</Section>\\n\\n\\n### isNotNull\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is not `null`\\n<Section>\\n```typescript\\nimport { isNotNull } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(isNotNull(table.column));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column IS NOT NULL\\n```\\n</Section>\\n\\n## ---\\n\\n### inArray\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is in array of values\\n<Section>\\n```typescript\\nimport { inArray } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(inArray(table.column, [1, 2, 3, 4]));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column in (1, 2, 3, 4)\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { inArray } from \"drizzle-orm\";\\n\\nconst query = db.select({ data: table2.column }).from(table2);\\ndb.select().from(table).where(inArray(table.column, query));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column IN (SELECT table2.column FROM table2)\\n```\\n</Section>\\n\\n### notInArray\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is not in array of values\\n<Section>\\n```typescript\\nimport { notInArray } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(notInArray(table.column, [1, 2, 3, 4]));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column NOT in (1, 2, 3, 4)\\n```\\n</Section>\\n\\n<Section>\\n```typescript\\nimport { notInArray } from \"drizzle-orm\";\\n\\nconst query = db.select({ data: table2.column }).from(table2);\\ndb.select().from(table).where(notInArray(table.column, query));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column NOT IN (SELECT table2.column FROM table2)\\n```\\n</Section>\\n\\n## ---\\n\\n### between\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is between two values\\n<Section>\\n```typescript\\nimport { between } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(between(table.column, 2, 7));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column BETWEEN 2 AND 7\\n```\\n</Section>\\n\\n### notBetween\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is not between two value\\n<Section>\\n```typescript\\nimport { notBetween } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(notBetween(table.column, 2, 7));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column NOT BETWEEN 2 AND 7\\n```\\n</Section>\\n\\n## ---\\n\\n### like\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is like other value, case sensitive\\n<Section>\\n```typescript\\nimport { like } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(like(table.column, \"%llo wor%\"));\\n```\\n\\n```sql\\nSELECT * FROM table  WHERE table.column LIKE \\'%llo wor%\\'\\n```\\n</Section>\\n\\n### ilike\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n  \\nValue is like some other value, case insensitive\\n<Section>\\n```typescript\\nimport { ilike } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(ilike(table.column, \"%llo wor%\"));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column ILIKE \\'%llo wor%\\'\\n```\\n</Section>\\n\\n### notIlike\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nValue is not like some other value, case insensitive\\n<Section>\\n```typescript\\nimport { notIlike } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(notIlike(table.column, \"%llo wor%\"));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE table.column NOT ILIKE \\'%llo wor%\\'\\n```\\n</Section>\\n\\n## ---\\n\\n### not\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nAll conditions must return `false`.\\n\\n<Section>\\n```typescript\\nimport { eq, not } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(not(eq(table.column, 5)));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE NOT (table.column = 5)\\n```\\n</Section>\\n\\n### and\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nAll conditions must return `true`.\\n\\n<Section>\\n```typescript\\nimport { gt, lt, and } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(and(gt(table.column, 5), lt(table.column, 7)));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE (table.column > 5 AND table.column < 7)\\n```\\n</Section>\\n\\n### or\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n  \\nOne or more conditions must return `true`.\\n\\n<Section>\\n```typescript\\nimport { gt, lt, or } from \"drizzle-orm\";\\n\\ndb.select().from(table).where(or(gt(table.column, 5), lt(table.column, 7)));\\n```\\n\\n```sql\\nSELECT * FROM table WHERE (table.column > 5 OR table.column < 7)\\n```\\n</Section>\\n\\n## ---\\n\\n### arrayContains\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n  \\nTest that a column or expression contains all elements of the list passed as the second argument\\n\\n<Section>\\n```typescript\\nimport { arrayContains } from \"drizzle-orm\";\\n\\nconst contains = await db.select({ id: posts.id }).from(posts)\\n  .where(arrayContains(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n\\nconst withSubQuery = await db.select({ id: posts.id }).from(posts)\\n  .where(arrayContains(\\n    posts.tags,\\n    db.select({ tags: posts.tags }).from(posts).where(eq(posts.id, 1)),\\n  ));\\n```\\n\\n```sql\\nselect \"id\" from \"posts\" where \"posts\".\"tags\" @> {Typescript,ORM};\\nselect \"id\" from \"posts\" where \"posts\".\"tags\" @> (select \"tags\" from \"posts\" where \"posts\".\"id\" = 1);\\n```\\n</Section>\\n\\n### arrayContained\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n  \\nTest that the list passed as the second argument contains all elements of a column or expression\\n\\n<Section>\\n```typescript\\nimport { arrayContained } from \"drizzle-orm\";\\n\\nconst contained = await db.select({ id: posts.id }).from(posts)\\n  .where(arrayContained(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n```\\n\\n```sql\\nselect \"id\" from \"posts\" where \"posts\".\"tags\" <@ {Typescript,ORM};\\n```\\n</Section>\\n\\n### arrayOverlaps\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n  \\nTest that a column or expression contains any elements of the list passed as the second argument.\\n\\n<Section>\\n```typescript\\nimport { arrayOverlaps } from \"drizzle-orm\";\\n\\nconst overlaps = await db.select({ id: posts.id }).from(posts)\\n  .where(arrayOverlaps(posts.tags, [\\'Typescript\\', \\'ORM\\']));\\n```\\n\\n```sql\\nselect \"id\" from \"posts\" where \"posts\".\"tags\" && {Typescript,ORM}\\n```\\n</Section>\\n', children=[]),\n",
       " DocItem(origPath=Path('overview.mdx'), name='overview.mdx', displayName='overview.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport YoutubeCards from \\'@mdx/YoutubeCards.astro\\';\\nimport GetStartedLinks from \\'@mdx/GetStartedLinks/index.astro\\'\\n\\n# Drizzle ORM\\n\\nDrizzle ORM is a headless TypeScript ORM with a head. ðŸ²\\n> Drizzle is a good friend who\\'s there for you when necessary and doesn\\'t bother when you need some space.\\n\\nIt looks and feels simple, performs on day _1000_ of your project,\\\\\\nlets you do things your way, and is there when you need it.\\n\\n**It\\'s the only ORM with both [relational](/docs/rqb) and [SQL-like](/docs/select) query APIs**, \\nproviding you the best of both worlds when it comes to accessing your relational data. \\nDrizzle is lightweight, performant, typesafe, non-lactose, gluten-free, sober, flexible and **serverless-ready by design**.\\nDrizzle is not just a library, it\\'s an experience. ðŸ¤©\\n\\n[![Drizzle bestofjs](@/assets/images/bestofjs.jpg)](https://bestofjs.org/projects/drizzle-orm)\\n\\n## Headless ORM? \\nFirst and foremost, Drizzle is a library and a collection of complementary opt-in tools. \\n\\n**ORM** stands for _object relational mapping_, and developers tend to call Django-like or Spring-like tools an ORM. \\nWe truly believe it\\'s a misconception based on legacy nomenclature, and we call them **data frameworks**.\\n\\n<Callout type=\"error\" emoji=\"ï¸ðŸ’”\">\\n  With data frameworks you have to build projects **around them** and not **with them**.\\n</Callout>\\n\\n**Drizzle** lets you build your project the way you want, without interfering with your project or structure. \\n\\nUsing Drizzle you can define and manage database schemas in TypeScript, access your data in a SQL-like \\nor relational way, and take advantage of opt-in tools \\nto push your developer experience _through the roof_. ðŸ¤¯ \\n\\n## Why SQL-like?\\n**If you know SQL, you know Drizzle.**\\n\\nOther ORMs and data frameworks tend to deviate/abstract you away from SQL, which \\nleads to a double learning curve: needing to know both SQL and the framework\\'s API.  \\n\\nDrizzle is the opposite. \\nWe embrace SQL and built Drizzle to be SQL-like at its core, so you can have zero to no \\nlearning curve and access to the full power of SQL.  \\n\\nWe bring all the familiar **[SQL schema](/docs/sql-schema-declaration)**, **[queries](/docs/select)**, \\n**[automatic migrations](/docs/migrations)** and **[one more thing](/docs/rqb)**. âœ¨\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\", \"migration.sql\"]}>\\n```typescript copy\\n// Access your data\\nawait db\\n\\t.select()\\n\\t.from(countries)\\n\\t.leftJoin(cities, eq(cities.countryId, countries.id))\\n\\t.where(eq(countries.id, 10))\\n```\\n```typescript copy\\n// manage your schema\\nexport const countries = pgTable(\\'countries\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: varchar(\\'name\\', { length: 256 }),\\n});\\n\\nexport const cities = pgTable(\\'cities\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: varchar(\\'name\\', { length: 256 }),\\n  countryId: integer(\\'country_id\\').references(() => countries.id),\\n});\\n```\\n```sql\\n-- generate migrations\\nCREATE TABLE IF NOT EXISTS \"countries\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" varchar(256)\\n);\\n\\nCREATE TABLE IF NOT EXISTS \"cities\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" varchar(256),\\n\\t\"country_id\" integer\\n);\\n\\nALTER TABLE \"cities\" ADD CONSTRAINT \"cities_country_id_countries_id_fk\" FOREIGN KEY (\"country_id\") REFERENCES \"countries\"(\"id\") ON DELETE no action ON UPDATE no action;\\n```\\n</CodeTabs>\\n\\n## Why not SQL-like?\\nWe\\'re always striving for a perfectly balanced solution, and while SQL-like does cover 100% of the needs, \\nthere are certain common scenarios where you can query data in a better way.  \\n\\nWe\\'ve built the **[Queries API](/docs/rqb)** for you, so you can fetch relational nested data from the database \\nin the most convenient and performant way, and never think about joins and data mapping.  \\n\\n**Drizzle always outputs exactly 1 SQL query.** Feel free to use it with serverless databases and never worry about performance or roundtrip costs!\\n\\n```ts\\nconst result = await db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: true\\n\\t},\\n});\\n```\\n\\n## Serverless?\\n<Callout type=\"info\" emoji=\"ðŸ¥³\">\\n  The best part is no part. **Drizzle has exactly 0 dependencies!**\\n</Callout>\\n\\n\\n![Drizzle is slim an Serverless ready](@/assets/images/drizzle31kb.jpg)\\n  \\nDrizzle ORM is dialect-specific, slim, performant and serverless-ready **by design**.  \\n\\nWe\\'ve spent a lot of time to make sure you have best-in-class SQL dialect support, including Postgres, MySQL, and others.\\n\\nDrizzle operates natively through industry-standard database drivers. We support all major **[PostgreSQL](/docs/get-started-postgresql)**, **[MySQL](/docs/get-started-mysql)**, **[SQLite](/docs/get-started-sqlite)** or **[SingleStore](/docs/get-started-singlestore)** drivers out there, and we\\'re adding new ones **[really fast](https://twitter.com/DrizzleORM/status/1653082492742647811?s=20)**.  \\n\\n\\n## Welcome on board!\\nMore and more companies are adopting Drizzle in production, experiencing immense benefits in both DX and performance.\\n\\n**We\\'re always there to help, so don\\'t hesitate to reach out. We\\'ll gladly assist you in your Drizzle journey!**\\n\\nWe have an outstanding **[Discord community](https://driz.link/discord)** and welcome all builders to our **[Twitter](https://twitter.com/drizzleorm)**.\\n  \\nNow go build something awesome with Drizzle and your **[PostgreSQL](/docs/get-started-postgresql)**, **[MySQL](/docs/get-started-mysql)** or **[SQLite](/docs/get-started-sqlite)** database. ðŸš€\\n\\n### Video Showcase\\n\\n{/* tRPC + NextJS App Router = Simple Typesafe APIs\\nJack Herrington 19:17\\nhttps://www.youtube.com/watch?v=qCLV0Iaq9zU */}\\n{/* https://www.youtube.com/watch?v=qDunJ0wVIec */}\\n{/* https://www.youtube.com/watch?v=NZpPMlSAez0 */}\\n\\n {/* https://www.youtube.com/watch?v=-A0kMiJqQRY */}\\n\\n<YoutubeCards cards={[\\n\\t{\\n\\t\\tid: \"vyU5mJGCJMw\",\\n\\t\\ttitle: \"Full Drizzle Course for Beginners\",\\n\\t\\tdescription: \"Code Genix\",\\n\\t\\ttime: \"1:37:39\",\\n\\t},\\n\\t{\\n\\t\\tid: \"7-NZ0MlPpJA\",\\n\\t\\ttitle: \"Learn Drizzle In 60 Minutes\",\\n\\t\\tdescription: \"Web Dev Simplified\",\\n\\t\\ttime: \"56:09\"\\n\\t},\\n\\t{\\n\\t\\tid: \"i_mAHOhpBSA\",\\n\\t\\ttitle: \"Drizzle ORM in 100 Seconds\",\\n\\t\\tdescription: \"Fireship\",\\n\\t\\ttime: \"2:55\"\\n\\t},\\n\\t{\\n\\t\\tid: \"hIYNOiZXQ7Y\",\\n\\t\\ttitle: \"Learn Drizzle ORM in 13 mins (crash course)\",\\n\\t\\tdescription: \"Neon\",\\n\\t\\ttime: \"14:00\"\\n\\t},\\n\\t{\\n\\t\\tid: \"4ZhtoOFKFP8\",\\n\\t\\ttitle: \"Easiest Database Setup in Next.js&nbsp;14 with Turso&nbsp;&&nbsp;Drizzle\",\\n\\t\\tdescription: \"Sam Meech-Ward\",\\n\\t\\ttime: \\'38:08\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"NfVELsEZFsA\",\\n\\t\\ttitle: \"Next.js Project with Vercel, Neon, Drizzle, TailwindCSS, FlowBite and more!\",\\n\\t\\tdescription: \"CodingEntrepreneurs\",\\n\\t\\ttime: \\'5:46:28\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"_SLxGYzv6jo\",\\n\\t\\ttitle: \"I Have A New Favorite Database&nbsp;Tool\",\\n\\t\\tdescription: \"Theo - t3.gg\",\\n\\t\\ttime: \\'5:46\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"Qo-RXkSwOtc\",\\n\\t\\ttitle: \"Drizzle ORM First impressions - migrations, relations, queries!\",\\n\\t\\tdescription: \"Marius Espejo\",\\n\\t\\ttime: \\'33:52\\'\\n\\t},\\n\\t{\\n\\t\\tid: \"yXNEqyvA0OY\",\\n\\t\\ttitle: \"I want to learn Drizzle ORM, so I\\'m starting another next14 project\",\\n\\t\\tdescription: \"Web Dev Cody\",\\n\\t\\ttime: \"9:00\"\\n\\t},\\n\\t{\\n\\t\\tid: \"h7vVhR-dFYo\",\\n\\t\\ttitle: \"Picking an ORM is Getting Harder...\",\\n\\t\\tdescription: \"Ben Davis\",\\n\\t\\ttime: \"5:18\"\\n\\t},\\n\\t{\\n\\t\\tid: \"8met6WTk0mQ\",\\n\\t\\ttitle: \"This New Database Tool is a Game-Changer\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"8:49\"\\n\\t},\\n\\t{\\n\\t\\tid: \"woWW1T9DXEY\",\\n\\t\\ttitle: \"My Favorite Database Tool Just Got EVEN Better\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"4:23\"\\n\\t},\\n\\t{\\n\\t\\tid: \"A3l6YYkXzzg\",\\n\\t\\ttitle: \"SaaS Notion Clone with Realtime cursors, Nextjs 13, Stripe, Drizzle ORM, Tailwind, Supabase, Sockets\",\\n\\t\\tdescription: \"Web Prodigies\",\\n\\t\\ttime: \"11:41:46\"\\n\\t},\\n\\t{\\n\\t\\tid: \"EQfaw5bDE1s\",\\n\\t\\ttitle: \"SvelteKit + Drizzle Code Breakdown\",\\n\\t\\tdescription: \"Ben Davis\",\\n\\t\\ttime: \"12:18\"\\n\\t},\\n\\t{\\n\\t\\tid: \"b6VhN_HHDiQ\",\\n\\t\\ttitle: \"Build a Multi-Tenanted, Role-Based Access Control System\",\\n\\t\\tdescription: \"TomDoesTech\",\\n\\t\\ttime: \"2:01:29\"\\n\\t},\\n\\t{\\n\\t\\tid: \"3tl9XCiQErA\",\\n\\t\\ttitle: \"The Prisma killer is finally here\",\\n\\t\\tdescription: \"SST\",\\n\\t\\ttime: \"5:42\"\\n\\t},\\n\\t{\\n\\t\\tid: \"VQFjyEa8vGE\",\\n\\t\\ttitle: \"Learning Drizzle ORM and working on a next14 project\",\\n\\t\\tdescription: \"Web Dev Cody\",\\n\\t\\ttime: \"1:07:41\"\\n\\t},\\n\\t{\\n\\t\\tid: \"5G0upg4sxgE\",\\n\\t\\ttitle: \"This Trick Makes My Favorite Database Tool Even Better\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"6:01\"\\n\\t},\\n\\t{\\n\\t\\tid: \"-JnEuvPmt-Q\",\\n\\t\\ttitle: \"Effortless Auth in Next.js 14: Use Auth.js & Drizzle ORM for Secure Login\",\\n\\t\\tdescription: \"Sam Meech-Ward\",\\n\\t\\ttime: \"26:29\"\\n\\t},\\n]} />\\n', children=[]),\n",
       " DocItem(origPath=Path('perf-queries.mdx'), name='perf-queries.mdx', displayName='perf-queries.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\n\\n# Query performance\\nWhen it comes to **Drizzle** â€” we\\'re a thin TypeScript layer on top of SQL with \\nalmost 0 overhead and to make it actual 0, you can utilise our prepared statements API.\\n  \\n**When you run a query on the database, there are several things that happen:**\\n- all the configurations of the query builder got concatenated to the SQL string\\n- that string and params are sent to the database driver\\n- driver compiles SQL query to the binary SQL executable format and sends it to the database\\n\\nWith prepared statements you do SQL concatenation once on the Drizzle ORM side and then database \\ndriver is able to reuse precompiled binary SQL instead of parsing query all the time. \\nIt has extreme performance benefits on large SQL queries.  \\n\\nDifferent database drivers support prepared statements in different ways and sometimes \\nDrizzle ORM you can go [**faster than better-sqlite3 driver.**](https://twitter.com/_alexblokh/status/1593593415907909634)\\n\\n## Prepared statement\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n    ```typescript copy {3}\\n    const db = drizzle(...);\\n\\n    const prepared = db.select().from(customers).prepare(\"statement_name\");\\n    \\n    const res1 = await prepared.execute();\\n    const res2 = await prepared.execute();\\n    const res3 = await prepared.execute();\\n    ```\\n  </Tab> \\n  <Tab>\\n    ```typescript copy {3}\\n    const db = drizzle(...);\\n\\n    const prepared = db.select().from(customers).prepare();\\n    \\n    const res1 = await prepared.execute();\\n    const res2 = await prepared.execute();\\n    const res3 = await prepared.execute();\\n    ```\\n  </Tab> \\n  <Tab>\\n    ```typescript copy {3}\\n    const db = drizzle(...);\\n\\n    const prepared = db.select().from(customers).prepare();\\n    \\n    const res1 = prepared.all();\\n    const res2 = prepared.all();\\n    const res3 = prepared.all();\\n    ```\\n  </Tab> \\n  <Tab>\\n    ```typescript copy {3}\\n    const db = drizzle(...);\\n\\n    const prepared = db.select().from(customers).prepare();\\n    \\n    const res1 = await prepared.execute();\\n    const res2 = await prepared.execute();\\n    const res3 = await prepared.execute();\\n    ```\\n  </Tab> \\n</Tabs>\\n\\n## Placeholder\\nWhenever you need to embed a dynamic runtime value - you can use the `sql.placeholder(...)` api\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n    ```ts {6,9-10,15,18}\\n    import { sql } from \"drizzle-orm\";\\n\\n    const p1 = db\\n      .select()\\n      .from(customers)\\n      .where(eq(customers.id, sql.placeholder(\\'id\\')))\\n      .prepare(\"p1\")\\n\\n    await p1.execute({ id: 10 }) // SELECT * FROM customers WHERE id = 10\\n    await p1.execute({ id: 12 }) // SELECT * FROM customers WHERE id = 12\\n\\n    const p2 = db\\n      .select()\\n      .from(customers)\\n      .where(sql`lower(${customers.name}) like ${sql.placeholder(\\'name\\')}`)\\n      .prepare(\"p2\");\\n\\n    await p2.execute({ name: \\'%an%\\' }) // SELECT * FROM customers WHERE name ilike \\'%an%\\'\\n    ```\\n  </Tab>\\n  <Tab>\\n    ```ts copy {6,9-10,15,18}\\n    import { sql } from \"drizzle-orm\";\\n\\n    const p1 = db\\n      .select()\\n      .from(customers)\\n      .where(eq(customers.id, sql.placeholder(\\'id\\')))\\n      .prepare()\\n\\n    await p1.execute({ id: 10 }) // SELECT * FROM customers WHERE id = 10\\n    await p1.execute({ id: 12 }) // SELECT * FROM customers WHERE id = 12\\n\\n    const p2 = db\\n      .select()\\n      .from(customers)\\n      .where(sql`lower(${customers.name}) like ${sql.placeholder(\\'name\\')}`)\\n      .prepare();\\n\\n    await p2.execute({ name: \\'%an%\\' }) // SELECT * FROM customers WHERE name ilike \\'%an%\\'\\n    ```\\n  </Tab>\\n  <Tab>\\n    ```ts copy {6,9-10,15,18}\\n    import { sql } from \"drizzle-orm\";\\n\\n    const p1 = db\\n      .select()\\n      .from(customers)\\n      .where(eq(customers.id, sql.placeholder(\\'id\\')))\\n      .prepare()\\n\\n    p1.get({ id: 10 }) // SELECT * FROM customers WHERE id = 10\\n    p1.get({ id: 12 }) // SELECT * FROM customers WHERE id = 12\\n\\n    const p2 = db\\n      .select()\\n      .from(customers)\\n      .where(sql`lower(${customers.name}) like ${sql.placeholder(\\'name\\')}`)\\n      .prepare();\\n\\n    p2.all({ name: \\'%an%\\' }) // SELECT * FROM customers WHERE name ilike \\'%an%\\'\\n    ```\\n  </Tab> \\n  <Tab>\\n    ```ts copy {6,9-10,15,18}\\n    import { sql } from \"drizzle-orm\";\\n\\n    const p1 = db\\n      .select()\\n      .from(customers)\\n      .where(eq(customers.id, sql.placeholder(\\'id\\')))\\n      .prepare()\\n\\n    await p1.execute({ id: 10 }) // SELECT * FROM customers WHERE id = 10\\n    await p1.execute({ id: 12 }) // SELECT * FROM customers WHERE id = 12\\n\\n    const p2 = db\\n      .select()\\n      .from(customers)\\n      .where(sql`lower(${customers.name}) like ${sql.placeholder(\\'name\\')}`)\\n      .prepare();\\n\\n    await p2.execute({ name: \\'%an%\\' }) // SELECT * FROM customers WHERE name ilike \\'%an%\\'\\n    ```\\n  </Tab>\\n</Tabs>\\n', children=[]),\n",
       " DocItem(origPath=Path('perf-serverless.mdx'), name='perf-serverless.mdx', displayName='perf-serverless.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"# Drizzle Serverless performance\\n\\nYou can get immense benefits with `serverless functions` like AWS Lambda or Vercel Server Functions (they're AWS Lambda based), \\nsince they can live up to 15mins and reuse both database connections and prepared statements.\\n\\nOn the other, hand `edge functions` tend to clean up straight after they're invoked which leads to little to no performance benefits.\\n  \\nTo reuse your database connection and prepared statements you just have to declare them outside of handler scope:\\n```ts\\nconst databaseConnection = ...;\\nconst db = drizzle({ client: databaseConnection });\\nconst prepared = db.select().from(...).prepare();\\n\\n// AWS handler\\nexport const handler = async (event: APIGatewayProxyEvent) => {\\n  return prepared.execute();\\n}\\n```\\n\", children=[]),\n",
       " DocItem(origPath=Path('prisma.mdx'), name='prisma.mdx', displayName='prisma.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Tab from \\'@mdx/Tab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\n\\n# Drizzle extension for Prisma\\n\\nIf you have an existing project with Prisma and want to try Drizzle or gradually adopt it,\\nyou can use our first-class extension that will add Drizzle API to your Prisma client. It will allow you to\\nuse Drizzle alongside your Prisma queries reusing your existing DB connection.\\n\\n## How to use\\n\\n<Steps>\\n#### Install dependencies\\n\\nYou need to install Drizzle itself and a generator package that will create Drizzle schema from the Prisma schema.\\n<Npm>\\ndrizzle-orm@latest\\n-D drizzle-prisma-generator\\n</Npm>\\n\\n#### Update your Prisma schema\\n\\nAdd Drizzle generator to your Prisma schema. `output` is the path where generated Drizzle schema TS files will be placed.\\n```prisma copy filename=\"schema.prisma\" {5-8}\\ngenerator client {\\n  provider = \"prisma-client-js\"\\n}\\n\\ngenerator drizzle {\\n  provider = \"drizzle-prisma-generator\"\\n  output   = \"./drizzle\" // Where to put generated Drizle tables\\n}\\n\\n// Rest of your Prisma schema\\n\\ndatasource db {\\n  provider = \"postgresql\"\\n  url      = env(\"DB_URL\")\\n}\\n\\nmodel User {\\n  id    Int     @id @default(autoincrement())\\n  email String  @unique\\n  name  String?\\n}\\n\\n...\\n```\\n\\n#### Generate Drizzle schema\\n\\n```bash\\nprisma generate\\n```\\n\\n#### Add Drizzle extension to your Prisma client\\n\\n<CodeTabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\"]}>\\n<CodeTab>\\n```ts copy\\nimport { PrismaClient } from \\'@prisma/client\\';\\nimport { drizzle } from \\'drizzle-orm/prisma/pg\\';\\n\\nconst prisma = new PrismaClient().$extends(drizzle());\\n```\\n</CodeTab>\\n<CodeTab>\\n```ts copy\\nimport { PrismaClient } from \\'@prisma/client\\';\\nimport { drizzle } from \\'drizzle-orm/prisma/mysql\\';\\n\\nconst prisma = new PrismaClient().$extends(drizzle());\\n```\\n</CodeTab>\\n<CodeTab>\\n```ts copy\\nimport { PrismaClient } from \\'@prisma/client\\';\\nimport { drizzle } from \\'drizzle-orm/prisma/sqlite\\';\\n\\nconst prisma = new PrismaClient().$extends(drizzle());\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n#### Run Drizzle queries via `prisma.$drizzle` âœ¨\\n\\nIn order to use Drizzle query builder, you need references to Drizzle tables.\\nYou can import them from the output path that you specified in the generator config.\\n\\n```ts copy\\nimport { User } from \\'./drizzle\\';\\n\\nawait prisma.$drizzle.insert().into(User).values({ email: \\'sorenbs@drizzle.team\\', name: \\'SÃ¸ren\\' });\\nconst users = await prisma.$drizzle.select().from(User);\\n```\\n\\n</Steps>\\n\\n## Limitations\\n\\n- [Relational queries](/docs/rqb) are not supported due to a [Prisma driver limitation](https://github.com/prisma/prisma/issues/17576). Because of it, Prisma is unable to return query results in array format, which is required for relational queries to work.\\n- In SQLite, `.values()` (e.g. `await db.select().from(table).values()`) is not supported, because of the same reason as above.\\n- [Prepared statements](/docs/perf-queries#prepared-statement) support is limited - `.prepare()` will only build the SQL query on Drizzle side, because there is no Prisma API for prepared queries.\\n', children=[]),\n",
       " DocItem(origPath=Path('query-utils.mdx'), name='query-utils.mdx', displayName='query-utils.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext=\"import Tab from '@mdx/Tab.astro';\\nimport Tabs from '@mdx/Tabs.astro';\\nimport Callout from '@mdx/Callout.astro';\\nimport Section from '@mdx/Section.astro';\\nimport IsSupportedChipGroup from '@mdx/IsSupportedChipGroup.astro';\\nimport $count from '@mdx/$count.mdx';\\n\\n# Drizzle query utils\\n\\n### $count\\n<$count/>\\n\\n\", children=[]),\n",
       " DocItem(origPath=Path('quick.mdx'), name='quick.mdx', displayName='quick.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\n\\n# Quick start\\nLets build a quick start app with `PostgreSQL` + `postgresjs` and run our first migration.\\n\\nThe first thing we need to do is to install `drizzle-orm` and `drizzle-kit`:\\n\\n<Npm>\\ndrizzle-orm postgres\\n-D drizzle-kit\\n</Npm>\\n\\nLets declare our `schema.ts`:\\n\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ...\\n â”œ ðŸ“‚ src\\n â”‚ â”” ðŸ“œ schema.ts\\n â”” ðŸ“œ package.json\\n```\\n```ts copy filename=\"schema.ts\"\\nimport { serial, text, timestamp, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const user = pgTable(\"user\", {\\n  id: serial(\"id\"),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n  password: text(\"password\"),\\n  role: text(\"role\").$type<\"admin\" | \"customer\">(),\\n  createdAt: timestamp(\"created_at\"),\\n  updatedAt: timestamp(\"updated_at\"),\\n});\\n```\\n\\nNow lets add drizzle configuration file:\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ...\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ package.json\\n```\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \"postgresql\",\\n  schema: \"./src/schema.ts\",\\n  out: \"./drizzle\",\\n});\\n```\\n\\nAdd `generate` and `migrate` commands to `package.json` and run our first migrations generation:\\n\\n```json filename=\"package.json\" {5,6}\\n{\\n  \"name\": \"first time?\",\\n  \"version\": \"0.0.1\",\\n  \"scripts\": {\\n    \"generate\": \"drizzle-kit generate\",\\n    \"migrate\": \"drizzle-kit migrate\"\\n  }, \\n}\\n```\\n```shell filename=\"terminal\"\\n$ npm run generate\\n...\\n\\n[âœ“] Your SQL migration file âžœ drizzle/0000_pale_mister_fear.sql ðŸš€\\n```\\n\\nDone! We now have our first SQL migration file ðŸ¥³\\n```plaintext {4}\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ drizzle\\n â”‚ â”œ ðŸ“‚ _meta\\n â”‚ â”” ðŸ“œ 0000_pale_mister_fear.sql\\n â”œ ðŸ“‚ src\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ package.json\\n```\\nNow lets run our first migration to the database:\\n\\n```shell filename=\"terminal\"\\n$ npm run migrate\\n```\\n\\nThat\\'s it, folks!  \\n\\n**My personal congratulations ðŸŽ‰**', children=[]),\n",
       " DocItem(origPath=Path('read-replicas.mdx'), name='read-replicas.mdx', displayName='read-replicas.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\n\\n# Read Replicas\\n\\nWhen your project involves a set of read replica instances, and you require a convenient method for managing \\nSELECT queries from read replicas, as well as performing create, delete, and update operations on the primary \\ninstance, you can leverage the `withReplicas()` function within Drizzle\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n<Tab>\\n```ts copy\\nimport { sql } from \\'drizzle-orm\\';\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport { boolean, jsonb, pgTable, serial, text, timestamp, withReplicas } from \\'drizzle-orm/pg-core\\';\\n\\nconst usersTable = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\' as string).primaryKey(),\\n\\tname: text(\\'name\\').notNull(),\\n\\tverified: boolean(\\'verified\\').notNull().default(false),\\n\\tjsonb: jsonb(\\'jsonb\\').$type<string[]>(),\\n\\tcreatedAt: timestamp(\\'created_at\\', { withTimezone: true }).notNull().defaultNow(),\\n});\\n\\nconst primaryDb = drizzle(\"postgres://user:password@host:port/primary_db\");\\nconst read1 = drizzle(\"postgres://user:password@host:port/read_replica_1\");\\nconst read2 = drizzle(\"postgres://user:password@host:port/read_replica_2\");\\n\\nconst db = withReplicas(primaryDb, [read1, read2]);\\n```\\n</Tab>\\n<Tab>\\n```ts copy\\nimport { drizzle } from \"drizzle-orm/mysql2\";\\nimport mysql from \"mysql2/promise\";\\nimport { boolean, mysqlTable, serial, text, withReplicas } from \\'drizzle-orm/mysql-core\\';\\n\\nconst usersTable = mysqlTable(\\'users\\', {\\n\\tid: serial(\\'id\\' as string).primaryKey(),\\n\\tname: text(\\'name\\').notNull(),\\n\\tverified: boolean(\\'verified\\').notNull().default(false),\\n});\\n\\nconst primaryClient = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"primary_db\",\\n})\\nconst primaryDb = drizzle({ client: primaryClient });\\n\\nconst read1Client = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"read_1\",\\n})\\nconst read1 = drizzle({ client: read1Client });\\n\\nconst read2Client = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"read_2\",\\n})\\nconst read2 = drizzle({ client: read2Client });\\n\\nconst db = withReplicas(primaryDb, [read1, read2]);\\n```\\n</Tab>\\n<Tab>\\n```ts copy\\nimport { sql } from \\'drizzle-orm\\';\\nimport { sqliteTable, int, text, withReplicas } from \\'drizzle-orm/sqlite-core\\';\\nimport { createClient } from \\'@libsql/client\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\nconst usersTable = sqliteTable(\\'users\\', {\\n\\tid: int(\\'id\\' as string).primaryKey(),\\n\\tname: text(\\'name\\').notNull(),\\n});\\n\\nconst primaryDb = drizzle({ client: createClient({ url: \\'DATABASE_URL\\', authToken: \\'DATABASE_AUTH_TOKEN\\' }) });\\nconst read1 = drizzle({ client: createClient({ url: \\'DATABASE_URL\\', authToken: \\'DATABASE_AUTH_TOKEN\\' }) });\\nconst read2 = drizzle({ client: createClient({ url: \\'DATABASE_URL\\', authToken: \\'DATABASE_AUTH_TOKEN\\' }) });\\n\\nconst db = withReplicas(primaryDb, [read1, read2]);\\n```\\n</Tab>\\n<Tab>\\n```ts copy\\nimport { drizzle } from \"drizzle-orm/singlestore\";\\nimport mysql from \"mysql2/promise\";\\nimport { boolean, singlestoreTable, serial, text, withReplicas } from \\'drizzle-orm/singlestore-core\\';\\n\\nconst usersTable = singlestoreTable(\\'users\\', {\\n\\tid: serial(\\'id\\' as string).primaryKey(),\\n\\tname: text(\\'name\\').notNull(),\\n\\tverified: boolean(\\'verified\\').notNull().default(false),\\n});\\n\\nconst primaryClient = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"primary_db\",\\n})\\nconst primaryDb = drizzle({ client: primaryClient });\\n\\nconst read1Client = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"read_1\",\\n})\\nconst read1 = drizzle({ client: read1Client });\\n\\nconst read2Client = await mysql.createConnection({\\n  host: \"host\",\\n  user: \"user\",\\n  database: \"read_2\",\\n})\\nconst read2 = drizzle({ client: read2Client });\\n\\nconst db = withReplicas(primaryDb, [read1, read2]);\\n```\\n</Tab>\\n</Tabs>\\n\\nYou can now use the `db` instance the same way you did before. Drizzle will \\nhandle the choice between read replica and the primary instance automatically\\n\\n```ts\\n// Read from either the read1 connection or the read2 connection\\nawait db.select().from(usersTable)\\n\\n// Use the primary database for the delete operation\\nawait db.delete(usersTable).where(eq(usersTable.id, 1))\\n```\\n\\nYou can use the `$primary` key to force using primary instances even for read operations\\n\\n```ts\\n// read from primary\\nawait db.$primary.select().from(usersTable);\\n```\\n\\nWith Drizzle, you can also specify custom logic for choosing read replicas. \\nYou can make a weighted decision or any other custom selection method for random read replica choice. \\nHere is an implementation example of custom logic for selecting read replicas, \\nwhere the first replica has a 70% chance of being chosen, and the second replica has a 30% \\nchance of being selected.\\n\\nKeep in mind that you can implement any type of random selection method for read replicas\\n\\n```ts\\nconst db = withReplicas(primaryDb, [read1, read2], (replicas) => {\\n    const weight = [0.7, 0.3];\\n    let cumulativeProbability = 0;\\n    const rand = Math.random();\\n\\n    for (const [i, replica] of replicas.entries()) {\\n      cumulativeProbability += weight[i]!;\\n      if (rand < cumulativeProbability) return replica;\\n    }\\n    return replicas[0]!\\n});\\n\\nawait db.select().from(usersTable)\\n```', children=[]),\n",
       " DocItem(origPath=Path('relations.mdx'), name='relations.mdx', displayName='relations.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\n\\n# Drizzle soft relations\\nThe sole purpose of Drizzle relations is to let you query your relational data in the most simple and consise way:\\n\\n<CodeTabs items={[\"Relational queries\", \"Select with joins\"]}>\\n<Section>\\n```ts\\nimport * as schema from \\'./schema\\';\\nimport { drizzle } from \\'drizzle-orm/â€¦\\';\\n\\nconst db = drizzle(client, { schema });\\n\\nconst result = db.query.users.findMany({\\n  with: {\\n    posts: true,\\n  },\\n});\\n```\\n```ts\\n[{\\n  id: 10,\\n  name: \"Dan\",\\n  posts: [\\n    {\\n      id: 1,\\n      content: \"SQL is awesome\",\\n      authorId: 10,\\n    },\\n    {\\n      id: 2,\\n      content: \"But check relational queries\",\\n      authorId: 10,\\n    }\\n  ]\\n}]\\n```\\n</Section>\\n<Section>\\n```ts\\nimport { drizzle } from \\'drizzle-orm/â€¦\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { posts, users } from \\'./schema\\';\\n\\nconst db = drizzle(client);\\n\\nconst res = await db.select()\\n                    .from(users)\\n                    .leftJoin(posts, eq(posts.authorId, users.id))\\n                    .orderBy(users.id)\\nconst mappedResult =  \\n```\\n</Section>\\n</CodeTabs>\\n\\n\\n### One-to-one\\nDrizzle ORM provides you an API to define `one-to-one` relations between tables with the `relations` operator.\\n\\nAn example of a `one-to-one` relation between users and users, where a user can invite another (this example uses a self reference):\\n\\n```typescript copy {10-15}\\nimport { pgTable, serial, text, integer, boolean } from \\'drizzle-orm/pg-core\\';\\nimport { relations } from \\'drizzle-orm\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n\\tinvitedBy: integer(\\'invited_by\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ one }) => ({\\n\\tinvitee: one(users, {\\n\\t\\tfields: [users.invitedBy],\\n\\t\\treferences: [users.id],\\n\\t}),\\n}));\\n```\\n\\nAnother example would be a user having a profile information stored in separate table. In this case, because the foreign key is stored in the \"profile_info\" table, the user relation have neither fields or references. This tells Typescript that `user.profileInfo` is nullable:\\n\\n```typescript copy {9-17}\\nimport { pgTable, serial, text, integer, jsonb } from \\'drizzle-orm/pg-core\\';\\nimport { relations } from \\'drizzle-orm\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ one }) => ({\\n\\tprofileInfo: one(profileInfo),\\n}));\\n\\nexport const profileInfo = pgTable(\\'profile_info\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tuserId: integer(\\'user_id\\').references(() => users.id),\\n\\tmetadata: jsonb(\\'metadata\\'),\\n});\\n\\nexport const profileInfoRelations = relations(profileInfo, ({ one }) => ({\\n\\tuser: one(users, { fields: [profileInfo.userId], references: [users.id] }),\\n}));\\n\\nconst user = await queryUserWithProfileInfo();\\n//____^? type { id: number, profileInfo: { ... } | null  }\\n```\\n\\n### One-to-many\\nDrizzle ORM provides you an API to define `one-to-many` relations between tables with `relations` operator. \\n\\nExample of `one-to-many` relation between users and posts they\\'ve written:\\n\\n```typescript copy {9-11, 19-24}\\nimport { pgTable, serial, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { relations } from \\'drizzle-orm\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ many }) => ({\\n\\tposts: many(posts),\\n}));\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\'),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one }) => ({\\n\\tauthor: one(users, {\\n\\t\\tfields: [posts.authorId],\\n\\t\\treferences: [users.id],\\n\\t}),\\n}));\\n```\\n\\nNow lets add comments to the posts:\\n```typescript copy {14,17-22,24-29}\\n...\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\'),\\n});\\n\\nexport const postsRelations = relations(posts, ({ one, many }) => ({\\n\\tauthor: one(users, {\\n\\t\\tfields: [posts.authorId],\\n\\t\\treferences: [users.id],\\n\\t}),\\n\\tcomments: many(comments)\\n}));\\n\\nexport const comments = pgTable(\\'comments\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\ttext: text(\\'text\\'),\\n\\tauthorId: integer(\\'author_id\\'),\\n\\tpostId: integer(\\'post_id\\'),\\n});\\n\\nexport const commentsRelations = relations(comments, ({ one }) => ({\\n\\tpost: one(posts, {\\n\\t\\tfields: [comments.postId],\\n\\t\\treferences: [posts.id],\\n\\t}),\\n}));\\n```\\n\\n\\n### Many-to-many\\nDrizzle ORM provides you an API to define `many-to-many` relations between tables through so called `junction` or `join` tables,\\nthey have to be explicitly defined and store associations between related tables.  \\n  \\nExample of `many-to-many` relation between users and groups:\\n```typescript copy {9-11, 18-20, 37-46}\\nimport { relations } from \\'drizzle-orm\\';\\nimport { integer, pgTable, primaryKey, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ many }) => ({\\n  usersToGroups: many(usersToGroups),\\n}));\\n\\nexport const groups = pgTable(\\'groups\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\'),\\n});\\n\\nexport const groupsRelations = relations(groups, ({ many }) => ({\\n  usersToGroups: many(usersToGroups),\\n}));\\n\\nexport const usersToGroups = pgTable(\\n  \\'users_to_groups\\',\\n  {\\n    userId: integer(\\'user_id\\')\\n      .notNull()\\n      .references(() => users.id),\\n    groupId: integer(\\'group_id\\')\\n      .notNull()\\n      .references(() => groups.id),\\n  },\\n  (t) => [\\n\\t\\tprimaryKey({ columns: [t.userId, t.groupId] })\\n\\t],\\n);\\n\\nexport const usersToGroupsRelations = relations(usersToGroups, ({ one }) => ({\\n  group: one(groups, {\\n    fields: [usersToGroups.groupId],\\n    references: [groups.id],\\n  }),\\n  user: one(users, {\\n    fields: [usersToGroups.userId],\\n    references: [users.id],\\n  }),\\n}));\\n```\\n\\n### Foreign keys\\n\\nYou might\\'ve noticed that `relations` look similar to foreign keys â€” they even have a `references` property. So what\\'s the difference?\\n\\nWhile foreign keys serve a similar purpose, defining relations between tables, they work on a different level compared to `relations`.\\n\\nForeign keys are a database level constraint, they are checked on every `insert`/`update`/`delete` operation and throw an error if a constraint is violated.\\nOn the other hand, `relations` are a higher level abstraction, they are used to define relations between tables on the application level only.\\nThey do not affect the database schema in any way and do not create foreign keys implicitly.\\n\\nWhat this means is `relations` and foreign keys can be used together, but they are not dependent on each other.\\nYou can define `relations` without using foreign keys (and vice versa), which allows them to be used with databases that do not support foreign keys.\\n\\nThe following two examples will work exactly the same in terms of querying the data using Drizzle relational queries.\\n<CodeTabs items={[\"schema1.ts\", \"schema2.ts\"]}>\\n<CodeTab>\\n```ts {15}\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ one, many }) => ({\\n\\tprofileInfo: one(users, {\\n\\t\\tfields: [profileInfo.userId],\\n\\t\\treferences: [users.id],\\n\\t}),\\n}));\\n\\nexport const profileInfo = pgTable(\\'profile_info\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tuserId: integer(\"user_id\"),\\n\\tmetadata: jsonb(\"metadata\"),\\n});\\n```\\n</CodeTab>\\n<CodeTab>\\n```ts {15}\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const usersRelations = relations(users, ({ one, many }) => ({\\n\\tprofileInfo: one(users, {\\n\\t\\tfields: [profileInfo.userId],\\n\\t\\treferences: [users.id],\\n\\t}),\\n}));\\n\\nexport const profileInfo = pgTable(\\'profile_info\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tuserId: integer(\"user_id\").references(() => users.id),\\n\\tmetadata: jsonb(\"metadata\"),\\n});\\n```\\n</CodeTab>\\n</CodeTabs>\\n\\n### Foreign key actions\\n\\nFor more information check the [PostgreSQL foreign keys docs](https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-FK)\\n\\nYou can specify actions that should occur when the referenced data in the parent table is modified. These actions are known as \"foreign key actions.\" PostgreSQL provides several options for these actions.\\n\\nOn Delete/ Update Actions\\n\\n- `CASCADE`: When a row in the parent table is deleted, all corresponding rows in the child table will also be deleted. This ensures that no orphaned rows exist in the child table.\\n\\n- `NO ACTION`: This is the default action. It prevents the deletion of a row in the parent table if there are related rows in the child table. The DELETE operation in the parent table will fail.\\n\\n- `RESTRICT`: Similar to NO ACTION, it prevents the deletion of a parent row if there are dependent rows in the child table. It is essentially the same as NO ACTION and included for compatibility reasons.\\n\\n- `SET DEFAULT`: If a row in the parent table is deleted, the foreign key column in the child table will be set to its default value if it has one. If it doesn\\'t have a default value, the DELETE operation will fail.\\n\\n- `SET NULL`: When a row in the parent table is deleted, the foreign key column in the child table will be set to NULL. This action assumes that the foreign key column in the child table allows NULL values.\\n\\n> Analogous to ON DELETE there is also ON UPDATE which is invoked when a referenced column is changed (updated). The possible actions are the same, except that column lists cannot be specified for SET NULL and SET DEFAULT. In this case, CASCADE means that the updated values of the referenced column(s) should be copied into the referencing row(s).\\nin drizzle you can add foreign key action using `references()` second argument.\\n\\ntype of the actions\\n\\n```typescript\\nexport type UpdateDeleteAction = \\'cascade\\' | \\'restrict\\' | \\'no action\\' | \\'set null\\' | \\'set default\\';\\n\\n// second argument of references interface\\nactions?: {\\n\\t\\tonUpdate?: UpdateDeleteAction;\\n\\t\\tonDelete?: UpdateDeleteAction;\\n\\t} | undefined\\n```\\n\\nIn the following example, adding `onDelete: \\'cascade\\'` to the author field on the `posts` schema means that deleting the `user` will also delete all related Post records.\\n\\n\\n```typescript {11}\\nimport { pgTable, serial, text, integer } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n\\tauthor: integer(\\'author\\').references(() => users.id, {onDelete: \\'cascade\\'}).notNull(),\\n});\\n```\\n\\nFor constraints specified with the `foreignKey` operator, foreign key actions are defined with the syntax:\\n\\n```typescript {18-19}\\nimport { foreignKey, pgTable, serial, text, integer } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n\\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n\\tauthor: integer(\\'author\\').notNull(),\\n}, (table) => [\\n\\tforeignKey({\\n\\t\\tname: \"author_fk\",\\n\\t\\tcolumns: [table.author],\\n\\t\\tforeignColumns: [users.id],\\n\\t})\\n\\t\\t.onDelete(\\'cascade\\')\\n\\t\\t.onUpdate(\\'cascade\\')\\n]);\\n```\\n\\n### Disambiguating relations\\n\\nDrizzle also provides the `relationName` option as a way to disambiguate\\nrelations when you define multiple of them between the same two tables. For\\nexample, if you define a `posts` table that has the `author` and `reviewer`\\nrelations.\\n\\n```ts {9-12, 21-32}\\nimport { pgTable, serial, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { relations } from \\'drizzle-orm\\';\\n \\nexport const users = pgTable(\\'users\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tname: text(\\'name\\'),\\n});\\n \\nexport const usersRelations = relations(users, ({ many }) => ({\\n\\tauthor: many(posts, { relationName: \\'author\\' }),\\n\\treviewer: many(posts, { relationName: \\'reviewer\\' }),\\n}));\\n \\nexport const posts = pgTable(\\'posts\\', {\\n\\tid: serial(\\'id\\').primaryKey(),\\n\\tcontent: text(\\'content\\'),\\n\\tauthorId: integer(\\'author_id\\'),\\n\\treviewerId: integer(\\'reviewer_id\\'),\\n});\\n \\nexport const postsRelations = relations(posts, ({ one }) => ({\\n\\tauthor: one(users, {\\n\\t\\tfields: [posts.authorId],\\n\\t\\treferences: [users.id],\\n\\t\\trelationName: \\'author\\',\\n\\t}),\\n\\treviewer: one(users, {\\n\\t\\tfields: [posts.reviewerId],\\n\\t\\treferences: [users.id],\\n\\t\\trelationName: \\'reviewer\\',\\n\\t}),\\n}));\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('rls.mdx'), name='rls.mdx', displayName='rls.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\n\\n# Row-Level Security (RLS)\\n\\nWith Drizzle, you can enable Row-Level Security (RLS) for any Postgres table, create policies with various options, and define and manage the roles those policies apply to.\\n\\nDrizzle supports a raw representation of Postgres policies and roles that can be used in any way you want.\\xa0This works with popular Postgres database providers such as `Neon` and `Supabase`.\\n\\nIn Drizzle, we have specific predefined RLS roles and functions for RLS with both database providers, but you can also define your own logic.\\n\\n## Enable RLS\\n\\nIf you just want to enable RLS on a table without adding policies, you can use `.enableRLS()`\\n\\nAs mentioned in the PostgreSQL documentation:\\n\\n> If no policy exists for the table, a default-deny policy is used, meaning that no rows are visible or can be modified. \\nOperations that apply to the whole table, such as TRUNCATE and REFERENCES, are not subject to row security.\\n\\n```ts\\nimport { integer, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}).enableRLS();\\n```\\n\\n<Callout title=\\'important\\'>\\nIf you add a policy to a table, RLS will be enabled automatically. So, thereâ€™s no need to explicitly enable RLS when adding policies to a table.\\n</Callout>\\n\\n## Roles\\n\\nCurrently, Drizzle supports defining roles with a few different options, as shown below. Support for more options will be added in a future release.\\n\\n```ts\\nimport { pgRole } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\', { createRole: true, createDb: true, inherit: true });\\n```\\n\\nIf a role already exists in your database, and you donâ€™t want drizzle-kit to â€˜seeâ€™ it or include it in migrations, you can mark the role as existing.\\n\\n```ts\\nimport { pgRole } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\').existing();\\n```\\n\\n## Policies\\n\\nTo fully leverage RLS, you can define policies within a Drizzle table.\\n\\n<Callout title=\\'info\\'>\\nIn PostgreSQL, policies should be linked to an existing table. Since policies are always associated with a specific table, we decided that policy definitions should be defined as a parameter of `pgTable`\\n</Callout>\\n\\n**Example of pgPolicy with all available properties**\\n```ts\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, pgPolicy, pgRole, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\');\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}, (t) => [\\n\\tpgPolicy(\\'policy\\', {\\n\\t\\tas: \\'permissive\\',\\n\\t\\tto: admin,\\n\\t\\tfor: \\'delete\\',\\n\\t\\tusing: sql``,\\n\\t\\twithCheck: sql``,\\n\\t}),\\n]);\\n```\\n\\n**Policy options**\\n|                          |                                                                                                                                           |\\n| :----------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- |\\n| `as`                     | Possible values are `permissive` or `restrictive`                                                                                         |\\n| `to`                     | Specifies the role to which the policy applies. Possible values include `public`, `current_role`, `current_user`, `session_user`, or any other role name as a string. You can also reference a `pgRole` object. |\\n| `for`                    | Defines the commands this policy will be applied to. Possible values are `all`, `select`, `insert`, `update`, `delete`.                   |\\n| `using`                  | The SQL statement that will be applied to the `USING` part of the policy creation statement.                                              |\\n| `withCheck`              | An SQL statement that will be applied to the `WITH CHECK` part of the policy creation statement.                                          |\\n\\n\\n**Link Policy to an existing table**\\n\\nThere are situations where you need to link a policy to an existing table in your database. \\nThe most common use case is with database providers like `Neon` or `Supabase`, where you need to add a policy \\nto their existing tables. In this case, you can use the `.link()` API\\n\\n```ts\\nimport { sql } from \"drizzle-orm\";\\nimport { pgPolicy } from \"drizzle-orm/pg-core\";\\nimport { authenticatedRole, realtimeMessages } from \"drizzle-orm/supabase\";\\n\\nexport const policy = pgPolicy(\"authenticated role insert policy\", {\\n  for: \"insert\",\\n  to: authenticatedRole,\\n  using: sql``,\\n}).link(realtimeMessages);\\n```\\n\\n{/* <Callout title=\\'important\\'>\\n<Callout> */}\\n\\n## Migrations\\n\\nIf you are using drizzle-kit to manage your schema and roles, there may be situations where you want to refer to roles that are not defined in your Drizzle schema. In such cases, you may want drizzle-kit to skip managing these roles without having to define each role in your drizzle schema and marking it with `.existing()`.\\n\\nIn these cases, you can use `entities.roles` in `drizzle.config.ts`. For a complete reference, refer to the the [`drizzle.config.ts`](docs/drizzle-config-file) documentation.\\n\\nBy default, `drizzle-kit` does not manage roles for you, so you will need to enable this feature in `drizzle.config.ts`.\\n\\n```ts {12-14}\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\',\\n  schema: \"./drizzle/schema.ts\",\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!\\n  },\\n  verbose: true,\\n  strict: true,\\n  entities: {\\n    roles: true\\n  }\\n});\\n```\\n\\nIn case you need additional configuration options, let\\'s take a look at a few more examples.\\n\\n**You have an `admin` role and want to exclude it from the list of manageable roles**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      exclude: [\\'admin\\']\\n    }\\n  }\\n});\\n```\\n\\n**You have an `admin` role and want to include it in the list of manageable roles**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      include: [\\'admin\\']\\n    }\\n  }\\n});\\n```\\n\\n**If you are using `Neon` and want to exclude Neon-defined roles, you can use the provider option**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'neon\\'\\n    }\\n  }\\n});\\n```\\n\\n**If you are using `Supabase` and want to exclude Supabase-defined roles, you can use the provider option**\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'supabase\\'\\n    }\\n  }\\n});\\n```\\n\\n<Callout title=\\'important\\'>\\nYou may encounter situations where Drizzle is slightly outdated compared to new roles specified by your database provider. \\nIn such cases, you can use the `provider` option and `exclude` additional roles:\\n\\n```ts\\n// drizzle.config.ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  ...\\n  entities: {\\n    roles: {\\n      provider: \\'supabase\\',\\n      exclude: [\\'new_supabase_role\\']\\n    }\\n  }\\n});\\n```\\n</Callout>\\n\\n## RLS on views\\n\\nWith Drizzle, you can also specify RLS policies on views. For this, you need to use `security_invoker` in the view\\'s WITH options. Here is a small example:\\n\\n```ts {5}\\n...\\n\\nexport const roomsUsersProfiles = pgView(\"rooms_users_profiles\")\\n  .with({\\n    securityInvoker: true,\\n  })\\n  .as((qb) =>\\n    qb\\n      .select({\\n        ...getTableColumns(roomsUsers),\\n        email: profiles.email,\\n      })\\n      .from(roomsUsers)\\n      .innerJoin(profiles, eq(roomsUsers.userId, profiles.id))\\n  );\\n```\\n\\n## Using with Neon\\n\\nThe Neon Team helped us implement their vision of a wrapper on top of our raw policies API. We defined a specific \\n`/neon` import with the `crudPolicy` function that includes predefined functions and Neon\\'s default roles.\\n\\nHere\\'s an example of how to use the `crudPolicy` function:\\n\\n```ts\\nimport { crudPolicy } from \\'drizzle-orm/neon\\';\\nimport { integer, pgRole, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\');\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}, (t) => [\\n\\tcrudPolicy({ role: admin, read: true, modify: false }),\\n]);\\n```\\n\\nThis policy is equivalent to:\\n\\n```ts\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, pgPolicy, pgRole, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\');\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}, (t) => [\\n\\tpgPolicy(`crud-${admin.name}-policy-insert`, {\\n\\t\\tfor: \\'insert\\',\\n\\t\\tto: admin,\\n\\t\\twithCheck: sql`false`,\\n\\t}),\\n\\tpgPolicy(`crud-${admin.name}-policy-update`, {\\n\\t\\tfor: \\'update\\',\\n\\t\\tto: admin,\\n\\t\\tusing: sql`false`,\\n\\t\\twithCheck: sql`false`,\\n\\t}),\\n\\tpgPolicy(`crud-${admin.name}-policy-delete`, {\\n\\t\\tfor: \\'delete\\',\\n\\t\\tto: admin,\\n\\t\\tusing: sql`false`,\\n\\t}),\\n\\tpgPolicy(`crud-${admin.name}-policy-select`, {\\n\\t\\tfor: \\'select\\',\\n\\t\\tto: admin,\\n\\t\\tusing: sql`true`,\\n\\t}),\\n]);\\n```\\n\\n`Neon` exposes predefined `authenticated` and `anaonymous` roles and related functions. If you are using `Neon` for RLS, you can use these roles, which are marked as existing, and the related functions in your RLS queries.\\n\\n```ts\\n// drizzle-orm/neon\\nexport const authenticatedRole = pgRole(\\'authenticated\\').existing();\\nexport const anonymousRole = pgRole(\\'anonymous\\').existing();\\n\\nexport const authUid = (userIdColumn: AnyPgColumn) => sql`(select auth.user_id() = ${userIdColumn})`;\\n\\nexport const neonIdentitySchema = pgSchema(\\'neon_identity\\');\\n\\nexport const usersSync = neonIdentitySchema.table(\\'users_sync\\', {\\n  rawJson: jsonb(\\'raw_json\\').notNull(),\\n  id: text().primaryKey().notNull(),\\n  name: text(),\\n  email: text(),\\n  createdAt: timestamp(\\'created_at\\', { withTimezone: true, mode: \\'string\\' }),\\n  deletedAt: timestamp(\\'deleted_at\\', { withTimezone: true, mode: \\'string\\' }),\\n});\\n```\\n\\nFor example, you can use the `Neon` predefined roles and functions like this:\\n\\n\\n```ts\\nimport { sql } from \\'drizzle-orm\\';\\nimport { authenticatedRole } from \\'drizzle-orm/neon\\';\\nimport { integer, pgPolicy, pgRole, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\');\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}, (t) => [\\n\\tpgPolicy(`policy-insert`, {\\n\\t\\tfor: \\'insert\\',\\n\\t\\tto: authenticatedRole,\\n\\t\\twithCheck: sql`false`,\\n\\t}),\\n]);\\n```\\n\\n## Using with Supabase\\n\\nWe also have a `/supabase` import with a set of predefined roles marked as existing, which you can use in your schema. \\nThis import will be extended in a future release with more functions and helpers to make using RLS and `Supabase` simpler.\\n\\n```ts\\n// drizzle-orm/supabase\\nexport const anonRole = pgRole(\\'anon\\').existing();\\nexport const authenticatedRole = pgRole(\\'authenticated\\').existing();\\nexport const serviceRole = pgRole(\\'service_role\\').existing();\\nexport const postgresRole = pgRole(\\'postgres_role\\').existing();\\nexport const supabaseAuthAdminRole = pgRole(\\'supabase_auth_admin\\').existing();\\n```\\n\\nFor example, you can use the `Supabase` predefined roles like this:\\n\\n```ts\\nimport { sql } from \\'drizzle-orm\\';\\nimport { serviceRole } from \\'drizzle-orm/supabase\\';\\nimport { integer, pgPolicy, pgRole, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\nexport const admin = pgRole(\\'admin\\');\\n\\nexport const users = pgTable(\\'users\\', {\\n\\tid: integer(),\\n}, (t) => [\\n\\tpgPolicy(`policy-insert`, {\\n\\t\\tfor: \\'insert\\',\\n\\t\\tto: serviceRole,\\n\\t\\twithCheck: sql`false`,\\n\\t}),\\n]);\\n```\\n\\nThe `/supabase` import also includes predefined tables and functions that you can use in your application\\n\\n```ts\\n// drizzle-orm/supabase\\n\\nconst auth = pgSchema(\\'auth\\');\\nexport const authUsers = auth.table(\\'users\\', {\\n\\tid: uuid().primaryKey().notNull(),\\n});\\n\\nconst realtime = pgSchema(\\'realtime\\');\\nexport const realtimeMessages = realtime.table(\\n\\t\\'messages\\',\\n\\t{\\n\\t\\tid: bigserial({ mode: \\'bigint\\' }).primaryKey(),\\n\\t\\ttopic: text().notNull(),\\n\\t\\textension: text({\\n\\t\\t\\tenum: [\\'presence\\', \\'broadcast\\', \\'postgres_changes\\'],\\n\\t\\t}).notNull(),\\n\\t},\\n);\\n\\nexport const authUid = sql`(select auth.uid())`;\\nexport const realtimeTopic = sql`realtime.topic()`;\\n```\\n\\nThis allows you to use it in your code, and Drizzle Kit will treat them as existing databases,\\nusing them only as information to connect to other entities\\n\\n```ts\\nimport { foreignKey, pgPolicy, pgTable, text, uuid } from \"drizzle-orm/pg-core\";\\nimport { sql } from \"drizzle-orm/sql\";\\nimport { authenticatedRole, authUsers } from \"drizzle-orm/supabase\";\\n\\nexport const profiles = pgTable(\\n  \"profiles\",\\n  {\\n    id: uuid().primaryKey().notNull(),\\n    email: text().notNull(),\\n  },\\n  (table) => [\\n    foreignKey({\\n      columns: [table.id],\\n\\t  // reference to the auth table from Supabase\\n      foreignColumns: [authUsers.id],\\n      name: \"profiles_id_fk\",\\n    }).onDelete(\"cascade\"),\\n    pgPolicy(\"authenticated can view all profiles\", {\\n      for: \"select\",\\n\\t  // using predefined role from Supabase\\n      to: authenticatedRole,\\n      using: sql`true`,\\n    }),\\n  ]\\n);\\n```\\n\\nLet\\'s check an example of adding a policy to a table that exists in `Supabase`\\n\\n```ts\\nimport { sql } from \"drizzle-orm\";\\nimport { pgPolicy } from \"drizzle-orm/pg-core\";\\nimport { authenticatedRole, realtimeMessages } from \"drizzle-orm/supabase\";\\n\\nexport const policy = pgPolicy(\"authenticated role insert policy\", {\\n  for: \"insert\",\\n  to: authenticatedRole,\\n  using: sql``,\\n}).link(realtimeMessages);\\n```\\n\\nWe also have a great example showcasing how to use Drizzle RLS with Supabase and how to make actual queries with it. \\nIt also includes a great wrapper, `createDrizzle`, that can handle all the transactional work with Supabase for you. \\nIn upcoming releases, it will be moved to drizzle-orm/supabase, allowing you to use it natively\\n\\nPlease check [Drizzle SupaSecureSlack repo](https://github.com/rphlmr/drizzle-supabase-rls)\\n\\nHere is an example of an implementation from this repository\\n```ts\\ntype SupabaseToken = {\\n  iss?: string;\\n  sub?: string;\\n  aud?: string[] | string;\\n  exp?: number;\\n  nbf?: number;\\n  iat?: number;\\n  jti?: string;\\n  role?: string;\\n};\\n\\nexport function createDrizzle(token: SupabaseToken, { admin, client }: { admin: PgDatabase<any>; client: PgDatabase<any> }) {\\n  return {\\n    admin,\\n    rls: (async (transaction, ...rest) => {\\n      return await client.transaction(async (tx) => {\\n        // Supabase exposes auth.uid() and auth.jwt()\\n        // https://supabase.com/docs/guides/database/postgres/row-level-security#helper-functions\\n        try {\\n          await tx.execute(sql`\\n          -- auth.jwt()\\n          select set_config(\\'request.jwt.claims\\', \\'${sql.raw(\\n            JSON.stringify(token)\\n          )}\\', TRUE);\\n          -- auth.uid()\\n          select set_config(\\'request.jwt.claim.sub\\', \\'${sql.raw(\\n            token.sub ?? \"\"\\n          )}\\', TRUE);\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n          -- set local role\\n          set local role ${sql.raw(token.role ?? \"anon\")};\\n          `);\\n          return await transaction(tx);\\n        } finally {\\n          await tx.execute(sql`\\n            -- reset\\n            select set_config(\\'request.jwt.claims\\', NULL, TRUE);\\n            select set_config(\\'request.jwt.claim.sub\\', NULL, TRUE);\\n            reset role;\\n            `);\\n        }\\n      }, ...rest);\\n    }) as typeof client.transaction,\\n  };\\n}\\n```\\n\\nAnd it can be used as \\n\\n```ts\\n// https://github.com/orgs/supabase/discussions/23224\\n// Should be secure because we use the access token that is signed, and not the data read directly from the storage\\nexport async function createDrizzleSupabaseClient() {\\n  const {\\n    data: { session },\\n  } = await createClient().auth.getSession();\\n  return createDrizzle(decode(session?.access_token ?? \"\"), { admin, client });\\n}\\n\\nasync function getRooms() {\\n  const db = await createDrizzleSupabaseClient();\\n  return db.rls((tx) => tx.select().from(rooms));\\n}\\n```', children=[]),\n",
       " DocItem(origPath=Path('rqb.mdx'), name='rqb.mdx', displayName='rqb.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\n\\n# Drizzle Queries\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': true, \\'SingleStore\\': false }} />\\n\\nDrizzle ORM is designed to be a thin typed layer on top of SQL. \\nWe truly believe we\\'ve designed the best way to operate an SQL database from TypeScript and it\\'s time to make it better.  \\n  \\nRelational queries are meant to provide you with a great developer experience for querying \\nnested relational data from an SQL database, avoiding multiple joins and complex data mappings.  \\n\\nIt is an extension to the existing schema definition and query builder. \\nYou can opt-in to use it based on your needs. \\nWe\\'ve made sure you have both the best-in-class developer experience and performance.  \\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy /schema/3\\n\\timport * as schema from \\'./schema\\';\\n\\timport { drizzle } from \\'drizzle-orm/...\\';\\n\\n\\tconst db = drizzle({ schema });\\n\\n\\tconst result = await db.query.users.findMany({\\n\\t\\twith: {\\n\\t\\t\\tposts: true\\t\\t\\t\\n\\t\\t},\\n\\t});\\n\\t```\\n\\n\\t```ts\\n\\t[{\\n\\t\\tid: 10,\\n\\t\\tname: \"Dan\",\\n\\t\\tposts: [\\n\\t\\t\\t{\\n\\t\\t\\t\\tid: 1,\\n\\t\\t\\t\\tcontent: \"SQL is awesome\",\\n\\t\\t\\t\\tauthorId: 10,\\n\\t\\t\\t},\\n\\t\\t\\t{\\n\\t\\t\\t\\tid: 2,\\n\\t\\t\\t\\tcontent: \"But check relational queries\",\\n\\t\\t\\t\\tauthorId: 10,\\n\\t\\t\\t}\\n\\t\\t]\\n\\t}]\\n\\t```\\n\\t</CodeTab>\\n\\n\\t```typescript copy\\n\\timport { integer, serial, text, pgTable } from \\'drizzle-orm/pg-core\\';\\n\\timport { relations } from \\'drizzle-orm\\';\\n\\n\\texport const users = pgTable(\\'users\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tname: text(\\'name\\').notNull(),\\n\\t});\\n\\n\\texport const usersRelations = relations(users, ({ many }) => ({\\n\\t\\tposts: many(posts),\\n\\t}));\\n\\n\\texport const posts = pgTable(\\'posts\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tcontent: text(\\'content\\').notNull(),\\n\\t\\tauthorId: integer(\\'author_id\\').notNull(),\\n\\t});\\n\\n\\texport const postsRelations = relations(posts, ({ one }) => ({\\n\\t\\tauthor: one(users, { fields: [posts.authorId], references: [users.id] }),\\n\\t}));\\n\\t```\\n</CodeTabs>\\n\\nâš ï¸ If you have SQL schema declared in multiple files you can do it like that\\n<CodeTabs items={[\"index.ts\", \"schema1.ts\", \"schema2.ts\"]}>\\n\\t```typescript copy /schema/3\\n\\timport * as schema1 from \\'./schema1\\';\\n\\timport * as schema2 from \\'./schema2\\';\\n\\timport { drizzle } from \\'drizzle-orm/...\\';\\n\\n\\tconst db = drizzle({ schema: { ...schema1, ...schema2 } });\\n\\n\\tconst result = await db.query.users.findMany({\\n\\t\\twith: {\\n\\t\\t\\tposts: true\\t\\t\\t\\n\\t\\t},\\n\\t});\\n\\t```\\n\\t\\n\\t```ts\\n\\t// schema declaration in the first file\\n\\t```\\n\\t```ts\\n\\t// schema declaration in the second file\\n\\t```\\n</CodeTabs>\\n\\n\\n## Modes\\nDrizzle relational queries always generate exactly one SQL statement to run on the database and it has certain caveats. \\nTo have best in class support for every database out there we\\'ve introduced **`modes`**.  \\n\\nDrizzle relational queries use lateral joins of subqueries under the hood and for now PlanetScale does not support them.\\n\\nWhen using **mysql2** driver with regular **MySQL** database â€” you should specify `mode: \"default\"`\\nWhen using **mysql2** driver with **PlanetScale** â€” you need to specify `mode: \"planetscale\"`\\n\\n```ts copy\\nimport * as schema from \\'./schema\\';\\nimport { drizzle } from \"drizzle-orm/mysql2\";\\nimport mysql from \"mysql2/promise\";\\n\\nconst connection = await mysql.createConnection({\\n  uri: process.env.PLANETSCALE_DATABASE_URL,\\n});\\n\\nconst db = drizzle({ client: connection, schema, mode: \\'planetscale\\' });\\n```\\n\\n## Querying\\nRelational queries are an extension to Drizzle\\'s original **[query builder](/docs/select)**.\\nYou need to provide all `tables` and `relations` from your schema file/files upon `drizzle()` \\ninitialization and then just use the `db.query` API.\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n\\t`drizzle` import path depends on the **[database driver](/docs/connect-overview)** you\\'re using.\\n</Callout>\\n<CodeTabs items={[\"index.ts\", \"schema.ts\"]}>\\n<CodeTab>\\n```ts\\nimport * as schema from \\'./schema\\';\\nimport { drizzle } from \\'drizzle-orm/...\\';\\n\\nconst db = drizzle({ schema });\\n\\nawait db.query.users.findMany(...);\\n```\\n```ts\\n// if you have schema in multiple files\\nimport * as schema1 from \\'./schema1\\';\\nimport * as schema2 from \\'./schema2\\';\\nimport { drizzle } from \\'drizzle-orm/...\\';\\n\\nconst db = drizzle({ schema: { ...schema1, ...schema2 } });\\n\\nawait db.query.users.findMany(...);\\n```\\n</CodeTab>\\n```typescript copy\\n\\timport { type AnyPgColumn, boolean, integer, pgTable, primaryKey, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\n\\timport { relations } from \\'drizzle-orm\\';\\n\\n\\texport const users = pgTable(\\'users\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tname: text(\\'name\\').notNull(),\\n\\t\\tverified: boolean(\\'verified\\').notNull(),\\n\\t\\tinvitedBy: integer(\\'invited_by\\').references((): AnyPgColumn => users.id),\\n\\t});\\n\\n\\texport const usersRelations = relations(users, ({ one, many }) => ({\\n\\t\\tinvitee: one(users, { fields: [users.invitedBy], references: [users.id] }),\\n\\t\\tusersToGroups: many(usersToGroups),\\n\\t\\tposts: many(posts),\\n\\t}));\\n\\n\\texport const groups = pgTable(\\'groups\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tname: text(\\'name\\').notNull(),\\n\\t\\tdescription: text(\\'description\\'),\\n\\t});\\n\\n\\texport const groupsRelations = relations(groups, ({ many }) => ({\\n\\t\\tusersToGroups: many(usersToGroups),\\n\\t}));\\n\\n\\texport const usersToGroups = pgTable(\\'users_to_groups\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tuserId: integer(\\'user_id\\').notNull().references(() => users.id),\\n\\t\\tgroupId: integer(\\'group_id\\').notNull().references(() => groups.id),\\n\\t}, (t) => [\\n\\t\\tprimaryKey({ columns: [t.userId, t.groupId] })\\n\\t]);\\n\\n\\texport const usersToGroupsRelations = relations(usersToGroups, ({ one }) => ({\\n\\t\\tgroup: one(groups, { fields: [usersToGroups.groupId], references: [groups.id] }),\\n\\t\\tuser: one(users, { fields: [usersToGroups.userId], references: [users.id] }),\\n\\t}));\\n\\n\\texport const posts = pgTable(\\'posts\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tcontent: text(\\'content\\').notNull(),\\n\\t\\tauthorId: integer(\\'author_id\\').references(() => users.id),\\n\\t\\tcreatedAt: timestamp(\\'created_at\\', { withTimezone: true }).notNull().defaultNow(),\\n\\t});\\n\\n\\texport const postsRelations = relations(posts, ({ one, many }) => ({\\n\\t\\tauthor: one(users, { fields: [posts.authorId], references: [users.id] }),\\n\\t\\tcomments: many(comments),\\n\\t}));\\n\\n\\texport const comments = pgTable(\\'comments\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tcontent: text(\\'content\\').notNull(),\\n\\t\\tcreator: integer(\\'creator\\').references(() => users.id),\\n\\t\\tpostId: integer(\\'post_id\\').references(() => posts.id),\\n\\t\\tcreatedAt: timestamp(\\'created_at\\', { withTimezone: true }).notNull().defaultNow(),\\n\\t});\\n\\n\\texport const commentsRelations = relations(comments, ({ one, many }) => ({\\n\\t\\tpost: one(posts, { fields: [comments.postId], references: [posts.id] }),\\n\\t\\tauthor: one(users, { fields: [comments.creator], references: [users.id] }),\\n\\t\\tlikes: many(commentLikes),\\n\\t}));\\n\\n\\texport const commentLikes = pgTable(\\'comment_likes\\', {\\n\\t\\tid: serial(\\'id\\').primaryKey(),\\n\\t\\tcreator: integer(\\'creator\\').references(() => users.id),\\n\\t\\tcommentId: integer(\\'comment_id\\').references(() => comments.id),\\n\\t\\tcreatedAt: timestamp(\\'created_at\\', { withTimezone: true }).notNull().defaultNow(),\\n\\t});\\n\\n\\texport const commentLikesRelations = relations(commentLikes, ({ one }) => ({\\n\\t\\tcomment: one(comments, { fields: [commentLikes.commentId], references: [comments.id] }),\\n\\t\\tauthor: one(users, { fields: [commentLikes.creator], references: [users.id] }),\\n\\t}));\\n```\\n</CodeTabs>\\n\\nDrizzle provides `.findMany()` and `.findFirst()` APIs.\\n### Find many\\n<Section>\\n```typescript copy\\nconst users = await db.query.users.findMany();\\n```\\n```ts\\n// result type\\nconst result: {\\n\\tid: number;\\n\\tname: string;\\n\\tverified: boolean;\\n\\tinvitedBy: number | null;\\n}[];\\n```\\n</Section>\\n\\n### Find first\\n<Callout>\\n  `.findFirst()` will add `limit 1` to the query.\\n</Callout>\\n<Section>\\n```typescript copy\\nconst user = await db.query.users.findFirst();\\n```\\n```ts\\n// result type\\nconst result: {\\n\\tid: number;\\n\\tname: string;\\n\\tverified: boolean;\\n\\tinvitedBy: number | null;\\n};\\n```\\n</Section>\\n\\n### Include relations\\n\\n`With` operator lets you combine data from multiple related tables and properly aggregate results.\\n\\n**Getting all posts with comments:**\\n```typescript copy\\nconst posts = await db.query.posts.findMany({\\n\\twith: {\\n\\t\\tcomments: true,\\n\\t},\\n});\\n```\\n\\n**Getting first post with comments:**\\n```typescript copy\\nconst post = await db.query.posts.findFirst({\\n\\twith: {\\n\\t\\tcomments: true,\\n\\t},\\n});\\n```\\n\\nYou can chain nested with statements as much as necessary.  \\nFor any nested `with` queries Drizzle will infer types using [Core Type API](/docs/goodies#type-api).\\n  \\n**Get all users with posts. Each post should contain a list of comments:**\\n```typescript copy\\nconst users = await db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twith: {\\n\\t\\t\\t\\tcomments: true,\\n\\t\\t\\t},\\n\\t\\t},\\n\\t},\\n});\\n```\\n\\n### Partial fields select\\n`columns` parameter lets you include or omit columns you want to get from the database.\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n  Drizzle performs partial selects on the query level, no additional data is transferred from the database.\\n\\n  Keep in mind that **a single SQL statement is outputted by Drizzle.**\\n</Callout>\\n\\n**Get all posts with just `id`, `content` and include `comments`:**\\n```typescript copy\\nconst posts = await db.query.posts.findMany({\\n\\tcolumns: {\\n\\t\\tid: true,\\n\\t\\tcontent: true,\\n\\t},\\n\\twith: {\\n\\t\\tcomments: true,\\n\\t}\\n});\\n```\\n\\n**Get all posts without `content`:**\\n```typescript copy\\nconst posts = await db.query.posts.findMany({\\n\\tcolumns: {\\n\\t\\tcontent: false,\\n\\t},\\n});\\n```\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\nWhen both `true` and `false` select options are present, all `false` options are ignored.\\n</Callout>\\n\\nIf you include the `name` field and exclude the `id` field, `id` exclusion will be redundant, \\nall fields apart from `name` would be excluded anyways.  \\n  \\n**Exclude and Include fields in the same query:**\\n<Section>\\n```typescript copy\\nconst users = await db.query.users.findMany({\\n\\tcolumns: {\\n\\t\\tname: true,\\n\\t\\tid: false //ignored\\n\\t},\\n});\\n```\\n```ts\\n// result type\\nconst users: {\\n\\tname: string;\\n};\\n```\\n</Section>\\n\\n**Only include columns from nested relations:**\\n<Section>\\n```typescript copy\\nconst res = await db.query.users.findMany({\\n\\tcolumns: {},\\n\\twith: {\\n\\t\\tposts: true\\n\\t}\\n});\\n```\\n```ts\\n// result type\\nconst res: {\\n\\tposts: {\\n\\t\\tid: number,\\n\\t\\ttext: string\\n\\t}\\n}[];\\n```\\n</Section>\\n\\n### Nested partial fields select\\nJust like with **[`partial select`](#partial-select)**, you can include or exclude columns of nested relations:\\n```typescript copy\\nconst posts = await db.query.posts.findMany({\\n\\tcolumns: {\\n\\t\\tid: true,\\n\\t\\tcontent: true,\\n\\t},\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\tcolumns: {\\n\\t\\t\\t\\tauthorId: false\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n});\\n```\\n\\n### Select filters\\nJust like in our SQL-like query builder, \\nrelational queries API lets you define filters and conditions with the list of our **[`operators`](/docs/operators)**.  \\n\\nYou can either import them from `drizzle-orm` or use from the callback syntax:\\n<Section>\\n```typescript copy\\nimport { eq } from \\'drizzle-orm\\';\\n\\nconst users = await db.query.users.findMany({\\n\\twhere: eq(users.id, 1)\\n})\\n```\\n```ts copy\\nconst users = await db.query.users.findMany({\\n\\twhere: (users, { eq }) => eq(users.id, 1),\\n})\\n```\\n</Section>\\n\\nFind post with `id=1` and comments that were created before particular date:\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\twhere: (posts, { eq }) => (eq(posts.id, 1)),\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\twhere: (comments, { lt }) => lt(comments.createdAt, new Date()),\\n\\t\\t},\\n\\t},\\n});\\n```\\n\\n### Limit & Offset\\nDrizzle ORM provides `limit` & `offset` API for queries and for the nested entities.\\n  \\n**Find 5 posts:**\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\tlimit: 5,\\n});\\n```\\n\\n**Find posts and get 3 comments at most:**\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\tlimit: 3,\\n\\t\\t},\\n\\t},\\n});\\n```\\n\\n<Callout type=\"warning\" emoji=\"âš ï¸\">\\n  `offset` is only available for top level query.\\n</Callout>\\n```typescript \\nawait db.query.posts.findMany({\\n\\tlimit: 5,\\n\\toffset: 2, // correct âœ…\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\toffset: 3, // incorrect âŒ\\n\\t\\t\\tlimit: 3,\\n\\t\\t},\\n\\t},\\n});\\n```\\n\\nFind posts with comments from the 5th to the 10th post:\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\tlimit: 5,\\n  offset: 5,\\n\\twith: {\\n\\t\\tcomments: true,\\n\\t},\\n});\\n```\\n\\n### Order By\\nDrizzle provides API for ordering in the relational query builder.  \\n\\nYou can use same ordering **[core API](/docs/select#order-by)** or use\\n`order by` operator from the callback with no imports.  \\n\\n<Section>\\n```typescript copy\\nimport { desc, asc } from \\'drizzle-orm\\';\\n\\nawait db.query.posts.findMany({\\n\\torderBy: [asc(posts.id)],\\n});\\n```\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\torderBy: (posts, { asc }) => [asc(posts.id)],\\n});\\n```\\n</Section>\\n\\n**Order by `asc` + `desc`:**\\n```typescript copy\\nawait db.query.posts.findMany({\\n\\torderBy: (posts, { asc }) => [asc(posts.id)],\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\torderBy: (comments, { desc }) => [desc(comments.id)],\\n\\t\\t},\\n\\t},\\n});\\n```\\n\\n### Include custom fields\\nRelational query API lets you add custom additional fields. \\nIt\\'s useful when you need to retrieve data and apply additional functions to it.\\n<Callout type=\"warning\" emoji=\"âš ï¸\">\\n\\tAs of now aggregations are not supported in `extras`, please use **[`core queries`](/docs/select)** for that.\\n</Callout>\\n\\n<Section>\\n```typescript copy {5}\\nimport { sql } from \\'drizzle-orm\\';\\n\\nawait db.query.users.findMany({\\n\\textras: {\\n\\t\\tloweredName: sql`lower(${users.name})`.as(\\'lowered_name\\'),\\n\\t},\\n})\\n```\\n```typescript copy {3}\\nawait db.query.users.findMany({\\n\\textras: {\\n\\t\\tloweredName: (users, { sql }) => sql`lower(${users.name})`.as(\\'lowered_name\\'),\\n\\t},\\n})\\n```\\n</Section>\\n\\n`lowerName` as a key will be included to all fields in returned object.\\n\\n<Callout type=\"warning\" emoji=\"âš ï¸\">\\n  You have to explicitly specify `.as(\"<name_for_column>\")`\\n</Callout>\\n\\nTo retrieve all users with groups, but with the fullName field included (which is a concatenation of firstName and lastName), \\nyou can use the following query with the Drizzle relational query builder.\\n\\n<Section>\\n```typescript copy\\nconst res = await db.query.users.findMany({\\n\\textras: {\\n\\t\\tfullName: sql<string>`concat(${users.name}, \" \", ${users.name})`.as(\\'full_name\\'),\\n\\t},\\n\\twith: {\\n\\t\\tusersToGroups: {\\n\\t\\t\\twith: {\\n\\t\\t\\t\\tgroup: true,\\n\\t\\t\\t},\\n\\t\\t},\\n\\t},\\n});\\n```\\n```ts\\n// result type\\nconst res: {\\n\\tid: number;\\n\\tname: string;\\n\\tverified: boolean;\\n\\tinvitedBy: number | null;\\n\\tfullName: string;\\n\\tusersToGroups: {\\n\\t\\t\\tgroup: {\\n\\t\\t\\t\\t\\tid: number;\\n\\t\\t\\t\\t\\tname: string;\\n\\t\\t\\t\\t\\tdescription: string | null;\\n\\t\\t\\t};\\n\\t}[];\\n}[];\\n\\n```\\n</Section>\\n\\n\\nTo retrieve all posts with comments and add an additional field to calculate the size of the post content and the size of each comment content:\\n<Section>\\n```typescript copy\\nconst res = await db.query.posts.findMany({\\n\\textras: (table, { sql }) => ({\\n\\t\\tcontentLength: (sql<number>`length(${table.content})`).as(\\'content_length\\'),\\n\\t}),\\n\\twith: {\\n\\t\\tcomments: {\\n\\t\\t\\textras: {\\n\\t\\t\\t\\tcommentSize: sql<number>`length(${comments.content})`.as(\\'comment_size\\'),\\n\\t\\t\\t},\\n\\t\\t},\\n\\t},\\n});\\n```\\n```ts\\n// result type\\nconst res: {\\n\\tid: number;\\n\\tcreatedAt: Date;\\n\\tcontent: string;\\n\\tauthorId: number | null;\\n\\tcontentLength: number;\\n\\tcomments: {\\n\\t\\t\\tid: number;\\n\\t\\t\\tcreatedAt: Date;\\n\\t\\t\\tcontent: string;\\n\\t\\t\\tcreator: number | null;\\n\\t\\t\\tpostId: number | null;\\n\\t\\t\\tcommentSize: number;\\n\\t}[];\\n};\\n```\\n</Section>\\n\\n### Prepared statements\\nPrepared statements are designed to massively improve query performance â€” [see here.](/docs/perf-queries)\\n\\nIn this section, you can learn how to define placeholders and execute prepared statements \\nusing the Drizzle relational query builder.\\n\\n##### **Placeholder in `where`**\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'id\\'))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t},\\n\\t},\\n}).prepare(\\'query_name\\');\\n\\nconst usersWithPosts = await prepared.execute({ id: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'id\\'))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ id: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'id\\'))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ id: 1 });\\n```\\n</Section>\\n</Tab>\\n</Tabs>\\n\\n\\n##### **Placeholder in `limit`**\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\tlimit: placeholder(\\'limit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare(\\'query_name\\');\\n\\nconst usersWithPosts = await prepared.execute({ limit: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\tlimit: placeholder(\\'limit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ limit: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\tlimit: placeholder(\\'limit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ limit: 1 });\\n```\\n</Section>\\n</Tab>\\n</Tabs>\\n\\n\\n##### **Placeholder in `offset`**\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\toffset: placeholder(\\'offset\\'),\\n\\twith: {\\n\\t\\tposts: true,\\n\\t},\\n}).prepare(\\'query_name\\');\\n\\nconst usersWithPosts = await prepared.execute({ offset: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\toffset: placeholder(\\'offset\\'),\\n\\twith: {\\n\\t\\tposts: true,\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ offset: 1 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\toffset: placeholder(\\'offset\\'),\\n\\twith: {\\n\\t\\tposts: true,\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ offset: 1 });\\n```\\n</Section>\\n</Tab>\\n</Tabs>\\n\\n##### **Multiple placeholders**\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\tlimit: placeholder(\\'uLimit\\'),\\n\\toffset: placeholder(\\'uOffset\\'),\\n\\twhere: ((users, { eq, or }) => or(eq(users.id, placeholder(\\'id\\')), eq(users.id, 3))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t\\tlimit: placeholder(\\'pLimit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare(\\'query_name\\');\\n\\nconst usersWithPosts = await prepared.execute({ pLimit: 1, uLimit: 3, uOffset: 1, id: 2, pid: 6 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\tlimit: placeholder(\\'uLimit\\'),\\n\\toffset: placeholder(\\'uOffset\\'),\\n\\twhere: ((users, { eq, or }) => or(eq(users.id, placeholder(\\'id\\')), eq(users.id, 3))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t\\tlimit: placeholder(\\'pLimit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ pLimit: 1, uLimit: 3, uOffset: 1, id: 2, pid: 6 });\\n```\\n</Section>\\n</Tab>\\n<Tab>\\n<Section>\\n```ts copy\\nconst prepared = db.query.users.findMany({\\n\\tlimit: placeholder(\\'uLimit\\'),\\n\\toffset: placeholder(\\'uOffset\\'),\\n\\twhere: ((users, { eq, or }) => or(eq(users.id, placeholder(\\'id\\')), eq(users.id, 3))),\\n\\twith: {\\n\\t\\tposts: {\\n\\t\\t\\twhere: ((users, { eq }) => eq(users.id, placeholder(\\'pid\\'))),\\n\\t\\t\\tlimit: placeholder(\\'pLimit\\'),\\n\\t\\t},\\n\\t},\\n}).prepare();\\n\\nconst usersWithPosts = await prepared.execute({ pLimit: 1, uLimit: 3, uOffset: 1, id: 2, pid: 6 });\\n```\\n</Section>\\n</Tab>\\n</Tabs>\\n', children=[]),\n",
       " DocItem(origPath=Path('schemas.mdx'), name='schemas.mdx', displayName='schemas.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# Table schemas\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': true, \\'SQLite\\': false, \\'SingleStore\\': true }} />\\n\\nDrizzle ORM provides you an API for declaring SQL schemas for PostgreSQL and MySQL dialects.\\n\\nIf you declare an entity within a schema, query builder will prepend schema names in queries:<br/>\\n`select * from \"schema\".\"users\"`\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n    <Section>\\n    ```ts copy {3,5,7}\\n    import { serial, text, pgSchema } from \"drizzle-orm/pg-core\";\\n\\n    export const mySchema = pgSchema(\"my_schema\");\\n\\n    export const colors = mySchema.enum(\\'colors\\', [\\'red\\', \\'green\\', \\'blue\\']);\\n\\n    export const mySchemaUsers = mySchema.table(\\'users\\', {\\n      id: serial(\\'id\\').primaryKey(),\\n      name: text(\\'name\\'),\\n      color: colors(\\'color\\').default(\\'red\\'),\\n    });\\n\\n    \\n    ```\\n    ```sql\\n    CREATE SCHEMA \"my_schema\";\\n\\n    CREATE TYPE \"my_schema\".\"colors\" AS ENUM (\\'red\\', \\'green\\', \\'blue\\');\\n\\n    CREATE TABLE \"my_schema\".\"users\" (\\n      \"id\" serial PRIMARY KEY,\\n      \"name\" text,\\n      \"color\" \"my_schema\".\"colors\" DEFAULT \\'red\\'\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```ts {3,5}\\n    import { int, text, mysqlSchema } from \"drizzle-orm/mysql-core\";\\n\\n    export const mySchema = mysqlSchema(\"my_schema\")\\n\\n    export const mySchemaUsers = mySchema.table(\"users\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n    });\\n    ```\\n    ```sql\\n    CREATE SCHEMA \"my_schema\";\\n\\n    CREATE TABLE \"my_schema\".\"users\" (\\n      \"id\" serial PRIMARY KEY,\\n      \"name\" text\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n  SQLite does not have support for schemas ðŸ˜•\\n  </Tab>\\n  <Tab>\\n    <Section>\\n    ```ts {3,5}\\n    import { int, text, singlestoreSchema } from \"drizzle-orm/singlestore-core\";\\n\\n    export const mySchema = singlestoreSchema(\"my_schema\")\\n\\n    export const mySchemaUsers = mySchema.table(\"users\", {\\n      id: int(\"id\").primaryKey().autoincrement(),\\n      name: text(\"name\"),\\n    });\\n    ```\\n    ```sql\\n    CREATE SCHEMA \"my_schema\";\\n\\n    CREATE TABLE \"my_schema\".\"users\" (\\n      \"id\" serial PRIMARY KEY,\\n      \"name\" text\\n    );\\n    ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n\\n{/* TODO: ??? example > **Warning**\\n> If you will have tables with same names in different schemas then drizzle will respond with `never[]` error in result types and error from database\\n>\\n> In this case you may use [alias syntax](./joins#join-aliases-and-self-joins) */}\\n', children=[]),\n",
       " DocItem(origPath=Path('seed-functions.mdx'), name='seed-functions.mdx', displayName='seed-functions.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\n\\n# Generators\\n\\n<Callout title=\\'warning\\'>\\nFor now, specifying `arraySize` along with `isUnique` in generators that support it will result in unique values being generated (not unique arrays), which will then be packed into arrays.\\n</Callout>\\n\\n## ---\\n\\n### `default`\\n\\n<rem025 />\\nGenerates the same given value each time the generator is called.\\n\\n|  | param          | default     | type\\n|:-| :--------      | :--------   | :--------\\n|  |`defaultValue`  |--           |`any`\\n|  |`arraySize`     |--           |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  posts: {\\n    columns: {\\n      content: funcs.default({\\n        // value you want to generate\\n        defaultValue: \"post content\",\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `valuesFromArray`\\n\\n<rem025 />\\nGenerates values from given array\\n\\n|  | param      | default                   | type\\n|:-| :--------  | :--------                 | :--------\\n|  |`values`    |--                         |`any[]` \\\\| `{ weight: number; values: any[] }[]`\\n|  |`isUnique`  |database column uniqueness |`boolean`\\n|  |`arraySize` |--                         |`number`\\n\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  posts: {\\n    columns: {\\n      title: funcs.valuesFromArray({\\n        // Array of values you want to generate (can be an array of weighted values)\\n        values: [\"Title1\", \"Title2\", \"Title3\", \"Title4\", \"Title5\"],\\n\\n        // Property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n        \\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `intPrimaryKey`\\n\\n<rem025 />\\nGenerates sequential integers starting from 1.\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |--          |--          |--\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  posts: {\\n    columns: {\\n      id: funcs.intPrimaryKey(),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `number`\\n\\n<rem025 />\\nGenerates numbers with a floating point within the given range\\n\\n|  | param      | default                                                                                               | type\\n|:-| :--------  | :--------                                                                                             | :--------\\n|  |`isUnique`  |database column uniqueness                                                                             |`boolean`\\n|  |`precision` |`100`                                                                                                  |`number`\\n|  |`maxValue`  |``` `precision * 1000` if isUnique equals false``` ``` `precision * count` if isUnique equals true```  |`number`\\n|  |`minValue`  |`-maxValue`                                                                                            |`number`\\n|  |`arraySize` |--                                                                                                     |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  products: {\\n    columns: {\\n      unitPrice: funcs.number({\\n        // lower border of range.\\n        minValue: 10,\\n\\n        // upper border of range.\\n        maxValue: 120,\\n        \\n        // precision of generated number:\\n        // precision equals 10 means that values will be accurate to one tenth (1.2, 34.6);\\n        // precision equals 100 means that values will be accurate to one hundredth (1.23, 34.67).\\n        precision: 100,\\n\\n        // property that controls if generated values gonna be unique or not.\\n        isUnique: false,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `int`\\n\\n<rem025 />\\nGenerates integers within the given range\\n\\n|  | param      | default                                                                            | type\\n|:-| :--------  | :--------                                                                          | :--------\\n|  |`isUnique`  |database column uniqueness                                                          |`boolean`\\n|  |`maxValue`  |``` `1000` if isUnique equals false``` ``` `count * 10` if isUnique equals true```  |`number \\\\| bigint`\\n|  |`minValue`  |`-maxValue`                                                                         |`number \\\\| bigint`\\n|  |`arraySize` |--                                                                                  |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  products: {\\n    columns: {\\n      unitsInStock: funcs.int({\\n        // lower border of range.\\n        minValue: 0,\\n\\n        // lower border of range.\\n        maxValue: 100,\\n\\n        // property that controls if generated values gonna be unique or not.\\n        isUnique: false,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `boolean`\\n\\n<rem025 />\\nGenerates boolean values (true or false)\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      isAvailable: funcs.boolean({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `date`\\n\\n<rem025 />\\nGenerates a date within the given range\\n\\n|  | param      | default                 | type\\n|:-| :--------  | :--------------         | :--------\\n|  |`minDate`   |`new Date(\\'2020-05-08\\')` | `string \\\\| Date`\\n|  |`maxDate`   |`new Date(\\'2028-05-08\\')` | `string \\\\| Date`\\n|  |`arraySize` |--                       |`number`\\n\\n<Callout type=\\'warning\\'>\\nIf only one of the parameters (`minDate` or `maxDate`) is provided, the unspecified parameter will be calculated by adding or subtracting 8 years to/from the specified one\\n</Callout>\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      birthDate: funcs.date({\\n        // lower border of range.\\n        minDate: \"1990-01-01\",\\n\\n        // upper border of range.\\n        maxDate: \"2010-12-31\",\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `time`\\n\\n<rem025 />\\nGenerates time in 24-hour format\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      birthTime: funcs.time({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `timestamp`\\n\\n<rem025 />\\nGenerates timestamps\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  orders: {\\n    columns: {\\n      shippedDate: funcs.timestamp({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `datetime`\\n\\n<rem025 />\\nGenerates datetime objects\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  orders: {\\n    columns: {\\n      shippedDate: funcs.datetime({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `year`\\n\\n<rem025 />\\nGenerates years in `YYYY` format\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      birthYear: funcs.year({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `json`\\n\\n<rem025 />\\nGenerates JSON objects with a fixed structure\\n\\n```ts\\n{ email, name, isGraduated, hasJob, salary, startedWorking, visitedCountries}\\n\\n// or\\n\\n{ email, name, isGraduated, hasJob, visitedCountries }\\n```\\n\\n> The JSON structure will be picked randomly\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      metadata: funcs.json({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `interval`\\n\\n<rem025 />\\nGenerates time intervals.\\n\\nExample of a generated value: `1 year 12 days 5 minutes`\\n\\n|  | param      | default            | type\\n|:-| :--------  | :--------          | :--------\\n|  |`isUnique`  | column uniqueness  |`boolean`\\n|  |`arraySize` |--                  |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      timeSpentOnWebsite: funcs.interval({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `string`\\n\\n<rem025 />\\nGenerates random strings\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      hashedPassword: funcs.string({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: false,\\n        \\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `uuid`\\n\\n<rem025 />\\nGenerates v4 UUID strings\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  products: {\\n    columns: {\\n      id: funcs.uuid({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n```\\n\\n### `firstName`\\n\\n<rem025 />\\nGenerates a person\\'s first name\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      firstName: funcs.firstName({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `lastName`\\n\\n<rem025 />\\nGenerates a person\\'s last name\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      lastName: funcs.lastName({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: false,\\n        \\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `fullName`\\n\\n<rem025 />\\nGenerates a person\\'s full name\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      fullName: funcs.fullName({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `email`\\n\\n<rem025 />\\nGenerates unique email addresses\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      email: funcs.email({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `phoneNumber`\\n\\n<rem025 />\\nGenerates unique phone numbers\\n\\n|  | param                    | default                                         | type\\n|:-| :--------                | :--------                                       | :--------\\n|  |`template`                |--                                               |`string`\\n|  |`prefixes`                |[Used dataset for prefixes](https://github.com/OleksiiKH0240/drizzle-orm/blob/main/drizzle-seed/src/datasets/phonesInfo.ts)   |`string[]`\\n|  |`generatedDigitsNumbers`  | `7` - `if prefixes was defined`                 |`number \\\\| number[]`\\n|  |`arraySize`               |--                                               |`number`\\n\\n<rem025 />\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\n//generate phone number using template property\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      phoneNumber: funcs.phoneNumber({ \\n        // `template` - phone number template, where all \\'#\\' symbols will be substituted with generated digits.\\n        template: \"+(380) ###-####\",\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\n//generate phone number using prefixes and generatedDigitsNumbers properties\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      phoneNumber: funcs.phoneNumber({\\n        // `prefixes` - array of any string you want to be your phone number prefixes.(not compatible with `template` property)\\n        prefixes: [\"+380 99\", \"+380 67\"],\\n\\n        // `generatedDigitsNumbers` - number of digits that will be added at the end of prefixes.(not compatible with `template` property)\\n        generatedDigitsNumbers: 7,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\n// generate phone number using prefixes and generatedDigitsNumbers properties but with different generatedDigitsNumbers for prefixes\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      phoneNumber: funcs.phoneNumber({\\n        // `prefixes` - array of any string you want to be your phone number prefixes.(not compatible with `template` property)\\n        prefixes: [\"+380 99\", \"+380 67\", \"+1\"],\\n\\n        // `generatedDigitsNumbers` - number of digits that will be added at the end of prefixes.(not compatible with `template` property)\\n        generatedDigitsNumbers: [7, 7, 10],\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n### `country`\\n\\n<rem025 />\\nGenerates country\\'s names\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      country: funcs.country({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: false,\\n        \\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `city`\\n\\n<rem025 />\\nGenerates city\\'s names\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      city: funcs.city({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: false,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `streetAddress`\\n\\n<rem025 />\\nGenerates street address\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      streetAddress: funcs.streetAddress({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: false,\\n        \\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3 \\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `jobTitle`\\n\\n<rem025 />\\nGenerates job titles\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      jobTitle: funcs.jobTitle({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `postcode`\\n\\n<rem025 />\\nGenerates postal codes\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      postcode: funcs.postcode({\\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `state`\\n\\n<rem025 />\\nGenerates US states\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      state: funcs.state({\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `companyName`\\n\\n<rem025 />\\nGenerates random company\\'s names\\n\\n|  | param      | default    | type\\n|:-| :--------  | :--------  | :--------\\n|  |`isUnique`  |--          |`boolean`\\n|  |`arraySize` |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  users: {\\n    columns: {\\n      company: funcs.companyName({ \\n        // `isUnique` - property that controls whether the generated values will be unique or not\\n        isUnique: true,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n### `loremIpsum`\\n\\n<rem025 />\\nGenerates `lorem ipsum` text sentences.\\n\\n|  | param            | default    | type\\n|:-| :--------        | :--------  | :--------\\n|  |`sentencesCount`  | 1          |`number`\\n|  |`arraySize`       |--          |`number`\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  posts: {\\n    columns: {\\n      content: funcs.loremIpsum({\\n        // `sentencesCount` - number of sentences you want to generate as one generated value(string).\\n        sentencesCount: 2,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `point`\\n\\n<rem025 />\\nGenerates 2D points within specified ranges for x and y coordinates.\\n\\n|  | param       | default                                                                                 | type\\n|:-| :--------   | :--------                                                                               | :--------\\n|  |`isUnique`   |database column uniqueness                                                               |`boolean`\\n|  |`maxXValue`  |``` `10 * 1000` if isUnique equals false``` ``` `10 * count` if isUnique equals true```  |`number`\\n|  |`minXValue`  |`-maxXValue`                                                                             |`number`\\n|  |`maxYValue`  |``` `10 * 1000` if isUnique equals false``` ``` `10 * count` if isUnique equals true```  |`number`\\n|  |`minYValue`  |`-maxYValue`                                                                             |`number`\\n|  |`arraySize`  |--                                                                                       |`number`\\n\\n\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  triangles: {\\n    columns: {\\n      pointCoords: funcs.point({\\n        // `isUnique` - property that controls if generated values gonna be unique or not.\\n        isUnique: true,\\n\\n        // `minXValue` - lower bound of range for x coordinate.\\n        minXValue: -5,\\n\\n        // `maxXValue` - upper bound of range for x coordinate.\\n        maxXValue: 20,\\n\\n        // `minYValue` - lower bound of range for y coordinate.\\n        minYValue: 0,\\n\\n        // `maxYValue` - upper bound of range for y coordinate.\\n        maxYValue: 30,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n\\n### `line`\\n\\n<rem025 />\\nGenerates 2D lines within specified ranges for a, b and c parameters of line.\\n\\n```\\nline equation: a*x + b*y + c = 0\\n```\\n\\n|  | param       | default                                                                                 | type\\n|:-| :--------   | :--------                                                                               | :--------\\n|  |`isUnique`   |database column uniqueness                                                               |`boolean`\\n|  |`maxAValue`  |``` `10 * 1000` if isUnique equals false``` ``` `10 * count` if isUnique equals true```  |`number`\\n|  |`minAValue`  |`-maxAValue`                                                                             |`number`\\n|  |`maxBValue`  |``` `10 * 1000` if isUnique equals false``` ``` `10 * count` if isUnique equals true```  |`number`\\n|  |`minBValue`  |`-maxBValue`                                                                             |`number`\\n|  |`maxCValue`  |``` `10 * 1000` if isUnique equals false``` ``` `10 * count` if isUnique equals true```  |`number`\\n|  |`minCValue`  |`-maxCValue`                                                                             |`number`\\n|  |`arraySize`  |--                                                                                       |`number`\\n<rem025 />\\n\\n```ts \\nimport { seed } from \"drizzle-seed\";\\n\\nawait seed(db, schema, { count: 1000 }).refine((funcs) => ({\\n  lines: {\\n    columns: {\\n      lineParams: funcs.point({\\n        // `isUnique` - property that controls if generated values gonna be unique or not.\\n        isUnique: true,\\n\\n        // `minAValue` - lower bound of range for a parameter.\\n        minAValue: -5,\\n\\n        // `maxAValue` - upper bound of range for x parameter.\\n        maxAValue: 20,\\n\\n        // `minBValue` - lower bound of range for y parameter.\\n        minBValue: 0,\\n\\n        // `maxBValue` - upper bound of range for y parameter.\\n        maxBValue: 30,\\n\\n        // `minCValue` - lower bound of range for y parameter.\\n        minCValue: 0,\\n\\n        // `maxCValue` - upper bound of range for y parameter.\\n        maxCValue: 10,\\n\\n        // number of elements in each one-dimensional array. \\n        // (If specified, arrays will be generated.)\\n        arraySize: 3\\n      }),\\n    },\\n  },\\n}));\\n\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('seed-limitations.mdx'), name='seed-limitations.mdx', displayName='seed-limitations.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='// type limitations for third param', children=[]),\n",
       " DocItem(origPath=Path('seed-overview.mdx'), name='seed-overview.mdx', displayName='seed-overview.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \"@mdx/Npm.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\n\\n# Drizzle Seed\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': true, \\'SingleStore\\': false }} />\\n\\n<Callout type=\\'warning\\'>\\n  `drizzle-seed` can only be used with `drizzle-orm@0.36.4` or higher. Versions lower than this may work at runtime but could have type issues and identity column issues, as this patch was introduced in `drizzle-orm@0.36.4`\\n</Callout>\\n\\n`drizzle-seed` is a TypeScript library that helps you generate deterministic, yet realistic,\\nfake data to populate your database. By leveraging a seedable pseudorandom number generator (pRNG),\\nit ensures that the data you generate is consistent and reproducible across different runs.\\nThis is especially useful for testing, development, and debugging purposes.\\n\\n#### What is Deterministic Data Generation?\\n\\nDeterministic data generation means that the same input will always produce the same output.\\nIn the context of `drizzle-seed`, when you initialize the library with the same seed number,\\nit will generate the same sequence of fake data every time. This allows for predictable and repeatable data sets.\\n\\n#### Pseudorandom Number Generator (pRNG)\\n\\nA pseudorandom number generator is an algorithm that produces a sequence of numbers\\nthat approximates the properties of random numbers. However, because it\\'s based on an initial value\\ncalled a seed, you can control its randomness. By using the same seed, the pRNG will produce the\\nsame sequence of numbers, making your data generation process reproducible.\\n\\n#### Benefits of Using a pRNG:\\n\\n- Consistency: Ensures that your tests run on the same data every time.\\n- Debugging: Makes it easier to reproduce and fix bugs by providing a consistent data set.\\n- Collaboration: Team members can share seed numbers to work with the same data sets.\\n\\nWith drizzle-seed, you get the best of both worlds: the ability to generate realistic fake data and the control to reproduce it whenever needed.\\n\\n## Installation\\n\\n<Npm>drizzle-seed</Npm>\\n\\n## Basic Usage\\n\\nIn this example we will create 10 users with random names and ids\\n\\n```ts {12}\\nimport { pgTable, integer, text } from \"drizzle-orm/pg-core\";\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\n\\nconst users = pgTable(\"users\", {\\n  id: integer().primaryKey(),\\n  name: text().notNull(),\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n  await seed(db, { users });\\n}\\n\\nmain();\\n```\\n\\n## Options\\n\\n**`count`**\\n\\nBy default, the `seed` function will create 10 entities.\\nHowever, if you need more for your tests, you can specify this in the seed options object\\n\\n```ts\\nawait seed(db, schema, { count: 1000 });\\n```\\n\\n**`seed`**\\n\\nIf you need a seed to generate a different set of values for all subsequent runs, you can define a different number\\nin the `seed` option. Any new number will generate a unique set of values\\n\\n```ts\\nawait seed(db, schema, { seed: 12345 });\\n```\\n\\n## Reset database\\n\\nWith `drizzle-seed`, you can easily reset your database and seed it with new values, for example, in your test suites\\n\\n```ts\\n// path to a file with schema you want to reset\\nimport * as schema from \"./schema.ts\";\\nimport { reset } from \"drizzle-seed\";\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n  await reset(db, schema);\\n}\\n\\nmain();\\n```\\n\\nDifferent dialects will have different strategies for database resetting\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\nFor PostgreSQL, the `drizzle-seed` package will generate `TRUNCATE` statements with the `CASCADE` option to \\nensure that all tables are empty after running the reset function\\n\\n```sql\\nTRUNCATE tableName1, tableName2, ... CASCADE;\\n```\\n\\n</Tab>\\n<Tab>\\nFor MySQL, the `drizzle-seed` package will first disable `FOREIGN_KEY_CHECKS` to ensure the next step won\\'t fail, and then \\ngenerate `TRUNCATE` statements to empty the content of all tables\\n\\n```sql\\nSET FOREIGN_KEY_CHECKS = 0;\\nTRUNCATE tableName1;\\nTRUNCATE tableName2;\\n...\\nSET FOREIGN_KEY_CHECKS = 1;\\n```\\n\\n</Tab>\\n<Tab>\\nFor SQLite, the `drizzle-seed` package will first disable the `foreign_keys` pragma to ensure the next step won\\'t fail, \\nand then generate `DELETE FROM` statements to empty the content of all tables\\n\\n```sql\\nPRAGMA foreign_keys = OFF;\\nDELETE FROM tableName1;\\nDELETE FROM tableName2;\\n...\\nPRAGMA foreign_keys = ON;\\n```\\n\\n</Tab>\\n</Tabs>\\n\\n## Refinements\\n\\nIn case you need to change the behavior of the seed generator functions that `drizzle-seed` uses by default, you can specify your own implementation and even use your own list of values for the seeding process\\n\\n`.refine` is a callback that receives a list of all available generator functions from `drizzle-seed`. It should return an object with keys representing the tables you want to refine, defining their behavior as needed. \\nEach table can specify several properties to simplify seeding your database:\\n\\n<rem025 />\\n\\n- `columns`: Refine the default behavior of each column by specifying the required generator function.\\n- `count`: Specify the number of rows to insert into the database. By default, it\\'s 10. If a global count is defined in the `seed()` options, the count defined here will override it for this specific table.\\n- `with`: Define how many referenced entities to create for each parent table if you want to generate associated entities.\\n\\n<Callout title=\\'info\\'>\\nYou can also specify a weighted random distribution for the number of referenced values you want to create. For details on this API, you can refer to [Weighted Random docs](#weighted-random) docs section\\n</Callout>\\n\\n**API**\\n```ts\\nawait seed(db, schema).refine((f) => ({\\n  users: {\\n    columns: {},\\n    count: 10,\\n    with: {\\n        posts: 10\\n    }\\n  },\\n}));\\n```\\n\\nLet\\'s check a few examples with an explanation of what will happen:\\n\\n```ts filename=\\'schema.ts\\'\\nimport { pgTable, integer, text } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\"users\", {\\n  id: integer().primaryKey(),\\n  name: text().notNull(),\\n});\\n\\nexport const posts = pgTable(\"posts\", {\\n  id: integer().primaryKey(),\\n  description: text(),\\n  userId: integer().references(() => users.id),\\n});\\n```\\n\\n**Example 1**: Seed only the `users` table with 20 entities and with refined seed logic for the `name` column\\n```ts filename=\\'index.ts\\'\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \\'./schema.ts\\'\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { users: schema.users }).refine((f) => ({\\n    users: {\\n        columns: {\\n            name: f.fullName(),\\n        },\\n        count: 20\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n\\n**Example 2**: Seed the `users` table with 20 entities and add 10 `posts` for each `user` by seeding the `posts` table and creating a reference from `posts` to `users`\\n```ts filename=\\'index.ts\\'\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \\'./schema.ts\\'\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, schema).refine((f) => ({\\n    users: {\\n        count: 20,\\n        with: {\\n            posts: 10\\n        }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n\\n**Example 3**: Seed the `users` table with 5 entities and populate the database with 100 `posts` without connecting them to the `users` entities. Refine `id` generation for `users` so \\nthat it will give any int from `10000` to `20000` and remains unique, and refine `posts` to retrieve values from a self-defined array\\n```ts filename=\\'index.ts\\'\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \\'./schema.ts\\'\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, schema).refine((f) => ({\\n    users: {\\n        count: 5,\\n        columns: {\\n            id: f.int({\\n              minValue: 10000,\\n              maxValue: 20000,\\n              isUnique: true,\\n            }),\\n        }\\n    },\\n    posts: {\\n        count: 100,\\n        columns: {\\n            description: f.valuesFromArray({\\n            values: [\\n                \"The sun set behind the mountains, painting the sky in hues of orange and purple\", \\n                \"I can\\'t believe how good this homemade pizza turned out!\", \\n                \"Sometimes, all you need is a good book and a quiet corner.\", \\n                \"Who else thinks rainy days are perfect for binge-watching old movies?\", \\n                \"Tried a new hiking trail today and found the most amazing waterfall!\",\\n                // ...\\n            ],\\n          })\\n        }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n\\n<Callout type=\\'warning\\'>\\nThere are many more possibilities that we will define in these docs, but for now, you can explore a few sections in this documentation. Check the [Generators](/docs/seed-functions) section to get familiar with all the available generator functions you can use.\\n\\nA particularly great feature is the ability to use weighted randomization, both for generator values created for a column and for determining the number of related entities that can be generated by `drizzle-seed`.\\n\\nPlease check [Weighted Random docs](#weighted-random) for more info.\\n</Callout>\\n\\n\\n## Weighted Random\\n\\nThere may be cases where you need to use multiple datasets with a different priority that should be inserted into your database during the seed stage. For such cases, drizzle-seed provides an API called weighted random\\n\\nThe Drizzle Seed package has a few places where weighted random can be used:\\n\\n- Columns inside each table refinements\\n- The `with` property, determining the amount of related entities to be created\\n\\nLet\\'s check an example for both:\\n\\n```ts filename=\"schema.ts\"\\nimport { pgTable, integer, text, varchar, doublePrecision } from \"drizzle-orm/pg-core\";\\n\\nexport const orders = pgTable(\\n  \"orders\",\\n  {\\n    id: integer().primaryKey(),\\n    name: text().notNull(),\\n    quantityPerUnit: varchar().notNull(),\\n    unitPrice: doublePrecision().notNull(),\\n    unitsInStock: integer().notNull(),\\n    unitsOnOrder: integer().notNull(),\\n    reorderLevel: integer().notNull(),\\n    discontinued: integer().notNull(),\\n  }\\n);\\n\\nexport const details = pgTable(\\n  \"details\",\\n  {\\n    unitPrice: doublePrecision().notNull(),\\n    quantity: integer().notNull(),\\n    discount: doublePrecision().notNull(),\\n\\n    orderId: integer()\\n      .notNull()\\n      .references(() => orders.id, { onDelete: \"cascade\" }),\\n  }\\n);\\n```\\n\\n**Example 1**: Refine the `unitPrice` generation logic to generate `5000` random prices, with a 30% chance of prices between 10-100 and a 70% chance of prices between 100-300\\n\\n```ts filename=\"index.ts\"\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \\'./schema.ts\\'\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, schema).refine((f) => ({\\n    orders: {\\n       count: 5000,\\n       columns: {\\n           unitPrice: f.weightedRandom(\\n               [\\n                   {\\n                       weight: 0.3,\\n                       value: funcs.int({ minValue: 10, maxValue: 100 })\\n                   },\\n                   {\\n                       weight: 0.7,\\n                       value: funcs.number({ minValue: 100, maxValue: 300, precision: 100 })\\n                   }\\n               ]\\n           ),\\n       }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n\\n**Example 2**: For each order, generate 1 to 3 details with a 60% chance, 5 to 7 details with a 30% chance, and 8 to 10 details with a 10% chance\\n\\n```ts filename=\"index.ts\"\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \\'./schema.ts\\'\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, schema).refine((f) => ({\\n    orders: {\\n       with: {\\n           details:\\n               [\\n                   { weight: 0.6, count: [1, 2, 3] },\\n                   { weight: 0.3, count: [5, 6, 7] },\\n                   { weight: 0.1, count: [8, 9, 10] },\\n               ]\\n       }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n\\n## Complex example\\n\\n<CodeTabs items={[\"main.ts\", \"schema.ts\"]}>\\n<Section>\\n```ts\\nimport { seed } from \"drizzle-seed\";\\nimport * as schema from \"./schema.ts\";\\n\\nconst main = async () => {\\n    const titlesOfCourtesy = [\"Ms.\", \"Mrs.\", \"Dr.\"];\\n    const unitsOnOrders = [0, 10, 20, 30, 50, 60, 70, 80, 100];\\n    const reorderLevels = [0, 5, 10, 15, 20, 25, 30];\\n    const quantityPerUnit = [\\n        \"100 - 100 g pieces\",\\n        \"100 - 250 g bags\",\\n        \"10 - 200 g glasses\",\\n        \"10 - 4 oz boxes\",\\n        \"10 - 500 g pkgs.\",\\n        \"10 - 500 g pkgs.\"\\n    ];\\n    const discounts = [0.05, 0.15, 0.2, 0.25];\\n\\n    await seed(db, schema).refine((funcs) => ({\\n        customers: {\\n            count: 10000,\\n            columns: {\\n                companyName: funcs.companyName(),\\n                contactName: funcs.fullName(),\\n                contactTitle: funcs.jobTitle(),\\n                address: funcs.streetAddress(),\\n                city: funcs.city(),\\n                postalCode: funcs.postcode(),\\n                region: funcs.state(),\\n                country: funcs.country(),\\n                phone: funcs.phoneNumber({ template: \"(###) ###-####\" }),\\n                fax: funcs.phoneNumber({ template: \"(###) ###-####\" })\\n            }\\n        },\\n        employees: {\\n            count: 200,\\n            columns: {\\n                firstName: funcs.firstName(),\\n                lastName: funcs.lastName(),\\n                title: funcs.jobTitle(),\\n                titleOfCourtesy: funcs.valuesFromArray({ values: titlesOfCourtesy }),\\n                birthDate: funcs.date({ minDate: \"2010-12-31\", maxDate: \"2010-12-31\" }),\\n                hireDate: funcs.date({ minDate: \"2010-12-31\", maxDate: \"2024-08-26\" }),\\n                address: funcs.streetAddress(),\\n                city: funcs.city(),\\n                postalCode: funcs.postcode(),\\n                country: funcs.country(),\\n                homePhone: funcs.phoneNumber({ template: \"(###) ###-####\" }),\\n                extension: funcs.int({ minValue: 428, maxValue: 5467 }),\\n                notes: funcs.loremIpsum()\\n            }\\n        },\\n        orders: {\\n            count: 50000,\\n            columns: {\\n                shipVia: funcs.int({ minValue: 1, maxValue: 3 }),\\n                freight: funcs.number({ minValue: 0, maxValue: 1000, precision: 100 }),\\n                shipName: funcs.streetAddress(),\\n                shipCity: funcs.city(),\\n                shipRegion: funcs.state(),\\n                shipPostalCode: funcs.postcode(),\\n                shipCountry: funcs.country()\\n            },\\n            with: {\\n                details:\\n                    [\\n                        { weight: 0.6, count: [1, 2, 3, 4] },\\n                        { weight: 0.2, count: [5, 6, 7, 8, 9, 10] },\\n                        { weight: 0.15, count: [11, 12, 13, 14, 15, 16, 17] },\\n                        { weight: 0.05, count: [18, 19, 20, 21, 22, 23, 24, 25] },\\n                    ]\\n            }\\n        },\\n        suppliers: {\\n            count: 1000,\\n            columns: {\\n                companyName: funcs.companyName(),\\n                contactName: funcs.fullName(),\\n                contactTitle: funcs.jobTitle(),\\n                address: funcs.streetAddress(),\\n                city: funcs.city(),\\n                postalCode: funcs.postcode(),\\n                region: funcs.state(),\\n                country: funcs.country(),\\n                phone: funcs.phoneNumber({ template: \"(###) ###-####\" })\\n            }\\n        },\\n        products: {\\n            count: 5000,\\n            columns: {\\n                name: funcs.companyName(),\\n                quantityPerUnit: funcs.valuesFromArray({ values: quantityPerUnit }),\\n                unitPrice: funcs.weightedRandom(\\n                    [\\n                        {\\n                            weight: 0.5,\\n                            value: funcs.int({ minValue: 3, maxValue: 300 })\\n                        },\\n                        {\\n                            weight: 0.5,\\n                            value: funcs.number({ minValue: 3, maxValue: 300, precision: 100 })\\n                        }\\n                    ]\\n                ),\\n                unitsInStock: funcs.int({ minValue: 0, maxValue: 125 }),\\n                unitsOnOrder: funcs.valuesFromArray({ values: unitsOnOrders }),\\n                reorderLevel: funcs.valuesFromArray({ values: reorderLevels }),\\n                discontinued: funcs.int({ minValue: 0, maxValue: 1 })\\n            }\\n        },\\n        details: {\\n            columns: {\\n                unitPrice: funcs.number({ minValue: 10, maxValue: 130 }),\\n                quantity: funcs.int({ minValue: 1, maxValue: 130 }),\\n                discount: funcs.weightedRandom(\\n                    [\\n                        { weight: 0.5, value: funcs.valuesFromArray({ values: discounts }) },\\n                        { weight: 0.5, value: funcs.default({ defaultValue: 0 }) }\\n                    ]\\n                )\\n            }\\n        }\\n    }));\\n}\\n\\nmain();\\n\\n```\\n</Section>\\n<Section>\\n```ts\\nimport type { AnyPgColumn } from \"drizzle-orm/pg-core\";\\nimport { integer, numeric, pgTable, text, timestamp, varchar } from \"drizzle-orm/pg-core\";\\n\\nexport const customers = pgTable(\\'customer\\', {\\n\\tid: varchar({ length: 256 }).primaryKey(),\\n\\tcompanyName: text().notNull(),\\n\\tcontactName: text().notNull(),\\n\\tcontactTitle: text().notNull(),\\n\\taddress: text().notNull(),\\n\\tcity: text().notNull(),\\n\\tpostalCode: text(),\\n\\tregion: text(),\\n\\tcountry: text().notNull(),\\n\\tphone: text().notNull(),\\n\\tfax: text(),\\n});\\n\\nexport const employees = pgTable(\\n\\t\\'employee\\',\\n\\t{\\n\\t\\tid: integer().primaryKey(),\\n\\t\\tlastName: text().notNull(),\\n\\t\\tfirstName: text(),\\n\\t\\ttitle: text().notNull(),\\n\\t\\ttitleOfCourtesy: text().notNull(),\\n\\t\\tbirthDate: timestamp().notNull(),\\n\\t\\thireDate: timestamp().notNull(),\\n\\t\\taddress: text().notNull(),\\n\\t\\tcity: text().notNull(),\\n\\t\\tpostalCode: text().notNull(),\\n\\t\\tcountry: text().notNull(),\\n\\t\\thomePhone: text().notNull(),\\n\\t\\textension: integer().notNull(),\\n\\t\\tnotes: text().notNull(),\\n\\t\\treportsTo: integer().references((): AnyPgColumn => employees.id),\\n\\t\\tphotoPath: text(),\\n\\t},\\n);\\n\\nexport const orders = pgTable(\\'order\\', {\\n\\tid: integer().primaryKey(),\\n\\torderDate: timestamp().notNull(),\\n\\trequiredDate: timestamp().notNull(),\\n\\tshippedDate: timestamp(),\\n\\tshipVia: integer().notNull(),\\n\\tfreight: numeric().notNull(),\\n\\tshipName: text().notNull(),\\n\\tshipCity: text().notNull(),\\n\\tshipRegion: text(),\\n\\tshipPostalCode: text(),\\n\\tshipCountry: text().notNull(),\\n\\n\\tcustomerId: text().notNull().references(() => customers.id, { onDelete: \\'cascade\\' }),\\n\\n\\temployeeId: integer().notNull().references(() => employees.id, { onDelete: \\'cascade\\' }),\\n});\\n\\nexport const suppliers = pgTable(\\'supplier\\', {\\n\\tid: integer().primaryKey(),\\n\\tcompanyName: text().notNull(),\\n\\tcontactName: text().notNull(),\\n\\tcontactTitle: text().notNull(),\\n\\taddress: text().notNull(),\\n\\tcity: text().notNull(),\\n\\tregion: text(),\\n\\tpostalCode: text().notNull(),\\n\\tcountry: text().notNull(),\\n\\tphone: text().notNull(),\\n});\\n\\nexport const products = pgTable(\\'product\\', {\\n\\tid: integer().primaryKey(),\\n\\tname: text().notNull(),\\n\\tquantityPerUnit: text().notNull(),\\n\\tunitPrice: numeric().notNull(),\\n\\tunitsInStock: integer().notNull(),\\n\\tunitsOnOrder: integer().notNull(),\\n\\treorderLevel: integer().notNull(),\\n\\tdiscontinued: integer().notNull(),\\n\\n\\tsupplierId: integer().notNull().references(() => suppliers.id, { onDelete: \\'cascade\\' }),\\n});\\n\\nexport const details = pgTable(\\'order_detail\\', {\\n\\tunitPrice: numeric().notNull(),\\n\\tquantity: integer().notNull(),\\n\\tdiscount: numeric().notNull(),\\n\\n\\torderId: integer().notNull().references(() => orders.id, { onDelete: \\'cascade\\' }),\\n\\n\\tproductId: integer().notNull().references(() => products.id, { onDelete: \\'cascade\\' }),\\n});\\n\\n```\\n</Section>\\n</CodeTabs>\\n\\n## Limitations\\n\\n#### Types limitations for `with`\\n\\nDue to certain TypeScript limitations and the current API in Drizzle, it is not possible to properly infer references between tables, especially when circular dependencies between tables exist.\\n\\nThis means the `with` option will display all tables in the schema, and you will need to manually select the one that has a one-to-many relationship\\n\\n<Callout title=\\'warning\\'>\\nThe `with` option works for one-to-many relationships. For example, if you have one `user` and many `posts`, you can use users `with` posts, but you cannot use posts `with` users\\n</Callout>\\n\\n#### Type limitations for the third parameter in Drizzle tables:\\n\\nCurrently, we do not have type support for the third parameter in Drizzle tables. While it will work at runtime, it will not function correctly at the type level\\n', children=[]),\n",
       " DocItem(origPath=Path('seed-versioning.mdx'), name='seed-versioning.mdx', displayName='seed-versioning.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \"@mdx/Tab.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\nimport TableWrapper from \"@mdx/TableWrapper.astro\";\\n\\n# Versioning\\n\\n`drizzle-seed` uses versioning to manage outputs for static and dynamic data. To ensure true \\ndeterminism, ensure that values remain unchanged when using the same `seed` number. If changes are made to \\nstatic data sources or dynamic data generation logic, the version will be updated, allowing\\nyou to choose between sticking with the previous version or using the latest.\\n\\nYou can upgrade to the latest `drizzle-seed` version for new features, such as additional\\ngenerators, while maintaining deterministic outputs with a previous version if needed. This\\nis particularly useful when you need to rely on existing deterministic data while accessing new functionality.\\n\\n```ts\\nawait seed(db, schema, { version: \\'2\\' });\\n```\\n\\n## History\\n<TableWrapper>\\n|          api version  |   npm version    |     Changed generators                             |\\n|  :-------------- | :-------------- | :-------------                         |\\n|       `v1`            | `0.1.1`          |                                         |\\n|       `v2 (LTS) `       | `0.2.1`          |`string()`, `interval({ isUnique: true })` |\\n</TableWrapper>\\n\\n<Callout collapsed=\"How it works under the hood?\">\\n> This is not an actual API change; it is just an example of how we will proceed with `drizzle-seed` versioning.\\n\\nFor example, `lastName` generator was changed, and new version, `V2`, of this generator became available.\\n\\nLater, `firstName` generator was changed, making `V3` version of this generator available.\\n\\n|                  |       `V1`       |      `V2`       |   `V3(latest)`   |\\n| :--------------: | :--------------: | :-------------: | :--------------: |\\n| **LastNameGen**  | `LastNameGenV1`  | `LastNameGenV2` |                  |\\n| **FirstNameGen** | `FirstNameGenV1` |                 | `FirstNameGenV3` |\\n\\n\\n##### Use the `firstName` generator of version 3 and the `lastName` generator of version 2\\n```ts\\nawait seed(db, schema);\\n```\\n\\nIf you are not ready to use latest generator version right away, you can specify max version to use\\n\\n##### Use the `firstName` generator of version 1 and the `lastName` generator of version 2\\n```ts\\nawait seed(db, schema, { version: \\'2\\' });\\n```\\n\\n##### Use the `firstName` generator of version 1 and the `lastName` generator of version 1.\\n```ts\\nawait seed(db, schema, { version: \\'1\\' });\\n```\\n\\n</Callout>\\n\\n## Version 2\\n#### Unique `interval` generator was changed\\n\\n<Callout title=\\'Reason for upgrade\\'>\\nAn older version of the generator could produce intervals like `1 minute 60 seconds` and `2 minutes 0 seconds`, treating them as distinct intervals.\\nHowever, when the `1 minute 60 seconds` interval is inserted into a PostgreSQL database, it is automatically converted to `2 minutes 0 seconds`. As a result, attempting to insert the `2 minutes 0 seconds` interval into a unique column afterwards will cause an error\\n</Callout>\\n\\nYou will be affected, if your table includes a unique column of type `interval`:\\n<Tabs items={[\\'PostgreSQL\\']}>\\n<Tab>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { pgTable, interval } from \"drizzle-orm/pg-core\";\\nimport { seed } from \"drizzle-seed\";\\n\\nconst intervals = pgTable(\"intervals\", {\\n    interval: interval().unique()\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { intervals });\\n}\\n\\nmain();\\n```\\n</Tab>\\n</Tabs>\\n\\nYou will be affected, if you use the unique `interval` generator in your seeding script, as shown in the script below:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { pgTable, interval, char, varchar, text } from \"drizzle-orm/pg-core\";\\nimport { seed } from \"drizzle-seed\";\\n\\nconst intervals = pgTable(\"intervals\", {\\n    interval: interval().unique(),\\n    interval1: interval(),\\n    interval2: char({ length: 256 }).unique(),\\n    interval3: char({ length: 256 }),\\n    interval4: varchar().unique(),\\n    interval5: varchar(),\\n    interval6: text().unique(),\\n    interval7: text(),\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { intervals }).refine((f) => ({\\n    intervals: {\\n        columns: {\\n            interval: f.interval({ isUnique: true }),\\n            interval1: f.interval({ isUnique: true }),\\n            interval2: f.interval({ isUnique: true }),\\n            interval3: f.interval({ isUnique: true }),\\n            interval4: f.interval({ isUnique: true }),\\n            interval5: f.interval({ isUnique: true }),\\n            interval6: f.interval({ isUnique: true }),\\n            interval7: f.interval({ isUnique: true }),\\n        }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { binary, char, mysqlTable, text, varbinary, varchar } from \\'drizzle-orm/mysql-core\\';\\nimport { drizzle } from \\'drizzle-orm/mysql2\\';\\nimport { seed } from \"drizzle-seed\";\\n\\nconst intervals = mysqlTable(\\'intervals\\', {\\n\\tinterval1: char({ length: 255 }).unique(),\\n\\tinterval2: char({ length: 255 }),\\n\\tinterval3: varchar({ length: 255 }).unique(),\\n\\tinterval4: varchar({ length: 255 }),\\n\\tinterval5: binary({ length: 255 }).unique(),\\n\\tinterval6: binary({ length: 255 }),\\n\\tinterval7: varbinary({ length: 255 }).unique(),\\n\\tinterval8: varbinary({ length: 255 }),\\n\\tinterval9: text(),\\n});\\n\\nasync function main() {\\n\\tconst db = drizzle(process.env.DATABASE_URL!);\\n\\n\\tawait seed(db, { intervals }, { version: \\'2\\' }).refine((f) => ({\\n\\t\\tintervals: {\\n\\t\\t\\tcolumns: {\\n\\t\\t\\t\\tinterval: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval1: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval2: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval3: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval4: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval5: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval6: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval7: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval8: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval9: f.interval({ isUnique: true }),\\n\\t\\t\\t},\\n\\t\\t},\\n\\t}));\\n}\\n\\nmain();\\n\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { blob, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\nimport { seed } from \\'drizzle-seed\\';\\n\\nconst intervals = sqliteTable(\\'intervals\\', {\\n\\tinterval1: text().unique(),\\n\\tinterval2: text(),\\n\\tinterval3: blob().unique(),\\n\\tinterval4: blob(),\\n});\\n\\nasync function main() {\\n\\tconst db = drizzle(process.env.DATABASE_URL!);\\n\\n\\tawait seed(db, { intervals }).refine((f) => ({\\n\\t\\tintervals: {\\n\\t\\t\\tcolumns: {\\n\\t\\t\\t\\tinterval1: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval2: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval3: f.interval({ isUnique: true }),\\n\\t\\t\\t\\tinterval4: f.interval({ isUnique: true }),\\n\\t\\t\\t},\\n\\t\\t},\\n\\t}));\\n}\\n\\nmain();\\n\\n```\\n</Tab>\\n</Tabs>\\n\\n#### `string` generators were changed: both non-unique and unique\\n\\n<Callout title=\\'Reason to upgrade\\'>\\nAbility to generate a unique string based on the length of the text column (e.g., `varchar(20)`)\\n</Callout>\\n\\nYou will be affected, if your table includes a column of a text-like type with a maximum length parameter or a unique column of a text-like type:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { pgTable, char, varchar, text } from \"drizzle-orm/pg-core\";\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = pgTable(\"strings\", {\\n    string2: char({ length: 256 }).unique(),\\n    string3: char({ length: 256 }),\\n    string4: varchar().unique(),\\n    string5: varchar({ length: 256 }).unique(),\\n    string6: varchar({ length: 256 }),\\n    string7: text().unique(),\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { strings });\\n}\\n\\nmain();\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { binary, char, mysqlTable, varbinary, varchar } from \\'drizzle-orm/mysql-core\\';\\nimport { drizzle } from \\'drizzle-orm/mysql2\\';\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = mysqlTable(\\'strings\\', {\\n\\tstring1: char({ length: 255 }).unique(),\\n\\tstring2: char({ length: 255 }),\\n\\tstring3: varchar({ length: 255 }).unique(),\\n\\tstring4: varchar({ length: 255 }),\\n\\tstring5: binary({ length: 255 }).unique(),\\n\\tstring6: binary({ length: 255 }),\\n\\tstring7: varbinary({ length: 255 }).unique(),\\n\\tstring8: varbinary({ length: 255 }),\\n});\\n\\nasync function main() {\\n\\tconst db = drizzle(process.env.DATABASE_URL!);\\n\\n\\tawait seed(db, { strings });\\n}\\n\\nmain();\\n\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\nimport { blob, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = sqliteTable(\\'strings\\', {\\n\\tstring1: text().unique(),\\n\\tstring2: text({ length: 256 }),\\n\\tstring3: text({ length: 256 }).unique(),\\n\\tstring4: blob().unique(),\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { strings });\\n}\\n\\nmain();\\n```\\n</Tab>\\n</Tabs>\\n\\nYou will be affected, if you use the `string` generator in your seeding script, as shown in the script below:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n```ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { pgTable, char, varchar, text } from \"drizzle-orm/pg-core\";\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = pgTable(\"strings\", {\\n    string1: char({ length: 256 }).unique(),\\n    string2: char({ length: 256 }),\\n    string3: char({ length: 256 }),\\n    string4: varchar(),\\n    string5: varchar().unique(),\\n    string6: varchar({ length: 256 }).unique(),\\n    string7: varchar({ length: 256 }),\\n    string8: varchar({ length: 256 }),\\n    string9: text().unique(),\\n    string10: text(),\\n});\\n\\nasync function main() {\\n  const db = drizzle(process.env.DATABASE_URL!);\\n\\n  await seed(db, { strings }).refine((f) => ({\\n    strings: {\\n        columns: {\\n            string1: f.string({ isUnique: true }),\\n            string2: f.string(),\\n            string3: f.string({ isUnique: true }),\\n            string4: f.string({ isUnique: true }),\\n            string5: f.string({ isUnique: true }),\\n            string6: f.string({ isUnique: true }),\\n            string7: f.string(),\\n            string8: f.string({ isUnique: true }),\\n            string9: f.string({ isUnique: true }),\\n            string10: f.string({ isUnique: true }),\\n        }\\n    }\\n  }));\\n}\\n\\nmain();\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { binary, char, mysqlTable, text, varbinary, varchar } from \\'drizzle-orm/mysql-core\\';\\nimport { drizzle } from \\'drizzle-orm/mysql2\\';\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = mysqlTable(\\'strings\\', {\\n\\tstring1: char({ length: 255 }).unique(),\\n\\tstring2: char({ length: 255 }),\\n\\tstring3: char({ length: 255 }),\\n\\tstring4: varchar({ length: 255 }).unique(),\\n\\tstring5: varchar({ length: 255 }),\\n\\tstring6: varchar({ length: 255 }),\\n\\tstring7: binary({ length: 255 }).unique(),\\n\\tstring8: binary({ length: 255 }),\\n\\tstring9: binary({ length: 255 }),\\n\\tstring10: varbinary({ length: 255 }).unique(),\\n\\tstring11: varbinary({ length: 255 }),\\n\\tstring12: varbinary({ length: 255 }),\\n\\tstring13: text(),\\n});\\n\\nasync function main() {\\n\\tconst db = drizzle(process.env.DATABASE_URL!);\\n\\n\\tawait seed(db, { strings }).refine((f) => ({\\n\\t\\tstrings: {\\n\\t\\t\\tcolumns: {\\n\\t\\t\\t\\tstring1: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring2: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring3: f.string(),\\n\\t\\t\\t\\tstring4: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring5: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring6: f.string(),\\n\\t\\t\\t\\tstring7: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring8: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring9: f.string(),\\n\\t\\t\\t\\tstring10: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring11: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring12: f.string(),\\n\\t\\t\\t\\tstring13: f.string({ isUnique: true }),\\n\\t\\t\\t},\\n\\t\\t},\\n\\t}));\\n}\\n\\nmain();\\n```\\n</Tab>\\n<Tab>\\n```ts\\nimport { blob, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\nimport { drizzle } from \\'drizzle-orm/better-sqlite3\\';\\nimport { seed } from \"drizzle-seed\";\\n\\nconst strings = sqliteTable(\"strings\", {\\n    string1: text().unique(),\\n\\tstring2: text(),\\n\\tstring3: text({ length: 256 }).unique(),\\n\\tstring4: text({ length: 256 }),\\n\\tstring5: text({ length: 256 }),\\n\\tstring6: blob().unique(),\\n\\tstring7: blob(),\\n});\\n\\nasync function main() {\\n\\tconst db = drizzle(process.env.DATABASE_URL!);\\n\\n\\tawait seed(db, { strings }).refine((f) => ({\\n\\t\\tstrings: {\\n\\t\\t\\tcolumns: {\\n\\t\\t\\t\\tstring1: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring2: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring3: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring4: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring5: f.string(),\\n\\t\\t\\t\\tstring6: f.string({ isUnique: true }),\\n\\t\\t\\t\\tstring7: f.string({ isUnique: true }),\\n\\t\\t\\t},\\n\\t\\t},\\n\\t}));\\n}\\n\\nmain();\\n```\\n</Tab>\\n</Tabs>', children=[]),\n",
       " DocItem(origPath=Path('select.mdx'), name='select.mdx', displayName='select.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport $count from \\'@mdx/$count.mdx\\';\\n\\n# SQL Select\\nDrizzle provides you the most SQL-like way to fetch data from your database, while remaining type-safe and composable.\\nIt natively supports mostly every query feature and capability of every dialect,\\nand whatever it doesn\\'t support yet, can be added by the user with the powerful [`sql`](/docs/sql) operator.\\n\\nFor the following examples, let\\'s assume you have a `users` table defined like this:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\', \\'SingleStore\\']}>\\n<Tab>\\n```typescript\\nimport { pgTable, serial, text } from \\'drizzle-orm/pg-core\\';\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\'),\\n});\\n```\\n</Tab>\\n<Tab>\\n```typescript\\nimport { mysqlTable, serial, text, int } from \\'drizzle-orm/mysql-core\\';\\n\\nexport const users = mysqlTable(\\'users\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: int(\\'age\\'),\\n});\\n```\\n</Tab>\\n<Tab>\\n```typescript\\nimport { sqliteTable, integer, text } from \\'drizzle-orm/sqlite-core\\';\\n\\nexport const users = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\'),\\n});\\n```\\n</Tab>\\n<Tab>\\n```typescript\\nimport { singlestoreTable, serial, text, int } from \\'drizzle-orm/singlestore-core\\';\\n\\nexport const users = singlestoreTable(\\'users\\', {\\n  id: int(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: int(\\'age\\'),\\n});\\n```\\n</Tab>\\n</Tabs>\\n\\n### Basic select\\nSelect all rows from a table including all columns:\\n\\n<Section>\\n```typescript\\nconst result = await db.select().from(users);\\n/*\\n  {\\n    id: number;\\n    name: string;\\n    age: number | null;\\n  }[]\\n*/\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\";\\n```\\n</Section>\\n\\nNotice that the result type is inferred automatically based on the table definition, including columns nullability.\\n\\n<Callout type=\"info\">\\nDrizzle always explicitly lists columns in the `select` clause instead of using `select *`.<br />\\nThis is required internally to guarantee the fields order in the query result, and is also generally considered a good practice.\\n</Callout>\\n\\n### Partial select\\nIn some cases, you might want to select only a subset of columns from a table.\\nYou can do that by providing a selection object to the `.select()` method:\\n<Section>\\n```typescript copy\\nconst result = await db.select({\\n  field1: users.id,\\n  field2: users.name,\\n}).from(users);\\n\\nconst { field1, field2 } = result[0];\\n```\\n```sql\\nselect \"id\", \"name\" from \"users\";\\n```\\n</Section>\\n\\nLike in SQL, you can use arbitrary expressions as selection fields, not just table columns:\\n\\n<Section>\\n```typescript\\nconst result = await db.select({\\n  id: users.id,\\n  lowerName: sql<string>`lower(${users.name})`,\\n}).from(users);\\n```\\n```sql\\nselect \"id\", lower(\"name\") from \"users\";\\n```\\n</Section>\\n\\n<Callout type=\"warning\">\\nBy specifying `sql<string>`, you are telling Drizzle that the **expected** type of the field is `string`.<br />\\nIf you specify it incorrectly (e.g. use `sql<number>` for a field that will be returned as a string), the runtime value won\\'t match the expected type.\\nDrizzle cannot perform any type casts based on the provided type generic, because that information is not available at runtime.\\n\\nIf you need to apply runtime transformations to the returned value, you can use the [`.mapWith()`](/docs/sql#sqlmapwith) method.\\n</Callout>\\n\\n### Conditional select\\n\\nYou can have a dynamic selection object based on some condition:\\n\\n```typescript\\nasync function selectUsers(withName: boolean) {\\n  return db\\n    .select({\\n      id: users.id,\\n      ...(withName ? { name: users.name } : {}),\\n    })\\n    .from(users);\\n}\\n\\nconst users = await selectUsers(true);\\n```\\n\\n### Distinct select\\n\\nYou can use `.selectDistinct()` instead of `.select()` to retrieve only unique rows from a dataset:\\n<Section>\\n```ts\\nawait db.selectDistinct().from(users).orderBy(users.id, users.name);\\n\\nawait db.selectDistinct({ id: users.id }).from(users).orderBy(users.id);\\n```\\n```sql\\nselect distinct \"id\", \"name\" from \"users\" order by \"id\", \"name\";\\n\\nselect distinct \"id\" from \"users\" order by \"id\";\\n```\\n</Section>\\n\\nIn PostgreSQL, you can also use the `distinct on` clause to specify how the unique rows are determined:\\n<Callout type=\\'warning\\'>\\n`distinct on` clause is only supported in PostgreSQL.\\n</Callout>\\n<Section>\\n```ts\\nawait db.selectDistinctOn([users.id]).from(users).orderBy(users.id);\\nawait db.selectDistinctOn([users.name], { name: users.name }).from(users).orderBy(users.name);\\n```\\n```sql\\nselect distinct on (\"id\") \"id\", \"name\" from \"users\" order by \"id\";\\nselect distinct on (\"name\") \"name\" from \"users\" order by \"name\";\\n```\\n</Section>\\n\\n\\n\\n### Advanced select\\nPowered by TypeScript, Drizzle APIs let you build your select queries in a variety of flexible ways.\\n\\nSneak peek of advanced partial select, for more detailed advanced usage examples - see our [dedicated guide](/docs/guides/include-or-exclude-columns).\\n<CodeTabs items={[\"example 1\", \"example 2\", \"example 3\", \"example 4\"]}>\\n```ts\\nimport { getTableColumns, sql } from \\'drizzle-orm\\';\\n\\nawait db.select({\\n    ...getTableColumns(posts),\\n    titleLength: sql<number>`length(${posts.title})`,\\n  }).from(posts);\\n```\\n```ts\\nimport { getTableColumns } from \\'drizzle-orm\\';\\n\\nconst { content, ...rest } = getTableColumns(posts); // exclude \"content\" column\\nawait db.select({ ...rest }).from(posts); // select all other columns\\n```\\n```ts\\nawait db.query.posts.findMany({\\n  columns: {\\n    title: true,\\n  },\\n});\\n```\\n```ts\\nawait db.query.posts.findMany({\\n  columns: {\\n    content: false,\\n  },\\n});\\n```\\n</CodeTabs>\\n\\n## ---\\n\\n### Filters\\n\\nYou can filter the query results using the [filter operators](/docs/operators) in the `.where()` method:\\n\\n<Section>\\n```typescript copy\\nimport { eq, lt, gte, ne } from \\'drizzle-orm\\';\\n\\nawait db.select().from(users).where(eq(users.id, 42));\\nawait db.select().from(users).where(lt(users.id, 42));\\nawait db.select().from(users).where(gte(users.id, 42));\\nawait db.select().from(users).where(ne(users.id, 42));\\n...\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" < 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" >= 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" <> 42;\\n```\\n</Section>\\n\\nAll filter operators are implemented using the [`sql`](/docs/sql) function.\\nYou can use it yourself to write arbitrary SQL filters, or build your own operators.\\nFor inspiration, you can check how the operators provided by Drizzle are [implemented](https://github.com/drizzle-team/drizzle-orm/blob/main/drizzle-orm/src/sql/expressions/conditions.ts).\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\';\\n\\nfunction equals42(col: Column) {\\n  return sql`${col} = 42`;\\n}\\n\\nawait db.select().from(users).where(sql`${users.id} < 42`);\\nawait db.select().from(users).where(sql`${users.id} = 42`);\\nawait db.select().from(users).where(equals42(users.id));\\nawait db.select().from(users).where(sql`${users.id} >= 42`);\\nawait db.select().from(users).where(sql`${users.id} <> 42`);\\nawait db.select().from(users).where(sql`lower(${users.name}) = \\'aaron\\'`);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where \\'id\\' < 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \\'id\\' = 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \\'id\\' = 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \\'id\\' >= 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where \\'id\\' <> 42;\\nselect \"id\", \"name\", \"age\" from \"users\" where lower(\"name\") = \\'aaron\\';\\n```\\n</Section>\\n\\n<Callout type=\\'info\\'>\\nAll the values provided to filter operators and to the `sql` function are parameterized automatically.\\nFor example, this query:\\n```ts\\nawait db.select().from(users).where(eq(users.id, 42));\\n```\\nwill be translated to:\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = $1; -- params: [42]\\n```\\n</Callout>\\n\\nInverting condition with a `not` operator:\\n<Section>\\n```typescript copy\\nimport { eq, not, sql } from \\'drizzle-orm\\';\\n\\nawait db.select().from(users).where(not(eq(users.id, 42)));\\nawait db.select().from(users).where(sql`not ${users.id} = 42`);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\\n```\\n</Section>\\n\\n<Callout type=\"info\">\\nYou can safely alter schema, rename tables and columns\\nand it will be automatically reflected in your queries because of template interpolation,\\nas opposed to hardcoding column or table names when writing raw SQL.\\n</Callout>\\n\\n### Combining filters\\nYou can logically combine filter operators with `and()` and `or()` operators:\\n<Section>\\n```typescript copy\\nimport { eq, and, sql } from \\'drizzle-orm\\';\\n\\nawait db.select().from(users).where(\\n  and(\\n    eq(users.id, 42),\\n    eq(users.name, \\'Dan\\')\\n  )\\n);\\nawait db.select().from(users).where(sql`${users.id} = 42 and ${users.name} = \\'Dan\\'`);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = \\'Dan\\';\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = \\'Dan\\';\\n```\\n</Section>\\n\\n<Section>\\n```typescript copy\\nimport { eq, or, sql } from \\'drizzle-orm\\';\\n\\nawait db.select().from(users).where(\\n  or(\\n    eq(users.id, 42), \\n    eq(users.name, \\'Dan\\')\\n  )\\n);\\nawait db.select().from(users).where(sql`${users.id} = 42 or ${users.name} = \\'Dan\\'`);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = \\'Dan\\';\\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = \\'Dan\\';\\n```\\n</Section>\\n\\n### Advanced filters\\nIn combination with TypeScript, Drizzle APIs provide you powerful and flexible ways to combine filters in queries.\\n\\nSneak peek of conditional filtering, for more detailed advanced usage examples - see our [dedicated guide](/docs/guides/conditional-filters-in-query).\\n<CodeTabs items={[\"example 1\", \"example 2\"]}>\\n```ts\\nconst searchPosts = async (term?: string) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(term ? ilike(posts.title, term) : undefined);\\n};\\nawait searchPosts();\\nawait searchPosts(\\'AI\\');\\n```\\n```ts\\nconst searchPosts = async (filters: SQL[]) => {\\n  await db\\n    .select()\\n    .from(posts)\\n    .where(and(...filters));\\n};\\nconst filters: SQL[] = [];\\nfilters.push(ilike(posts.title, \\'AI\\'));\\nfilters.push(inArray(posts.category, [\\'Tech\\', \\'Art\\', \\'Science\\']));\\nfilters.push(gt(posts.views, 200));\\nawait searchPosts(filters);\\n```\\n</CodeTabs>\\n\\n## ---\\n\\n### Limit & offset\\nUse `.limit()` and `.offset()` to add `limit` and `offset` clauses to the query - for example, to implement pagination:\\n<Section>\\n```typescript\\nawait db.select().from(users).limit(10);\\nawait db.select().from(users).limit(10).offset(10);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" limit 10;\\nselect \"id\", \"name\", \"age\" from \"users\" limit 10 offset 10;\\n```\\n</Section>\\n\\n### Order By\\nUse `.orderBy()` to add `order by` clause to the query, sorting the results by the specified fields:\\n<Section>\\n```typescript\\nimport { asc, desc } from \\'drizzle-orm\\';\\n\\nawait db.select().from(users).orderBy(users.name);\\nawait db.select().from(users).orderBy(desc(users.name));\\n\\n// order by multiple fields\\nawait db.select().from(users).orderBy(users.name, users.name2);\\nawait db.select().from(users).orderBy(asc(users.name), desc(users.name2));\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\";\\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" desc;\\n\\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\", \"name2\";\\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" asc, \"name2\" desc;\\n```\\n</Section>\\n\\n### Advanced pagination\\nPowered by TypeScript, Drizzle APIs let you implement all possible SQL paginations and sorting approaches.\\n\\nSneak peek of advanced pagination, for more detailed advanced\\nusage examples - see our dedicated [limit offset pagination](/docs/guides/limit-offset-pagination)\\nand [cursor pagination](/docs/guides/cursor-based-pagination) guides.\\n\\n<CodeTabs items={[\"example 1\", \"example 2\", \"example 3\", \"example 4\"]}>\\n```ts\\nawait db\\n  .select()\\n  .from(users)\\n  .orderBy(asc(users.id)) // order by is mandatory\\n  .limit(4) // the number of rows to return\\n  .offset(4); // the number of rows to skip\\n```\\n```ts\\nconst getUsers = async (page = 1, pageSize = 3) => {\\n  await db.query.users.findMany({\\n    orderBy: (users, { asc }) => asc(users.id),\\n    limit: pageSize,\\n    offset: (page - 1) * pageSize,\\n  });\\n};\\nawait getUsers();\\n```\\n```ts\\nconst getUsers = async (page = 1, pageSize = 10) => {\\n   const sq = db\\n    .select({ id: users.id })\\n    .from(users)\\n    .orderBy(users.id)\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize)\\n    .as(\\'subquery\\');\\n   await db.select().from(users).innerJoin(sq, eq(users.id, sq.id)).orderBy(users.id);\\n};\\n```\\n```ts\\nconst nextUserPage = async (cursor?: number, pageSize = 3) => {\\n  await db\\n    .select()\\n    .from(users)\\n    .where(cursor ? gt(users.id, cursor) : undefined) // if cursor is provided, get rows after it\\n    .limit(pageSize) // the number of rows to return\\n    .orderBy(asc(users.id)); // ordering\\n};\\n// pass the cursor of the last row of the previous page (id)\\nawait nextUserPage(3);\\n```\\n</CodeTabs>\\n\\n## ---\\n\\n### WITH clause\\n\\n<Callout>\\n  Check how to use WITH statement with [insert](/docs/insert#with-insert-clause), [update](/docs/update#with-update-clause), [delete](/docs/delete#with-delete-clause)\\n</Callout>\\n\\nUsing the `with` clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\\n<Section>\\n```typescript copy\\nconst sq = db.$with(\\'sq\\').as(db.select().from(users).where(eq(users.id, 42)));\\n\\nconst result = await db.with(sq).select().from(sq);\\n```\\n```sql\\nwith sq as (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42)\\nselect \"id\", \"name\", \"age\" from sq;\\n```\\n</Section>\\n\\nYou can also provide `insert`, `update` and `delete` statements inside `with`\\n\\n<Section>\\n```typescript copy\\nconst sq = db.$with(\\'sq\\').as(\\n    db.insert(users).values({ name: \\'John\\' }).returning(),\\n);\\n\\nconst result = await db.with(sq).select().from(sq);\\n```\\n```sql\\nwith \"sq\" as (insert into \"users\" (\"id\", \"name\") values (default, \\'John\\') returning \"id\", \"name\") \\nselect \"id\", \"name\" from \"sq\"\\n```\\n</Section>\\n\\n<Section>\\n```typescript copy\\nconst sq = db.$with(\\'sq\\').as(\\n    db.update(users).set({ age: 25 }).where(eq(users.name, \\'John\\')).returning(),\\n);\\nconst result = await db.with(sq).select().from(sq);\\n```\\n```sql\\nwith \"sq\" as (update \"users\" set \"age\" = 25 where \"users\".\"name\" = \\'John\\' returning \"id\", \"name\", \"age\") \\nselect \"id\", \"name\", \"age\" from \"sq\"\\n```\\n</Section>\\n\\n<Section>\\n```typescript copy\\nconst sq = db.$with(\\'sq\\').as(\\n  db.delete(users).where(eq(users.name, \\'John\\')).returning(),\\n);\\n\\nconst result = await db.with(sq).select().from(sq);\\n```\\n```sql\\nwith \"sq\" as (delete from \"users\" where \"users\".\"name\" = $1 returning \"id\", \"name\", \"age\") \\nselect \"id\", \"name\", \"age\" from \"sq\"\\n```\\n</Section>\\n\\nTo select arbitrary SQL values as fields in a CTE and reference them in other CTEs or in the main query,\\nyou need to add aliases to them:\\n```typescript copy\\n\\nconst sq = db.$with(\\'sq\\').as(db.select({ \\n  name: sql<string>`upper(${users.name})`.as(\\'name\\'),\\n})\\n.from(users));\\n\\nconst result = await db.with(sq).select({ name: sq.name }).from(sq);\\n```\\nIf you don\\'t provide an alias, the field type will become `DrizzleTypeError` and you won\\'t be able to reference it in other queries.\\nIf you ignore the type error and still try to use the field,\\nyou will get a runtime error, since there\\'s no way to reference that field without an alias.\\n\\n### Select from subquery\\nJust like in SQL, you can embed queries into other queries by using the subquery API:\\n<Section>\\n```typescript copy\\nconst sq = db.select().from(users).where(eq(users.id, 42)).as(\\'sq\\');\\nconst result = await db.select().from(sq);\\n```\\n```sql\\nselect \"id\", \"name\", \"age\" from (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\";\\n```\\n</Section>\\n\\nSubqueries can be used in any place where a table can be used, for example in joins:\\n<Section>\\n```typescript copy\\nconst sq = db.select().from(users).where(eq(users.id, 42)).as(\\'sq\\');\\nconst result = await db.select().from(users).leftJoin(sq, eq(users.id, sq.id));\\n```\\n```sql\\nselect \"users\".\"id\", \"users\".\"name\", \"users\".\"age\", \"sq\".\"id\", \"sq\".\"name\", \"sq\".\"age\" from \"users\"\\n  left join (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\"\\n    on \"users\".\"id\" = \"sq\".\"id\";\\n```\\n</Section>\\n\\n## ---\\n\\n### Aggregations\\nWith Drizzle, you can do aggregations using functions like `sum`, `count`, `avg`, etc. by\\ngrouping and filtering with `.groupBy()` and `.having()` respectfully, same as you would do in raw SQL:\\n\\n<Section>\\n```typescript\\nimport { gt } from \\'drizzle-orm\\';\\n\\nawait db.select({\\n  age: users.age,\\n  count: sql<number>`cast(count(${users.id}) as int)`,\\n})\\n  .from(users)\\n  .groupBy(users.age);\\n\\nawait db.select({\\n  age: users.age,\\n  count: sql<number>`cast(count(${users.id}) as int)`,\\n})\\n  .from(users)\\n  .groupBy(users.age)\\n  .having(({ count }) => gt(count, 1));\\n```\\n```sql\\nselect \"age\", cast(count(\"id\") as int)\\n  from \"users\"\\n  group by \"age\";\\n\\nselect \"age\", cast(count(\"id\") as int)\\n  from \"users\"\\n  group by \"age\"\\n  having cast(count(\"id\") as int) > 1;\\n```\\n</Section>\\n\\n<Callout type=\"info\">\\n`cast(... as int)` is necessary because `count()` returns `bigint` in PostgreSQL and `decimal` in MySQL, which are treated as string values instead of numbers.\\nAlternatively, you can use [`.mapWith(Number)`](/docs/sql#sqlmapwith) to cast the value to a number at runtime.\\n\\nIf you need count aggregation - we recommend using our [`$count`](/docs/select#count) API\\n</Callout>\\n\\n### Aggregations helpers\\n\\nDrizzle has a set of wrapped `sql` functions, so you don\\'t need to write\\n`sql` templates for common cases in your app\\n\\n<Callout type=\"info\">\\n Remember, aggregation functions are often used with the GROUP BY clause of the SELECT statement. \\n So if you are selecting using aggregating functions and other columns in one query, \\n be sure to use the `.groupBy` clause\\n</Callout>\\n\\n\\n**count**\\n\\nReturns the number of values in `expression`.\\n<Section>\\n```ts\\nimport { count } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: count() }).from(users);\\nawait db.select({ value: count(users.id) }).from(users);\\n```\\n```sql\\nselect count(\"*\") from \"users\";\\nselect count(\"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`count(\\'*\\'))`.mapWith(Number) \\n}).from(users);\\n\\nawait db.select({ \\n  value: sql`count(${users.id})`.mapWith(Number) \\n}).from(users);\\n```\\n</Section>\\n\\n**countDistinct**\\n\\nReturns the number of non-duplicate values in `expression`.\\n<Section>\\n```ts\\nimport { countDistinct } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: countDistinct(users.id) }).from(users);\\n```\\n```sql\\nselect count(distinct \"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`count(${users.id})`.mapWith(Number) \\n}).from(users);\\n```\\n</Section>\\n\\n**avg**\\n\\nReturns the average (arithmetic mean) of all non-null values in `expression`.\\n<Section>\\n```ts\\nimport { avg } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: avg(users.id) }).from(users);\\n```\\n```sql\\nselect avg(\"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`avg(${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n</Section>\\n\\n**avgDistinct**\\n\\nReturns the average (arithmetic mean) of all non-null values in `expression`.\\n<Section>\\n```ts\\nimport { avgDistinct } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: avgDistinct(users.id) }).from(users);\\n```\\n```sql\\nselect avg(distinct \"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`avg(distinct ${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n</Section>\\n\\n**sum**\\n\\nReturns the sum of all non-null values in `expression`.\\n<Section>\\n```ts\\nimport { sum } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: sum(users.id) }).from(users);\\n```\\n```sql\\nselect sum(\"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`sum(${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n</Section>\\n\\n**sumDistinct**\\n\\nReturns the sum of all non-null and non-duplicate values in `expression`.\\n<Section>\\n```ts\\nimport { sumDistinct } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: sumDistinct(users.id) }).from(users);\\n```\\n```sql\\nselect sum(distinct \"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`sum(distinct ${users.id})`.mapWith(String) \\n}).from(users);\\n```\\n</Section>\\n\\n**max**\\n\\nReturns the maximum value in `expression`.\\n<Section>\\n```ts\\nimport { max } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: max(users.id) }).from(users);\\n```\\n```sql\\nselect max(\"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`max(${expression})`.mapWith(users.id) \\n}).from(users);\\n```\\n</Section>\\n\\n**min**\\n\\nReturns the minimum value in `expression`.\\n<Section>\\n```ts\\nimport { min } from \\'drizzle-orm\\'\\n\\nawait db.select({ value: min(users.id) }).from(users);\\n```\\n```sql\\nselect min(\"id\") from \"users\";\\n```\\n```ts\\n// It\\'s equivalent to writing\\nawait db.select({ \\n  value: sql`min(${users.id})`.mapWith(users.id) \\n}).from(users);\\n```\\n</Section>\\n\\nA more advanced example:\\n\\n```typescript copy\\nconst orders = sqliteTable(\\'order\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  orderDate: integer(\\'order_date\\', { mode: \\'timestamp\\' }).notNull(),\\n  requiredDate: integer(\\'required_date\\', { mode: \\'timestamp\\' }).notNull(),\\n  shippedDate: integer(\\'shipped_date\\', { mode: \\'timestamp\\' }),\\n  shipVia: integer(\\'ship_via\\').notNull(),\\n  freight: numeric(\\'freight\\').notNull(),\\n  shipName: text(\\'ship_name\\').notNull(),\\n  shipCity: text(\\'ship_city\\').notNull(),\\n  shipRegion: text(\\'ship_region\\'),\\n  shipPostalCode: text(\\'ship_postal_code\\'),\\n  shipCountry: text(\\'ship_country\\').notNull(),\\n  customerId: text(\\'customer_id\\').notNull(),\\n  employeeId: integer(\\'employee_id\\').notNull(),\\n});\\n\\nconst details = sqliteTable(\\'order_detail\\', {\\n  unitPrice: numeric(\\'unit_price\\').notNull(),\\n  quantity: integer(\\'quantity\\').notNull(),\\n  discount: numeric(\\'discount\\').notNull(),\\n  orderId: integer(\\'order_id\\').notNull(),\\n  productId: integer(\\'product_id\\').notNull(),\\n});\\n\\n\\ndb\\n  .select({\\n    id: orders.id,\\n    shippedDate: orders.shippedDate,\\n    shipName: orders.shipName,\\n    shipCity: orders.shipCity,\\n    shipCountry: orders.shipCountry,\\n    productsCount: sql<number>`cast(count(${details.productId}) as int)`,\\n    quantitySum: sql<number>`sum(${details.quantity})`,\\n    totalPrice: sql<number>`sum(${details.quantity} * ${details.unitPrice})`,\\n  })\\n  .from(orders)\\n  .leftJoin(details, eq(orders.id, details.orderId))\\n  .groupBy(orders.id)\\n  .orderBy(asc(orders.id))\\n  .all();\\n```\\n\\n### $count\\n<$count />\\n\\n## ---\\n\\n### Iterator\\n\\n<IsSupportedChipGroup chips={{ \\'MySQL\\': true, \\'PostgreSQL[WIP]\\': false, \\'SQLite[WIP]\\': false, \\'SingleStore[WIP]\\': false }} />\\n\\nIf you need to return a very large amount of rows from a query and you don\\'t want to load them all into memory, you can use `.iterator()` to convert the query into an async iterator:\\n\\n```ts copy\\nconst iterator = await db.select().from(users).iterator();\\n\\nfor await (const row of iterator) {\\n  console.log(row);\\n}\\n```\\n\\nIt also works with prepared statements:\\n\\n```ts copy\\nconst query = await db.select().from(users).prepare();\\nconst iterator = await query.iterator();\\n\\nfor await (const row of iterator) {\\n  console.log(row);\\n}\\n```\\n\\n## ---\\n\\n### Use Index\\n\\nThe `USE INDEX` hint suggests to the optimizer which indexes to consider when processing the query. The optimizer is not forced to use these indexes but will prioritize them if they are suitable.\\n\\n<IsSupportedChipGroup chips={{ \\'MySQL\\': true, \\'PostgreSQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n\\n```ts copy\\nexport const users = mysqlTable(\\'users\\', {\\n\\tid: int(\\'id\\').primaryKey(),\\n\\tname: varchar(\\'name\\', { length: 100 }).notNull(),\\n}, () => [usersTableNameIndex]);\\n\\nconst usersTableNameIndex = index(\\'users_name_index\\').on(users.name);\\n\\nawait db.select()\\n  .from(users, { useIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n\\nYou can also use this option on any join you want\\n\\n```ts\\nawait db.select()\\n  .from(users)\\n  .leftJoin(posts, eq(posts.userId, users.id), { useIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n\\n### Ignore Index\\n\\nThe `IGNORE INDEX` hint tells the optimizer to avoid using specific indexes for the query. MySQL will consider all other indexes (if any) or perform a full table scan if necessary.\\n\\n<IsSupportedChipGroup chips={{ \\'MySQL\\': true, \\'PostgreSQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n\\n```ts copy\\nexport const users = mysqlTable(\\'users\\', {\\n\\tid: int(\\'id\\').primaryKey(),\\n\\tname: varchar(\\'name\\', { length: 100 }).notNull(),\\n}, () => [usersTableNameIndex]);\\n\\nconst usersTableNameIndex = index(\\'users_name_index\\').on(users.name);\\n\\nawait db.select()\\n  .from(users, { ignoreIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n\\nYou can also use this option on any join you want\\n\\n```ts\\nawait db.select()\\n  .from(users)\\n  .leftJoin(posts, eq(posts.userId, users.id), { useIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n\\n\\n### Force Index\\n\\nThe `FORCE INDEX` hint forces the optimizer to use the specified index(es) for the query. If the specified index cannot be used, MySQL will not fall back to other indexes; it might resort to a full table scan instead.\\n\\n<IsSupportedChipGroup chips={{ \\'MySQL\\': true, \\'PostgreSQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n\\n```ts copy\\nexport const users = mysqlTable(\\'users\\', {\\n\\tid: int(\\'id\\').primaryKey(),\\n\\tname: varchar(\\'name\\', { length: 100 }).notNull(),\\n}, () => [usersTableNameIndex]);\\n\\nconst usersTableNameIndex = index(\\'users_name_index\\').on(users.name);\\n\\nawait db.select()\\n  .from(users, { forceIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n\\nYou can also use this option on any join you want\\n\\n```ts\\nawait db.select()\\n  .from(users)\\n  .leftJoin(posts, eq(posts.userId, users.id), { useIndex: usersTableNameIndex })\\n  .where(eq(users.name, \\'David\\'));\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('sequences.mdx'), name='sequences.mdx', displayName='sequences.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# Sequences\\n\\n<Callout type=\"info\">\\nTo use this feature you would need to have `drizzle-orm@0.32.0` or higher and `drizzle-kit@0.23.0` or higher\\n</Callout>\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': false, \\'MySQL\\': false, \\'SingleStore\\': false }} />\\n\\nSequences in PostgreSQL are special single-row tables created to generate unique identifiers, often used for auto-incrementing primary key values. They provide a thread-safe way to generate unique sequential values across multiple sessions.\\n<br/>\\n\\n**Key Features**\\n- Creation and Initialization: Use CREATE SEQUENCE to create a new sequence. Parameters such as increment value, start value, min/max values, and cache size can be specified.\\n\\n- Manipulation Functions\\n    - `nextval(\\'sequence_name\\')`: Advances the sequence and returns the next value.\\n    - `currval(\\'sequence_name\\')`: Returns the current value of the sequence for the current session.\\n    - `setval(\\'sequence_name\\', value)`: Sets the sequence\\'s current value.\\n    - `lastval()`: Returns the last value returned by nextval in the current session.\\n\\n- Ownership: Sequences can be linked to table columns using the OWNED BY clause. Dropping the table or column will automatically drop the associated sequence.\\n- Cycling: Sequences can be set to cycle when they reach their maximum or minimum value using the CYCLE option. The default is NO CYCLE.\\n- Caching: Sequence values can be preallocated using the CACHE option for improved performance.\\n<br/>\\n\\n**Limitations**\\n- Gaps: Sequences are not gapless. Aborted transactions or crashes can lead to gaps in the sequence values.\\n- Concurrency: While sequences provide unique values across sessions, the values may be out of order when considering all sessions.\\n- No Rollback: Changes to sequences are not rolled back if a transaction fails. This ensures unique values but can lead to gaps.\\n- Crash Recovery: Unlogged sequences or sequences modified before a crash might not be properly restored to their previous state.\\n<br/>\\n\\n**Practical Use**\\n- Default Behavior: By default, sequences increment by 1 and start at 1.\\n- Custom Behavior: Custom start points, increments, min/max values, and cycling can be specified.\\n- Associations: Commonly associated with table columns for auto-incrementing fields, making management of unique identifiers seamless.\\n<br/>\\n\\n**Usage Example**\\n```ts\\nimport { pgSchema, pgSequence } from \"drizzle-orm/pg-core\";\\n\\n// No params specified\\nexport const customSequence = pgSequence(\"name\");\\n\\n// Sequence with params\\nexport const customSequence = pgSequence(\"name\", {\\n      startWith: 100,\\n      maxValue: 10000,\\n      minValue: 100,\\n      cycle: true,\\n      cache: 10,\\n      increment: 2\\n});\\n\\n// Sequence in custom schema\\nexport const customSchema = pgSchema(\\'custom_schema\\');\\nexport const customSequence = customSchema.sequence(\"name\");\\n```', children=[]),\n",
       " DocItem(origPath=Path('set-operations.mdx'), name='set-operations.mdx', displayName='set-operations.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# Set Operations\\n\\nSQL set operations combine the results of multiple query blocks into a single result. \\nThe SQL standard defines the following three set operations: `UNION`, `INTERSECT`, `EXCEPT`, `UNION ALL`, `INTERSECT ALL`, `EXCEPT ALL`.\\n\\n### Union\\nCombine all results from two query blocks into a single result, omitting any duplicates.\\n\\nGet all names from customers and users tables without duplicates.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { union } from \\'drizzle-orm/pg-core\\'\\n    import { users, customers } from \\'./schema\\'\\n\\n    const allNamesForUserQuery = db.select({ name: users.name }).from(users);\\n\\n    const result = await union(\\n\\t\\tallNamesForUserQuery,\\n\\t\\tdb.select({ name: customers.name }).from(customers)\\n\\t).limit(10);\\n    ```\\n    ```sql\\n    (select \"name\" from \"sellers\")\\n    union\\n    (select \"name\" from \"customers\")\\n    limit $1\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { users, customers } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ name: users.name })\\n      .from(users)\\n      .union(db.select({ name: customers.name }).from(customers))\\n      .limit(10);\\n    ```\\n    ```sql\\n    (select \"name\" from \"sellers\")\\n    union\\n    (select \"name\" from \"customers\")\\n    limit $1\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable, text, varchar } from \"drizzle-orm/pg-core\";\\n\\n    const users = pgTable(\\'sellers\\', {\\n        id: integer(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        address: text(\\'address\\'),\\n    });\\n    \\n    const customers = pgTable(\\'customers\\', {\\n        id: integer(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        city: text(\\'city\\'),\\n        email: varchar(\\'email\\', { length: 256 }).notNull()\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { union } from \\'drizzle-orm/mysql-core\\'\\n    import { users, customers } from \\'./schema\\'\\n\\n    const allNamesForUserQuery = db.select({ name: users.name }).from(users);\\n\\n    const result = await union(\\n\\t\\tallNamesForUserQuery,\\n\\t\\tdb.select({ name: customers.name }).from(customers)\\n\\t).limit(10);\\n    ```\\n    ```sql\\n    (select `name` from `sellers`)\\n    union\\n    (select `name` from `customers`)\\n    limit ?\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { users, customers } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ name: users.name })\\n      .from(users)\\n      .union(db.select({ name: customers.name }).from(customers))\\n      .limit(10);\\n    ```\\n    ```sql\\n    (select `name` from `sellers`)\\n    union\\n    (select `name` from `customers`)\\n    limit ?\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, text, varchar } from \"drizzle-orm/mysql-core\";\\n\\n    const users = mysqlTable(\\'sellers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        address: text(\\'address\\'),\\n    });\\n    \\n    const customers = mysqlTable(\\'customers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        city: text(\\'city\\'),\\n        email: varchar(\\'email\\', { length: 256 }).notNull()\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { union } from \\'drizzle-orm/sqlite-core\\'\\n    import { users, customers } from \\'./schema\\'\\n\\n    const allNamesForUserQuery = db.select({ name: users.name }).from(users);\\n\\n    const result = await union(\\n\\t\\tallNamesForUserQuery,\\n\\t\\tdb.select({ name: customers.name }).from(customers)\\n\\t).limit(10);\\n    ```\\n    ```sql\\n    (select \"name\" from \"sellers\")\\n    union \\n    (select \"name\" from \"customers\")\\n    limit ?\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { users, customers } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ name: users.name })\\n      .from(users)\\n      .union(db.select({ name: customers.name }).from(customers))\\n      .limit(10);\\n    ```\\n    ```sql\\n    select \"name\" from \"sellers\" union select \"name\" from \"customers\" limit ?\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\n    const users = sqliteTable(\\'sellers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: text(\\'name\\').notNull(),\\n        address: text(\\'address\\'),\\n    });\\n    \\n    const customers = sqliteTable(\\'customers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: text(\\'name\\').notNull(),\\n        city: text(\\'city\\'),\\n        email: text(\\'email\\').notNull()\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { union } from \\'drizzle-orm/singlestore-core\\'\\n    import { users, customers } from \\'./schema\\'\\n\\n    const allNamesForUserQuery = db.select({ name: users.name }).from(users);\\n\\n    const result = await union(\\n\\t\\tallNamesForUserQuery,\\n\\t\\tdb.select({ name: customers.name }).from(customers)\\n\\t).limit(10);\\n    ```\\n    ```sql\\n    (select `name` from `sellers`)\\n    union\\n    (select `name` from `customers`)\\n    limit ?\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { users, customers } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ name: users.name })\\n      .from(users)\\n      .union(db.select({ name: customers.name }).from(customers))\\n      .limit(10);\\n    ```\\n    ```sql\\n    (select `name` from `sellers`)\\n    union\\n    (select `name` from `customers`)\\n    limit ?\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, text, varchar } from \"drizzle-orm/singlestore-core\";\\n\\n    const users = mysqlTable(\\'sellers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        address: text(\\'address\\'),\\n    });\\n    \\n    const customers = mysqlTable(\\'customers\\', {\\n        id: int(\\'id\\').primaryKey(),\\n        name: varchar(\\'name\\', { length: 256 }).notNull(),\\n        city: text(\\'city\\'),\\n        email: varchar(\\'email\\', { length: 256 }).notNull()\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n</Tabs>\\n\\n### Union All\\nCombine all results from two query blocks into a single result, with duplicates.\\n\\nLet\\'s consider a scenario where you have two tables, one representing online sales and the other \\nrepresenting in-store sales. In this case, you want to combine the data from both tables into a\\nsingle result set. Since there might be duplicate transactions, \\nyou want to keep all the records and not eliminate duplicates.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { unionAll } from \\'drizzle-orm/pg-core\\'\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const onlineTransactions = db.select({ transaction: onlineSales.transactionId }).from(onlineSales);\\n    const inStoreTransactions = db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales);\\n\\n    const result = await unionAll(onlineTransactions, inStoreTransactions);\\n    ```\\n    ```sql\\n    select \"transaction_id\" from \"online_sales\"\\n    union all\\n    select \"transaction_id\" from \"in_store_sales\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ transaction: onlineSales.transactionId })\\n      .from(onlineSales)\\n      .unionAll(\\n        db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales)\\n      );\\n    ```\\n    ```sql\\n    select \"transaction_id\" from \"online_sales\"\\n    union all\\n    select \"transaction_id\" from \"in_store_sales\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable, text, timestamp, varchar } from \"drizzle-orm/pg-core\";\\n\\n    const onlineSales = pgTable(\\'online_sales\\', {\\n        transactionId: integer(\\'transaction_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').unique(),\\n        quantitySold: integer(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    \\n    const inStoreSales = pgTable(\\'in_store_sales\\', {\\n        transactionId: integer(\\'transaction_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').unique(),\\n        quantitySold: integer(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n<Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { unionAll } from \\'drizzle-orm/mysql-core\\'\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const onlineTransactions = db.select({ transaction: onlineSales.transactionId }).from(onlineSales);\\n    const inStoreTransactions = db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales);\\n\\n    const result = await unionAll(onlineTransactions, inStoreTransactions);\\n    ```\\n    ```sql\\n    select `transaction_id` from `online_sales`\\n    union all\\n    select `transaction_id` from `in_store_sales`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ transaction: onlineSales.transactionId })\\n      .from(onlineSales)\\n      .unionAll(\\n        db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales)\\n      );\\n    ```\\n    ```sql\\n    (select `transaction_id` from `online_sales`)\\n    union all \\n    (select `transaction_id` from `in_store_sales`)\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, text, timestamp, varchar } from \"drizzle-orm/mysql-core\";\\n\\n    const onlineSales = mysqlTable(\\'online_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    \\n    const inStoreSales = mysqlTable(\\'in_store_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { unionAll } from \\'drizzle-orm/sqlite-core\\'\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const onlineTransactions = db.select({ transaction: onlineSales.transactionId }).from(onlineSales);\\n    const inStoreTransactions = db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales);\\n\\n    const result = await unionAll(onlineTransactions, inStoreTransactions);\\n    ```\\n    ```sql\\n    select \"transaction_id\" from \"online_sales\" \\n    union all \\n    select \"transaction_id\" from \"in_store_sales\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ transaction: onlineSales.transactionId })\\n      .from(onlineSales)\\n      .unionAll(\\n        db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales)\\n      );\\n    ```\\n    ```sql\\n    select \"transaction_id\" from \"online_sales\" \\n    union all \\n    select \"transaction_id\" from \"in_store_sales\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n    const onlineSales = sqliteTable(\\'online_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: int(\\'sale_date\\', { mode: \\'timestamp\\' }),\\n    });\\n    \\n    const inStoreSales = sqliteTable(\\'in_store_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: int(\\'sale_date\\', { mode: \\'timestamp\\' }),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <Callout type=\\'warning\\'>\\n  UNION ALL with ORDER BY behavior inconsistent with MySQL: SingleStore parses UNION ALL followed by ORDER BY commands differently from MySQL. In SingleStore, the following query is valid. In MySQL, it is invalid.\\n  </Callout>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { unionAll } from \\'drizzle-orm/singlestore-core\\'\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const onlineTransactions = db.select({ transaction: onlineSales.transactionId }).from(onlineSales);\\n    const inStoreTransactions = db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales);\\n\\n    const result = await unionAll(onlineTransactions, inStoreTransactions);\\n    ```\\n    ```sql\\n    select `transaction_id` from `online_sales`\\n    union all\\n    select `transaction_id` from `in_store_sales`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { onlineSales, inStoreSales } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ transaction: onlineSales.transactionId })\\n      .from(onlineSales)\\n      .unionAll(\\n        db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales)\\n      );\\n    ```\\n    ```sql\\n    (select `transaction_id` from `online_sales`)\\n    union all \\n    (select `transaction_id` from `in_store_sales`)\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, text, timestamp, varchar } from \"drizzle-orm/singlestore-core\";\\n\\n    const onlineSales = mysqlTable(\\'online_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    \\n    const inStoreSales = mysqlTable(\\'in_store_sales\\', {\\n        transactionId: int(\\'transaction_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').unique(),\\n        quantitySold: int(\\'quantity_sold\\'),\\n        saleDate: timestamp(\\'sale_date\\', { mode: \\'date\\' }),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n</Tabs>\\n\\n### Intersect\\nCombine only those rows which the results of two query blocks have in common, omitting any duplicates.\\n\\nSuppose you have two tables that store information about students\\' course enrollments. \\nYou want to find the courses that are common between two different departments,\\nbut you want distinct course names, and you\\'re not interested in counting multiple \\nenrollments of the same course by the same student.\\n\\nIn this scenario, you want to find courses that are common between the two departments but don\\'t want \\nto count the same course multiple times even if multiple students from the same department are enrolled in it.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersect } from \\'drizzle-orm/pg-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.courseName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.courseName }).from(depB);\\n\\n    const result = await intersect(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select \"course_name\" from \"department_a_courses\"\\n    intersect\\n    select \"course_name\" from \"department_b_courses\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```typescript copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ courseName: depA.courseName })\\n      .from(depA)\\n      .intersect(db.select({ courseName: depB.courseName }).from(depB));\\n    ```\\n    ```sql\\n    select \"course_name\" from \"department_a_courses\"\\n    intersect\\n    select \"course_name\" from \"department_b_courses\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable, varchar } from \"drizzle-orm/pg-core\";\\n\\n    const depA = pgTable(\\'department_a_courses\\', {\\n        studentId: integer(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\').notNull(),\\n    });\\n    \\n    const depB = pgTable(\\'department_b_courses\\', {\\n        studentId: integer(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n    <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersect } from \\'drizzle-orm/mysql-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.courseName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.courseName }).from(depB);\\n\\n    const result = await intersect(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    intersect\\n    select `projects_name` from `department_b_projects`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```typescript copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ courseName: depA.courseName })\\n      .from(depA)\\n      .intersect(db.select({ courseName: depB.courseName }).from(depB));\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    intersect\\n    select `projects_name` from `department_b_projects`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, varchar } from \"drizzle-orm/mysql-core\";\\n\\n    const depA = mysqlTable(\\'department_a_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\', { length: 256 }).notNull(),\\n    });\\n    \\n    const depB = pgTable(\\'department_b_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\', { length: 256 }).notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n      <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersect } from \\'drizzle-orm/sqlite-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.courseName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.courseName }).from(depB);\\n\\n    const result = await intersect(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select \"course_name\" from \"department_a_courses\"\\n    intersect\\n    select \"course_name\" from \"department_b_courses\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```typescript copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ courseName: depA.courseName })\\n      .from(depA)\\n      .intersect(db.select({ courseName: depB.courseName }).from(depB));\\n    ```\\n    ```sql\\n    select \"course_name\" from \"department_a_courses\" \\n    intersect \\n    select \"course_name\" from \"department_b_courses\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\n    const depA = sqliteTable(\\'department_a_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: text(\\'course_name\\').notNull(),\\n    });\\n    \\n    const depB = sqliteTable(\\'department_b_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: text(\\'course_name\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n    <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersect } from \\'drizzle-orm/singlestore-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.courseName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.courseName }).from(depB);\\n\\n    const result = await intersect(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    intersect\\n    select `projects_name` from `department_b_projects`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```typescript copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n      .select({ courseName: depA.courseName })\\n      .from(depA)\\n      .intersect(db.select({ courseName: depB.courseName }).from(depB));\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    intersect\\n    select `projects_name` from `department_b_projects`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable, varchar } from \"drizzle-orm/singlestore-core\";\\n\\n    const depA = mysqlTable(\\'department_a_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\', { length: 256 }).notNull(),\\n    });\\n    \\n    const depB = pgTable(\\'department_b_courses\\', {\\n        studentId: int(\\'student_id\\'),\\n        courseName: varchar(\\'course_name\\', { length: 256 }).notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n</Tabs>\\n\\n### Intersect All\\nCombine only those rows which the results of two query blocks have in common, with duplicates.\\n\\nLet\\'s consider a scenario where you have two tables containing data about customer orders, and you want \\nto identify products that are ordered by both regular customers and VIP customers. In this case, \\nyou want to keep track of the quantity of each product, even if it\\'s ordered multiple times by \\ndifferent customers.\\n\\nIn this scenario, you want to find products that are ordered by both regular customers and VIP customers, \\nbut you want to retain the quantity information, even if the same product is ordered multiple \\ntimes by different customers.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersectAll } from \\'drizzle-orm/pg-core\\'\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const regularOrders = db.select({ \\n        productId: regularCustomerOrders.productId,\\n        quantityOrdered: regularCustomerOrders.quantityOrdered }\\n    ).from(regularCustomerOrders);\\n\\n    const vipOrders = db.select({ \\n        productId: vipCustomerOrders.productId,\\n        quantityOrdered: vipCustomerOrders.quantityOrdered }\\n    ).from(vipCustomerOrders);\\n\\n    const result = await intersectAll(regularOrders, vipOrders);\\n    ```\\n    ```sql\\n    select \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\\n    intersect all\\n    select \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\\n    ```\\n\\t</CodeTab>\\n    ```ts copy\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({\\n          productId: regularCustomerOrders.productId,\\n          quantityOrdered: regularCustomerOrders.quantityOrdered,\\n        })\\n        .from(regularCustomerOrders)\\n        .intersectAll(\\n          db\\n            .select({\\n              productId: vipCustomerOrders.productId,\\n              quantityOrdered: vipCustomerOrders.quantityOrdered,\\n            })\\n            .from(vipCustomerOrders)\\n        );\\n    ```\\n    ```sql\\n    select \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\\n    intersect all\\n    select \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\\n    ```\\n    <CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    const regularCustomerOrders = pgTable(\\'regular_customer_orders\\', {\\n        customerId: integer(\\'customer_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').notNull(),\\n        quantityOrdered: integer(\\'quantity_ordered\\').notNull(),\\n    });\\n    \\n    const vipCustomerOrders = pgTable(\\'vip_customer_orders\\', {\\n        customerId: integer(\\'customer_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').notNull(),\\n        quantityOrdered: integer(\\'quantity_ordered\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n    <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { intersectAll } from \\'drizzle-orm/mysql-core\\'\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const regularOrders = db.select({ \\n        productId: regularCustomerOrders.productId,\\n        quantityOrdered: regularCustomerOrders.quantityOrdered }\\n    ).from(regularCustomerOrders);\\n\\n    const vipOrders = db.select({ \\n        productId: vipCustomerOrders.productId,\\n        quantityOrdered: vipCustomerOrders.quantityOrdered }\\n    ).from(vipCustomerOrders);\\n\\n    const result = await intersectAll(regularOrders, vipOrders);\\n    ```\\n    ```sql\\n    select `product_id`, `quantity_ordered` from `regular_customer_orders`\\n    intersect all\\n    select `product_id`, `quantity_ordered` from `vip_customer_orders`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({\\n          productId: regularCustomerOrders.productId,\\n          quantityOrdered: regularCustomerOrders.quantityOrdered,\\n        })\\n        .from(regularCustomerOrders)\\n        .intersectAll(\\n          db\\n            .select({\\n              productId: vipCustomerOrders.productId,\\n              quantityOrdered: vipCustomerOrders.quantityOrdered,\\n            })\\n            .from(vipCustomerOrders)\\n        );\\n    ```\\n    ```sql\\n    select `product_id`, `quantity_ordered` from `regular_customer_orders`\\n    intersect all \\n    select `product_id`, `quantity_ordered` from `vip_customer_orders`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, mysqlTable } from \"drizzle-orm/mysql-core\";\\n\\n    const regularCustomerOrders = mysqlTable(\\'regular_customer_orders\\', {\\n        customerId: int(\\'customer_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').notNull(),\\n        quantityOrdered: int(\\'quantity_ordered\\').notNull(),\\n    });\\n    \\n    const vipCustomerOrders = mysqlTable(\\'vip_customer_orders\\', {\\n        customerId: int(\\'customer_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').notNull(),\\n        quantityOrdered: int(\\'quantity_ordered\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab>\\n  <Tab>\\n  Not supported by SingleStore\\n  </Tab> \\n</Tabs>\\n\\n### Except\\nFor two query blocks A and B, return all results from A which are not also present in B, omitting any duplicates.\\n\\nSuppose you have two tables that store information about employees\\' project assignments. \\nYou want to find the projects that are unique to one department \\nand not shared with another department, excluding duplicates.\\n\\nIn this scenario, you want to identify the projects that are exclusive to one department and\\nnot shared with the other department. You don\\'t want to count the same project \\nmultiple times, even if multiple employees from the same department are assigned to it.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { except } from \\'drizzle-orm/pg-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.projectsName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.projectsName }).from(depB);\\n\\n    const result = await except(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select \"projects_name\" from \"department_a_projects\"\\n    except\\n    select \"projects_name\" from \"department_b_projects\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({ courseName: depA.projectsName })\\n        .from(depA)\\n        .except(db.select({ courseName: depB.projectsName }).from(depB));\\n    ```\\n    ```sql\\n    select \"projects_name\" from \"department_a_projects\"\\n    except\\n    select \"projects_name\" from \"department_b_projects\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable, varchar } from \"drizzle-orm/pg-core\";\\n\\n    const depA = pgTable(\\'department_a_projects\\', {\\n        employeeId: integer(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\').notNull(),\\n    });\\n    \\n    const depB = pgTable(\\'department_b_projects\\', {\\n        employeeId: integer(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { except } from \\'drizzle-orm/mysql-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.projectsName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.projectsName }).from(depB);\\n\\n    const result = await except(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    except\\n    select `projects_name` from `department_b_projects`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({ courseName: depA.projectsName })\\n        .from(depA)\\n        .except(db.select({ courseName: depB.projectsName }).from(depB));\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    except\\n    select `projects_name` from `department_b_projects`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript \\n    import { int, mysqlTable, varchar } from \"drizzle-orm/mysql-core\";\\n\\n    const depA = mysqlTable(\\'department_a_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\', { length: 256 }).notNull(),\\n    });\\n    \\n    const depB = mysqlTable(\\'department_b_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\', { length: 256 }).notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { except } from \\'drizzle-orm/sqlite-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.projectsName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.projectsName }).from(depB);\\n\\n    const result = await except(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select \"projects_name\" from \"department_a_projects\" \\n    except \\n    select \"projects_name\" from \"department_b_projects\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({ courseName: depA.projectsName })\\n        .from(depA)\\n        .except(db.select({ courseName: depB.projectsName }).from(depB));\\n    ```\\n    ```sql\\n    select \"projects_name\" from \"department_a_projects\" \\n    except \\n    select \"projects_name\" from \"department_b_projects\"\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript copy\\n    import { int, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\n    const depA = sqliteTable(\\'department_a_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: text(\\'projects_name\\').notNull(),\\n    });\\n    \\n    const depB = sqliteTable(\\'department_b_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: text(\\'projects_name\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { except } from \\'drizzle-orm/singlestore-core\\'\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const departmentACourses = db.select({ courseName: depA.projectsName }).from(depA);\\n    const departmentBCourses = db.select({ courseName: depB.projectsName }).from(depB);\\n\\n    const result = await except(departmentACourses, departmentBCourses);\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    except\\n    select `projects_name` from `department_b_projects`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { depA, depB } from \\'./schema\\'\\n\\n    const result = await db\\n        .select({ courseName: depA.projectsName })\\n        .from(depA)\\n        .except(db.select({ courseName: depB.projectsName }).from(depB));\\n    ```\\n    ```sql\\n    select `projects_name` from `department_a_projects`\\n    except\\n    select `projects_name` from `department_b_projects`\\n    ```\\n    </CodeTab>\\n    <CodeTab>\\n\\t```typescript \\n    import { int, mysqlTable, varchar } from \"drizzle-orm/singlestore-core\";\\n\\n    const depA = mysqlTable(\\'department_a_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\', { length: 256 }).notNull(),\\n    });\\n    \\n    const depB = mysqlTable(\\'department_b_projects\\', {\\n        employeeId: int(\\'employee_id\\'),\\n        projectsName: varchar(\\'projects_name\\', { length: 256 }).notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n</Tabs>\\n\\n### Except All\\nFor two query blocks A and B, return all results from A which are not also present in B, with duplicates.\\n\\nLet\\'s consider a scenario where you have two tables containing data about customer orders, and you want to \\nidentify products that are exclusively ordered by regular customers (without VIP customers). \\nIn this case, you want to keep track of the quantity of each product, even if it\\'s ordered multiple times by different regular customers.\\n\\nIn this scenario, you want to find products that are exclusively ordered by regular customers and not \\nordered by VIP customers. You want to retain the quantity information, even if the same product is ordered multiple times by different regular customers.\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SingleStore\"]}>\\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { exceptAll } from \\'drizzle-orm/pg-core\\'\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const regularOrders = db.select({ \\n        productId: regularCustomerOrders.productId,\\n        quantityOrdered: regularCustomerOrders.quantityOrdered }\\n    ).from(regularCustomerOrders);\\n\\n    const vipOrders = db.select({ \\n        productId: vipCustomerOrders.productId,\\n        quantityOrdered: vipCustomerOrders.quantityOrdered }\\n    ).from(vipCustomerOrders);\\n\\n    const result = await exceptAll(regularOrders, vipOrders);\\n    ```\\n    ```sql\\n    select \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\\n    except all\\n    select \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n \\n    const result = await db\\n        .select({\\n          productId: regularCustomerOrders.productId,\\n          quantityOrdered: regularCustomerOrders.quantityOrdered,\\n        })\\n        .from(regularCustomerOrders)\\n        .exceptAll(\\n          db\\n            .select({\\n              productId: vipCustomerOrders.productId,\\n              quantityOrdered: vipCustomerOrders.quantityOrdered,\\n            })\\n            .from(vipCustomerOrders)\\n        );\\n    ```\\n    ```sql\\n    select \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\\n    except all\\n    select \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\\n    ```\\n    </CodeTab>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { integer, pgTable } from \"drizzle-orm/pg-core\";\\n\\n    const regularCustomerOrders = pgTable(\\'regular_customer_orders\\', {\\n        customerId: integer(\\'customer_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').notNull(),\\n        quantityOrdered: integer(\\'quantity_ordered\\').notNull(),\\n    });\\n    \\n    const vipCustomerOrders = pgTable(\\'vip_customer_orders\\', {\\n        customerId: integer(\\'customer_id\\').primaryKey(),\\n        productId: integer(\\'product_id\\').notNull(),\\n        quantityOrdered: integer(\\'quantity_ordered\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  <CodeTabs items={[\"import-pattern\", \"builder-pattern\", \"schema.ts\"]}>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    import { exceptAll } from \\'drizzle-orm/mysql-core\\'\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n\\n    const regularOrders = db.select({ \\n        productId: regularCustomerOrders.productId,\\n        quantityOrdered: regularCustomerOrders.quantityOrdered }\\n    ).from(regularCustomerOrders);\\n\\n    const vipOrders = db.select({ \\n        productId: vipCustomerOrders.productId,\\n        quantityOrdered: vipCustomerOrders.quantityOrdered }\\n    ).from(vipCustomerOrders);\\n\\n    const result = await exceptAll(regularOrders, vipOrders);\\n    ```\\n    ```sql\\n    select `product_id`, `quantity_ordered` from `regular_customer_orders`\\n    except all\\n    select `product_id`, `quantity_ordered` from `vip_customer_orders`\\n    ```\\n\\t</CodeTab>\\n    <CodeTab>\\n    ```ts copy\\n    import { regularCustomerOrders, vipCustomerOrders } from \\'./schema\\'\\n \\n    const result = await db\\n        .select({\\n          productId: regularCustomerOrders.productId,\\n          quantityOrdered: regularCustomerOrders.quantityOrdered,\\n        })\\n        .from(regularCustomerOrders)\\n        .exceptAll(\\n          db\\n            .select({\\n              productId: vipCustomerOrders.productId,\\n              quantityOrdered: vipCustomerOrders.quantityOrdered,\\n            })\\n            .from(vipCustomerOrders)\\n        );\\n    ```\\n    ```sql\\n    select `product_id`, `quantity_ordered` from `regular_customer_orders`\\n    except all\\n    select `product_id`, `quantity_ordered` from `vip_customer_orders`\\n    ```\\n    </CodeTab>\\n\\t<CodeTab>\\n\\t```typescript copy\\n    const regularCustomerOrders = mysqlTable(\\'regular_customer_orders\\', {\\n        customerId: int(\\'customer_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').notNull(),\\n        quantityOrdered: int(\\'quantity_ordered\\').notNull(),\\n    });\\n    \\n    const vipCustomerOrders = mysqlTable(\\'vip_customer_orders\\', {\\n        customerId: int(\\'customer_id\\').primaryKey(),\\n        productId: int(\\'product_id\\').notNull(),\\n        quantityOrdered: int(\\'quantity_ordered\\').notNull(),\\n    });\\n    ```\\n    </CodeTab>\\n  </CodeTabs>\\n  </Tab> \\n  <Tab>\\n  Not supported by SingleStore\\n  </Tab>\\n</Tabs>\\n', children=[]),\n",
       " DocItem(origPath=Path('sql-schema-declaration.mdx'), name='sql-schema-declaration.mdx', displayName='sql-schema-declaration.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport SimpleLinkCards from \\'@mdx/SimpleLinkCards.astro\\';\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport Section from \\'@mdx/Section.astro\\';\\nimport Flex from \"@mdx/Flex.astro\"\\nimport LinksList from \"@mdx/LinksList.astro\"\\n\\n# Drizzle schema\\n\\nDrizzle lets you define a schema in TypeScript with various models and properties supported by the underlying database. \\nWhen you define your schema, it serves as the source of truth for future modifications in queries (using Drizzle-ORM)\\nand migrations (using Drizzle-Kit).\\n\\n<Callout> \\nIf you are using Drizzle-Kit for the migration process, make sure to export all the models defined in your schema files so that Drizzle-Kit can import them and use them in the migration diff process. \\n</Callout>\\n\\n## Organize your schema files \\nYou can declare your SQL schema directly in TypeScript either in a single `schema.ts` file,\\nor you can spread them around â€” whichever you prefer, all the freedom!\\n\\n#### Schema in 1 file\\nThe most common way to declare your schema with Drizzle is to put all your tables into one `schema.ts` file.\\n\\n> Note: You can name your schema file whatever you like. For example, it could be `models.ts`, or something else.\\n\\nThis approach works well if you don\\'t have too many table models defined, or if you\\'re okay with keeping them all in one file\\n\\nExample:\\n```plaintext\\nðŸ“¦ <project root>\\n â”” ðŸ“‚ src\\n    â”” ðŸ“‚ db\\n       â”” ðŸ“œ schema.ts\\n```\\n\\nIn the `drizzle.config.ts` file, you need to specify the path to your schema file. With this configuration, Drizzle will \\nread from the `schema.ts` file and use this information during the migration generation process. For more information \\nabout the `drizzle.config.ts` file and migrations with Drizzle, please check: [link](/docs/drizzle-config-file)\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\', // \\'mysql\\' | \\'sqlite\\' | \\'turso\\'\\n  schema: \\'./src/db/schema.ts\\'\\n})\\n```\\n\\n#### Schema in multiple files\\n\\nYou can place your Drizzle models â€” such as tables, enums, sequences, etc. â€” not only in one file but in any file you prefer. \\nThe only thing you must ensure is that you export all the models from those files so that the Drizzle kit can import \\nthem and use them in migrations.\\n\\nOne use case would be to separate each table into its own file.\\n```plaintext\\nðŸ“¦ <project root>\\n â”” ðŸ“‚ src\\n    â”” ðŸ“‚ db\\n       â”” ðŸ“‚ schema\\n          â”œ ðŸ“œ users.ts\\n          â”œ ðŸ“œ countries.ts\\n          â”œ ðŸ“œ cities.ts\\n          â”œ ðŸ“œ products.ts\\n          â”œ ðŸ“œ clients.ts\\n          â”” ðŸ“œ etc.ts\\n```\\n\\nIn the `drizzle.config.ts` file, you need to specify the path to your schema folder. With this configuration, Drizzle will \\nread from the `schema` folder and find all the files recursively and get all the drizzle tables from there. For more information \\nabout the `drizzle.config.ts` file and migrations with Drizzle, please check: [link](/docs/drizzle-config-file)\\n\\n```ts\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  dialect: \\'postgresql\\', // \\'mysql\\' | \\'sqlite\\' | \\'turso\\'\\n  schema: \\'./src/db/schema\\'\\n})\\n```\\n\\nYou can also group them in any way you like, such as creating groups for user-related tables, messaging-related tables, product-related tables, etc. \\n```plaintext\\nðŸ“¦ <project root>\\n â”” ðŸ“‚ src\\n    â”” ðŸ“‚ db\\n       â”” ðŸ“‚ schema\\n          â”œ ðŸ“œ users.ts\\n          â”œ ðŸ“œ messaging.ts\\n          â”” ðŸ“œ products.ts\\n```\\n\\n## Shape your data schema\\n\\nDrizzle schema consists of several model types from database you are using. With drizzle you can specify:\\n- Tables with columns, constraints, etc.\\n- Schemas(PostgreSQL only)\\n- Enums\\n- Sequences(PostgreSQL only)\\n- Views\\n- Materialized Views\\n- etc.\\n\\nLet\\'s go one by one and check how the schema should be defined with drizzle\\n\\n#### **Tables and columns declaration** \\n\\nA table in Drizzle should be defined with at least 1 column, the same as it should be done in database. There is one important thing to know,\\nthere is no such thing as a common table object in drizzle. You need to choose a dialect you are using, PostgreSQL, MySQL or SQLite\\n\\n![](@/assets/images/table-structure.svg)\\n\\n<CodeTabs items={[\"PostgreSQL Table\", \"MySQL Table\", \"SQLite Table\"]}>\\n```ts copy\\nimport { pgTable, integer } from \"drizzle-orm/pg-core\"\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: integer()\\n});\\n```\\n```ts copy\\nimport { mysqlTable, int } from \"drizzle-orm/mysql-core\"\\n\\nexport const users = mysqlTable(\\'users\\', {\\n  id: int()\\n});\\n```\\n```ts copy\\nimport { sqliteTable, integer } from \"drizzle-orm/sqlite-core\"\\n\\nexport const users = sqliteTable(\\'users\\', {\\n  id: integer()\\n});\\n```\\n</CodeTabs>\\n\\nBy default, Drizzle will use the TypeScript key names for columns in database queries. \\nTherefore, the schema and query from the example will generate the SQL query shown below\\n\\n<Callout>\\nThis example uses a db object, whose initialization is not covered in this part of the documentation. To learn how to connect to the database, please refer to the [Connections Docs](/docs/get-started-postgresql)\\n</Callout>\\n\\n\\\\\\n**TypeScript key = database key**\\n<Section>\\n```ts\\n// schema.ts\\nimport { integer, pgTable, varchar } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: integer(),\\n  first_name: varchar()\\n})\\n```\\n```ts\\n// query.ts\\nawait db.select().from(users);\\n```\\n```sql\\nSELECT \"id\", \"first_name\" from users;\\n```\\n</Section>\\n\\nIf you want to use different names in your TypeScript code and in the database, you can use column aliases\\n\\n<Section>\\n```ts\\n// schema.ts\\nimport { integer, pgTable, varchar } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: integer(),\\n  firstName: varchar(\\'first_name\\')\\n})\\n```\\n```ts\\n// query.ts\\nawait db.select().from(users);\\n```\\n```sql\\nSELECT \"id\", \"first_name\" from users;\\n```\\n</Section>\\n\\n### Camel and Snake casing\\n\\nDatabase model names often use `snake_case` conventions, while in TypeScript, it is common to use `camelCase` for naming models. \\nThis can lead to a lot of alias definitions in the schema. To address this, Drizzle provides a way to automatically \\nmap `camelCase` from TypeScript to `snake_case` in the database by including one optional parameter during Drizzle database initialization\\n\\nFor such mapping, you can use the `casing` option in the Drizzle DB declaration. This parameter will \\nhelp you specify the database model naming convention and will attempt to map all JavaScript keys accordingly\\n\\n<Section>\\n```ts\\n// schema.ts\\nimport { drizzle } from \"drizzle-orm/node-postgres\";\\nimport { integer, pgTable, varchar } from \"drizzle-orm/pg-core\";\\n\\nexport const users = pgTable(\\'users\\', {\\n  id: integer(),\\n  firstName: varchar()\\n})\\n```\\n```ts\\n// db.ts\\nconst db = drizzle({ connection: process.env.DATABASE_URL, casing: \\'snake_case\\' })\\n```\\n```ts\\n// query.ts\\nawait db.select().from(users);\\n```\\n```sql\\nSELECT \"id\", \"first_name\" from users;\\n```\\n</Section>\\n\\n### Advanced\\n\\nThere are a few tricks you can use with Drizzle ORM. As long as Drizzle is entirely in TypeScript files, \\nyou can essentially do anything you would in a simple TypeScript project with your code.\\n\\nOne common feature is to separate columns into different places and then reuse them. \\nFor example, consider the `updated_at`, `created_at`, and `deleted_at` columns. Many tables/models may need these \\nthree fields to track and analyze the creation, deletion, and updates of entities in a system\\n\\nWe can define those columns in a separate file and then import and spread them across all the table objects you have\\n\\n<Section>\\n```ts\\n// columns.helpers.ts\\nconst timestamps = {\\n  updated_at: timestamp(),\\n  created_at: timestamp().defaultNow().notNull(),\\n  deleted_at: timestamp(),\\n}\\n```\\n```ts\\n// users.sql.ts\\nexport const users = pgTable(\\'users\\', {\\n  id: integer(),\\n  ...timestamps\\n})\\n```\\n```ts\\n// posts.sql.ts\\nexport const posts = pgTable(\\'posts\\', {\\n  id: integer(),\\n  ...timestamps\\n})\\n```\\n</Section>\\n\\n#### **Schemas**\\n\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n<Tab>\\n\\\\\\nIn PostgreSQL, there is an entity called a `schema` (which we believe should be called `folders`). This creates a structure in PostgreSQL:\\n\\n![](@/assets/images/postgresql-db-structure.png)\\n\\nYou can manage your PostgreSQL schemas with `pgSchema` and place any other models inside it.\\n\\nDefine the schema you want to manage using Drizzle\\n```ts\\nimport { pgSchema } from \"drizzle-orm/pg-core\"\\n\\nexport const customSchema = pgSchema(\\'custom\\');\\n```\\n\\nThen place the table inside the schema object\\n```ts {5-7}\\nimport { integer, pgSchema } from \"drizzle-orm/pg-core\";\\n\\nexport const customSchema = pgSchema(\\'custom\\');\\n\\nexport const users = customSchema.table(\\'users\\', {\\n  id: integer()\\n})\\n```\\n</Tab>\\n<Tab>\\n\\\\\\nIn MySQL, there is an entity called `Schema`, but in MySQL terms, this is equivalent to a `Database`. \\n\\nYou can define them with `drizzle-orm` and use them in queries, but they won\\'t be detected by `drizzle-kit` or included in the migration flow\\n\\n![](@/assets/images/mysql-db-structure.png)\\n\\nDefine the schema you want to manage using Drizzle\\n```ts\\nimport { mysqlSchema } from \"drizzle-orm/mysql-core\"\\n\\nexport const customSchema = mysqlSchema(\\'custom\\');\\n```\\n\\nThen place the table inside the schema object\\n```ts {5-7}\\nimport { int, mysqlSchema } from \"drizzle-orm/mysql-core\";\\n\\nexport const customSchema = mysqlSchema(\\'custom\\');\\n\\nexport const users = customSchema.table(\\'users\\', {\\n  id: int()\\n})\\n```\\n</Tab>\\n<Tab>\\n\\\\\\nIn SQLite, there is no concept of a schema, so you can only define tables within a single SQLite file context\\n\\n![](@/assets/images/sqlite-db-structure.png)\\n</Tab>\\n</Tabs>\\n\\n### Example\\n\\nOnce you know the basics, let\\'s define a schema example for a real project to get a better view and understanding\\n\\n> All examples will use `generateUniqueString`. The implementation for it will be provided after all the schema examples\\n\\n<CodeTabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n```ts copy\\nimport { AnyPgColumn } from \"drizzle-orm/pg-core\";\\nimport { pgEnum, pgTable as table } from \"drizzle-orm/pg-core\";\\nimport * as t from \"drizzle-orm/pg-core\";\\n\\nexport const rolesEnum = pgEnum(\"roles\", [\"guest\", \"user\", \"admin\"]);\\n\\nexport const users = table(\\n  \"users\",\\n  {\\n    id: t.integer().primaryKey().generatedAlwaysAsIdentity(),\\n    firstName: t.varchar(\"first_name\", { length: 256 }),\\n    lastName: t.varchar(\"last_name\", { length: 256 }),\\n    email: t.varchar().notNull(),\\n    invitee: t.integer().references((): AnyPgColumn => users.id),\\n    role: rolesEnum().default(\"guest\"),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"email_idx\").on(table.email)\\n  ]\\n);\\n\\nexport const posts = table(\\n  \"posts\",\\n  {\\n    id: t.integer().primaryKey().generatedAlwaysAsIdentity(),\\n    slug: t.varchar().$default(() => generateUniqueString(16)),\\n    title: t.varchar({ length: 256 }),\\n    ownerId: t.integer(\"owner_id\").references(() => users.id),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"slug_idx\").on(table.slug),\\n    t.index(\"title_idx\").on(table.title),\\n  ]\\n);\\n\\nexport const comments = table(\"comments\", {\\n  id: t.integer().primaryKey().generatedAlwaysAsIdentity(),\\n  text: t.varchar({ length: 256 }),\\n  postId: t.integer(\"post_id\").references(() => posts.id),\\n  ownerId: t.integer(\"owner_id\").references(() => users.id),\\n});\\n```\\n```ts copy\\nimport { mysqlTable as table } from \"drizzle-orm/mysql-core\";\\nimport * as t from \"drizzle-orm/mysql-core\";\\nimport { AnyMySqlColumn } from \"drizzle-orm/mysql-core\";\\n\\nexport const users = table(\\n  \"users\",\\n  {\\n    id: t.int().primaryKey().autoincrement(),\\n    firstName: t.varchar(\"first_name\", { length: 256 }),\\n    lastName: t.varchar(\"last_name\", { length: 256 }),\\n    email: t.varchar({ length: 256 }).notNull(),\\n    invitee: t.int().references((): AnyMySqlColumn => users.id),\\n    role: t.mysqlEnum([\"guest\", \"user\", \"admin\"]).default(\"guest\"),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"email_idx\").on(table.email)\\n  ]\\n);\\n\\nexport const posts = table(\\n  \"posts\",\\n  {\\n    id: t.int().primaryKey().autoincrement(),\\n    slug: t.varchar({ length: 256 }).$default(() => generateUniqueString(16)),\\n    title: t.varchar({ length: 256 }),\\n    ownerId: t.int(\"owner_id\").references(() => users.id),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"slug_idx\").on(table.slug),\\n    t.index(\"title_idx\").on(table.title),\\n  ]\\n);\\n\\nexport const comments = table(\"comments\", {\\n  id: t.int().primaryKey().autoincrement(),\\n  text: t.varchar({ length: 256 }),\\n  postId: t.int(\"post_id\").references(() => posts.id),\\n  ownerId: t.int(\"owner_id\").references(() => users.id),\\n});\\n```\\n```ts copy\\nimport { sqliteTable as table } from \"drizzle-orm/sqlite-core\";\\nimport * as t from \"drizzle-orm/sqlite-core\";\\nimport { AnySQLiteColumn } from \"drizzle-orm/sqlite-core\";\\n\\nexport const users = table(\\n  \"users\",\\n  {\\n    id: t.int().primaryKey({ autoIncrement: true }),\\n    firstName: t.text(\"first_name\"),\\n    lastName: t.text(\"last_name\"),\\n    email: t.text().notNull(),\\n    invitee: t.int().references((): AnySQLiteColumn => users.id),\\n    role: t.text().$type<\"guest\" | \"user\" | \"admin\">().default(\"guest\"),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"email_idx\").on(table.email)\\n  ]\\n);\\n\\nexport const posts = table(\\n  \"posts\",\\n  {\\n    id: t.int().primaryKey({ autoIncrement: true }),\\n    slug: t.text().$default(() => generateUniqueString(16)),\\n    title: t.text(),\\n    ownerId: t.int(\"owner_id\").references(() => users.id),\\n  },\\n  (table) => [\\n    t.uniqueIndex(\"slug_idx\").on(table.slug),\\n    t.index(\"title_idx\").on(table.title),\\n  ]\\n);\\n\\nexport const comments = table(\"comments\", {\\n  id: t.int().primaryKey({ autoIncrement: true }),\\n  text: t.text({ length: 256 }),\\n  postId: t.int(\"post_id\").references(() => posts.id),\\n  ownerId: t.int(\"owner_id\").references(() => users.id),\\n});\\n```\\n</CodeTabs>\\n\\n**`generateUniqueString` implementation:**\\n```ts\\nfunction generateUniqueString(length: number = 12): string {\\n  const characters =\\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\";\\n  let uniqueString = \"\";\\n\\n  for (let i = 0; i < length; i++) {\\n    const randomIndex = Math.floor(Math.random() * characters.length);\\n    uniqueString += characters[randomIndex];\\n  }\\n\\n  return uniqueString;\\n}\\n```\\n\\n\\n#### What\\'s next?\\n<br/>\\n<Flex>\\n  <LinksList \\n    title=\\'Manage schema\\'\\n    links={[\\n        [\"Column types\", \"/docs/column-types/pg\"], \\n        [\"Indexes and Constraints\", \"/docs/indexes-constraints\"],\\n        [\"Database Views\", \"/docs/views\"],\\n        [\"Database Schemas\", \"/docs/schemas\"],\\n        [\"Sequences\", \"/docs/sequences\"],\\n        [\"Extensions\", \"/docs/extensions/pg\"],\\n      ]}\\n  />\\n  <LinksList \\n    title=\\'Zero to Hero\\'\\n    links={[\\n        [\"Database connection\", \"/docs/connect-overview\"], \\n        [\"Data querying\", \"/docs/data-querying\"], \\n        [\"Migrations\", \"/docs/migrations\"], \\n      ]}\\n  />\\n</Flex>\\n', children=[]),\n",
       " DocItem(origPath=Path('sql.mdx'), name='sql.mdx', displayName='sql.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport CodeTab from \\'@mdx/CodeTab.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# Magical `sql` operator ðŸª„\\n\\nWhen working with an ORM library, there may be cases where you find it challenging to write a\\nspecific query using the provided ORM syntax. In such situations, you can resort to using\\nraw queries, which involve constructing a query as a raw string. However, raw queries often\\nlack the benefits of type safety and query parameterization.\\n\\nTo address this, many libraries have introduced the concept of an `sql` template. This template \\nallows you to write more type-safe and parameterized queries, enhancing the overall safety and \\nflexibility of your code. Drizzle, being a powerful ORM library, also supports the sql template.\\n\\nWith Drizzle\\'s `sql` template, you can go even further in crafting queries. If you encounter \\ndifficulties in writing an entire query using the library\\'s query builder, you can selectively\\nuse the `sql` template within specific sections of the Drizzle query. This flexibility enables you \\nto employ the sql template in partial SELECT statements, WHERE clauses, ORDER BY clauses, HAVING\\nclauses, GROUP BY clauses, and even in relational query builders.\\n\\nBy leveraging the capabilities of the sql template in Drizzle, you can maintain the advantages \\nof type safety and query parameterization while achieving the desired query structure and complexity.\\nThis empowers you to create more robust and maintainable code within your application.\\n\\n## sql`` template\\n\\nOne of the most common usages you may encounter in other ORMs as well \\nis the ability to use `sql` queries as-is for raw queries.\\n\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\' \\n\\nconst id = 69;\\nawait db.execute(sql`select * from ${usersTable} where ${usersTable.id} = ${id}`)\\n```\\n\\nIt will generate the current query\\n\\n```sql\\nselect * from \"users\" where \"users\".\"id\" = $1; --> [69]\\n```\\n\\nAny tables and columns provided to the sql parameter are automatically mapped to their corresponding SQL \\nsyntax with escaped names for tables, and the escaped table names are appended to column names. \\n\\nAdditionally, any dynamic parameters such as `${id}` will be mapped to the $1 placeholder, \\nand the corresponding values will be moved to an array of values that are passed separately to the database. \\n\\nThis approach effectively prevents any potential SQL Injection vulnerabilities.\\n\\n## `sql<T>`\\n\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\n    Please note that `sql<T>` does not perform any runtime mapping. The type you define using `sql<T>` is\\n    purely a helper for Drizzle. It is important to understand that there is no feasible way to \\n    determine the exact type dynamically, as SQL queries can be highly versatile and customizable. \\n</Callout>\\n\\nYou can define a custom type in Drizzle to be used in places where fields require a specific type other than `unknown`.\\n\\nThis feature is particularly useful in partial select queries, ensuring consistent typing for selected fields:\\n\\n```typescript\\n// without sql<T> type defined\\nconst response: { lowerName: unknown }[] = await db.select({\\n    lowerName: sql`lower(${usersTable.id})`\\n}).from(usersTable);\\n\\n// with sql<T> type defined\\nconst response: { lowerName: string }[] = await db.select({\\n    lowerName: sql<string>`lower(${usersTable.id})`\\n}).from(usersTable);\\n```\\n\\n## `sql``.mapWith()`\\n\\nFor the cases you need to make a runtime mapping for values passed from database driver to drizzle you can use `.mapWith()`\\n\\nThis function accepts different values, that will map response in runtime.\\n\\nYou can replicate a specific column mapping strategy as long as\\nthe interface inside mapWith is the same interface that is implemented by Column.\\n\\n```typescript\\nconst usersTable = pgTable(\\'users\\', {\\n    id: serial(\\'id\\').primaryKey(),\\n    name: text(\\'name\\').notNull(),\\n});\\n\\n//  at runtime this values will be mapped same as `text` column is mapped in drizzle\\nsql`...`.mapWith(usersTable.name);\\n```\\n\\nYou can also pass your own implementation for the `DriverValueDecoder` interface:\\n\\n```ts \\nsql``.mapWith({\\n\\tmapFromDriverValue: (value: any) => {\\n\\t\\tconst mappedValue = value;\\n\\t\\t// mapping you want to apply\\n\\t\\treturn mappedValue;\\n\\t},\\n});\\n    \\n// or\\nsql``.mapWith(Number);\\n```\\n\\n## `sql``.as<T>()`\\n\\nIn different cases, it can sometimes be challenging to determine how to name a custom field that you want to use.\\nYou may encounter situations where you need to explicitly specify an alias for a \\nfield that will be selected. This can be particularly useful when dealing with complex queries. \\n\\nTo address these scenarios, we have introduced a helpful `.as(\\'alias_name\\')` helper, which allows \\nyou to define an alias explicitly. By utilizing this feature, you can provide a clear and meaningful \\nname for the field, making your queries more intuitive and readable.\\n\\n<Section>\\n```typescript\\nsql`lower(usersTable.name)`.as(\\'lower_name\\')\\n```\\n```sql\\n... \"usersTable\".\"name\" as lower_name ...\\n```\\n</Section>\\n\\n## `sql.raw()`\\n\\nThere are cases where you may not need to create parameterized values from input or map tables/columns to escaped ones. \\nInstead, you might simply want to generate queries as they are. For such situations, we provide the `sql.raw()` function.\\n\\nThe `sql.raw()` function allows you to include raw SQL statements within your queries without any additional processing or escaping.\\nThis can be useful when you have pre-constructed SQL statements or when you need to incorporate complex or dynamic \\nSQL code directly into your queries.\\n\\n<Section>\\n```typescript\\nsql.raw(`select * from users where id = ${12}`);\\n// vs\\nsql`select * from users where id = ${12}`;\\n```\\n```sql\\nselect * from users where id = 12;\\n--> vs\\nselect * from users where id = $1; --> [12]\\n```\\n</Section>\\n\\nYou can also utilize `sql.raw()` within the sql function, enabling you to include any raw string\\nwithout escaping it through the main `sql` template function.\\n\\nBy using `sql.raw()` inside the `sql` function, you can incorporate unescaped raw strings \\ndirectly into your queries. This can be particularly useful when you have specific\\nSQL code or expressions that should remain untouched by the template function\\'s automatic escaping or modification.\\n\\n<Section>\\n```typescript\\nsql`select * from ${usersTable} where id = ${12}`;\\n// vs\\nsql`select * from ${usersTable} where id = ${sql.raw(12)}`;\\n```\\n```sql\\nselect * from \"users\" where id = $1; --> [12]\\n--> vs\\nselect * from \"users\" where id = 12;\\n```\\n</Section>\\n\\n## sql.fromList()\\n\\nThe `sql` template generates sql chunks, which are arrays of SQL parts that will be concatenated \\ninto the query and params after applying the SQL to the database or query in Drizzle.\\n\\nIn certain scenarios, you may need to aggregate these chunks into an array using custom business \\nlogic and then concatenate them into a single SQL statement that can be passed to the database or query.\\nFor such cases, the fromList function can be quite useful.\\n\\nThe fromList function allows you to combine multiple SQL chunks into a single SQL statement. \\nYou can use it to aggregate and concatenate the individual SQL parts according to your specific \\nrequirements and then obtain a unified SQL query that can be executed.\\n\\n<Section>\\n```typescript\\nconst sqlChunks: SQL[] = [];\\n\\nsqlChunks.push(sql`select * from users`);\\n\\n// some logic\\n\\nsqlChunks.push(sql` where `);\\n\\n// some logic\\n\\nfor (let i = 0; i < 5; i++) {\\n\\tsqlChunks.push(sql`id = ${i}`);\\n\\n\\tif (i === 4) continue;\\n\\tsqlChunks.push(sql` or `);\\n}\\n\\nconst finalSql: SQL = sql.fromList(sqlChunks)\\n```\\n```sql\\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\\n```\\n</Section>\\n\\n## sql.join()\\n\\nIndeed, the `sql.join` function serves a similar purpose to the fromList helper. \\nHowever, it provides additional flexibility when it comes to handling spaces between\\nSQL chunks or specifying custom separators for concatenating the SQL chunks.\\n\\nWith `sql.join`, you can concatenate SQL chunks together using a specified separator. \\nThis separator can be any string or character that you want to insert between the chunks. \\n\\nThis is particularly useful when you have specific requirements for formatting or delimiting \\nthe SQL chunks. By specifying a custom separator, you can achieve the desired structure and formatting \\nin the final SQL query.\\n\\n<Section>\\n```typescript\\nconst sqlChunks: SQL[] = [];\\n\\nsqlChunks.push(sql`select * from users`);\\n\\n// some logic\\n\\nsqlChunks.push(sql`where`);\\n\\n// some logic\\n\\nfor (let i = 0; i < 5; i++) {\\n\\tsqlChunks.push(sql`id = ${i}`);\\n\\nif (i === 4) continue;\\n    sqlChunks.push(sql`or`);\\n}\\n\\nconst finalSql: SQL = sql.join(sqlChunks, sql.raw(\\' \\'));\\n```\\n```sql\\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\\n```\\n</Section>\\n\\n## sql.append()\\n\\nIf you have already generated SQL using the `sql` template, you can achieve the same behavior as `fromList`\\nby using the append function to directly add a new chunk to the generated SQL.\\n\\nBy using the append function, you can dynamically add additional SQL chunks to the existing SQL string,\\neffectively concatenating them together. This allows you to incorporate custom logic or business \\nrules for aggregating the chunks into the final SQL query.\\n\\n<Section>\\n```typescript \\nconst finalSql = sql`select * from users`;\\n\\n// some logic\\n\\nfinalSql.append(sql` where `);\\n\\n// some logic\\n\\nfor (let i = 0; i < 5; i++) {\\n\\tfinalSql.append(sql`id = ${i}`);\\n\\n\\tif (i === 4) continue;\\n\\tfinalSql.append(sql` or `);\\n}\\n```\\n```sql\\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\\n```\\n</Section>\\n\\n## sql.empty()\\n\\nBy using sql.empty(), you can start with a blank SQL object and then dynamically append SQL chunks to it as needed. This allows you to construct the SQL query incrementally, applying custom logic or conditions to determine the contents of each chunk.\\n\\nOnce you have initialized the SQL object using sql.empty(), you can take advantage of the full range\\nof sql template features such as parameterization, composition, and escaping. \\nThis empowers you to construct the SQL query in a flexible and controlled manner, \\nadapting it to your specific requirements.\\n\\n```typescript \\nconst finalSql = sql.empty();\\n\\n// some logic\\n\\nfinalSql.append(sql`select * from users`);\\n\\n// some logic\\n\\nfinalSql.append(sql` where `);\\n\\n// some logic\\n\\nfor (let i = 0; i < 5; i++) {\\n\\tfinalSql.append(sql`id = ${i}`);\\n\\n\\tif (i === 4) continue;\\n\\tfinalSql.append(sql` or `);\\n}\\n```\\n```sql\\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\\n```\\n\\n## Convert `sql` to string and params\\n\\nIn all the previous examples, you observed the usage of SQL template syntax in TypeScript along with \\nthe generated SQL output.\\n\\nIf you need to obtain the query string and corresponding parameters generated from the SQL template, \\nyou must specify the database dialect you intend to generate the query for. Different databases have\\nvarying syntax for parameterization and escaping, so selecting the appropriate dialect is crucial.\\n\\nOnce you have chosen the dialect, you can utilize the corresponding implementation\\'s functionality\\nto convert the SQL template into the desired query string and parameter format. This ensures \\ncompatibility with the specific database system you are working with.\\n\\n<CodeTabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\"]}>\\n<CodeTab>\\n<Section>\\n```typescript copy\\nimport { PgDialect } from \\'drizzle-orm/pg-core\\';\\n\\nconst pgDialect = new PgDialect();\\npgDialect.sqlToQuery(sql`select * from ${usersTable} where ${usersTable.id} = ${12}`);\\n```\\n```sql\\nselect * from \"users\" where \"users\".\"id\" = $1; --> [ 12 ]\\n```\\n</Section>\\n\\n</CodeTab>\\n<CodeTab>\\n<Section>\\n```typescript copy\\nimport { MySqlDialect } from \\'drizzle-orm/mysql-core\\';\\n\\nconst mysqlDialect = new MySqlDialect();\\nmysqlDialect.sqlToQuery(sql`select * from ${usersTable} where ${usersTable.id} = ${12}`);\\n```\\n```sql\\nselect * from `users` where `users`.`id` = ?; --> [ 12 ]\\n```\\n</Section>\\n</CodeTab>\\n<CodeTab>\\n<Section>\\n```typescript copy\\nimport { SQLiteSyncDialect } from \\'drizzle-orm/sqlite-core\\';\\n\\nconst sqliteDialect = new SQLiteSyncDialect();\\nsqliteDialect.sqlToQuery(sql`select * from ${usersTable} where ${usersTable.id} = ${12}`);\\n```\\n```sql\\nselect * from \"users\" where \"users\".\"id\" = ?; --> [ 12 ]\\n```\\n</Section>\\n</CodeTab>\\n</CodeTabs>\\n\\n## `sql` select\\n\\nYou can use the sql functionality in partial select queries as well. Partial select queries allow you to \\nretrieve specific fields or columns from a table rather than fetching the entire row.\\n\\nFor more detailed information about partial select queries, you can refer to the Core API\\ndocumentation available at **[Core API docs](/docs/select#basic-and-partial-select)**.\\n\\n**Select different custom fields from table**\\n\\nHere you can see a usage for **[`sql<T>`](/docs/sql#sqlt)**, **[`sql``.mapWith()`](/docs/sql#sqlmapwith)**, **[`sql``.as<T>()`](/docs/sql#sqlast)**.\\n\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\'\\nimport { usersTable } from \\'schema\\'\\n\\nawait db.select({\\n    id: usersTable.id,\\n    lowerName: sql<string>`lower(${usersTable.name})`,\\n    aliasedName: sql<string>`lower(${usersTable.name})`.as(\\'aliased_column\\'),\\n    count: sql<number>`count(*)`.mapWith(Number) \\n}).from(usersTable)\\n```\\n```sql\\nselect `id`, lower(`name`), lower(`name`) as `aliased_column`, count(*) from `users`;\\n```\\n</Section>\\n\\n## `sql` in where\\n\\nIndeed, Drizzle provides a set of available expressions that you can use within the sql template. \\nHowever, it is true that databases often have a wider range of expressions available, \\nincluding those provided through extensions or other means.\\n\\nTo ensure flexibility and enable you to utilize any expressions that are not natively\\nsupported by Drizzle, you have the freedom to write the SQL template\\ndirectly using the sql function. This allows you to leverage the full power of\\nSQL and incorporate any expressions or functionalities specific to your target database.\\n\\nBy using the sql template, you are not restricted to only the predefined expressions in Drizzle. \\nInstead, you can express complex queries and incorporate any supported expressions that \\nthe underlying database system provides.\\n\\n\\n**Filtering by `id` but with sql**\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\'\\nimport { usersTable } from \\'schema\\'\\n\\nconst id = 77\\n\\nawait db.select()\\n        .from(usersTable)\\n        .where(sql`${usersTable.id} = ${id}`)\\n```\\n```sql\\nselect * from \"users\" where \"users\".\"id\" = $1; --> [ 77 ]\\n```\\n</Section>\\n\\n**Advanced fulltext search where statement**\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\'\\nimport { usersTable } from \\'schema\\'\\n\\nconst searchParam = \"Ale\"\\n\\nawait db.select()\\n        .from(usersTable)\\n        .where(sql`to_tsvector(\\'simple\\', ${usersTable.name}) @@ to_tsquery(\\'simple\\', ${searchParam})`)\\n```\\n```sql\\nselect * from \"users\" where to_tsvector(\\'simple\\', \"users\".\"name\") @@ to_tsquery(\\'simple\\', \\'$1\\'); --> [ \"Ale\" ]\\n```\\n</Section>\\n\\n## `sql` in orderBy\\n\\nThe `sql` template can indeed be used in the ORDER BY clause when you need specific functionality for ordering that is not\\navailable in Drizzle, but you prefer not to resort to raw SQL.\\n\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\'\\nimport { usersTable } from \\'schema\\'\\n\\nawait db.select().from(usersTable).orderBy(sql`${usersTable.id} desc nulls first`)\\n```\\n```sql\\nselect * from \"users\" order by \"users\".\"id\" desc nulls first;\\n```\\n</Section>\\n\\n## `sql` in having and groupBy\\n\\nThe `sql` template can indeed be used in the HAVING and GROUP BY clauses when you need specific functionality for ordering that is not\\navailable in Drizzle, but you prefer not to resort to raw SQL.\\n\\n<Section>\\n```typescript copy\\nimport { sql } from \\'drizzle-orm\\'\\nimport { usersTable } from \\'schema\\'\\n\\nawait db.select({ \\n    projectId: usersTable.projectId,\\n    count: sql<number>`count(${usersTable.id})`.mapWith(Number)\\n}).from(usersTable)\\n    .groupBy(sql`${usersTable.projectId}`)\\n    .having(sql`count(${usersTable.id}) > 300`)\\n```\\n```sql\\nselect \"project_id\", count(\"users\".\"id\") from users group by \"users\".\"project_id\" having count(\"users\".\"id\") > 300; \\n```\\n</Section>\\n', children=[]),\n",
       " DocItem(origPath=Path('transactions.mdx'), name='transactions.mdx', displayName='transactions.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\n\\n# Transactions\\n\\nSQL transaction is a grouping of one or more SQL statements that interact with a database.\\nA transaction in its entirety can commit to a database as a single logical unit\\nor rollback (become undone) as a single logical unit.\\n\\nDrizzle ORM provides APIs to run SQL statements in transactions:\\n\\n```ts copy\\nconst db = drizzle(...)\\n\\nawait db.transaction(async (tx) => {\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \\'Dan\\'));\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \\'Andrew\\'));\\n});\\n```\\n\\nDrizzle ORM supports `savepoints` with nested transactions API:\\n\\n```ts copy {7-9}\\nconst db = drizzle(...)\\n\\nawait db.transaction(async (tx) => {\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \\'Dan\\'));\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \\'Andrew\\'));\\n\\n  await tx.transaction(async (tx2) => {\\n    await tx2.update(users).set({ name: \"Mr. Dan\" }).where(eq(users.name, \"Dan\"));\\n  });\\n});\\n```\\n\\nYou can embed business logic to the transaction and rollback whenever needed:\\n\\n```ts copy {7}\\nconst db = drizzle(...)\\n\\nawait db.transaction(async (tx) => {\\n  const [account] = await tx.select({ balance: accounts.balance }).from(accounts).where(eq(users.name, \\'Dan\\'));\\n  if (account.balance < 100) {\\n    // This throws an exception that rollbacks the transaction.\\n    tx.rollback()\\n  }\\n\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \\'Dan\\'));\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \\'Andrew\\'));\\n});\\n```\\n\\nYou can return values from the transaction:\\n\\n```ts copy {8}\\nconst db = drizzle(...)\\n\\nconst newBalance: number = await db.transaction(async (tx) => {\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \\'Dan\\'));\\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \\'Andrew\\'));\\n\\n  const [account] = await tx.select({ balance: accounts.balance }).from(accounts).where(eq(users.name, \\'Dan\\'));\\n  return account.balance;\\n});\\n```\\n\\nYou can use transactions with **[relational queries](/docs/rqb)**:\\n\\n```ts\\nconst db = drizzle({ schema })\\n\\nawait db.transaction(async (tx) => {\\n  await tx.query.users.findMany({\\n    with: {\\n      accounts: true\\n    }\\n  });\\n});\\n```\\n\\n\\n\\n\\n\\nWe provide dialect-specific transaction configuration APIs:\\n\\n<Tabs items={[\"PostgreSQL\", \"MySQL\", \"SQLite\", \"SingleStore\"]}>\\n<Tab>\\n```ts copy {6-8}\\nawait db.transaction(\\n  async (tx) => {\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \"Dan\"));\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \"Andrew\"));\\n  }, {\\n    isolationLevel: \"read committed\",\\n    accessMode: \"read write\",\\n    deferrable: true,\\n  }\\n);\\n\\ninterface PgTransactionConfig {\\n  isolationLevel?:\\n    | \"read uncommitted\"\\n    | \"read committed\"\\n    | \"repeatable read\"\\n    | \"serializable\";\\n  accessMode?: \"read only\" | \"read write\";\\n  deferrable?: boolean;\\n}\\n```\\n</Tab>\\n<Tab>\\n```ts {6-8}\\nawait db.transaction(\\n  async (tx) => {\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \"Dan\"));\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \"Andrew\"));\\n  }, {\\n    isolationLevel: \"read committed\",\\n    accessMode: \"read write\",\\n    withConsistentSnapshot: true,\\n  }\\n);\\n\\ninterface MySqlTransactionConfig {\\n  isolationLevel?:\\n    | \"read uncommitted\"\\n    | \"read committed\"\\n    | \"repeatable read\"\\n    | \"serializable\";\\n  accessMode?: \"read only\" | \"read write\";\\n  withConsistentSnapshot?: boolean;\\n}\\n```\\n</Tab>\\n<Tab>\\n```ts {6}\\nawait db.transaction(\\n  async (tx) => {\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \"Dan\"));\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \"Andrew\"));\\n  }, {\\n    behavior: \"deferred\",\\n  }\\n);\\n\\ninterface SQLiteTransactionConfig {\\n    behavior?: \\'deferred\\' | \\'immediate\\' | \\'exclusive\\';\\n}\\n```\\n</Tab>\\n<Tab>\\n```ts {6-8}\\nawait db.transaction(\\n  async (tx) => {\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \"Dan\"));\\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \"Andrew\"));\\n  }, {\\n    isolationLevel: \"read committed\",\\n    accessMode: \"read write\",\\n    withConsistentSnapshot: true,\\n  }\\n);\\n\\ninterface SingleStoreTransactionConfig {\\n  isolationLevel?:\\n    | \"read uncommitted\"\\n    | \"read committed\"\\n    | \"repeatable read\"\\n    | \"serializable\";\\n  accessMode?: \"read only\" | \"read write\";\\n  withConsistentSnapshot?: boolean;\\n}\\n```\\n</Tab>\\n</Tabs>\\n\\n', children=[]),\n",
       " DocItem(origPath=Path('tutorials'), name='tutorials', displayName='tutorials', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('tutorials/drizzle-on-the-edge'), name='drizzle-on-the-edge', displayName='drizzle-on-the-edge', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('tutorials/drizzle-on-the-edge/drizzle-with-netlify-edge-functions-neon.mdx'), name='drizzle-with-netlify-edge-functions-neon.mdx', displayName='drizzle-with-netlify-edge-functions-neon.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Netlify Edge Functions and Neon Postgres \"\\ndate: \"2025-01-30\"\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Netlify Edge Functions](https://docs.netlify.com/edge-functions/overview/) and [Neon Postgres](https://neon.tech/) database.\\n\\n<Prerequisites>\\n- You should have the latest version of [Netlify CLI](https://docs.netlify.com/cli/get-started/#installation) installed.\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n- You should have installed the `dotenv` package for managing environment variables. If you use Node.js `v20.6.0` or later, there is no need to install it because Node.js natively supports `.env` files. Read more about it [here](https://nodejs.org/en/blog/release/v20.6.0#built-in-env-file-support).\\n<Npm>\\n  dotenv\\n</Npm>\\n\\n- Optionally, you can install the `@netlify/edge-functions` package to import the types for the `Context` object which will be used later.\\n<Npm>\\n  @netlify/edge-functions\\n</Npm>\\n</Prerequisites>\\n\\n<Callout type=\"warning\">\\nThese installed packages are used only to create table in the database in [Create a table](#create-a-table), [Setup Drizzle config file](#setup-drizzle-config-file) and [Apply changes to the database](#apply-changes-to-the-database) steps. These packages do not affect the code running inside Netlify Edge Functions. We will use `import_map.json` to import the necessary packages for the Edge Functions.\\n</Callout>\\n\\n<Steps>\\n#### Setup Neon Postgres\\n\\nLog in to the [Neon Console](https://console.neon.tech/app/projects) and navigate to the Projects section. Select a project or click the `New Project` button to create a new one. \\n\\nYour Neon projects come with a ready-to-use Postgres database named `neondb`. We\\'ll use it in this tutorial.\\n\\n#### Setup connection string variable\\n\\nIn **Project Dashboard** section click the `Connect` button and copy your database connection string. It should look similar to this:\\n\\n```bash\\npostgres://username:password@ep-cool-darkness-123456.us-east-2.aws.neon.tech/neondb?sslmode=require\\n```\\n\\nAdd the `DATABASE_URL` environment variable to your `.env` file, which you\\'ll use to connect to the Neon database.\\n\\n```text copy\\nDATABASE_URL=NEON_DATABASE_CONNECTION_STRING\\n```\\n\\n#### Setup Netlify Edge Functions\\n\\nCreate `netlify/edge-functions` directory in the root of your project. This is where you\\'ll store your Edge Functions.\\n\\nCreate a function `user.ts` in the `netlify/edge-functions` directory.\\n\\n```typescript copy filename=\"netlify/edge-functions/user.ts\"\\nimport type { Context } from \"@netlify/edge-functions\";\\n\\nexport default async (request: Request, context: Context) => {\\n  return new Response(\"User data\");\\n};\\n```\\n\\n<Callout type=\"warning\">\\nThe types for the `Request` and `Response` objects are in the global scope.\\n</Callout>\\n\\n#### Setup imports\\n\\nCreate a `import_map.json` file in the root of your project and add the following content:\\n\\n```json copy filename=\"import_map.json\"\\n{\\n  \"imports\": {\\n    \"drizzle-orm/\": \"https://esm.sh/drizzle-orm/\",\\n    \"@neondatabase/serverless\": \"https://esm.sh/@neondatabase/serverless\"\\n  }\\n}\\n```\\n\\nRead more about `import_map.json` in Netlify Edge Functions [here](https://docs.netlify.com/edge-functions/api/#import-maps).\\n\\n#### Create a Netlify configuration file\\n\\nCreate a `netlify.toml` file in the root of your project and add the following content:\\n\\n```toml copy filename=\"netlify.toml\"\\n[functions]\\n  deno_import_map = \"./import_map.json\"\\n\\n[[edge_functions]]\\n  path = \"/user\"\\n  function = \"user\"\\n```\\n\\nThis configuration tells Netlify to use the `import_map.json` file for Deno imports and to route requests to the `/user` path to the `user.ts` function. \\nRead more about `netlify.toml` [here](https://docs.netlify.com/configure-builds/file-based-configuration/).\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `netlify/edge-functions/common` directory and declare a table schema:\\n\\n```typescript copy filename=\"netlify/edge-functions/common/schema.ts\"\\nimport { pgTable, serial, text, integer } from \"drizzle-orm/pg-core\";\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\'; // remove this line if you use Node.js v20.6.0 or later\\nimport type { Config } from \"drizzle-kit\";\\n\\nexport default {\\n  schema: \\'./netlify/edge-functions/common/schema.ts\\',\\n  out: \\'./drizzle\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n} satisfies Config;\\n```\\n\\nIn this tutorial we will use Drizzle kit to push changes to the Neon database.\\n\\n#### Apply changes to the database\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\nAlternatively, you can use migrations workflow. Read about it here: [Migrations](/docs/migrations).\\n\\n#### Connect Drizzle ORM to your database\\n\\nUpdate your `netlify/edge-functions/user.ts` file and set up your database configuration:\\n\\n```typescript copy filename=\"netlify/edge-functions/user.ts\"\\nimport type { Context } from \"@netlify/edge-functions\";\\nimport { usersTable } from \"./common/schema.ts\";\\nimport { neon } from \\'@neondatabase/serverless\\';\\nimport { drizzle } from \\'drizzle-orm/neon-http\\';\\n\\nexport default async (request: Request, context: Context) => {\\n  const sql = neon(Netlify.env.get(\"DATABASE_URL\")!);\\n  const db = drizzle({ client: sql });\\n\\n  const users = await db.select().from(usersTable);\\n\\n  return new Response(JSON.stringify(users));\\n};\\n```\\n\\n<Callout type=\"warning\">\\nYou might see a red underline under the imports if you\\'re using VS Code. The Edge Function will still execute. To get rid of the red underline, you can configure VS Code to use Edge Functions in the next step.\\n</Callout>\\n\\n#### Test your code locally\\n\\nRun the following command to start the Netlify dev server:\\n\\n```bash copy\\nnetlify dev\\n```\\n\\nWhen you first run the command it will suggest to configure VS Code to use Edge Functions. Click `Yes` to configure it. `settings.json` file will be created in the `.vscode` directory.\\nIf you still see red underlines, you can restart the Deno Language Server.\\n\\nOpen your browser and navigate to the route `/user`. You should see the user data returned from the Neon database:\\n\\n```plaintext\\n[]\\n```\\n\\nIt could be an empty array if you haven\\'t added any data to the `users_table` table.\\n\\n#### Initialize a new Netlify project\\n\\nRun the following command to initialize a new Netlify project:\\n\\n```bash copy\\nnetlify init\\n```\\n\\nAnswer the questions in the CLI to create a new Netlify project. In this tutorial, we will choose `Yes, create and deploy site manually` -> `<YOUR_TEAM>` -> `<SITE_NAME>`.\\n\\n#### Setup Netlify environment variables\\n\\nRun the following command to import your environment variables into Netlify:\\n\\n```bash copy\\nnetlify env:import .env\\n```\\n\\nRead more about Netlify environment variables [here](https://docs.netlify.com/environment-variables/get-started/).\\n\\n#### Deploy your project\\n\\nRun the following command to deploy your project:\\n\\n```bash copy\\nnetlify deploy\\n```\\n\\nFollow the instructions in the CLI to deploy your project to Netlify. In this tutorial our publish directory is `\\'.\\'`.\\n\\nIt is a [draft deployment](https://docs.netlify.com/cli/get-started/#draft-deploys) by default.\\nTo do a production deployment, run the following command:\\n\\n```bash copy\\nnetlify deploy --prod\\n```\\n\\n</Steps>\\n\\nFinally, you can use URL of the deployed website and navigate to the route you created `(e.g. /user)` to access your edge function.\\n\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-on-the-edge/drizzle-with-netlify-edge-functions-supabase.mdx'), name='drizzle-with-netlify-edge-functions-supabase.mdx', displayName='drizzle-with-netlify-edge-functions-supabase.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Netlify Edge Functions and Supabase Database\"\\ndate: \"2025-01-30\"\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Netlify Edge Functions](https://docs.netlify.com/edge-functions/overview/) and [Supabase Database](https://supabase.com/docs/guides/database/overview) database.\\n\\n<Prerequisites>\\n- You should have the latest version of [Netlify CLI](https://docs.netlify.com/cli/get-started/#installation) installed.\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n- You should have installed the `dotenv` package for managing environment variables. If you use Node.js `v20.6.0` or later, there is no need to install it because Node.js natively supports `.env` files. Read more about it [here](https://nodejs.org/en/blog/release/v20.6.0#built-in-env-file-support).\\n<Npm>\\n  dotenv\\n</Npm>\\n\\n- Optionally, you can install the `@netlify/edge-functions` package to import the types for the `Context` object which will be used later.\\n<Npm>\\n  @netlify/edge-functions\\n</Npm>\\n</Prerequisites>\\n\\n<Callout type=\"warning\">\\nThese installed packages are used only to create table in the database in [Create a table](#create-a-table), [Setup Drizzle config file](#setup-drizzle-config-file) and [Apply changes to the database](#apply-changes-to-the-database) steps. These packages do not affect the code running inside Netlify Edge Functions. We will use `import_map.json` to import the necessary packages for the Edge Functions.\\n</Callout>\\n\\n<Steps>\\n#### Create a new Supabase project\\n\\nYou can create new Supabase project in the [dashboard](https://supabase.com/dashboard) or by following this [link](https://database.new/).\\n\\n#### Setup connection string variable\\n\\nYou can find `Project connect details` by clicking **Connect** in the top bar of the dashboard and copy the URI from the `Transaction pooler` section. Remember to replace the password placeholder with your actual database password.\\n\\nAdd `DATABASE_URL` variable to your `.env` file.\\n\\n```plaintext copy\\nDATABASE_URL=<YOUR_DATABASE_URL>\\n```\\n\\nRead more about connecting to Supabase Database in the [documentation](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler).\\n\\n#### Setup Netlify Edge Functions\\n\\nCreate `netlify/edge-functions` directory in the root of your project. This is where you\\'ll store your Edge Functions.\\n\\nCreate a function `user.ts` in the `netlify/edge-functions` directory.\\n\\n```typescript copy filename=\"netlify/edge-functions/user.ts\"\\nimport type { Context } from \"@netlify/edge-functions\";\\n\\nexport default async (request: Request, context: Context) => {\\n  return new Response(\"User data\");\\n};\\n```\\n\\n<Callout type=\"warning\">\\nThe types for the `Request` and `Response` objects are in the global scope.\\n</Callout>\\n\\n#### Setup imports\\n\\nCreate a `import_map.json` file in the root of your project and add the following content:\\n\\n```json copy filename=\"import_map.json\"\\n{\\n  \"imports\": {\\n    \"drizzle-orm/\": \"https://esm.sh/drizzle-orm/\",\\n    \"postgres\": \"https://esm.sh/postgres\"\\n  }\\n}\\n```\\n\\nRead more about `import_map.json` in Netlify Edge Functions [here](https://docs.netlify.com/edge-functions/api/#import-maps).\\n\\n#### Create a Netlify configuration file\\n\\nCreate a `netlify.toml` file in the root of your project and add the following content:\\n\\n```toml copy filename=\"netlify.toml\"\\n[functions]\\n  deno_import_map = \"./import_map.json\"\\n\\n[[edge_functions]]\\n  path = \"/user\"\\n  function = \"user\"\\n```\\n\\nThis configuration tells Netlify to use the `import_map.json` file for Deno imports and to route requests to the `/user` path to the `user.ts` function. \\nRead more about `netlify.toml` [here](https://docs.netlify.com/configure-builds/file-based-configuration/).\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `netlify/edge-functions/common` directory and declare a table schema:\\n\\n```typescript copy filename=\"netlify/edge-functions/common/schema.ts\"\\nimport { pgTable, serial, text, integer } from \"drizzle-orm/pg-core\";\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\'; // remove this line if you use Node.js v20.6.0 or later\\nimport type { Config } from \"drizzle-kit\";\\n\\nexport default {\\n  schema: \\'./netlify/edge-functions/common/schema.ts\\',\\n  out: \\'./drizzle\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n} satisfies Config;\\n```\\n\\nIn this tutorial we will use Drizzle kit to push changes to the Neon database.\\n\\n#### Apply changes to the database\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\nAlternatively, you can use migrations workflow. Read about it here: [Migrations](/docs/migrations).\\n\\n#### Connect Drizzle ORM to your database\\n\\nUpdate your `netlify/edge-functions/user.ts` file and set up your database configuration:\\n\\n```typescript copy filename=\"netlify/edge-functions/user.ts\"\\nimport type { Context } from \"@netlify/edge-functions\";\\nimport { usersTable } from \"./common/schema.ts\";\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nexport default async (request: Request, context: Context) => {\\n  const queryClient = postgres(Netlify.env.get(\"DATABASE_URL\")!);\\n  const db = drizzle({ client: queryClient });\\n\\n  const users = await db.select().from(usersTable);\\n\\n  return new Response(JSON.stringify(users));\\n};\\n```\\n\\n<Callout type=\"warning\">\\nYou might see a red underline under the imports if you\\'re using VS Code. The Edge Function will still execute. To get rid of the red underline, you can configure VS Code to use Edge Functions in the next step.\\n</Callout>\\n\\n#### Test your code locally\\n\\nRun the following command to start the Netlify dev server:\\n\\n```bash copy\\nnetlify dev\\n```\\n\\nWhen you first run the command it will suggest to configure VS Code to use Edge Functions. Click `Yes` to configure it. `settings.json` file will be created in the `.vscode` directory.\\nIf you still see red underlines, you can restart the Deno Language Server.\\n\\nOpen your browser and navigate to the route `/user`. You should see the user data returned from the Neon database:\\n\\n```plaintext\\n[]\\n```\\n\\nIt could be an empty array if you haven\\'t added any data to the `users_table` table.\\n\\n#### Initialize a new Netlify project\\n\\nRun the following command to initialize a new Netlify project:\\n\\n```bash copy\\nnetlify init\\n```\\n\\nAnswer the questions in the CLI to create a new Netlify project. In this tutorial, we will choose `Yes, create and deploy site manually` -> `<YOUR_TEAM>` -> `<SITE_NAME>`.\\n\\n#### Setup Netlify environment variables\\n\\nRun the following command to import your environment variables into Netlify:\\n\\n```bash copy\\nnetlify env:import .env\\n```\\n\\nRead more about Netlify environment variables [here](https://docs.netlify.com/environment-variables/get-started/).\\n\\n#### Deploy your project\\n\\nRun the following command to deploy your project:\\n\\n```bash copy\\nnetlify deploy\\n```\\n\\nFollow the instructions in the CLI to deploy your project to Netlify. In this tutorial our publish directory is `\\'.\\'`.\\n\\nIt is a [draft deployment](https://docs.netlify.com/cli/get-started/#draft-deploys) by default.\\nTo do a production deployment, run the following command:\\n\\n```bash copy\\nnetlify deploy --prod\\n```\\n\\n</Steps>\\n\\nFinally, you can use URL of the deployed website and navigate to the route you created `(e.g. /user)` to access your edge function.\\n\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-on-the-edge/drizzle-with-supabase-edge-functions.mdx'), name='drizzle-with-supabase-edge-functions.mdx', displayName='drizzle-with-supabase-edge-functions.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Supabase Edge Functions\"\\ndate: \"2024-05-03\"\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Supabase Edge Functions](https://supabase.com/docs/guides/functions).\\n\\n<Prerequisites>\\n- You should have the latest version of [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started#installing-the-supabase-cli) installed.\\n- You should have installed Drizzle ORM and [Drizzle kit](https://orm.drizzle.team/kit-docs/overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n- You should have installed Docker Desktop. It is a prerequisite for local development. Follow the official [docs](https://docs.docker.com/desktop) to install.\\n</Prerequisites>\\n\\nTo learn how to create a basic Edge Function on your local machine and then deploy it, see the [Edge Functions Quickstart](https://supabase.com/docs/guides/functions/quickstart).\\n\\n<Steps>\\n#### Create a table\\n\\nCreate a `schema.ts` file in your `src` directory and declare a table schema:\\n\\n```typescript copy filename=\"src/schema.ts\"\\nimport { pgTable, serial, text, integer } from \"drizzle-orm/pg-core\";\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull()\\n})\\n```\\n\\nThis file will be used to generate migrations for your database.\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](https://orm.drizzle.team/kit-docs/overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/schema.ts\",\\n  out: \"./supabase/migrations\",\\n  dialect: \"postgresql\",\\n});\\n```\\n\\nIn this tutorial we will use Drizzle kit to generate migrations for our schema.\\n\\n#### Initialize a new Supabase project\\n\\nCreate a new Supabase project in a folder on your local machine:\\n\\n```bash copy\\nsupabase init\\n```\\n\\nIt will create `supabase` folder with `config.toml` file:\\n\\n```text\\nâ””â”€â”€ supabase\\n    â””â”€â”€ config.toml\\n```\\n\\nIf you are using Visual Studio Code, follow the [Supabase documentation](https://supabase.com/docs/guides/functions/local-development#deno-with-visual-studio-code) to setup settings for Deno.\\n\\n#### Generate migrations\\n\\nRun the `drizzle-kit generate` command to generate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nIt will create a new migration file in the `supabase/migrations` directory:\\n\\n#### Apply migrations\\n\\nTo start the Supabase local development stack, run the following command:\\n\\n```bash copy\\nsupabase start\\n```\\n\\nTo apply migrations, run the following command:\\n\\n```bash copy\\nsupabase migration up\\n```\\n\\nYou can read more about Supabase migrations in the [documentation](https://supabase.com/docs/guides/deployment/database-migrations).\\n\\n<Callout type=\"warning\">Don\\'t forget to run Docker</Callout>\\n\\nAlternatively, you can apply migrations using the `drizzle-kit migrate` command. Learn more about this migration process in the [documentation](https://orm.drizzle.team/docs/migrations).\\n\\n#### Create a new Edge Function\\n\\nRun the `supabase functions new [FUNCTION_NAME]` command to create a new Edge Function:\\n\\n```bash copy\\nsupabase functions new drizzle-tutorial\\n```\\n\\nIt will create a new folder with the function name in the `supabase/functions` directory:\\n\\n```text\\nâ””â”€â”€ supabase\\n    â””â”€â”€ functions\\n    â”‚   â””â”€â”€ drizzle-tutorial\\n    â”‚   â”‚   â”œâ”€â”€ .npmrc ## Function-specific npm configuration (if needed)\\n    â”‚   â”‚   â”œâ”€â”€ deno.json ## Function-specific Deno configuration\\n    â”‚   â”‚   â””â”€â”€ index.ts ## Your function code\\n```\\n\\nWhen you create a new Edge Function, it will use TypeScript by default. However, it is possible write Edge Function in JavaScript. Learn more about it in the [documentation](https://supabase.com/docs/guides/functions/quickstart#not-using-typescript).\\n\\n#### Setup imports\\n\\nAdd the following imports to the `deno.json` file in the `supabase/functions/drizzle-tutorial` directory:\\n\\n```json copy filename=\"supabase/functions/drizzle-tutorial/deno.json\"\\n{\\n  \"imports\": {\\n    \"drizzle-orm/\": \"npm:/drizzle-orm/\",\\n    \"postgres\": \"npm:postgres\"\\n  }\\n}\\n```\\n\\nYou can read more about managing dependencies [here](https://supabase.com/docs/guides/functions/dependencies#managing-dependencies).\\n\\n#### Copy your schema to the functions directory\\n\\nCopy the code that you will use in your edge function from `src/schema.ts` file to the `supabase/functions/drizzle-tutorial/index.ts` file:\\n\\n```typescript copy filename=\"supabase/functions/drizzle-tutorial/index.ts\"\\n// Setup type definitions for built-in Supabase Runtime APIs\\nimport \"jsr:@supabase/functions-js/edge-runtime.d.ts\"\\nimport { pgTable, serial, text, integer } from \"drizzle-orm/pg-core\";\\n\\nconst usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull()\\n})\\n\\nDeno.serve(async (req) => {\\n  const { name } = await req.json()\\n  const data = {\\n    message: `Hello ${name}!`,\\n  }\\n\\n  return new Response(\\n    JSON.stringify(data),\\n    { headers: { \"Content-Type\": \"application/json\" } },\\n  )\\n})  \\n```\\n\\n<Callout type=\"warning\">\\nIn the Deno ecosystem, each function should be treated as an independent project with its own set of dependencies and configurations.\\nFor these reasons, Supabase recommend maintaining separate configuration files (`deno.json`, `.npmrc`, or `import_map.json`) within each function\\'s directory, even if it means duplicating some configurations. Read more [here](https://supabase.com/docs/guides/functions/dependencies#managing-dependencies).\\n</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nUpdate your edge function code with your database configuration:\\n\\n```typescript copy filename=\"supabase/functions/drizzle-tutorial/index.ts\" {14,17,18}\\n// Setup type definitions for built-in Supabase Runtime APIs\\nimport { integer, pgTable, serial, text } from \"drizzle-orm/pg-core\";\\nimport { drizzle } from \"drizzle-orm/postgres-js\";\\nimport \"jsr:@supabase/functions-js/edge-runtime.d.ts\";\\nimport postgres from \"postgres\";\\n\\nconst usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull()\\n})\\n\\nDeno.serve(async () => {\\n  const connectionString = Deno.env.get(\"SUPABASE_DB_URL\")!;\\n\\n  // Disable prefetch as it is not supported for \"Transaction\" pool mode\\n  const client = postgres(connectionString, { prepare: false });\\n  const db = drizzle({ client });\\n\\n  await db.insert(usersTable).values({\\n    name: \"Alice\",\\n    age: 25\\n  })\\n  const data = await db.select().from(usersTable);\\n\\n  return new Response(\\n    JSON.stringify(data)\\n  )\\n})\\n```\\n\\n`SUPABASE_DB_URL` is default environment variable for the direct database connection. Learn more about managing environment variables in Supabase Edge Functions in the [documentation](https://supabase.com/docs/guides/functions/secrets).\\n\\n#### Test your code locally\\n\\nRun the following command to test your function locally:\\n\\n```bash copy\\nsupabase functions serve --no-verify-jwt\\n```\\n\\nNavigate to the route `(e.g. /drizzle-tutorial)` in your browser:\\n\\n```plaintext\\n[\\n  {\\n    \"id\": 1,\\n    \"name\": \"Alice\",\\n    \"age\": 25\\n  }\\n]\\n```\\n\\n#### Link your local project to a hosted Supabase project\\n\\nYou can create new Supabase project in the [dashboard](https://supabase.com/dashboard) or by following this [link](https://database.new/).\\n\\nCopy the `Reference ID` from project settings and use it to link your local development project to a hosted Supabase project by running the following command:\\n\\n```bash copy\\nsupabase link --project-ref=<REFERENCE_ID>\\n```\\n\\nPush your schema changes to the hosted Supabase project by running the following command:\\n\\n```bash copy\\nsupabase db push\\n```\\n\\n#### Setup environment variables\\n\\nYou can find `Project connect details` by clicking **Connect** in the top bar of the dashboard and copy the URI from the `Transaction pooler` section. Remember to replace the password placeholder with your actual database password.\\n\\nRead more about Connection Pooler in the [documentation](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler).\\n\\nUpdate your edge function code to use the `DATABASE_URL` environment variable instead of `SUPABASE_DB_URL`:\\n\\n```typescript copy filename=\"supabase/functions/drizzle-tutorial/index.ts\"\\n// imports\\n\\n// const connectionString = Deno.env.get(\"SUPABASE_DB_URL\")!;\\nconst connectionString = Deno.env.get(\"DATABASE_URL\")!;\\n\\n// code\\n```\\n\\nRun the following command to set the environment variable:\\n\\n```bash copy\\nsupabase secrets set DATABASE_URL=<CONNECTION_STRING>\\n```\\n\\nLearn more about managing environment variables in Supabase Edge Functions in the [documentation](https://supabase.com/docs/guides/functions/secrets).\\n\\n#### Deploy your function\\n\\nDeploy your function by running the following command:\\n\\n```bash copy\\nsupabase functions deploy drizzle-tutorial --no-verify-jwt\\n```\\n</Steps>\\n\\nFinally, you can use URL of the deployed project and navigate to the route you created `(e.g. /drizzle-tutorial)` to access your edge function.\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-on-the-edge/drizzle-with-vercel-edge-functions.mdx'), name='drizzle-with-vercel-edge-functions.mdx', displayName='drizzle-with-vercel-edge-functions.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Vercel Edge Functions\"\\ndate: \"2024-04-17\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12 5L4 19H20L12 5Z\" fill=\"currentColor\" stroke=\"currentColor\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/></svg>]\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Vercel Functions](https://vercel.com/docs/functions) in [Edge runtime](https://vercel.com/docs/functions/runtimes/edge-runtime).\\n\\n<Prerequisites>\\n- You should have the latest version of [Vercel CLI](https://vercel.com/docs/cli#) installed.\\n<Npm>\\n-g vercel\\n</Npm>\\n\\n- You should have an existing Next.js project or create a new one using the following command:\\n\\n```bash copy\\nnpx create-next-app@latest --typescript\\n```\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n</Prerequisites>\\n\\n<Callout type=\"warning\">\\nIn case you face the issue with resolving dependencies during installation:\\n\\nIf you\\'re not using React Native, forcing the installation with `--force` or `--legacy-peer-deps` should resolve the issue. If you are using React Native, then you need to use the exact version of React which is compatible with your React Native version.\\n</Callout>\\n\\n## Edge-compatible driver\\n\\nWhen using Drizzle ORM with Vercel Edge functions you have to use edge-compatible drivers because the functions run in [Edge runtime](https://vercel.com/docs/functions/runtimes/edge-runtime) not in Node.js runtime, so there are some limitations of standard Node.js APIs.\\n\\nYou can choose one of these drivers according to your database dialect:\\n\\n- [Neon serverless driver](/docs/get-started-postgresql#neon) allows you to query your Neon Postgres databases from serverless and edge environments over HTTP or WebSockets in place of TCP. We recommend using this driver for connecting to `Neon Postgres`.\\n- [Vercel Postgres driver](/docs/get-started-postgresql#vercel-postgres) is built on top of the `Neon serverless driver`. We recommend using this driver for connecting to `Vercel Postgres`.\\n- [PlanetScale serverless driver](/docs/get-started-mysql#planetscale) allows you access any `MySQL` client and execute queries over an HTTP connection, which is generally not blocked by cloud providers.\\n- [libSQL client](/docs/get-started-sqlite#turso) allows you to access [Turso](https://docs.turso.tech/introduction) database.\\n\\n## Navigation\\n\\n- Navigate directly to the [Neon Postgres](/docs/tutorials/drizzle-with-vercel-edge-functions#neon-postgres) section.\\n- Navigate directly to the [Vercel Postgres](/docs/tutorials/drizzle-with-vercel-edge-functions#vercel-postgres) section.\\n- Navigate directly to the [PlanetScale](/docs/tutorials/drizzle-with-vercel-edge-functions#planetscale) section.\\n- Navigate directly to the [Turso](/docs/tutorials/drizzle-with-vercel-edge-functions#turso) section.\\n\\n### Neon Postgres\\n\\n<Steps>\\n#### Install the `@neondatabase/serverless` driver\\n\\nInstall the `@neondatabase/serverless` driver:\\n\\n<Npm>\\n@neondatabase/serverless\\n</Npm>\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare a table schema:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { pgTable, serial, text } from \"drizzle-orm/pg-core\";\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: text(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/db/schema.ts\",\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: process.env.POSTGRES_URL!,\\n  },\\n});\\n```\\n\\nConfigure your database connection string in the `.env` file:\\n\\n```plaintext filename=\".env\"\\nPOSTGRES_URL=\"postgres://[user]:[password]@[host]-[region].aws.neon.tech:5432/[db-name]?sslmode=[ssl-mode]\"\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle` directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" text NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { drizzle } from \\'drizzle-orm/neon-serverless\\';\\n\\n\\nexport const db = drizzle(process.env.POSTGRES_URL!)\\n```\\n\\n#### Create an API route\\n\\nCreate `route.ts` file in `src/app/api/hello` directory. To learn more about how to write a function, see the [Functions API Reference](https://vercel.com/docs/functions/functions-api-reference) and [Vercel Functions Quickstart](https://vercel.com/docs/functions/quickstart).\\n\\n```ts copy filename=\"src/app/api/hello/route.ts\"\\nimport { db } from \"@/db\";\\nimport { usersTable } from \"@/db/schema\";\\nimport { NextResponse } from \"next/server\";\\n\\nexport const dynamic = \\'force-dynamic\\'; // static by default, unless reading the request\\nexport const runtime = \\'edge\\' // specify the runtime to be edge\\n\\nexport async function GET(request: Request) {\\n  const users = await db.select().from(usersTable)\\n\\n  return NextResponse.json({ users, message: \\'success\\' });\\n}\\n```\\n\\n#### Test your code locally\\n\\nRun the `next dev` command to start your local development server:\\n\\n```bash copy\\nnpx next dev\\n```\\n\\nNavigate to the route you created `(e.g. /api/hello)` in your browser:\\n\\n```plaintext\\n{\\n  \"users\": [],\\n  \"message\": \"success\"\\n}\\n```\\n\\n#### Deploy your project\\n\\nCreate a new project in the [dashboard](https://vercel.com/new) or run the `vercel` command to deploy your project:\\n\\n```bash copy\\nvercel\\n```\\n\\nAdd `POSTGRES_URL` environment variable:\\n\\n```bash copy\\nvercel env add POSTGRES_URL\\n```\\n\\nRedeploy your project to update your environment variables:\\n\\n```bash copy\\nvercel\\n```\\n</Steps>\\n\\nFinally, you can use URL of the deployed project and navigate to the route you created `(e.g. /api/hello)` to access your edge function.\\n\\n### Vercel Postgres\\n\\nYou can check quickstart guide for Drizzle with Vercel Postgres client in the [documentation](/docs/get-started-postgresql#vercel-postgres).\\n\\n<Steps>\\n#### Install the `@vercel/postgres` driver\\n\\nInstall the `@vercel/postgres` driver:\\n\\n<Npm>\\n@vercel/postgres\\n</Npm>\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare a table schema:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { pgTable, serial, text } from \"drizzle-orm/pg-core\";\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: text(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/db/schema.ts\",\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: process.env.POSTGRES_URL!,\\n  },\\n});\\n```\\n\\nConfigure your database connection string in the `.env` file:\\n\\n```plaintext filename=\".env\"\\nPOSTGRES_URL=\"postgres://[user]:[password]@[host]-[region].aws.neon.tech:5432/[db-name]?sslmode=[ssl-mode]\"\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle` directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" text NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\n\\nexport const db = drizzle()\\n```\\n\\n#### Create an API route\\n\\nCreate `route.ts` in `src/app/api/hello` directory. To learn more about how to write a function, see the [Functions API Reference](https://vercel.com/docs/functions/functions-api-reference) and [Vercel Functions Quickstart](https://vercel.com/docs/functions/quickstart).\\n\\n```ts copy filename=\"src/app/api/hello/route.ts\"\\n\\nimport { db } from \"@/db\";\\nimport { usersTable } from \"@/db/schema\";\\nimport { NextResponse } from \"next/server\";\\n\\nexport const dynamic = \\'force-dynamic\\'; // static by default, unless reading the request\\nexport const runtime = \\'edge\\' // specify the runtime to be edge\\n\\nexport async function GET(request: Request) {\\n  const users = await db.select().from(usersTable)\\n\\n  return NextResponse.json({ users, message: \\'success\\' });\\n}\\n```\\n\\n#### Test your code locally\\n\\nRun the `next dev` command to start your local development server:\\n\\n```bash copy\\nnpx next dev\\n```\\n\\nNavigate to the route you created `(e.g. /api/hello)` in your browser:\\n\\n```plaintext\\n{\\n  \"users\": [],\\n  \"message\": \"success\"\\n}\\n```\\n\\n#### Deploy your project\\n\\nCreate a new project in the [dashboard](https://vercel.com/new) or run the `vercel` command to deploy your project:\\n\\n```bash copy\\nvercel\\n```\\n\\nAdd `POSTGRES_URL` environment variable:\\n\\n```bash copy\\nvercel env add POSTGRES_URL\\n```\\n\\nRedeploy your project to update your environment variables:\\n\\n```bash copy\\nvercel\\n```\\n</Steps>\\n\\nFinally, you can use URL of the deployed project and navigate to the route you created `(e.g. /api/hello)` to access your edge function.\\n\\n### PlanetScale\\n\\nIn this tutorial we use [PlanetScale MySQL](https://planetscale.com).\\n\\n<Steps>\\n#### Install the `@planetscale/database` driver\\n\\nInstall the `@planetscale/database` driver:\\n\\n<Npm>\\n@planetscale/database\\n</Npm>\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare a table schema:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { mysqlTable, serial, text } from \"drizzle-orm/mysql-core\";\\n\\nexport const usersTable = mysqlTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: text(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/db/schema.ts\",\\n  dialect: \"mysql\",\\n  dbCredentials: {\\n    url: process.env.MYSQL_URL!,\\n  },\\n});\\n```\\n\\nConfigure your database connection string in the `.env` file:\\n\\n```plaintext filename=\".env\"\\nMYSQL_URL=\"mysql://[user]:[password]@[host].[region].psdb.cloud/[db-name]?ssl={\\'rejectUnauthorized\\':[ssl-rejectUnauthorized]}\"\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle` directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE `users_table` (\\n\\t`id` serial AUTO_INCREMENT NOT NULL,\\n\\t`name` text NOT NULL,\\n\\t`age` text NOT NULL,\\n\\t`email` text NOT NULL,\\n\\tCONSTRAINT `users_table_id` PRIMARY KEY(`id`),\\n\\tCONSTRAINT `users_table_email_unique` UNIQUE(`email`)\\n);\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { drizzle } from \"drizzle-orm/planetscale-serverless\";\\n\\nexport const db = drizzle(process.env.MYSQL_URL!)\\n```\\n\\n#### Create an API route\\n\\nCreate `route.ts` in `src/app/api/hello` directory. To learn more about how to write a function, see the [Functions API Reference](https://vercel.com/docs/functions/functions-api-reference) and [Vercel Functions Quickstart](https://vercel.com/docs/functions/quickstart).\\n\\n```ts copy filename=\"src/app/api/hello/route.ts\"\\nimport { db } from \"@/app/db/db\";\\nimport { usersTable } from \"@/app/db/schema\";\\nimport { NextResponse } from \"next/server\";\\n\\nexport const dynamic = \\'force-dynamic\\'; // static by default, unless reading the request\\nexport const runtime = \\'edge\\' // specify the runtime to be edge\\n\\nexport async function GET(request: Request) {\\n  const users = await db.select().from(usersTable)\\n\\n  return NextResponse.json({ users, message: \\'success\\' });\\n}\\n```\\n\\n#### Test your code locally\\n\\nRun the `next dev` command to start your local development server:\\n\\n```bash copy\\nnpx next dev\\n```\\n\\nNavigate to the route you created `(e.g. /api/hello)` in your browser:\\n\\n```plaintext\\n{\\n  \"users\": [],\\n  \"message\": \"success\"\\n}\\n```\\n\\n#### Deploy your project\\n\\nCreate a new project in the [dashboard](https://vercel.com/new) or run the `vercel` command to deploy your project:\\n\\n```bash copy\\nvercel\\n```\\n\\nAdd `MYSQL_URL` environment variable:\\n\\n```bash copy\\nvercel env add MYSQL_URL\\n```\\n\\nRedeploy your project to update your environment variables:\\n\\n```bash copy\\nvercel\\n```\\n</Steps>\\n\\nFinally, you can use URL of the deployed project and navigate to the route you created `(e.g. /api/hello)` to access your edge function.\\n\\n### Turso\\n\\nYou can check [quickstart guide](/docs/get-started-sqlite#turso) or [tutorial](/docs/tutorials/drizzle-with-turso) for Drizzle with Turso in the documentation.\\n\\n<Steps>\\n#### Install the `@libsql/client` driver\\n\\nInstall the `@libsql/client` driver:\\n\\n<Npm>\\n@libsql/client\\n</Npm>\\n\\n#### Create a table\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare a table schema:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { integer, sqliteTable, text } from \"drizzle-orm/sqlite-core\";\\n\\nexport const usersTable = sqliteTable(\\'users_table\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: text(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n})\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nexport default defineConfig({\\n  schema: \"./src/db/schema.ts\",\\n  dialect: \"turso\",\\n  dbCredentials: {\\n    url: process.env.TURSO_CONNECTION_URL!,\\n    authToken: process.env.TURSO_AUTH_TOKEN!,\\n  },\\n});\\n```\\n\\nConfigure your database connection string and auth token in the `.env` file:\\n\\n```plaintext filename=\".env\"\\nTURSO_CONNECTION_URL=\"libsql://[db-name].turso.io\"\\nTURSO_AUTH_TOKEN=\"[auth-token]\"\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle` directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE `users_table` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`name` text NOT NULL,\\n\\t`age` text NOT NULL,\\n\\t`email` text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE UNIQUE INDEX `users_table_email_unique` ON `users_table` (`email`);\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\nexport const db = drizzle({ connection: {\\n  url: process.env.TURSO_CONNECTION_URL!,\\n  authToken: process.env.TURSO_AUTH_TOKEN!,\\n}})\\n```\\n\\n#### Create an API route\\n\\nCreate `route.ts` in `src/app/api/hello` directory. To learn more about how to write a function, see the [Functions API Reference](https://vercel.com/docs/functions/functions-api-reference) and [Vercel Functions Quickstart](https://vercel.com/docs/functions/quickstart).\\n\\n```ts copy filename=\"src/app/api/hello/route.ts\"\\nimport { db } from \"@/app/db/db\";\\nimport { usersTable } from \"@/app/db/schema\";\\nimport { NextResponse } from \"next/server\";\\n\\nexport const dynamic = \\'force-dynamic\\'; // static by default, unless reading the request\\nexport const runtime = \\'edge\\' // specify the runtime to be edge\\n\\nexport async function GET(request: Request) {\\n  const users = await db.select().from(usersTable)\\n\\n  return NextResponse.json({ users, message: \\'success\\' });\\n}\\n```\\n\\n#### Test your code locally\\n\\nRun the `next dev` command to start your local development server:\\n\\n```bash copy\\nnpx next dev\\n```\\n\\nNavigate to the route you created `(e.g. /api/hello)` in your browser:\\n\\n```plaintext\\n{\\n  \"users\": [],\\n  \"message\": \"success\"\\n}\\n```\\n\\n#### Deploy your project\\n\\nCreate a new project in the [dashboard](https://vercel.com/new) or run the `vercel` command to deploy your project:\\n\\n```bash copy\\nvercel\\n```\\n\\nAdd `TURSO_CONNECTION_URL` environment variable:\\n\\n```bash copy\\nvercel env add TURSO_CONNECTION_URL\\n```\\n\\nAdd `TURSO_AUTH_TOKEN` environment variable:\\n\\n```bash copy\\nvercel env add TURSO_AUTH_TOKEN\\n```\\n\\nRedeploy your project to update your environment variables:\\n\\n```bash copy\\nvercel\\n```\\n</Steps>\\n\\nFinally, you can use URL of the deployed project and navigate to the route you created `(e.g. /api/hello)` to access your edge function.\\n', children=[])]), DocItem(origPath=Path('tutorials/drizzle-with-db'), name='drizzle-with-db', displayName='drizzle-with-db', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='', children=[DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-neon.mdx'), name='drizzle-with-neon.mdx', displayName='drizzle-with-neon.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Neon Postgres\"\\ndate: \"2024-05-10\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\',<svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M4 6.75867C4 6.02702 4.29064 5.32535 4.80799 4.80799C5.32535 4.29064 6.02702 4 6.75867 4H17.2413C17.973 4 18.6747 4.29064 19.192 4.80799C19.7094 5.32535 20 6.02702 20 6.75867V15.6742C20 17.2502 18.0053 17.9342 17.0382 16.6902L14.0138 12.7996V17.5173C14.0138 18.1758 13.7522 18.8073 13.2866 19.2728C12.821 19.7384 12.1896 20 11.5311 20H6.75867C6.02702 20 5.32535 19.7094 4.80799 19.192C4.29064 18.6747 4 17.973 4 17.2413V6.75867ZM6.75867 6.20711C6.45378 6.20711 6.20711 6.45378 6.20711 6.75822V17.2413C6.20711 17.5462 6.45378 17.7933 6.75822 17.7933H11.6138C11.7662 17.7933 11.8067 17.6698 11.8067 17.5173V11.1911C11.8067 9.61467 13.8013 8.93067 14.7689 10.1751L17.7933 14.0653V6.75867C17.7933 6.45378 17.8218 6.20711 17.5173 6.20711H6.75867Z\" /></svg>]\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \"@mdx/Npm.astro\";\\nimport Steps from \"@mdx/Steps.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Neon Postgres](https://neon.tech/) database. If you do not have an existing Neon account, sign up [here](https://neon.tech). \\n\\n<Prerequisites>  \\n  - You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n  <Npm>\\n    drizzle-orm \\n    -D drizzle-kit\\n  </Npm>\\n\\n  - You should also install the [Neon serverless driver](https://neon.tech/docs/serverless/serverless-driver). \\n  <Npm>\\n    @neondatabase/serverless\\n  </Npm>\\n  \\n  - You should have installed the `dotenv` package for managing environment variables. \\n  <Npm>\\n    dotenv\\n  </Npm>  \\n</Prerequisites>\\n\\n## Setup Neon and Drizzle ORM\\n\\n<Steps>\\n#### Create a new Neon project\\n\\nLog in to the [Neon Console](https://console.neon.tech/app/projects) and navigate to the Projects section. Select a project or click the `New Project` button to create a new one. \\n\\nYour Neon projects come with a ready-to-use Postgres database named `neondb`. We\\'ll use it in this tutorial.\\n\\n#### Setup connection string variable\\n\\nNavigate to the **Connection Details** section in the project console to find your database connection string. It should look similar to this:\\n\\n```bash\\npostgres://username:password@ep-cool-darkness-123456.us-east-2.aws.neon.tech/neondb\\n```\\n\\nAdd the `DATABASE_URL` environment variable to your `.env` or `.env.local` file, which you\\'ll use to connect to the Neon database.\\n\\n```text copy\\nDATABASE_URL=NEON_DATABASE_CONNECTION_STRING\\n```\\n\\n#### Connect Drizzle ORM to your database \\n\\nCreate a `db.ts` file and set up your database configuration:\\n\\n```typescript copy filename=\"src/db.ts\"\\nimport { drizzle } from \"drizzle-orm/neon-http\";\\nimport { neon } from \"@neondatabase/serverless\";\\nimport { config } from \"dotenv\";\\n\\nconfig({ path: \".env\" }); // or .env.local\\n\\nconst sql = neon(process.env.DATABASE_URL!);\\nexport const db = drizzle({ client: sql });\\n```\\n\\n#### Create tables\\n\\nCreate a `schema.ts` file and declare your tables:\\n\\n```typescript copy filename=\"src/schema.ts\"\\nimport { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n});\\n\\nexport const postsTable = pgTable(\\'posts_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  title: text(\\'title\\').notNull(),\\n  content: text(\\'content\\').notNull(),\\n  userId: integer(\\'user_id\\')\\n    .notNull()\\n    .references(() => usersTable.id, { onDelete: \\'cascade\\' }),\\n  createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  updatedAt: timestamp(\\'updated_at\\')\\n    .notNull()\\n    .$onUpdate(() => new Date()),\\n});\\n\\nexport type InsertUser = typeof usersTable.$inferInsert;\\nexport type SelectUser = typeof usersTable.$inferSelect;\\n\\nexport type InsertPost = typeof postsTable.$inferInsert;\\nexport type SelectPost = typeof postsTable.$inferSelect;\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nconfig({ path: \\'.env\\' });\\n\\nexport default defineConfig({\\n  schema: \"./src/schema.ts\",\\n  out: \"./migrations\",\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle/migrations`  directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"posts_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"content\" text NOT NULL,\\n\\t\"user_id\" integer NOT NULL,\\n\\t\"created_at\" timestamp DEFAULT now() NOT NULL,\\n\\t\"updated_at\" timestamp NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" integer NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"posts_table\" ADD CONSTRAINT \"posts_table_user_id_users_table_id_fk\" FOREIGN KEY (\"user_id\") REFERENCES \"public\".\"users_table\"(\"id\") ON DELETE cascade ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n</Steps>\\n\\n### Basic file structure\\n\\nThis is the basic file structure of the project. In the `src/db` directory, we have database-related files including connection in `db.ts`, schema definitions in `schema.ts`, and a migration script in `migrate.ts` file which is responsible for applying migrations that stored in the `migrations` directory.\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“œ db.ts\\n â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“‚ migrations\\n â”‚  â”œ ðŸ“‚ meta\\n â”‚  â”‚  â”œ ðŸ“œ _journal.json\\n â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚  â”” ðŸ“œ 0000_dry_richard_fisk.sql\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n## Query examples\\n\\nFor instance, we create `src/queries` folder and separate files for each operation: insert, select, update, delete.\\n\\n#### Insert data\\n\\nRead more about insert query in the [documentation](/docs/insert).\\n\\n```typescript copy filename=\"src/queries/insert.ts\" {4, 8}\\nimport { db } from \\'../db\\';\\nimport { InsertPost, InsertUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function createUser(data: InsertUser) {\\n  await db.insert(usersTable).values(data);\\n}\\n\\nexport async function createPost(data: InsertPost) {\\n  await db.insert(postsTable).values(data);\\n}\\n```\\n\\n#### Select data\\n\\nRead more about select query in the [documentation](/docs/select).\\n\\n```typescript copy filename=\"src/queries/select.ts\" {5, 16, 41}\\nimport { asc, between, count, eq, getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../db\\';\\nimport { SelectUser, usersTable, postsTable } from \\'../schema\\';\\n\\nexport async function getUserById(id: SelectUser[\\'id\\']): Promise<\\n  Array<{\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db.select().from(usersTable).where(eq(usersTable.id, id));\\n}\\n\\nexport async function getUsersWithPostsCount(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    postsCount: number;\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      ...getTableColumns(usersTable),\\n      postsCount: count(postsTable.id),\\n    })\\n    .from(usersTable)\\n    .leftJoin(postsTable, eq(usersTable.id, postsTable.userId))\\n    .groupBy(usersTable.id)\\n    .orderBy(asc(usersTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nexport async function getPostsForLast24Hours(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    id: number;\\n    title: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      id: postsTable.id,\\n      title: postsTable.title,\\n    })\\n    .from(postsTable)\\n    .where(between(postsTable.createdAt, sql`now() - interval \\'1 day\\'`, sql`now()`))\\n    .orderBy(asc(postsTable.title), asc(postsTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n```\\n\\nAlternatively, you can use [relational query syntax](/docs/rqb).\\n\\n#### Update data\\n\\nRead more about update query in the [documentation](/docs/update).\\n\\n```typescript copy filename=\"src/queries/update.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../db\\';\\nimport { SelectPost, postsTable } from \\'../schema\\';\\n\\nexport async function updatePost(id: SelectPost[\\'id\\'], data: Partial<Omit<SelectPost, \\'id\\'>>) {\\n  await db.update(postsTable).set(data).where(eq(postsTable.id, id));\\n}\\n```\\n\\n#### Delete data\\n\\nRead more about delete query in the [documentation](/docs/delete).\\n\\n```typescript copy filename=\"src/queries/delete.ts\" {5}\\nimport { db } from \\'../db\\';\\nimport { eq } from \\'drizzle-orm\\';\\nimport { SelectUser, usersTable } from \\'../schema\\';\\n\\nexport async function deleteUser(id: SelectUser[\\'id\\']) {\\n  await db.delete(usersTable).where(eq(usersTable.id, id));\\n}\\n```\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-nile.mdx'), name='drizzle-with-nile.mdx', displayName='drizzle-with-nile.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Nile Database\"\\ndate: \"2025-01-15\"\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport TransferCode from \\'@mdx/get-started/TransferCode.mdx\\';\\nimport ApplyChanges from \\'@mdx/get-started/ApplyChanges.mdx\\';\\nimport RunFile from \\'@mdx/get-started/RunFile.mdx\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Nile Database](https://thenile.dev). Nile is Postgres, re-engineered for multi-tenant applications. \\n\\nThis tutorial will demonstrate how to use Drizzle with Nile\\'s virtual tenant databases to developer a secure, scalable, multi-tenant application. \\n\\nWe\\'ll walk through building this example application step-by-step. If you want to peek at the complete example, you can take a look at its [Github repository](https://github.com/niledatabase/niledatabase/tree/main/examples/quickstart/drizzle).\\n\\n<Prerequisites>\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n- You should have installed `dotenv` package for managing environment variables. Read more about this package [here](https://www.npmjs.com/package/dotenv)\\n<Npm>\\n  dotenv\\n</Npm>\\n- You should have installed `node-postgres` package for connecting to the Postgres database. Read more about this package [here](https://www.npmjs.com/package/node-postgres)\\n<Npm>\\n  node-postgres\\n</Npm>\\n- You should have installed `express` package for the web framework. Read more about express [here](https://expressjs.com/)\\n<Npm>\\n  express\\n</Npm>\\n\\n- This guide uses [AsyncLocalStorage](https://nodejs.org/api/async_context.html) to manage the tenant context. If your framework or runtime does not support `AsyncLocalStorage`, you can refer to [Drizzle\\\\<\\\\>Nile](../connect-nile) doc for alternative options. \\n</Prerequisites>\\n\\n## Setup Nile and Drizzle ORM\\n\\n<Steps>\\n#### Signup to Nile and create a database\\n\\nIf you haven\\'t already, sign up to [Nile](https://console.thenile.dev) and follow the app instructions to create a new database.\\n\\n#### Get database connection string\\n\\nOn the left side-bar menu, select the \"Settings\" option, click on the Postgres logo, and click \"generate credentials\". Copy the connection string and add it to the `.env` file in your project:\\n\\n```plaintext copy\\nNILEDB_URL=postgres://youruser:yourpassword@us-west-2.db.thenile.dev:5432:5432/your_db_name\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `db.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/db.ts\"\\nimport { drizzle } from \\'drizzle-orm/node-postgres\\';\\nimport dotenv from \"dotenv/config\";\\nimport { sql } from \"drizzle-orm\";\\nimport { AsyncLocalStorage } from \"async_hooks\";\\n\\nexport const db = drizzle(process.env.NILEDB_URL);\\nexport const tenantContext = new AsyncLocalStorage<string | undefined>();\\n\\nexport function tenantDB<T>(cb: (tx: any) => T | Promise<T>): Promise<T> {\\n  return db.transaction(async (tx) => {\\n    const tenantId = tenantContext.getStore();\\n    console.log(\"executing query with tenant: \" + tenantId);\\n    // if there\\'s a tenant ID, set it in the transaction context\\n    if (tenantId) {\\n      await tx.execute(sql`set local nile.tenant_id = \\'${sql.raw(tenantId)}\\'`);\\n    }\\n\\n    return cb(tx);\\n  }) as Promise<T>;\\n}\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport \\'dotenv/config\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\nexport default defineConfig({\\n  out: \\'./drizzle\\',\\n  schema: \\'./src/db/schema.ts\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.NILEDB_URL!,\\n  },\\n});\\n```\\n\\n#### Introspect Nile database\\n\\nNile databases have built-in tables. The most important of these is the `tenants` table, which is used to create and manage tenants. \\nIn order to use this table from our application, we\\'ll use Drizzle Kit CLI to generate a schema file that includes this schema.\\n\\n```bash copy\\nnpx drizzle-kit pull\\n```\\n\\nThe result of introspection will be a `schema.ts` file, `meta` folder with snapshots of your database schema, sql file with the migration and `relations.ts` file for [relational queries](/docs/rqb).\\n\\n<TransferCode/>\\n\\nHere is an example of the generated `schema.ts` file:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\n// table schema generated by introspection\\nimport { pgTable, uuid, text, timestamp, varchar, vector, boolean } from \"drizzle-orm/pg-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const tenants = pgTable(\"tenants\", {\\n\\tid: uuid().default(sql`public.uuid_generate_v7()`).primaryKey().notNull(),\\n\\tname: text(),\\n\\tcreated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tupdated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tdeleted: timestamp({ mode: \\'string\\' }),\\n});\\n```\\n\\n#### Create additional tables\\n\\nIn addition to the built-in tables, our application will need some tables to store its data. We will add them to `src/db/schema.ts` that we previously generated, so this file will look like this:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\n// table schema generated by introspection\\nimport { pgTable, uuid, text, timestamp, varchar, vector, boolean } from \"drizzle-orm/pg-core\"\\nimport { sql } from \"drizzle-orm\"\\n\\nexport const tenants = pgTable(\"tenants\", {\\n\\tid: uuid().default(sql`public.uuid_generate_v7()`).primaryKey().notNull(),\\n\\tname: text(),\\n\\tcreated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tupdated: timestamp({ mode: \\'string\\' }).default(sql`LOCALTIMESTAMP`).notNull(),\\n\\tdeleted: timestamp({ mode: \\'string\\' }),\\n});\\n\\nexport const todos = pgTable(\"todos\", {\\n\\tid: uuid().defaultRandom(),\\n\\ttenantId: uuid(\"tenant_id\"),\\n\\ttitle: varchar({ length: 256 }),\\n\\testimate: varchar({ length: 256 }),\\n\\tembedding: vector({ dimensions: 3 }),\\n\\tcomplete: boolean(),\\n});\\n```\\n\\n#### Apply changes to the database\\n\\n<ApplyChanges />\\n\\n#### Initialize the webapp\\n\\nNow that we have set up Drizzle to connect to Nile and we have our schema in place, we can use them in a multi-tenant web application. \\nWe are using Express as the web framework in this example, although Nile and Drizzle can be used from any web framework.\\n\\nTo keep the example simple, we\\'ll implement the webapp in a single file - `src/app.ts`. We\\'ll start by initializing the webapp:\\n\\n```typescript copy filename=\"src/app.ts\"\\nimport express from \"express\";\\nimport { tenantDB, tenantContext, db } from \"./db/db\";\\nimport {\\n  tenants as tenantSchema,\\n  todos as todoSchema,\\n} from \"./db/schema\";\\nimport { eq } from \"drizzle-orm\";\\n\\nconst PORT = process.env.PORT || 3001;\\n\\nconst app = express();\\napp.listen(PORT, () => console.log(`Server is running on port ${PORT}`));\\napp.use(express.json());\\n```\\n\\n#### Initialize the tenant-aware middleware\\n\\nNext, we\\'ll add middleware to the example. This middleware grabs the tenant ID from the path parameters and stores it in the `AsyncLocalStorage`. \\nThe `tenantDB` wrapper that we created in `src/db/index.ts` uses this tenant ID to set `nile.tenant_id` when executing queries, \\nwhich then guarantees that the queries will execute against this tenant\\'s virtual database.\\n\\n```typescript copy filename=\"src/app.ts\"\\n// set the tenant ID in the context based on the URL parameter\\napp.use(\\'/api/tenants/:tenantId/*\\', (req, res, next) => {\\n  const tenantId = req.params.tenantId;\\n  console.log(\"setting context to tenant: \" + tenantId);\\n  tenantContext.run(tenantId, next);\\n});\\n```\\n\\n<Callout>\\nThe example gets the tenant ID from path parameter, but it is also common to set the tenant ID in a header such as `x-tenant-id` or in a cookie.\\n</Callout>\\n\\n#### Add routes\\n\\nLastly, we need to add some routes for creating and listing tenants and todos. Note how we are using `tenantDB` wrapper to connect to the tenant\\'s virtual database.\\nAlso note how in `app.get(\"/api/tenants/:tenantId/todos\"` we did not need to specify `where tenant_id=...` in the query. \\nThis is exactly because we are routed to that tenant\\'s database and the query cannot return data for any other tenant.\\n\\n```typescript copy filename=\"src/app.ts\" {6,20,39,58,62,75,83}\\n// create new tenant\\napp.post(\"/api/tenants\", async (req, res) => {\\n  try {\\n    const name = req.body.name;\\n    var tenants: any = null;\\n    tenants = await tenantDB(async (tx) => {\\n        return await tx.insert(tenantSchema).values({ name }).returning();\\n    });\\n    res.json(tenants);\\n  } catch (error: any) {\\n    console.log(\"error creating tenant: \" + error.message);\\n    res.status(500).json({message: \"Internal Server Error\",});\\n  }\\n});\\n\\n// return list of tenants\\napp.get(\"/api/tenants\", async (req, res) => {\\n  let tenants: any = [];\\n  try {\\n      tenants = await tenantDB(async (tx) => {\\n        return await tx.select().from(tenantSchema);\\n      });\\n    res.json(tenants);\\n  } catch (error: any) {\\n    console.log(\"error listing tenants: \" + error.message);\\n    res.status(500).json({message: \"Internal Server Error\",});\\n  }\\n});\\n\\n// add new task for tenant\\napp.post(\"/api/tenants/:tenantId/todos\", async (req, res) => {\\n  try {\\n    const { title, complete } = req.body;\\n    if (!title) {\\n      res.status(400).json({message: \"No task title provided\",});\\n    }\\n    const tenantId = req.params.tenantId;\\n\\n    const newTodo = await tenantDB(async (tx) => {\\n      return await tx\\n        .insert(todoSchema)\\n        .values({ tenantId, title, complete })\\n        .returning();\\n    });\\n    // return without the embedding vector, since it is huge and useless\\n    res.json(newTodo);\\n  } catch (error: any) {\\n    console.log(\"error adding task: \" + error.message);\\n    res.status(500).json({message: \"Internal Server Error\",});\\n  }\\n});\\n\\n// update tasks for tenant\\n// No need for where clause because we have the tenant in the context\\napp.put(\"/api/tenants/:tenantId/todos\", async (req, res) => {\\n  try {\\n    const { id, complete } = req.body;\\n    await tenantDB(async (tx) => {\\n      return await tx\\n        .update(todoSchema)\\n        .set({ complete })\\n        .where(eq(todoSchema.id, id));\\n    });\\n    res.sendStatus(200);\\n  } catch (error: any) {\\n    console.log(\"error updating tasks: \" + error.message);\\n    res.status(500).json({message: \"Internal Server Error\",});\\n  }\\n});\\n\\n// get all tasks for tenant\\napp.get(\"/api/tenants/:tenantId/todos\", async (req, res) => {\\n  try {\\n    // No need for a \"where\" clause here because we are setting the tenant ID in the context\\n    const todos = await tenantDB(async (tx) => {\\n      return await tx\\n        .select({\\n          id: todoSchema.id,\\n          tenant_id: todoSchema.tenantId,\\n          title: todoSchema.title,\\n          estimate: todoSchema.estimate,\\n        })\\n        .from(todoSchema);\\n    });\\n    res.json(todos);\\n  } catch (error: any) {\\n    console.log(\"error listing tasks: \" + error.message);\\n    res.status(500).json({message: error.message,});\\n  }\\n});\\n```\\n\\n#### Try it out!\\n\\nYou can now run your new web application:\\n\\n```bash copy\\nnpx tsx src/app.ts\\n```\\n\\nand use `curl` to try the routes you just created:\\n\\n```bash\\n# create a tenant\\ncurl --location --request POST \\'localhost:3001/api/tenants\\' \\\\\\n--header \\'Content-Type: application/json\\' \\\\\\n--data-raw \\'{\"name\":\"my first customer\"}\\'\\n\\n# get tenants\\ncurl  -X GET \\'http://localhost:3001/api/tenants\\'\\n\\n# create a todo (don\\'t forget to use a real tenant-id in the URL)\\ncurl  -X POST \\\\\\n  \\'http://localhost:3001/api/tenants/108124a5-2e34-418a-9735-b93082e9fbf2/todos\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data-raw \\'{\"title\": \"feed the cat\", \"complete\": false}\\'\\n\\n# list todos for tenant (don\\'t forget to use a real tenant-id in the URL)\\ncurl  -X GET \\\\\\n  \\'http://localhost:3001/api/tenants/108124a5-2e34-418a-9735-b93082e9fbf2/todos\\'\\n```\\n</Steps>\\n\\n## Project file structure\\n\\nThis is the file structure of the project. In the `src/db` directory, we have database-related files including connection in `db.ts` and schema definitions \\nin `schema.ts`. The files generated by the migrations and introspections are in `./drizzle`\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚   â”œ ðŸ“‚ db\\n â”‚   â”‚  â”œ ðŸ“œ db.ts\\n â”‚   â”‚  â”” ðŸ“œ schema.ts\\n â”‚   â”” ðŸ“œ app.ts\\n â”œ ðŸ“‚ drizzle\\n â”‚   â”œ ðŸ“‚ meta\\n â”‚   â”‚  â”œ ðŸ“œ _journal.json\\n â”‚   â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚   â”œ ðŸ“œ relations.ts\\n â”‚   â”œ ðŸ“œ schema.ts\\n â”‚   â”” ðŸ“œ 0000_watery_spencer_smythe.sql\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts\\n â”” ðŸ“œ package.json\\n```', children=[]), DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-supabase.mdx'), name='drizzle-with-supabase.mdx', displayName='drizzle-with-supabase.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Supabase Database\"\\ndate: \"2024-05-07\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', <svg width=\"24\" height=\"25\" viewBox=\"0 0 24 25\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M13.3501 21.1611C12.9303 21.6898 12.079 21.4002 12.0689 20.7251L11.921 10.8511H18.5603C19.7628 10.8511 20.4335 12.24 19.6857 13.1818L13.3501 21.1611Z\" /><path d=\"M10.6499 5.27307C11.0697 4.7443 11.921 5.03403 11.9311 5.70913L11.996 15.5831H5.43981C4.23723 15.5831 3.56652 14.1942 4.31432 13.2524L10.6499 5.27307Z\"/></svg>]\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Supabase Database](https://supabase.com/docs/guides/database/overview). Every Supabase project comes with a full [Postgres](https://www.postgresql.org/) database.\\n\\n<Prerequisites>\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n- You should have installed `dotenv` package for managing environment variables. Read more about this package [here](https://www.npmjs.com/package/dotenv)\\n<Npm>\\n  dotenv\\n</Npm>\\n\\n- You should have installed `postgres` package for connecting to the Postgres database. Read more about this package [here](https://www.npmjs.com/package/postgres)\\n<Npm>\\n  postgres\\n</Npm>\\n\\n- You should have the latest version of [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started#installing-the-supabase-cli) installed (Only if you want to use the Supabase CLI for migrations)\\n</Prerequisites>\\n\\nCheck [Supabase documentation](https://supabase.com/docs/guides/database/connecting-to-postgres#connecting-with-drizzle) to learn how to connect to the database with Drizzle ORM.\\n\\n## Setup Supabase and Drizzle ORM\\n\\n<Steps>\\n#### Create a new Supabase project\\n\\nYou can create new Supabase project in the [dashboard](https://supabase.com/dashboard) or by following this [link](https://database.new/).\\n\\n#### Setup connection string variable\\n\\nNavigate to [Database Settings](https://supabase.com/dashboard/project/_/settings/database) and copy the URI from the `Connection String` section. Make sure to use `connection pooling`. Remember to replace the password placeholder with your actual database password.\\n\\nAdd `DATABASE_URL` variable to your `.env` or `.env.local` file.\\n\\n```plaintext copy\\nDATABASE_URL=<YOUR_DATABASE_URL>\\n```\\n\\nRead more about Connection Pooler and pooling modes in the [documentation](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler).\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nconfig({ path: \\'.env\\' }); // or .env.local\\n\\nconst client = postgres(process.env.DATABASE_URL!);\\nexport const db = drizzle({ client });\\n```\\n\\n#### Create tables\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare your tables:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n});\\n\\nexport const postsTable = pgTable(\\'posts_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  title: text(\\'title\\').notNull(),\\n  content: text(\\'content\\').notNull(),\\n  userId: integer(\\'user_id\\')\\n    .notNull()\\n    .references(() => usersTable.id, { onDelete: \\'cascade\\' }),\\n  createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  updatedAt: timestamp(\\'updated_at\\')\\n    .notNull()\\n    .$onUpdate(() => new Date()),\\n});\\n\\nexport type InsertUser = typeof usersTable.$inferInsert;\\nexport type SelectUser = typeof usersTable.$inferSelect;\\n\\nexport type InsertPost = typeof postsTable.$inferInsert;\\nexport type SelectPost = typeof postsTable.$inferSelect;\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nconfig({ path: \\'.env\\' });\\n\\nexport default defineConfig({\\n  schema: \\'./src/db/schema.ts\\',\\n  out: \\'./supabase/migrations\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `supabase/migrations`  directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"posts_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"content\" text NOT NULL,\\n\\t\"user_id\" integer NOT NULL,\\n\\t\"created_at\" timestamp DEFAULT now() NOT NULL,\\n\\t\"updated_at\" timestamp NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" integer NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"posts_table\" ADD CONSTRAINT \"posts_table_user_id_users_table_id_fk\" FOREIGN KEY (\"user_id\") REFERENCES \"users_table\"(\"id\") ON DELETE cascade ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nLearn more about [migration process](/docs/migrations). You can also apply migrations using [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started):\\n- For tables that already exist, manually review the generated migration files from `npx drizzle-kit generate` and comment out or adjust any unsafe pure create statements (e.g., `CREATE SCHEMA \"auth\";`) while ensuring safe conditional creates (e.g., `CREATE TABLE IF NOT EXISTS \"auth\".\"users\"`) are properly handled.\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\nTo apply migrations using the Supabase CLI you should follow these steps:\\n \\nGenerate migrations using Drizzle Kit:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nInitialize the local Supabase project:\\n\\n```bash copy\\nsupabase init\\n```\\n\\nLink it to your remote project:\\n\\n```bash copy\\nsupabase link\\n```\\n\\nPush changes to the database:\\n\\n```bash copy\\nsupabase db push\\n```\\n</Steps>\\n\\n## Basic file structure\\n\\nThis is the basic file structure of the project. In the `src/db` directory, we have database-related files including connection in `index.ts` and schema definitions in `schema.ts`.\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚   â”œ ðŸ“‚ db\\n â”‚   â”‚  â”œ ðŸ“œ index.ts\\n â”‚   â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“‚ supabase\\n â”‚   â”œ ðŸ“‚ migrations\\n â”‚   â”‚  â”œ ðŸ“‚ meta\\n â”‚   â”‚  â”‚  â”œ ðŸ“œ _journal.json\\n â”‚   â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚   â”‚  â”” ðŸ“œ 0000_watery_spencer_smythe.sql\\n â”‚   â”” ðŸ“œ config.toml\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n## Query examples\\n\\nFor instance, we create `src/db/queries` folder and separate files for each operation: insert, select, update, delete.\\n\\n#### Insert data\\n\\nRead more about insert query in the [documentation](/docs/insert).\\n\\n```typescript copy filename=\"src/db/queries/insert.ts\" {4, 8}\\nimport { db } from \\'../index\\';\\nimport { InsertPost, InsertUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function createUser(data: InsertUser) {\\n  await db.insert(usersTable).values(data);\\n}\\n\\nexport async function createPost(data: InsertPost) {\\n  await db.insert(postsTable).values(data);\\n}\\n```\\n\\n#### Select data\\n\\nRead more about select query in the [documentation](/docs/select).\\n\\n```typescript copy filename=\"src/db/queries/select.ts\" {5, 16, 41}\\nimport { asc, between, count, eq, getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function getUserById(id: SelectUser[\\'id\\']): Promise<\\n  Array<{\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db.select().from(usersTable).where(eq(usersTable.id, id));\\n}\\n\\nexport async function getUsersWithPostsCount(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    postsCount: number;\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      ...getTableColumns(usersTable),\\n      postsCount: count(postsTable.id),\\n    })\\n    .from(usersTable)\\n    .leftJoin(postsTable, eq(usersTable.id, postsTable.userId))\\n    .groupBy(usersTable.id)\\n    .orderBy(asc(usersTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nexport async function getPostsForLast24Hours(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    id: number;\\n    title: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      id: postsTable.id,\\n      title: postsTable.title,\\n    })\\n    .from(postsTable)\\n    .where(between(postsTable.createdAt, sql`now() - interval \\'1 day\\'`, sql`now()`))\\n    .orderBy(asc(postsTable.title), asc(postsTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n```\\n\\nAlternatively, you can use [relational query syntax](/docs/rqb).\\n#### Update data\\n\\nRead more about update query in the [documentation](/docs/update).\\n\\n```typescript copy filename=\"src/db/queries/update.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectPost, postsTable } from \\'../schema\\';\\n\\nexport async function updatePost(id: SelectPost[\\'id\\'], data: Partial<Omit<SelectPost, \\'id\\'>>) {\\n  await db.update(postsTable).set(data).where(eq(postsTable.id, id));\\n}\\n```\\n\\n#### Delete data\\n\\nRead more about delete query in the [documentation](/docs/delete).\\n\\n```typescript copy filename=\"src/db/queries/delete.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, usersTable } from \\'../schema\\';\\n\\nexport async function deleteUser(id: SelectUser[\\'id\\']) {\\n  await db.delete(usersTable).where(eq(usersTable.id, id));\\n}\\n```', children=[]), DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-turso.mdx'), name='drizzle-with-turso.mdx', displayName='drizzle-with-turso.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Turso\"\\ndate: \"2024-02-17\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', \\'<svg width=\"241\" height=\"240\" viewBox=\"0 0 241 240\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M220.035 83.61C215.365 55.67 190.875 35 190.875 35V65.78L176.335 69.53L167.225 58.56L162.415 68.02C152.495 65.32 138.835 63.58 120.045 63.58C101.255 63.58 87.5949 65.33 77.6749 68.02L72.8649 58.56L63.7549 69.53L49.2149 65.78V35C49.2149 35 24.7249 55.67 20.0549 83.61L52.1949 94.73C53.2449 114.16 61.9849 166.61 64.4849 171.37C67.1449 176.44 81.2649 190.93 92.3149 196.5C92.3149 196.5 96.3149 192.27 98.7549 188.54C101.855 192.19 117.865 204.99 120.055 204.99C122.245 204.99 138.255 192.2 141.355 188.54C143.795 192.27 147.795 196.5 147.795 196.5C158.845 190.93 172.965 176.44 175.625 171.37C178.125 166.61 186.865 114.16 187.915 94.73L220.055 83.61H220.035ZM173.845 128.35L152.095 130.29L154.005 156.96C154.005 156.96 140.775 167.91 120.045 167.91C99.3149 167.91 86.0849 156.96 86.0849 156.96L87.9949 130.29L66.2449 128.35L62.5249 98.31L98.5749 110.79L95.7749 148.18C102.475 149.88 109.525 151.57 120.055 151.57C130.585 151.57 137.625 149.88 144.325 148.18L141.525 110.79L177.575 98.31L173.855 128.35H173.845Z\" fill=\"currentColor\"/></svg>\\']\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Turso](https://docs.turso.tech/introduction).\\n\\n<Prerequisites>\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n- You should have installed `dotenv` package for managing environment variables. Read more about this package [here](https://www.npmjs.com/package/dotenv)\\n<Npm>\\n  dotenv\\n</Npm>\\n- You should have installed `@libsql/client` package. Read more about this package [here](https://www.npmjs.com/package/@libsql/client).\\n<Npm>\\n  @libsql/client\\n</Npm>\\n- You should have installed Turso CLI. Check [documentation](https://docs.turso.tech/cli/introduction) for more information\\n</Prerequisites>\\n\\n[Turso](https://docs.turso.tech/concepts) is a SQLite-compatible database built on\\xa0[libSQL](https://docs.turso.tech/libsql), the Open Contribution fork of SQLite. It enables scaling to hundreds of thousands of databases per organization and supports replication to any location, including your own servers, for microsecond-latency access. You can read more about Tursoâ€™s concepts [here](https://docs.turso.tech/concepts).\\n\\nDrizzle ORM natively supports libSQL driver.\\nWe embrace SQL dialects and dialect specific drivers and syntax and mirror most popular SQLite-like\\xa0`all`,\\xa0`get`,\\xa0`values`\\xa0and\\xa0`run`\\xa0query methods syntax.\\n\\nCheck [official documentation](https://docs.turso.tech/quickstart) to setup Turso database.\\n\\n## Setup Turso and Drizzle ORM\\n\\n<Steps>\\n#### Signup or login to Turso\\n\\nSignup:\\n\\n```bash copy\\nturso auth signup\\n```\\n\\nLogin:\\n\\n```bash copy\\nturso auth login\\n```\\n\\n#### Create new database\\n\\nCreate new database by running the `turso db create <DATABASE_NAME>` command:\\n\\n```bash copy\\nturso db create drizzle-turso-db\\n```\\n\\nTo see information about the database, run the following command:\\n\\n```bash copy\\nturso db show drizzle-turso-db\\n```\\n\\n#### Create an authentication token\\n\\nTo create an authentication token for your database, run the following command:\\n\\n```bash copy\\nturso db tokens create drizzle-turso-db\\n```\\n\\nLearn more about this command and its options in the [documentation](https://docs.turso.tech/cli/db/tokens/create).\\n\\n#### Update environment variables\\n\\nUpdate your `.env` or `.env.local` file with connection url and authentication token.\\n\\n```text copy\\nTURSO_CONNECTION_URL=\\nTURSO_AUTH_TOKEN=\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { drizzle } from \\'drizzle-orm/libsql\\';\\n\\nconfig({ path: \\'.env\\' }); // or .env.local\\n\\nexport const db = drizzle({ connection: {\\n  url: process.env.TURSO_CONNECTION_URL!,\\n  authToken: process.env.TURSO_AUTH_TOKEN!,\\n}});\\n```\\n\\n#### Create tables\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare your tables:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { sql } from \\'drizzle-orm\\';\\nimport { integer, sqliteTable, text } from \\'drizzle-orm/sqlite-core\\';\\n\\nexport const usersTable = sqliteTable(\\'users\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').unique().notNull(),\\n});\\n\\nexport const postsTable = sqliteTable(\\'posts\\', {\\n  id: integer(\\'id\\').primaryKey(),\\n  title: text(\\'title\\').notNull(),\\n  content: text(\\'content\\').notNull(),\\n  userId: integer(\\'user_id\\')\\n    .notNull()\\n    .references(() => usersTable.id, { onDelete: \\'cascade\\' }),\\n  createdAt: text(\\'created_at\\')\\n    .default(sql`(CURRENT_TIMESTAMP)`)\\n    .notNull(),\\n  updatedAt: integer(\\'updated_at\\', { mode: \\'timestamp\\' }).$onUpdate(() => new Date()),\\n});\\n\\nexport type InsertUser = typeof usersTable.$inferInsert;\\nexport type SelectUser = typeof usersTable.$inferSelect;\\n\\nexport type InsertPost = typeof postsTable.$inferInsert;\\nexport type SelectPost = typeof postsTable.$inferSelect;\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nconfig({ path: \\'.env\\' });\\n\\nexport default defineConfig({\\n  schema: \\'./src/db/schema.ts\\',\\n  out: \\'./migrations\\',\\n  dialect: \\'turso\\',\\n  dbCredentials: {\\n    url: process.env.TURSO_CONNECTION_URL!,\\n    authToken: process.env.TURSO_AUTH_TOKEN!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `migrations`  directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE `posts` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`title` text NOT NULL,\\n\\t`content` text NOT NULL,\\n\\t`user_id` integer NOT NULL,\\n\\t`created_at` text DEFAULT (CURRENT_TIMESTAMP) NOT NULL,\\n\\t`updated_at` integer,\\n\\tFOREIGN KEY (`user_id`) REFERENCES `users`(`id`) ON UPDATE no action ON DELETE cascade\\n);\\n--> statement-breakpoint\\nCREATE TABLE `users` (\\n\\t`id` integer PRIMARY KEY NOT NULL,\\n\\t`name` text NOT NULL,\\n\\t`age` integer NOT NULL,\\n\\t`email` text NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE UNIQUE INDEX `users_email_unique` ON `users` (`email`);\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n</Steps>\\n\\n### Basic file structure\\n\\nThis is the basic file structure of the project. In the `src/db` directory, we have database-related files including connection in `index.ts` and schema definitions in `schema.ts`.\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚   â”œ ðŸ“‚ db\\n â”‚   â”‚  â”œ ðŸ“œ index.ts\\n â”‚   â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“‚ migrations\\n â”‚  â”œ ðŸ“‚ meta\\n â”‚  â”‚  â”œ ðŸ“œ _journal.json\\n â”‚  â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚  â”” ðŸ“œ 0000_watery_spencer_smythe.sql\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n## Query examples\\n\\nFor instance, we create `src/db/queries` folder and separate files for each operation: insert, select, update, delete.\\n\\n#### Insert data\\n\\nRead more about insert query in the [documentation](/docs/insert).\\n\\n```typescript copy filename=\"src/db/queries/insert.ts\" {4, 8}\\nimport { db } from \\'../index\\';\\nimport { InsertPost, InsertUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function createUser(data: InsertUser) {\\n  await db.insert(usersTable).values(data);\\n}\\n\\nexport async function createPost(data: InsertPost) {\\n  await db.insert(postsTable).values(data);\\n}\\n```\\n\\n#### Select data\\n\\nRead more about select query in the [documentation](/docs/select).\\n\\n```typescript copy filename=\"src/db/queries/select.ts\" {5, 16, 41}\\nimport { asc, count, eq, getTableColumns, gt, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function getUserById(id: SelectUser[\\'id\\']): Promise<\\n  Array<{\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db.select().from(usersTable).where(eq(usersTable.id, id));\\n}\\n\\nexport async function getUsersWithPostsCount(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    postsCount: number;\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      ...getTableColumns(usersTable),\\n      postsCount: count(postsTable.id),\\n    })\\n    .from(usersTable)\\n    .leftJoin(postsTable, eq(usersTable.id, postsTable.userId))\\n    .groupBy(usersTable.id)\\n    .orderBy(asc(usersTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nexport async function getPostsForLast24Hours(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    id: number;\\n    title: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      id: postsTable.id,\\n      title: postsTable.title,\\n    })\\n    .from(postsTable)\\n    .where(gt(postsTable.createdAt, sql`(datetime(\\'now\\',\\'-24 hour\\'))`))\\n    .orderBy(asc(postsTable.title), asc(postsTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n```\\n\\nAlternatively, you can use [relational query syntax](/docs/rqb).\\n\\n#### Update data\\n\\nRead more about update query in the [documentation](/docs/update).\\n\\n```typescript copy filename=\"src/db/queries/update.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectPost, postsTable } from \\'../schema\\';\\n\\nexport async function updatePost(id: SelectPost[\\'id\\'], data: Partial<Omit<SelectPost, \\'id\\'>>) {\\n  await db.update(postsTable).set(data).where(eq(postsTable.id, id));\\n}\\n```\\n\\n#### Delete data\\n\\nRead more about delete query in the [documentation](/docs/delete).\\n\\n```typescript copy filename=\"src/db/queries/delete.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, usersTable } from \\'../schema\\';\\n\\nexport async function deleteUser(id: SelectUser[\\'id\\']) {\\n  await db.delete(usersTable).where(eq(usersTable.id, id));\\n}\\n```\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-vercel.mdx'), name='drizzle-with-vercel.mdx', displayName='drizzle-with-vercel.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Vercel Postgres\"\\ndate: \"2024-06-09\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12 5L4 19H20L12 5Z\" fill=\"currentColor\" stroke=\"currentColor\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/></svg>]\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Vercel Postgres](https://vercel.com/docs/storage/vercel-postgres). Vercel Postgres is a serverless SQL database designed to integrate with Vercel Functions and your frontend framework.\\n\\n<Prerequisites>\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n\\n- You should have installed `dotenv` package for managing environment variables. Read more about this package [here](https://www.npmjs.com/package/dotenv)\\n<Npm>\\n  dotenv\\n</Npm>\\n\\n- You should have installed `@vercel/postgres` package. Read more about this package [here](https://www.npmjs.com/package/@vercel/postgres)\\n<Npm>\\n  @vercel/postgres\\n</Npm>  \\n</Prerequisites>\\n\\nCheck [Vercel documentation](https://vercel.com/docs/storage/vercel-postgres/using-an-orm#drizzle) to learn how to connect to the database with Drizzle ORM.\\n\\n## Setup Vercel Postgres and Drizzle ORM\\n\\n<Steps>\\n#### Create a new Vercel Postgres database\\n\\nYou can create new Vercel Postgres database in the [dashboard](https://vercel.com/dashboard).\\n\\nRead Vercel Postgres [documentation](https://vercel.com/docs/storage/vercel-postgres/quickstart) to learn how to create a new database.\\n\\n#### Setup connection string variable\\n\\nNavigate to your Vercel Postgres database and copy `POSTGRES_URL` from `.env.local` section.\\n\\nAdd `POSTGRES_URL` to your `.env.local` or `.env` file.\\n\\n```plaintext copy\\nPOSTGRES_URL=<YOUR_DATABASE_URL>\\n```\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { drizzle } from \\'drizzle-orm/vercel-postgres\\';\\nimport { config } from \\'dotenv\\';\\n\\nconfig({ path: \\'.env.local\\' }); // or .env\\n\\nexport const db = drizzle();\\n\\n```\\n\\n#### Create tables\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare your tables:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n});\\n\\nexport const postsTable = pgTable(\\'posts_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  title: text(\\'title\\').notNull(),\\n  content: text(\\'content\\').notNull(),\\n  userId: integer(\\'user_id\\')\\n    .notNull()\\n    .references(() => usersTable.id, { onDelete: \\'cascade\\' }),\\n  createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  updatedAt: timestamp(\\'updated_at\\')\\n    .notNull()\\n    .$onUpdate(() => new Date()),\\n});\\n\\nexport type InsertUser = typeof usersTable.$inferInsert;\\nexport type SelectUser = typeof usersTable.$inferSelect;\\n\\nexport type InsertPost = typeof postsTable.$inferInsert;\\nexport type SelectPost = typeof postsTable.$inferSelect;\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nconfig({ path: \\'.env.local\\' });\\n\\nexport default defineConfig({\\n  schema: \\'./src/db/schema.ts\\',\\n  out: \\'./migrations\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.POSTGRES_URL!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle/migrations`  directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"posts_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"content\" text NOT NULL,\\n\\t\"user_id\" integer NOT NULL,\\n\\t\"created_at\" timestamp DEFAULT now() NOT NULL,\\n\\t\"updated_at\" timestamp NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" integer NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"posts_table\" ADD CONSTRAINT \"posts_table_user_id_users_table_id_fk\" FOREIGN KEY (\"user_id\") REFERENCES \"users_table\"(\"id\") ON DELETE cascade ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n</Steps>\\n\\n## Basic file structure\\n\\nThis is the basic file structure of the project. In the `src/db` directory, we have database-related files including connection in `index.ts` and schema definitions in `schema.ts`.\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚   â”œ ðŸ“‚ db\\n â”‚   â”‚  â”œ ðŸ“œ index.ts\\n â”‚   â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“‚ migrations\\n â”‚   â”œ ðŸ“‚ meta\\n â”‚   â”‚  â”œ ðŸ“œ _journal.json\\n â”‚   â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚   â”” ðŸ“œ 0000_watery_spencer_smythe.sql\\n â”œ ðŸ“œ .env.local\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n## Query examples\\n\\nFor instance, we create `src/db/queries` folder and separate files for each operation: insert, select, update, delete.\\n\\n#### Insert data\\n\\nRead more about insert query in the [documentation](/docs/insert).\\n\\n```typescript copy filename=\"src/db/queries/insert.ts\" {4, 8}\\nimport { db } from \\'../index\\';\\nimport { InsertPost, InsertUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function createUser(data: InsertUser) {\\n  await db.insert(usersTable).values(data);\\n}\\n\\nexport async function createPost(data: InsertPost) {\\n  await db.insert(postsTable).values(data);\\n}\\n```\\n\\n#### Select data\\n\\nRead more about select query in the [documentation](/docs/select).\\n\\n```typescript copy filename=\"src/db/queries/select.ts\" {5, 16, 41}\\nimport { asc, between, count, eq, getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function getUserById(id: SelectUser[\\'id\\']): Promise<\\n  Array<{\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db.select().from(usersTable).where(eq(usersTable.id, id));\\n}\\n\\nexport async function getUsersWithPostsCount(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    postsCount: number;\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      ...getTableColumns(usersTable),\\n      postsCount: count(postsTable.id),\\n    })\\n    .from(usersTable)\\n    .leftJoin(postsTable, eq(usersTable.id, postsTable.userId))\\n    .groupBy(usersTable.id)\\n    .orderBy(asc(usersTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nexport async function getPostsForLast24Hours(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    id: number;\\n    title: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      id: postsTable.id,\\n      title: postsTable.title,\\n    })\\n    .from(postsTable)\\n    .where(between(postsTable.createdAt, sql`now() - interval \\'1 day\\'`, sql`now()`))\\n    .orderBy(asc(postsTable.title), asc(postsTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n```\\n\\nAlternatively, you can use [relational query syntax](/docs/rqb).\\n\\n#### Update data\\n\\nRead more about update query in the [documentation](/docs/update).\\n\\n```typescript copy filename=\"src/db/queries/update.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectPost, postsTable } from \\'../schema\\';\\n\\nexport async function updatePost(id: SelectPost[\\'id\\'], data: Partial<Omit<SelectPost, \\'id\\'>>) {\\n  await db.update(postsTable).set(data).where(eq(postsTable.id, id));\\n}\\n```\\n\\n#### Delete data\\n\\nRead more about delete query in the [documentation](/docs/delete).\\n\\n```typescript copy filename=\"src/db/queries/delete.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, usersTable } from \\'../schema\\';\\n\\nexport async function deleteUser(id: SelectUser[\\'id\\']) {\\n  await db.delete(usersTable).where(eq(usersTable.id, id));\\n}\\n```\\n', children=[]), DocItem(origPath=Path('tutorials/drizzle-with-db/drizzle-with-xata.mdx'), name='drizzle-with-xata.mdx', displayName='drizzle-with-xata.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Drizzle with Xata\"\\ndate: \"2024-12-13\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', \\'<svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M12 2L2 7L12 12L22 7L12 2Z\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/><path d=\"M2 17L12 22L22 17\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/><path d=\"M2 12L12 17L22 12\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/></svg>\\']\\n---\\n\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Npm from \\'@mdx/Npm.astro\\';\\nimport Steps from \\'@mdx/Steps.astro\\';\\nimport Section from \"@mdx/Section.astro\";\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\nThis tutorial demonstrates how to use Drizzle ORM with [Xata](https://xata.io). Xata is a PostgreSQL database platform designed to help developers operate and scale databases with enhanced productivity and performance, featuring instant copy-on-write database branches, zero-downtime schema changes, data anonymization, and AI-powered performance monitoring.\\n\\n<Prerequisites>\\n- You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n<Npm>\\ndrizzle-orm\\n-D drizzle-kit\\n</Npm>\\n- You should have installed `dotenv` package for managing environment variables. Read more about this package [here](https://www.npmjs.com/package/dotenv)\\n<Npm>\\n  dotenv\\n</Npm>\\n\\n- You should have installed `postgres` package for connecting to the Postgres database. Read more about this package [here](https://www.npmjs.com/package/postgres)\\n<Npm>\\n  postgres\\n</Npm>\\n\\n- You should have a Xata account and database set up. Follow the [Xata documentation](https://xata.io/documentation/getting-started) to create your account and database\\n</Prerequisites>\\n\\nCheck [Xata documentation](https://xata.io/documentation/quickstarts/drizzle) to learn more about using Drizzle ORM with Xata.\\n\\n## Setup Xata and Drizzle ORM\\n\\n<Steps>\\n#### Create a new Xata database\\n\\nYou can create a new Xata database by following these steps:\\n\\n1. Sign up or log in to your [Xata account](https://xata.io/)\\n2. Create a new database from the dashboard\\n3. Choose your region and database name\\n4. Your database will be created with a PostgreSQL endpoint\\n\\n#### Setup connection string variable\\n\\nNavigate to the Xata dashboard and copy the PostgreSQL connection string. You can find this on the branch overview page.\\n\\nAdd `DATABASE_URL` variable to your `.env` or `.env.local` file:\\n\\n```plaintext copy\\nDATABASE_URL=<YOUR_XATA_DATABASE_URL>\\n```\\n\\nThe connection string format will be:\\n```plaintext\\npostgresql://postgres:<password>@<branch-id>.<region>.xata.tech/<database>?sslmode=require\\n```\\n\\nExample:\\n```plaintext\\npostgresql://postgres:password@t56hgfp7hd2sjfeiqcn66qpo8s.us-east-1.xata.tech/app?sslmode=require\\n```\\n\\n<Callout type=\"info\">\\nXata provides branch-based development, allowing you to create isolated database branches for development, staging, and production environments.\\n</Callout>\\n\\n#### Connect Drizzle ORM to your database\\n\\nCreate a `index.ts` file in the `src/db` directory and set up your database configuration:\\n\\n```typescript copy filename=\"src/db/index.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { drizzle } from \\'drizzle-orm/postgres-js\\';\\nimport postgres from \\'postgres\\';\\n\\nconfig({ path: \\'.env\\' }); // or .env.local\\n\\nconst client = postgres(process.env.DATABASE_URL!);\\nexport const db = drizzle({ client });\\n```\\n\\n#### Create tables\\n\\nCreate a `schema.ts` file in the `src/db` directory and declare your tables:\\n\\n```typescript copy filename=\"src/db/schema.ts\"\\nimport { integer, pgTable, serial, text, timestamp } from \\'drizzle-orm/pg-core\\';\\n\\nexport const usersTable = pgTable(\\'users_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  age: integer(\\'age\\').notNull(),\\n  email: text(\\'email\\').notNull().unique(),\\n});\\n\\nexport const postsTable = pgTable(\\'posts_table\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  title: text(\\'title\\').notNull(),\\n  content: text(\\'content\\').notNull(),\\n  userId: integer(\\'user_id\\')\\n    .notNull()\\n    .references(() => usersTable.id, { onDelete: \\'cascade\\' }),\\n  createdAt: timestamp(\\'created_at\\').notNull().defaultNow(),\\n  updatedAt: timestamp(\\'updated_at\\')\\n    .notNull()\\n    .$onUpdate(() => new Date()),\\n});\\n\\nexport type InsertUser = typeof usersTable.$inferInsert;\\nexport type SelectUser = typeof usersTable.$inferSelect;\\n\\nexport type InsertPost = typeof postsTable.$inferInsert;\\nexport type SelectPost = typeof postsTable.$inferSelect;\\n```\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \\'drizzle-kit\\';\\n\\nconfig({ path: \\'.env\\' });\\n\\nexport default defineConfig({\\n  schema: \\'./src/db/schema.ts\\',\\n  out: \\'./migrations\\',\\n  dialect: \\'postgresql\\',\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash copy\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `migrations` directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"posts_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"title\" text NOT NULL,\\n\\t\"content\" text NOT NULL,\\n\\t\"user_id\" integer NOT NULL,\\n\\t\"created_at\" timestamp DEFAULT now() NOT NULL,\\n\\t\"updated_at\" timestamp NOT NULL\\n);\\n--> statement-breakpoint\\nCREATE TABLE IF NOT EXISTS \"users_table\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" text NOT NULL,\\n\\t\"age\" integer NOT NULL,\\n\\t\"email\" text NOT NULL,\\n\\tCONSTRAINT \"users_table_email_unique\" UNIQUE(\"email\")\\n);\\n--> statement-breakpoint\\nDO $$ BEGIN\\n ALTER TABLE \"posts_table\" ADD CONSTRAINT \"posts_table_user_id_users_table_id_fk\" FOREIGN KEY (\"user_id\") REFERENCES \"users_table\"(\"id\") ON DELETE cascade ON UPDATE no action;\\nEXCEPTION\\n WHEN duplicate_object THEN null;\\nEND $$;\\n```\\n\\nRun migrations:\\n\\n```bash copy\\nnpx drizzle-kit migrate\\n```\\n\\nLearn more about [migration process](/docs/migrations).\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash copy\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n\\n<Callout type=\"info\">\\n**Xata Branch-Based Development**: Xata allows you to create database branches for different environments. You can use different connection strings for development, staging, and production branches, making it easy to test schema changes before deploying to production.\\n</Callout>\\n</Steps>\\n\\n## Basic file structure\\n\\nThis is the basic file structure of the project. In the `src/db` directory, we have database-related files including connection in `index.ts` and schema definitions in `schema.ts`.\\n\\n```plaintext\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ src\\n â”‚   â”œ ðŸ“‚ db\\n â”‚   â”‚  â”œ ðŸ“œ index.ts\\n â”‚   â”‚  â”” ðŸ“œ schema.ts\\n â”œ ðŸ“‚ migrations\\n â”‚   â”œ ðŸ“‚ meta\\n â”‚   â”‚  â”œ ðŸ“œ _journal.json\\n â”‚   â”‚  â”” ðŸ“œ 0000_snapshot.json\\n â”‚   â”” ðŸ“œ 0000_watery_spencer_smythe.sql\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ package.json\\n â”” ðŸ“œ tsconfig.json\\n```\\n\\n## Query examples\\n\\nFor instance, we create `src/db/queries` folder and separate files for each operation: insert, select, update, delete.\\n\\n#### Insert data\\n\\nRead more about insert query in the [documentation](/docs/insert).\\n\\n```typescript copy filename=\"src/db/queries/insert.ts\" {4, 8}\\nimport { db } from \\'../index\\';\\nimport { InsertPost, InsertUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function createUser(data: InsertUser) {\\n  await db.insert(usersTable).values(data);\\n}\\n\\nexport async function createPost(data: InsertPost) {\\n  await db.insert(postsTable).values(data);\\n}\\n```\\n\\n#### Select data\\n\\nRead more about select query in the [documentation](/docs/select).\\n\\n```typescript copy filename=\"src/db/queries/select.ts\" {5, 16, 41}\\nimport { asc, between, count, eq, getTableColumns, sql } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, postsTable, usersTable } from \\'../schema\\';\\n\\nexport async function getUserById(id: SelectUser[\\'id\\']): Promise<\\n  Array<{\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db.select().from(usersTable).where(eq(usersTable.id, id));\\n}\\n\\nexport async function getUsersWithPostsCount(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    postsCount: number;\\n    id: number;\\n    name: string;\\n    age: number;\\n    email: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      ...getTableColumns(usersTable),\\n      postsCount: count(postsTable.id),\\n    })\\n    .from(usersTable)\\n    .leftJoin(postsTable, eq(usersTable.id, postsTable.userId))\\n    .groupBy(usersTable.id)\\n    .orderBy(asc(usersTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n\\nexport async function getPostsForLast24Hours(\\n  page = 1,\\n  pageSize = 5,\\n): Promise<\\n  Array<{\\n    id: number;\\n    title: string;\\n  }>\\n> {\\n  return db\\n    .select({\\n      id: postsTable.id,\\n      title: postsTable.title,\\n    })\\n    .from(postsTable)\\n    .where(between(postsTable.createdAt, sql`now() - interval \\'1 day\\'`, sql`now()`))\\n    .orderBy(asc(postsTable.title), asc(postsTable.id))\\n    .limit(pageSize)\\n    .offset((page - 1) * pageSize);\\n}\\n```\\n\\nAlternatively, you can use [relational query syntax](/docs/rqb).\\n\\n#### Update data\\n\\nRead more about update query in the [documentation](/docs/update).\\n\\n```typescript copy filename=\"src/db/queries/update.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectPost, postsTable } from \\'../schema\\';\\n\\nexport async function updatePost(id: SelectPost[\\'id\\'], data: Partial<Omit<SelectPost, \\'id\\'>>) {\\n  await db.update(postsTable).set(data).where(eq(postsTable.id, id));\\n}\\n```\\n\\n#### Delete data\\n\\nRead more about delete query in the [documentation](/docs/delete).\\n\\n```typescript copy filename=\"src/db/queries/delete.ts\" {5}\\nimport { eq } from \\'drizzle-orm\\';\\nimport { db } from \\'../index\\';\\nimport { SelectUser, usersTable } from \\'../schema\\';\\n\\nexport async function deleteUser(id: SelectUser[\\'id\\']) {\\n  await db.delete(usersTable).where(eq(usersTable.id, id));\\n}\\n```\\n\\n## Next Steps\\n\\nNow that you have successfully set up Drizzle ORM with Xata, you can explore more advanced features:\\n\\n- Learn about [Drizzle relations](/docs/rqb) for complex queries\\n- Explore [Xata\\'s documentation](https://xata.io/documentation/)\\n- Implement [database migrations](/docs/migrations) for production deployments', children=[])]), DocItem(origPath=Path('tutorials/drizzle-with-frameworks/drizzle-nextjs-neon.mdx'), name='drizzle-nextjs-neon.mdx', displayName='drizzle-nextjs-neon.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='---\\ntitle: \"Todo App with Neon Postgres\"\\ndate: \"2024-01-17\"\\nsvgs: [\\'<svg width=\"160\" height=\"160\" viewBox=\"0 0 160 160\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 43.4805 67.3037)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 76.9395 46.5342)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 128.424 46.5352)\" fill=\"currentColor\"></rect><rect width=\"9.63139\" height=\"40.8516\" rx=\"4.8157\" transform=\"matrix(0.873028 0.48767 -0.497212 0.867629 94.957 67.3037)\" fill=\"currentColor\"></rect></svg>\\', \\'<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><g clip-path=\"url(#clip0_84_2)\"><path d=\"M128 256C198.692 256 256 198.692 256 128C256 57.3075 198.692 0 128 0C57.3075 0 0 57.3075 0 128C0 198.692 57.3075 256 128 256Z\" fill=\"black\"/><path d=\"M212.63 224.03L98.34 76.8H76.8V179.16H94.03V98.68L199.11 234.45C203.85 231.27 208.37 227.79 212.63 224.03Z\" fill=\"url(#paint0_linear_84_2)\"/><path d=\"M180.63 76.8H163.56V179.2H180.63V76.8Z\" fill=\"url(#paint1_linear_84_2)\"/></g><defs><linearGradient id=\"paint0_linear_84_2\" x1=\"132.707\" y1=\"181.561\" x2=\"178.076\" y2=\"237.79\" gradientUnits=\"userSpaceOnUse\"><stop stop-color=\"white\"/><stop offset=\"1\" stop-color=\"white\" stop-opacity=\"0\"/></linearGradient><linearGradient id=\"paint1_linear_84_2\" x1=\"172.083\" y1=\"76.7712\" x2=\"171.776\" y2=\"151.973\" gradientUnits=\"userSpaceOnUse\"><stop stop-color=\"white\"/><stop offset=\"1\" stop-color=\"white\" stop-opacity=\"0\"/></linearGradient><clipPath id=\"clip0_84_2\"><rect width=\"256\" height=\"256\" fill=\"white\"/></clipPath></defs></svg>\\', \\'<svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M2 6.27586C2 4.46665 3.54385 3 5.44828 3H18.5517C20.4562 3 22 4.46665 22 6.27586V16.8631C22 18.7349 19.5068 19.5471 18.2976 18.0694L14.5173 13.4496V19.0517C14.5173 20.68 13.1278 22 11.4138 22H5.44828C3.54385 22 2 20.5333 2 18.7241V6.27586ZM5.44828 5.62069C5.06739 5.62069 4.75863 5.91402 4.75863 6.27586V18.7241C4.75863 19.086 5.06739 19.3793 5.44828 19.3793H11.5172C11.7077 19.3793 11.7586 19.2327 11.7586 19.0517V11.5393C11.7586 9.66758 14.2518 8.8552 15.461 10.333L19.2414 14.9528V6.27586C19.2414 5.91402 19.2774 5.62069 18.8966 5.62069H5.44828Z\" fill=\"currentColor\"/></svg>\\']\\n---\\n\\nimport Steps from \"@mdx/Steps.astro\";\\nimport Npm from \"@mdx/Npm.astro\";\\nimport CodeTabs from \"@mdx/CodeTabs.astro\";\\nimport CodeTab from \"@mdx/CodeTab.astro\";\\nimport Section from \"@mdx/Section.astro\";\\nimport Tabs from \"@mdx/Tabs.astro\";\\nimport Tab from \"@mdx/Tab.astro\";\\nimport Prerequisites from \"@mdx/Prerequisites.astro\";\\nimport Callout from \"@mdx/Callout.astro\";\\n\\nThis tutorial demonstrates how to build `Todo app` using **Drizzle ORM** with **Neon database** and **Next.js**.\\n\\n<Prerequisites>  \\n  - You should have an existing Next.js project or create a new one using the following command:\\n  ```bash\\n  npx create-next-app@latest --typescript\\n  ```\\n\\n  - You should have installed Drizzle ORM and [Drizzle kit](/docs/kit-overview). You can do this by running the following command:\\n  <Npm>\\n    drizzle-orm \\n    -D drizzle-kit\\n  </Npm>\\n\\n  - You should have installed the [Neon serverless driver](https://neon.tech/docs/serverless/serverless-driver). \\n  <Npm>\\n    @neondatabase/serverless\\n  </Npm>\\n\\n  - You should have installed the `dotenv` package for managing environment variables. \\n  <Npm>\\n    dotenv\\n  </Npm>  \\n</Prerequisites>\\n\\n<Callout type=\"warning\">\\nIn case you face the issue with resolving dependencies during installation:\\n\\nIf you\\'re not using React Native, forcing the installation with `--force` or `--legacy-peer-deps` should resolve the issue. If you are using React Native, then you need to use the exact version of React which is compatible with your React Native version.\\n</Callout>\\n\\n## Setup Neon and Drizzle ORM\\n\\n<Steps>\\n#### Create a new Neon project\\n\\nLog in to the [Neon Console](https://console.neon.tech/app/projects) and navigate to the Projects section. Select a project or click the `New Project` button to create a new one. \\n\\nYour Neon projects come with a ready-to-use Postgres database named `neondb`. We\\'ll use it in this tutorial.\\n\\n#### Setup connection string variable\\n\\nNavigate to the **Connection Details** section in the project console to find your database connection string. It should look similar to this:\\n\\n```bash\\npostgres://username:password@ep-cool-darkness-123456.us-east-2.aws.neon.tech/neondb\\n```\\n\\nAdd the `DATABASE_URL` environment variable to your `.env` or `.env.local` file, which you\\'ll use to connect to the Neon database.\\n\\n```bash\\nDATABASE_URL=NEON_DATABASE_CONNECTION_STRING\\n```\\n\\n#### Connect Drizzle ORM to your database \\n\\nCreate a `drizzle.ts` file in your `src/db` folder and set up your database configuration:\\n\\n```tsx copy filename=\"src/db/drizzle.ts\"\\nimport { config } from \"dotenv\";\\nimport { drizzle } from \\'drizzle-orm/neon-http\\';\\n\\nconfig({ path: \".env\" }); // or .env.local\\n\\nexport const db = drizzle(process.env.DATABASE_URL!);\\n```\\n\\n#### Declare todo schema\\n\\n```tsx copy filename=\"src/db/schema.ts\"\\nimport { integer, text, boolean, pgTable } from \"drizzle-orm/pg-core\";\\n\\nexport const todo = pgTable(\"todo\", {\\n  id: integer(\"id\").primaryKey(),\\n  text: text(\"text\").notNull(),\\n  done: boolean(\"done\").default(false).notNull(),\\n});\\n```\\n\\nHere we define the **`todo`** table with fields **`id`**, **`text`**, and **`done`**, using data types from Drizzle ORM.\\n\\n#### Setup Drizzle config file\\n\\n**Drizzle config** - a configuration file that is used by [Drizzle Kit](/docs/kit-overview) and contains all the information about your database connection, migration folder and schema files.\\n\\nCreate a `drizzle.config.ts` file in the root of your project and add the following content:\\n\\n```typescript copy filename=\"drizzle.config.ts\"\\nimport { config } from \\'dotenv\\';\\nimport { defineConfig } from \"drizzle-kit\";\\n\\nconfig({ path: \\'.env\\' });\\n\\nexport default defineConfig({\\n  schema: \"./src/db/schema.ts\",\\n  out: \"./migrations\",\\n  dialect: \"postgresql\",\\n  dbCredentials: {\\n    url: process.env.DATABASE_URL!,\\n  },\\n});\\n```\\n\\n#### Applying changes to the database\\n\\nYou can generate migrations using `drizzle-kit generate` command and then run them using the `drizzle-kit migrate` command.\\n\\nGenerate migrations:\\n\\n```bash\\nnpx drizzle-kit generate\\n```\\n\\nThese migrations are stored in the `drizzle/migrations`  directory, as specified in your `drizzle.config.ts`. This directory will contain the SQL files necessary to update your database schema and a `meta` folder for storing snapshots of the schema at different migration stages.\\n\\nExample of a generated migration:\\n\\n```sql\\nCREATE TABLE IF NOT EXISTS \"todo\" (\\n\\t\"id\" integer PRIMARY KEY NOT NULL,\\n\\t\"text\" text NOT NULL,\\n\\t\"done\" boolean DEFAULT false NOT NULL\\n);\\n```\\n\\nRun migrations:\\n\\n```bash\\nnpx drizzle-kit migrate\\n```\\n\\nAlternatively, you can push changes directly to the database using [Drizzle kit push command](/docs/kit-overview#prototyping-with-db-push):\\n\\n```bash\\nnpx drizzle-kit push\\n```\\n\\n<Callout type=\"warning\">Push command is good for situations where you need to quickly test new schema designs or changes in a local development environment, allowing for fast iterations without the overhead of managing migration files.</Callout>\\n</Steps>\\n\\n#### Establish server-side functions\\nIn this step, we establish server-side functions in the **src/actions/todoAction.ts** file to handle crucial operations on todo items:\\n\\n1. **`getData`:**\\n    - Fetches all existing todo items from the database.\\n2. **`addTodo`:**\\n    - Adds a new todo item to the database with the provided text.\\n    - Initiates revalidation of the home page using **`revalidatePath(\"/\")`**.\\n3. **`deleteTodo`:**\\n    - Removes a todo item from the database based on its unique ID.\\n    - Triggers a revalidation of the home page.\\n4. **`toggleTodo`:**\\n    - Toggles the completion status of a todo item, updating the database accordingly.\\n    - Revalidates the home page after the operation.\\n5. **`editTodo`:**\\n    - Modifies the text of a todo item identified by its ID in the database.\\n    - Initiates a revalidation of the home page.\\n\\n```tsx collapsable copy filename=\"src/actions/todoAction.ts\"\\n\"use server\";\\nimport { eq, not } from \"drizzle-orm\";\\nimport { revalidatePath } from \"next/cache\";\\nimport { db } from \"@/db/drizzle\";\\nimport { todo } from \"@/db/schema\";\\n\\nexport const getData = async () => {\\n  const data = await db.select().from(todo);\\n  return data;\\n};\\n\\nexport const addTodo = async (id: number, text: string) => {\\n  await db.insert(todo).values({\\n    id: id,\\n    text: text,\\n  });\\n};\\n\\nexport const deleteTodo = async (id: number) => {\\n  await db.delete(todo).where(eq(todo.id, id));\\n\\n  revalidatePath(\"/\");\\n};\\n\\nexport const toggleTodo = async (id: number) => {\\n  await db\\n    .update(todo)\\n    .set({\\n      done: not(todo.done),\\n    })\\n    .where(eq(todo.id, id));\\n\\n  revalidatePath(\"/\");\\n};\\n\\nexport const editTodo = async (id: number, text: string) => {\\n  await db\\n    .update(todo)\\n    .set({\\n      text: text,\\n    })\\n    .where(eq(todo.id, id));\\n\\n  revalidatePath(\"/\");\\n};\\n```\\n\\n## Setup home page with Next.js\\n\\n<Steps>\\n#### Define a TypeScript type\\n\\nDefine a TypeScript type for a todo item in `src/types/todoType.ts` with three properties: **`id`** of type **`number`**, **`text`** of type **`string`**, and **`done`** of type **`boolean`**. This type, named **`todoType`**, represents the structure of a typical todo item within your application.\\n\\n```ts copy filename=\"src/types/todoType.ts\"\\nexport type todoType = {\\n  id: number;\\n  text: string;\\n  done: boolean;\\n};\\n```\\n\\n#### Create a home page for a to-do application\\n\\n1. **`src/components/todo.tsx`:**\\n    Create a `Todo` component that represents a single todo item. It includes features for displaying and editing the todo text, marking it as done with a checkbox, and providing actions for editing, saving, canceling, and deleting the todo.\\n2. **`src/components/addTodo.tsx`:**\\n    The `AddTodo` component provides a simple form for adding new todo items to the Todo app. It includes an input field for entering the todo text and a button for triggering the addition of the new todo.\\n3. **`src/components/todos.tsx`:**\\n    Create Todos components that represents the main interface of a Todo app. It manages the state of todo items, provides functions for creating, editing, toggling, and deleting todos, and renders the individual todo items using the `Todo` component.\\n\\n<CodeTabs items={[\"todo.tsx\", \"addTodo.tsx\", \"todos.tsx\"]}>\\n```tsx collapsable copy\\n\"use client\";\\nimport { ChangeEvent, FC, useState } from \"react\";\\nimport { todoType } from \"@/types/todoType\";\\n\\ninterface Props {\\n  todo: todoType;\\n  changeTodoText: (id: number, text: string) => void;\\n  toggleIsTodoDone: (id: number, done: boolean) => void;\\n  deleteTodoItem: (id: number) => void;\\n}\\n\\nconst Todo: FC<Props> = ({\\n  todo,\\n  changeTodoText,\\n  toggleIsTodoDone,\\n  deleteTodoItem,\\n}) => {\\n  // State for handling editing mode\\n  const [editing, setEditing] = useState(false);\\n\\n  // State for handling text input\\n  const [text, setText] = useState(todo.text);\\n\\n  // State for handling \"done\" status\\n  const [isDone, setIsDone] = useState(todo.done);\\n\\n  // Event handler for text input change\\n  const handleTextChange = (e: ChangeEvent<HTMLInputElement>) => {\\n    setText(e.target.value);\\n  };\\n\\n  // Event handler for toggling \"done\" status\\n  const handleIsDone = async () => {\\n    toggleIsTodoDone(todo.id, !isDone);\\n    setIsDone((prev) => !prev);\\n  };\\n\\n  // Event handler for initiating the edit mode\\n  const handleEdit = () => {\\n    setEditing(true);\\n  };\\n\\n  // Event handler for saving the edited text\\n  const handleSave = async () => {\\n    changeTodoText(todo.id, text);\\n    setEditing(false);\\n  };\\n\\n  // Event handler for canceling the edit mode\\n  const handleCancel = () => {\\n    setEditing(false);\\n    setText(todo.text);\\n  };\\n\\n  // Event handler for deleting a todo item\\n  const handleDelete = () => {\\n    if (confirm(\"Are you sure you want to delete this todo?\")) {\\n      deleteTodoItem(todo.id);\\n    }\\n  };\\n\\n  // Rendering the Todo component\\n  return (\\n    <div className=\"flex items-center gap-2 p-4 border-gray-200 border-solid border rounded-lg\">\\n      {/* Checkbox for marking the todo as done */}\\n      <input\\n        type=\"checkbox\"\\n        className=\"text-blue-200 rounded-sm h-4 w-4\"\\n        checked={isDone}\\n        onChange={handleIsDone}\\n      />\\n      {/* Input field for todo text */}\\n      <input\\n        type=\"text\"\\n        value={text}\\n        onChange={handleTextChange}\\n        readOnly={!editing}\\n        className={`${\\n          todo.done ? \"line-through\" : \"\"\\n        } outline-none read-only:border-transparent focus:border border-gray-200 rounded px-2 py-1 w-full`}\\n      />\\n      {/* Action buttons for editing, saving, canceling, and deleting */}\\n      <div className=\"flex gap-1 ml-auto\">\\n        {editing ? (\\n          <button\\n            onClick={handleSave}\\n            className=\"bg-green-600 text-green-50 rounded px-2 w-14 py-1\"\\n          >\\n            Save\\n          </button>\\n        ) : (\\n          <button\\n            onClick={handleEdit}\\n            className=\"bg-blue-400 text-blue-50 rounded w-14 px-2 py-1\"\\n          >\\n            Edit\\n          </button>\\n        )}\\n        {editing ? (\\n          <button\\n            onClick={handleCancel}\\n            className=\"bg-red-400 w-16 text-red-50 rounded px-2 py-1\"\\n          >\\n            Close\\n          </button>\\n        ) : (\\n          <button\\n            onClick={handleDelete}\\n            className=\"bg-red-400 w-16 text-red-50 rounded px-2 py-1\"\\n          >\\n            Delete\\n          </button>\\n        )}\\n      </div>\\n    </div>\\n  );\\n};\\n\\nexport default Todo;\\n```\\n```tsx collapsable copy\\n\"use client\";\\nimport { ChangeEvent, FC, useState } from \"react\";\\n\\ninterface Props {\\n  createTodo: (value: string) => void;\\n}\\n\\nconst AddTodo: FC<Props> = ({ createTodo }) => {\\n  // State for handling input value\\n  const [input, setInput] = useState(\"\");\\n\\n  // Event handler for input change\\n  const handleInput = (e: ChangeEvent<HTMLInputElement>) => {\\n    setInput(e.target.value);\\n  };\\n\\n  // Event handler for adding a new todo\\n  const handleAdd = async () => {\\n    createTodo(input);\\n    setInput(\"\");\\n  };\\n\\n  // Rendering the AddTodo component\\n  return (\\n    <div className=\"w-full flex gap-1 mt-2\">\\n      {/* Input field for entering new todo text */}\\n      <input\\n        type=\"text\"\\n        className=\"w-full px-2 py-1 border border-gray-200 rounded outline-none\"\\n        onChange={handleInput}\\n        value={input}\\n      />\\n      {/* Button for adding a new todo */}\\n      <button\\n        className=\"flex items-center justify-center bg-green-600 text-green-50 rounded px-2 h-9 w-14 py-1\"\\n        onClick={handleAdd}\\n      >\\n        Add\\n      </button>\\n    </div>\\n  );\\n};\\n\\nexport default AddTodo;\\n```\\n\\n\\t<CodeTab>\\n```tsx collapsable copy\\n\"use client\";\\nimport { FC, useState } from \"react\";\\nimport { todoType } from \"@/types/todoType\";\\nimport Todo from \"./todo\";\\nimport AddTodo from \"./addTodo\";\\nimport { addTodo, deleteTodo, editTodo, toggleTodo } from \"@/actions/todoAction\";\\n\\ninterface Props {\\n  todos: todoType[];\\n}\\n\\nconst Todos: FC<Props> = ({ todos }) => {\\n  // State to manage the list of todo items\\n  const [todoItems, setTodoItems] = useState<todoType[]>(todos);\\n\\n  // Function to create a new todo item\\n  const createTodo = (text: string) => {\\n    const id = (todoItems.at(-1)?.id || 0) + 1;\\n    addTodo(id, text);\\n    setTodoItems((prev) => [...prev, { id: id, text, done: false }]);\\n  };\\n\\n  // Function to change the text of a todo item\\n  const changeTodoText = (id: number, text: string) => {\\n    setTodoItems((prev) =>\\n      prev.map((todo) => (todo.id === id ? { ...todo, text } : todo))\\n    );\\n    editTodo(id, text);\\n  };\\n\\n  // Function to toggle the \"done\" status of a todo item\\n  const toggleIsTodoDone = (id: number) => {\\n    setTodoItems((prev) =>\\n      prev.map((todo) => (todo.id === id ? { ...todo, done: !todo.done } : todo))\\n    );\\n    toggleTodo(id);\\n  };\\n\\n  // Function to delete a todo item\\n  const deleteTodoItem = (id: number) => {\\n    setTodoItems((prev) => prev.filter((todo) => todo.id !== id));\\n    deleteTodo(id);\\n  };\\n\\n  // Rendering the Todo List component\\n  return (\\n    <main className=\"flex mx-auto max-w-xl w-full min-h-screen flex-col items-center p-16\">\\n      <div className=\"text-5xl font-medium\">To-do app</div>\\n      <div className=\"w-full flex flex-col mt-8 gap-2\">\\n        {/* Mapping through todoItems and rendering Todo component for each */}\\n        {todoItems.map((todo) => (\\n          <Todo\\n            key={todo.id}\\n            todo={todo}\\n            changeTodoText={changeTodoText}\\n            toggleIsTodoDone={toggleIsTodoDone}\\n            deleteTodoItem={deleteTodoItem}\\n          />\\n        ))}\\n      </div>\\n      {/* Adding Todo component for creating new todos */}\\n      <AddTodo createTodo={createTodo} />\\n    </main>\\n  );\\n};\\n\\nexport default Todos;\\n```\\n\\n    </CodeTab>\\n</CodeTabs>\\n\\nUpdate the `page.tsx` file in the `src/app` folder to fetch the todo items from the database and render the `Todos` component:\\n\\n```tsx copy filename=\"src/app/page.tsx\"\\nimport { getData } from \"@/actions/todoAction\";\\nimport Todos from \"@/components/todos\";\\n\\nexport default async function Home() {\\n  const data = await getData();\\n  return <Todos todos={data} />;\\n}\\n```\\n</Steps>\\n\\n## Basic file structure\\n\\nThis guide uses the following file structure:\\n\\n```text\\nðŸ“¦ <project root>\\n â”œ ðŸ“‚ migrations\\n â”‚  â”œ ðŸ“‚ meta\\n â”‚  â”” ðŸ“œ 0000_heavy_doctor_doom.sql\\n â”œ ðŸ“‚ public\\n â”œ ðŸ“‚ src\\n â”‚  â”œ ðŸ“‚ actions\\n â”‚  â”‚  â”” ðŸ“œ todoActions.ts\\n â”‚  â”œ ðŸ“‚ app\\n â”‚  â”‚  â”œ ðŸ“œ favicon.ico\\n â”‚  â”‚  â”œ ðŸ“œ globals.css\\n â”‚  â”‚  â”œ ðŸ“œ layout.tsx\\n â”‚  â”‚  â”” ðŸ“œ page.tsx\\n â”‚  â”œ ðŸ“‚ components\\n â”‚  â”‚  â”œ ðŸ“œ addTodo.tsx\\n â”‚  â”‚  â”œ ðŸ“œ todo.tsx\\n â”‚  â”‚  â”” ðŸ“œ todos.tsx\\n â”‚  â”” ðŸ“‚ db\\n â”‚  â”‚  â”œ ðŸ“œ drizzle.ts\\n â”‚  â”‚  â”” ðŸ“œ schema.ts\\n â”‚  â”” ðŸ“‚ types\\n â”‚     â”” ðŸ“œ todoType.ts\\n â”œ ðŸ“œ .env\\n â”œ ðŸ“œ .eslintrc.json\\n â”œ ðŸ“œ .gitignore\\n â”œ ðŸ“œ drizzle.config.ts\\n â”œ ðŸ“œ next-env.d.ts\\n â”œ ðŸ“œ next.config.mjs\\n â”œ ðŸ“œ package-lock.json\\n â”œ ðŸ“œ package.json\\n â”œ ðŸ“œ postcss.config.mjs\\n â”œ ðŸ“œ README.md\\n â”œ ðŸ“œ tailwind.config.ts\\n â”” ðŸ“œ tsconfig.json\\n```\\n', children=[])]),\n",
       " DocItem(origPath=Path('tutorials.mdx'), name='tutorials.mdx', displayName='tutorials.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tutorials from \"@components/Tutorials.astro\";\\n\\n<Tutorials/>', children=[]),\n",
       " DocItem(origPath=Path('typebox.mdx'), name='typebox.mdx', displayName='typebox.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# drizzle-typebox\\n\\n`drizzle-typebox` is a plugin for **[Drizzle ORM](https://github.com/drizzle-team/drizzle-orm)** that allows you to generate **[Typebox](https://github.com/sinclairzx81/typebox)** schemas from Drizzle ORM schemas.\\n\\n### Install the dependencies\\n\\n<Npm>\\ndrizzle-typebox\\n</Npm>\\n\\n<Callout type=\"warning\">\\nThis documentation is for `drizzle-typebox@0.2.0` and higher\\n\\nYou must also have Drizzle ORM v0.36.0 or greater and Typebox v0.34.8 or greater installed.\\n</Callout>\\n\\n### Select schema\\n\\nDefines the shape of data queried from the database - can be used to validate API responses.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-typebox\\';\\nimport { Value } from \\'@sinclair/typebox/value\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users);\\n\\nconst rows = await db.select({ id: users.id, name: users.name }).from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = Value.Parse(userSelectSchema, rows[0]); // Error: `age` is not returned in the above query\\n\\nconst rows = await db.select().from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = Value.Parse(userSelectSchema, rows[0]); // Will parse successfully\\n```\\n\\nViews and enums are also supported.\\n\\n```ts copy\\nimport { pgEnum } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-typebox\\';\\nimport { Value } from \\'@sinclair/typebox/value\\';\\n\\nconst roles = pgEnum(\\'roles\\', [\\'admin\\', \\'basic\\']);\\nconst rolesSchema = createSelectSchema(roles);\\nconst parsed: \\'admin\\' | \\'basic\\' = Value.Parse(rolesSchema, ...);\\n\\nconst usersView = pgView(\\'users_view\\').as((qb) => qb.select().from(users).where(gt(users.age, 18)));\\nconst usersViewSchema = createSelectSchema(usersView);\\nconst parsed: { id: number; name: string; age: number } = Value.Parse(usersViewSchema, ...);\\n```\\n\\n### Insert schema\\n\\nDefines the shape of data to be inserted into the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createInsertSchema } from \\'drizzle-typebox\\';\\nimport { Value } from \\'@sinclair/typebox/value\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userInsertSchema = createInsertSchema(users);\\n\\nconst user = { name: \\'John\\' };\\nconst parsed: { name: string, age: number } = Value.Parse(userInsertSchema, user); // Error: `age` is not defined\\n\\nconst user = { name: \\'Jane\\', age: 30 };\\nconst parsed: { name: string, age: number } = Value.Parse(userInsertSchema, user); // Will parse successfully\\nawait db.insert(users).values(parsed);\\n```\\n\\n### Update schema\\n\\nDefines the shape of data to be updated in the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createUpdateSchema } from \\'drizzle-typebox\\';\\nimport { Value } from \\'@sinclair/typebox/value\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userUpdateSchema = createUpdateSchema(users);\\n\\nconst user = { id: 5, name: \\'John\\' };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = Value.Parse(userUpdateSchema, user); // Error: `id` is a generated column, it can\\'t be updated\\n\\nconst user = { age: 35 };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = Value.Parse(userUpdateSchema, user); // Will parse successfully\\nawait db.update(users).set(parsed).where(eq(users.name, \\'Jane\\'));\\n```\\n\\n### Refinements\\n\\nEach create schema function accepts an additional optional parameter that you can used to extend, modify or completely overwite a field\\'s schema. Defining a callback function will extend or modify while providing a Typebox schema will overwrite it.\\n\\n```ts copy\\nimport { pgTable, text, integer, json } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-typebox\\';\\nimport { Type } from \\'@sinclair/typebox\\';\\nimport { Value } from \\'@sinclair/typebox/value\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  bio: text(),\\n  preferences: json()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users, {\\n  name: (schema) => Type.String({ ...schema, maxLength: 20 }), // Extends schema\\n  bio: (schema) => Type.String({ ...schema, maxLength: 1000 }), // Extends schema before becoming nullable/optional\\n  preferences: Type.Object({ theme: Type.String() }) // Overwrites the field, including its nullability\\n});\\n\\nconst parsed: {\\n  id: number;\\n  name: string,\\n  bio?: string | undefined;\\n  preferences: {\\n    theme: string;\\n  };\\n} = Value.Parse(userSelectSchema, ...);\\n```\\n\\n### Factory functions\\n\\nFor more advanced use cases, you can use the `createSchemaFactory` function.\\n\\n**Use case: Using an extended Typebox instance**\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSchemaFactory } from \\'drizzle-typebox\\';\\nimport { t } from \\'elysia\\'; // Extended Typebox instance\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst { createInsertSchema } = createSchemaFactory({ typeboxInstance: t });\\n\\nconst userInsertSchema = createInsertSchema(users, {\\n  // We can now use the extended instance\\n  name: (schema) => t.Number({ ...schema }, { error: \\'`name` must be a string\\' })\\n});\\n```\\n\\n### Data type reference\\n\\n```ts\\npg.boolean();\\n\\nmysql.boolean();\\n\\nsqlite.integer({ mode: \\'boolean\\' });\\n\\n// Schema\\nType.Boolean();\\n```\\n\\n```ts\\npg.date({ mode: \\'date\\' });\\npg.timestamp({ mode: \\'date\\' });\\n\\nmysql.date({ mode: \\'date\\' });\\nmysql.datetime({ mode: \\'date\\' });\\nmysql.timestamp({ mode: \\'date\\' });\\n\\nsqlite.integer({ mode: \\'timestamp\\' });\\nsqlite.integer({ mode: \\'timestamp_ms\\' });\\n\\n// Schema\\nType.Date();\\n```\\n\\n```ts\\npg.date({ mode: \\'string\\' });\\npg.timestamp({ mode: \\'string\\' });\\npg.cidr();\\npg.inet();\\npg.interval();\\npg.macaddr();\\npg.macaddr8();\\npg.numeric();\\npg.text();\\npg.sparsevec();\\npg.time();\\n\\nmysql.binary();\\nmysql.date({ mode: \\'string\\' });\\nmysql.datetime({ mode: \\'string\\' });\\nmysql.decimal();\\nmysql.time();\\nmysql.timestamp({ mode: \\'string\\' });\\nmysql.varbinary();\\n\\nsqlite.numeric();\\nsqlite.text({ mode: \\'text\\' });\\n\\n// Schema\\nType.String();\\n```\\n\\n```ts\\npg.bit({ dimensions: ... });\\n\\n// Schema\\nt.RegExp(/^[01]+$/, { maxLength: dimensions });\\n```\\n\\n```ts\\npg.uuid();\\n\\n// Schema\\nType.String({ format: \\'uuid\\' });\\n```\\n\\n```ts\\npg.char({ length: ... });\\n\\nmysql.char({ length: ... });\\n\\n// Schema\\nType.String({ minLength: length, maxLength: length });\\n```\\n\\n```ts\\npg.varchar({ length: ... });\\n\\nmysql.varchar({ length: ... });\\n\\nsqlite.text({ mode: \\'text\\', length: ... });\\n\\n// Schema\\nType.String({ maxLength: length });\\n```\\n\\n```ts\\nmysql.tinytext();\\n\\n// Schema\\nType.String({ maxLength: 255 }); // unsigned 8-bit integer limit\\n```\\n\\n```ts\\nmysql.text();\\n\\n// Schema\\nType.String({ maxLength: 65_535 }); // unsigned 16-bit integer limit\\n```\\n\\n```ts\\nmysql.mediumtext();\\n\\n// Schema\\nType.String({ maxLength: 16_777_215 }); // unsigned 24-bit integer limit\\n```\\n\\n```ts\\nmysql.longtext();\\n\\n// Schema\\nType.String({ maxLength: 4_294_967_295 }); // unsigned 32-bit integer limit\\n```\\n\\n```ts\\npg.text({ enum: ... });\\npg.char({ enum: ... });\\npg.varchar({ enum: ... });\\n\\nmysql.tinytext({ enum: ... });\\nmysql.mediumtext({ enum: ... });\\nmysql.text({ enum: ... });\\nmysql.longtext({ enum: ... });\\nmysql.char({ enum: ... });\\nmysql.varchar({ enum: ... });\\nmysql.mysqlEnum(..., ...);\\n\\nsqlite.text({ mode: \\'text\\', enum: ... });\\n\\n// Schema\\nType.Enum(enum);\\n```\\n\\n```ts\\nmysql.tinyint();\\n\\n// Schema\\nType.Integer({ minimum: -128, maximum: 127 }); // 8-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.tinyint({ unsigned: true });\\n\\n// Schema\\nType.Integer({ minimum: 0, maximum: 255 }); // unsigned 8-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.smallint();\\npg.smallserial();\\n\\nmysql.smallint();\\n\\n// Schema\\nType.Integer({ minimum: -32_768, maximum: 32_767 }); // 16-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.smallint({ unsigned: true });\\n\\n// Schema\\nType.Integer({ minimum: 0, maximum: 65_535 }); // unsigned 16-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.real();\\n\\nmysql.float();\\n\\n// Schema\\nType.Number().min(-8_388_608).max(8_388_607); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint();\\n\\n// Schema\\nType.Integer({ minimum: -8_388_608, maximum: 8_388_607 }); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.float({ unsigned: true });\\n\\n// Schema\\nType.Number({ minimum: 0, maximum: 16_777_215 }); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint({ unsigned: true });\\n\\n// Schema\\nType.Integer({ minimum: 0, maximum: 16_777_215 }); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.integer();\\npg.serial();\\n\\nmysql.int();\\n\\n// Schema\\nType.Integer({ minimum: -2_147_483_648, maximum: 2_147_483_647 }); // 32-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.int({ unsigned: true });\\n\\n// Schema\\nType.Integer({ minimum: 0, maximum: 4_294_967_295 }); // unsgined 32-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.doublePrecision();\\n\\nmysql.double();\\nmysql.real();\\n\\nsqlite.real();\\n\\n// Schema\\nType.Number({ minimum: -140_737_488_355_328, maximum: 140_737_488_355_327 }); // 48-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.double({ unsigned: true });\\n\\n// Schema\\nType.Numer({ minimum: 0, maximum: 281_474_976_710_655 }); // unsigned 48-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.bigint({ mode: \\'number\\' });\\npg.bigserial({ mode: \\'number\\' });\\n\\nmysql.bigint({ mode: \\'number\\' });\\nmysql.bigserial({ mode: \\'number\\' });\\n\\nsqlite.integer({ mode: \\'number\\' });\\n\\n// Schema\\nType.Integer({ minimum: -9_007_199_254_740_991, maximum: 9_007_199_254_740_991 }); // Javascript min. and max. safe integers\\n```\\n\\n```ts\\nmysql.serial();\\n\\nType.Integer({ minimum: 0, maximum: 9_007_199_254_740_991 }); // Javascript max. safe integer\\n```\\n\\n```ts\\npg.bigint({ mode: \\'bigint\\' });\\npg.bigserial({ mode: \\'bigint\\' });\\n\\nmysql.bigint({ mode: \\'bigint\\' });\\n\\nsqlite.blob({ mode: \\'bigint\\' });\\n\\n// Schema\\nType.BigInt({ minimum: -9_223_372_036_854_775_808n, maximum: 9_223_372_036_854_775_807n }); // 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.bigint({ mode: \\'bigint\\', unsigned: true });\\n\\n// Schema\\nType.BigInt({ minimum: 0, maximum: 18_446_744_073_709_551_615n }); // unsigned 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.year();\\n\\n// Schema\\nType.Integer({ minimum: 1_901, maximum: 2_155 });\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'tuple\\' });\\npg.point({ mode: \\'tuple\\' });\\n\\n// Schema\\nType.Tuple([Type.Number(), Type.Number()]);\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'xy\\' });\\npg.point({ mode: \\'xy\\' });\\n\\n// Schema\\nType.Object({ x: Type.Number(), y: Type.Number() });\\n```\\n\\n```ts\\npg.halfvec({ dimensions: ... });\\npg.vector({ dimensions: ... });\\n\\n// Schema\\nType.Array(Type.Number(), { minItems: dimensions, maxItems: dimensions });\\n```\\n\\n```ts\\npg.line({ mode: \\'abc\\' });\\n\\n// Schema\\nType.Object({ a: Type.Number(), b: Type.Number(), c: Type.Number() });\\n```\\n\\n```ts\\npg.line({ mode: \\'tuple\\' });\\n\\n// Schema\\nType.Tuple([Type.Number(), Type.Number(), Type.Number()]);\\n```\\n\\n```ts\\npg.json();\\npg.jsonb();\\n\\nmysql.json();\\n\\nsqlite.blob({ mode: \\'json\\' });\\nsqlite.text({ mode: \\'json\\' });\\n\\n// Schema\\nType.Recursive((self) => Type.Union([Type.Union([Type.String(), Type.Number(), Type.Boolean(), Type.Null()]), Type.Array(self), Type.Record(Type.String(), self)]));\\n```\\n\\n```ts\\nsqlite.blob({ mode: \\'buffer\\' });\\n\\n// Schema\\nt.Union([t.Union([t.String(), t.Number(), t.Boolean(), t.Null()]), t.Array(t.Any()), t.Record(t.String(), t.Any())]);\\n```\\n\\n```ts\\npg.dataType().array(...);\\n\\n// Schema\\nType.Array(baseDataTypeSchema, { minItems: size, maxItems: size });\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('update.mdx'), name='update.mdx', displayName='update.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# SQL Update\\n\\n```typescript copy\\nawait db.update(users)\\n  .set({ name: \\'Mr. Dan\\' })\\n  .where(eq(users.name, \\'Dan\\'));\\n```\\n\\nThe object that you pass to `update` should have keys that match column names in your database schema.\\nValues of `undefined` are ignored in the object: to set a column to `null`, pass `null`.\\nYou can pass SQL as a value to be used in the update object, like this:\\n\\n```typescript copy\\nawait db.update(users)\\n  .set({ updatedAt: sql`NOW()` })\\n  .where(eq(users.name, \\'Dan\\'));\\n```\\n\\n### Limit\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': false, \\'MySQL\\': true, \\'SQLite\\': true, \\'SingleStore\\': true }} />\\n\\nUse `.limit()` to add `limit` clause to the query - for example:\\n<Section>\\n```typescript\\nawait db.update(usersTable).set({ verified: true }).limit(2);\\n```\\n```sql\\nupdate \"users\" set \"verified\" = $1 limit $2;\\n```\\n</Section>\\n\\n### Order By\\nUse `.orderBy()` to add `order by` clause to the query, sorting the results by the specified fields:\\n<Section>\\n```typescript\\nimport { asc, desc } from \\'drizzle-orm\\';\\n\\nawait db.update(usersTable).set({ verified: true }).orderBy(usersTable.name);\\nawait db.update(usersTable).set({ verified: true }).orderBy(desc(usersTable.name));\\n\\n// order by multiple fields\\nawait db.update(usersTable).set({ verified: true }).orderBy(usersTable.name, usersTable.name2);\\nawait db.update(usersTable).set({ verified: true }).orderBy(asc(usersTable.name), desc(usersTable.name2));\\n```\\n```sql\\nupdate \"users\" set \"verified\" = $1 order by \"name\";\\nupdate \"users\" set \"verified\" = $1 order by \"name\" desc;\\n\\nupdate \"users\" set \"verified\" = $1 order by \"name\", \"name2\";\\nupdate \"users\" set \"verified\" = $1 order by \"name\" asc, \"name2\" desc;\\n```\\n</Section>\\n\\n### Update with returning\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': false , \\'SingleStore\\': false}} />\\nYou can update a row and get it back in PostgreSQL and SQLite:\\n```typescript copy\\nconst updatedUserId: { updatedId: number }[] = await db.update(users)\\n  .set({ name: \\'Mr. Dan\\' })\\n  .where(eq(users.name, \\'Dan\\'))\\n  .returning({ updatedId: users.id });\\n```\\n\\n## `with update` clause\\n\\n<Callout>\\n  Check how to use WITH statement with [select](/docs/select#with-clause), [insert](/docs/insert#with-insert-clause), [delete](/docs/delete#with-delete-clause)\\n</Callout>\\n\\nUsing the `with` clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\\n<Section>\\n```typescript copy\\nconst averagePrice = db.$with(\\'average_price\\').as(\\n        db.select({ value: sql`avg(${products.price})`.as(\\'value\\') }).from(products)\\n);\\n\\nconst result = await db.with(averagePrice)\\n\\t\\t.update(products)\\n\\t\\t.set({\\n\\t\\t\\tcheap: true\\n\\t\\t})\\n\\t\\t.where(lt(products.price, sql`(select * from ${averagePrice})`))\\n\\t\\t.returning({\\n\\t\\t\\tid: products.id\\n\\t\\t});\\n```\\n```sql\\nwith \"average_price\" as (select avg(\"price\") as \"value\" from \"products\") \\nupdate \"products\" set \"cheap\" = $1 \\nwhere \"products\".\"price\" < (select * from \"average_price\") \\nreturning \"id\"\\n```\\n</Section>\\n\\n## Update ... from\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': true, \\'SingleStore\\': false }} />\\n\\nAs the SQLite documentation mentions:\\n\\n> The UPDATE-FROM idea is an extension to SQL that allows an UPDATE statement to be driven by other tables in the database. \\nThe \"target\" table is the specific table that is being updated. With UPDATE-FROM you can join the target table \\nagainst other tables in the database in order to help compute which rows need updating and what \\nthe new values should be on those rows\\n\\nSimilarly, the PostgreSQL documentation states:\\n\\n> A table expression allowing columns from other tables to appear in the WHERE condition and update expressions\\n\\nDrizzle also supports this feature starting from version `drizzle-orm@0.36.3`\\n\\n<Section>\\n```ts\\nawait db\\n  .update(users)\\n  .set({ cityId: cities.id })\\n  .from(cities)\\n  .where(and(eq(cities.name, \\'Seattle\\'), eq(users.name, \\'John\\')))\\n```\\n```sql\\nupdate \"users\" set \"city_id\" = \"cities\".\"id\" \\nfrom \"cities\" \\nwhere (\"cities\".\"name\" = $1 and \"users\".\"name\" = $2)\\n\\n-- params: [ \\'Seattle\\', \\'John\\' ]\\n```\\n</Section>\\n\\nYou can also alias tables that are joined (in PG, you can also alias the updating table too).\\n<Section>\\n```ts\\nconst c = alias(cities, \\'c\\');\\nawait db\\n  .update(users)\\n  .set({ cityId: c.id })\\n  .from(c);\\n```\\n```sql\\nupdate \"users\" set \"city_id\" = \"c\".\"id\" \\nfrom \"cities\" \"c\"\\n```\\n</Section>\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false, \\'SingleStore\\': false }} />\\n\\nIn Postgres, you can also return columns from the joined tables.\\n<Section>\\n```ts\\nconst updatedUsers = await db\\n  .update(users)\\n  .set({ cityId: cities.id })\\n  .from(cities)\\n  .returning({ id: users.id, cityName: cities.name });\\n```\\n```sql\\nupdate \"users\" set \"city_id\" = \"cities\".\"id\" \\nfrom \"cities\" \\nreturning \"users\".\"id\", \"cities\".\"name\"\\n```\\n</Section>', children=[]),\n",
       " DocItem(origPath=Path('upgrade-21.mdx'), name='upgrade-21.mdx', displayName='upgrade-21.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\n\\n## How to migrate to `0.21.0`\\n\\n#### 1. Remove all `:dialect` prefixes from your drizzle-kit commands.\\nExample: Change `drizzle-kit push:mysql` to `drizzle-kit push`.\\n\\n#### 2. Update your `drizzle.config.ts` file:\\n - Add `dialect` to `drizzle.config.ts`. It is now mandatory and can be `postgresql`, `mysql`, or `sqlite`.\\n - Add `driver` to `drizzle.config.ts` ONLY if you are using `aws-data-api`, `turso`, `d1-http`(WIP), or `expo`. Otherwise, you can remove the `driver` from `drizzle.config.ts`.\\n - If you were using `connectionString` or `uri` in `dbCredentials`, you should now use `url`.\\n    \\n```ts\\nimport { defineConfig } from \"drizzle-kit\"\\n\\nexport default defineConfig({\\n    dialect: \"sqlite\", // \"postgresql\" | \"mysql\"\\n    driver: \"turso\", // optional and used only if `aws-data-api`, `turso`, `d1-http`(WIP) or `expo` are used\\n    dbCredentials: {\\n        url: \"\"\\n    }\\n})\\n```\\n\\n#### 3. If you are using PostgreSQL or SQLite and had migrations generated in your project, please run `drizzle-kit up` so Drizzle can upgrade all the snapshots to version 6.\\n\\n<Callout>\\n  You can check everything that was changed in `0.21.0` in details here\\n</Callout>\\n\\n## Changelog\\n\\n**â— Snapshots Upgrade**\\n\\nAll PostgreSQL and SQLite-generated snapshots will be upgraded to version 6. You will be prompted to upgrade them by running `drizzle-kit up`\\n\\n**â— Removing :dialect from `drizzle-kit` cli commands**\\n\\nYou can now just use commands, like:\\n\\n- `drizzle-kit generate`\\n- `drizzle-kit push`\\n- etc.\\n\\nwithout specifying dialect. This param is moved to `drizzle.config.ts`\\n\\n**â— `drizzle.config` update**\\n\\n- `dialect` is now mandatory; specify which database dialect you are connecting to. Options include `mysql`, `postgresql`, or `sqlite`.\\n- `driver` has become optional and will have a specific driver, each with a different configuration of `dbCredentials`. Available drivers are:\\n  - `aws-data-api`\\n  - `turso`\\n  - `d1-http` - currently WIP\\n  - `expo`\\n- `url` - a unified parameter for the previously existing `connectionString` and `uri`.\\n- `migrations` - a new object parameter to specify a custom table and schema for the migrate command:\\n  - `table` - the custom table where drizzle will store migrations.\\n  - `schema` - the custom schema where drizzle will store migrations (Postgres only).\\n\\nUsage examples for all new and updated commands\\n```ts\\nimport { defineConfig } from \"drizzle-kit\"\\n\\nexport default defineConfig({\\n    dialect: \"sqlite\", // \"postgresql\" | \"mysql\"\\n    driver: \"turso\"\\n    dbCredentials: {\\n        url: \"\"\\n    },\\n    migration: {\\n        table: \"migrations\",\\n        schema: \"public\"\\n    }\\n})\\n```\\n\\nDrizzle driver selection follows the current strategy:\\n\\nIf a `driver` is specified, use this driver for querying.\\n\\nIf no driver is specified:\\n\\n- For `postgresql` dialect, Drizzle will:\\n  - Check if the `pg` driver is installed and use it.\\n  - If not, try to find the `postgres` driver and use it.\\n  - If still not found, try to find `@vercel/postgres`.\\n  - Then try `@neondatabase/serverless`.\\n  - If nothing is found, an error will be thrown.\\n\\n- For `mysql` dialect, Drizzle will:\\n  - Check if the `mysql2` driver is installed and use it.\\n  - If not, try to find `@planetscale/database` and use it.\\n  - If nothing is found, an error will be thrown.\\n\\n- For `sqlite` dialect, Drizzle will:\\n  - Check if the `@libsql/client` driver is installed and use it.\\n  - If not, try to find `better-sqlite3` and use it.\\n  - If nothing is found, an error will be thrown\\n\\n**â— MySQL schemas/database are no longer supported by drizzle-kit**\\n\\nDrizzle Kit won\\'t handle any schema changes for additional schemas/databases in your drizzle schema file\\n\\n# New Features\\n\\n**ðŸŽ‰ Pull relations**\\n\\nDrizzle will now pull `relations` from the database by extracting foreign key information and translating it into a `relations` object. You can view the `relations.ts` file in the `out` folder after introspection is complete\\n\\nFor more info about relations, please check [the docs](/docs/rqb#declaring-relations)\\n\\n\\n**ðŸŽ‰ Custom name for generated migrations**\\n\\nTo specify a name for your migration you should use `--name <name>`\\n\\nUsage\\n```\\ndrizzle-kit generate --name init_db\\n```\\n\\n**ðŸŽ‰ New command `migrate`**\\n\\nYou can now apply generated migrations to your database directly from `drizzle-kit`\\n\\nUsage\\n```\\ndrizzle-kit migrate\\n```\\n\\nBy default, drizzle-kit will store migration data entries in the `__drizzle_migrations` table and, in the case of PostgreSQL, in a `drizzle` schema. If you want to change this, you will need to specify the modifications in `drizzle.config.ts`.\\n\\n```ts\\nimport { defineConfig } from \"drizzle-kit\"\\n\\nexport default defineConfig({\\n    migrations: {\\n        table: \"migrations\",\\n        schema: \"public\"\\n    }\\n})\\n```', children=[]),\n",
       " DocItem(origPath=Path('valibot.mdx'), name='valibot.mdx', displayName='valibot.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# drizzle-valibot\\n\\n`drizzle-valibot` is a plugin for **[Drizzle ORM](https://github.com/drizzle-team/drizzle-orm)** that allows you to generate **[Valibot](https://valibot.dev/)** schemas from Drizzle ORM schemas.\\n\\n### Install the dependencies\\n\\n<Npm>\\ndrizzle-valibot\\n</Npm>\\n\\n<Callout type=\"warning\">\\nThis documentation is for `drizzle-valibot@0.3.0` and higher\\n\\nYou must also have Drizzle ORM v0.36.0 or greater and Valibot v1.0.0-beta.7 or greater installed.\\n</Callout>\\n\\n### Select schema\\n\\nDefines the shape of data queried from the database - can be used to validate API responses.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-valibot\\';\\nimport { parse } from \\'valibot\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users);\\n\\nconst rows = await db.select({ id: users.id, name: users.name }).from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = parse(userSelectSchema, rows[0]); // Error: `age` is not returned in the above query\\n\\nconst rows = await db.select().from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = parse(userSelectSchema, rows[0]); // Will parse successfully\\n```\\n\\nViews and enums are also supported.\\n\\n```ts copy\\nimport { pgEnum } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-valibot\\';\\nimport { parse } from \\'valibot\\';\\n\\nconst roles = pgEnum(\\'roles\\', [\\'admin\\', \\'basic\\']);\\nconst rolesSchema = createSelectSchema(roles);\\nconst parsed: \\'admin\\' | \\'basic\\' = parse(rolesSchema, ...);\\n\\nconst usersView = pgView(\\'users_view\\').as((qb) => qb.select().from(users).where(gt(users.age, 18)));\\nconst usersViewSchema = createSelectSchema(usersView);\\nconst parsed: { id: number; name: string; age: number } = parse(usersViewSchema, ...);\\n```\\n\\n### Insert schema\\n\\nDefines the shape of data to be inserted into the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createInsertSchema } from \\'drizzle-valibot\\';\\nimport { parse } from \\'valibot\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userInsertSchema = createInsertSchema(users);\\n\\nconst user = { name: \\'John\\' };\\nconst parsed: { name: string, age: number } = parse(userInsertSchema, user); // Error: `age` is not defined\\n\\nconst user = { name: \\'Jane\\', age: 30 };\\nconst parsed: { name: string, age: number } = parse(userInsertSchema, user); // Will parse successfully\\nawait db.insert(users).values(parsed);\\n```\\n\\n### Update schema\\n\\nDefines the shape of data to be updated in the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createUpdateSchema } from \\'drizzle-valibot\\';\\nimport { parse } from \\'valibot\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userUpdateSchema = createUpdateSchema(users);\\n\\nconst user = { id: 5, name: \\'John\\' };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = parse(userUpdateSchema, user); // Error: `id` is a generated column, it can\\'t be updated\\n\\nconst user = { age: 35 };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = parse(userUpdateSchema, user); // Will parse successfully\\nawait db.update(users).set(parsed).where(eq(users.name, \\'Jane\\'));\\n```\\n\\n### Refinements\\n\\nEach create schema function accepts an additional optional parameter that you can used to extend, modify or completely overwite a field\\'s schema. Defining a callback function will extend or modify while providing a Valibot schema will overwrite it.\\n\\n```ts copy\\nimport { pgTable, text, integer, json } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-valibot\\';\\nimport { parse, pipe, maxLength, object, string } from \\'valibot\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  bio: text(),\\n  preferences: json()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users, {\\n  name: (schema) => pipe(schema, maxLength(20)), // Extends schema\\n  bio: (schema) => pipe(schema, maxLength(1000)), // Extends schema before becoming nullable/optional\\n  preferences: object({ theme: string() }) // Overwrites the field, including its nullability\\n});\\n\\nconst parsed: {\\n  id: number;\\n  name: string,\\n  bio?: string | undefined;\\n  preferences: {\\n    theme: string;\\n  };\\n} = parse(userSelectSchema, ...);\\n```\\n\\n### Data type reference\\n\\n```ts\\npg.boolean();\\n\\nmysql.boolean();\\n\\nsqlite.integer({ mode: \\'boolean\\' });\\n\\n// Schema\\nboolean();\\n```\\n\\n```ts\\npg.date({ mode: \\'date\\' });\\npg.timestamp({ mode: \\'date\\' });\\n\\nmysql.date({ mode: \\'date\\' });\\nmysql.datetime({ mode: \\'date\\' });\\nmysql.timestamp({ mode: \\'date\\' });\\n\\nsqlite.integer({ mode: \\'timestamp\\' });\\nsqlite.integer({ mode: \\'timestamp_ms\\' });\\n\\n// Schema\\ndate();\\n```\\n\\n```ts\\npg.date({ mode: \\'string\\' });\\npg.timestamp({ mode: \\'string\\' });\\npg.cidr();\\npg.inet();\\npg.interval();\\npg.macaddr();\\npg.macaddr8();\\npg.numeric();\\npg.text();\\npg.sparsevec();\\npg.time();\\n\\nmysql.binary();\\nmysql.date({ mode: \\'string\\' });\\nmysql.datetime({ mode: \\'string\\' });\\nmysql.decimal();\\nmysql.time();\\nmysql.timestamp({ mode: \\'string\\' });\\nmysql.varbinary();\\n\\nsqlite.numeric();\\nsqlite.text({ mode: \\'text\\' });\\n\\n// Schema\\nstring();\\n```\\n\\n```ts\\npg.bit({ dimensions: ... });\\n\\n// Schema\\npipe(string(), regex(/^[01]+$/), maxLength(dimensions));\\n```\\n\\n```ts\\npg.uuid();\\n\\n// Schema\\npipe(string(), uuid());\\n```\\n\\n```ts\\npg.char({ length: ... });\\n\\nmysql.char({ length: ... });\\n\\n// Schema\\npipe(string(), length(length));\\n```\\n\\n```ts\\npg.varchar({ length: ... });\\n\\nmysql.varchar({ length: ... });\\n\\nsqlite.text({ mode: \\'text\\', length: ... });\\n\\n// Schema\\npipe(string(), maxLength(length));\\n```\\n\\n```ts\\nmysql.tinytext();\\n\\n// Schema\\npipe(string(), maxLength(255)); // unsigned 8-bit integer limit\\n```\\n\\n```ts\\nmysql.text();\\n\\n// Schema\\npipe(string(), maxLength(65_535)); // unsigned 16-bit integer limit\\n```\\n\\n```ts\\nmysql.mediumtext();\\n\\n// Schema\\npipe(string(), maxLength(16_777_215)); // unsigned 24-bit integer limit\\n```\\n\\n```ts\\nmysql.longtext();\\n\\n// Schema\\npipe(string(), maxLength(4_294_967_295)); // unsigned 32-bit integer limit\\n```\\n\\n```ts\\npg.text({ enum: ... });\\npg.char({ enum: ... });\\npg.varchar({ enum: ... });\\n\\nmysql.tinytext({ enum: ... });\\nmysql.mediumtext({ enum: ... });\\nmysql.text({ enum: ... });\\nmysql.longtext({ enum: ... });\\nmysql.char({ enum: ... });\\nmysql.varchar({ enum: ... });\\nmysql.mysqlEnum(..., ...);\\n\\nsqlite.text({ mode: \\'text\\', enum: ... });\\n\\n// Schema\\nenum(enum);\\n```\\n\\n```ts\\nmysql.tinyint();\\n\\n// Schema\\npipe(number(), minValue(-128), maxValue(127), integer()); // 8-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.tinyint({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(255), integer()); // unsigned 8-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.smallint();\\npg.smallserial();\\n\\nmysql.smallint();\\n\\n// Schema\\npipe(number(), minValue(-32_768), maxValue(32_767), integer()); // 16-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.smallint({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(65_535), integer()); // unsigned 16-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.real();\\n\\nmysql.float();\\n\\n// Schema\\npipe(number(), minValue(-8_388_608), maxValue(8_388_607)); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint();\\n\\n// Schema\\npipe(number(), minValue(-8_388_608), maxValue(8_388_607), integer()); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.float({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(16_777_215)); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(16_777_215), integer()); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.integer();\\npg.serial();\\n\\nmysql.int();\\n\\n// Schema\\npipe(number(), minValue(-2_147_483_648), maxValue(2_147_483_647), integer()); // 32-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.int({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(4_294_967_295), integer()); // unsgined 32-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.doublePrecision();\\n\\nmysql.double();\\nmysql.real();\\n\\nsqlite.real();\\n\\n// Schema\\npipe(number(), minValue(-140_737_488_355_328), maxValue(140_737_488_355_327)); // 48-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.double({ unsigned: true });\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(281_474_976_710_655)); // unsigned 48-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.bigint({ mode: \\'number\\' });\\npg.bigserial({ mode: \\'number\\' });\\n\\nmysql.bigint({ mode: \\'number\\' });\\nmysql.bigserial({ mode: \\'number\\' });\\n\\nsqlite.integer({ mode: \\'number\\' });\\n\\n// Schema\\npipe(number(), minValue(-9_007_199_254_740_991), maxValue(9_007_199_254_740_991), integer()); // Javascript min. and max. safe integers\\n```\\n\\n```ts\\nmysql.serial();\\n\\n// Schema\\npipe(number(), minValue(0), maxValue(9_007_199_254_740_991), integer()); // Javascript max. safe integer\\n```\\n\\n```ts\\npg.bigint({ mode: \\'bigint\\' });\\npg.bigserial({ mode: \\'bigint\\' });\\n\\nmysql.bigint({ mode: \\'bigint\\' });\\n\\nsqlite.blob({ mode: \\'bigint\\' });\\n\\n// Schema\\npipe(bigint(), minValue(-9_223_372_036_854_775_808n), maxValue(9_223_372_036_854_775_807n)); // 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.bigint({ mode: \\'bigint\\', unsigned: true });\\n\\n// Schema\\npipe(bigint(), minValue(0n), maxValue(18_446_744_073_709_551_615n)); // unsigned 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.year();\\n\\n// Schema\\npipe(number(), minValue(1_901), maxValue(2_155), integer());\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'tuple\\' });\\npg.point({ mode: \\'tuple\\' });\\n\\n// Schema\\ntuple([number(), number()]);\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'xy\\' });\\npg.point({ mode: \\'xy\\' });\\n\\n// Schema\\nobject({ x: number(), y: number() });\\n```\\n\\n```ts\\npg.halfvec({ dimensions: ... });\\npg.vector({ dimensions: ... });\\n\\n// Schema\\npipe(array(number()), length(dimensions));\\n```\\n\\n```ts\\npg.line({ mode: \\'abc\\' });\\n\\n// Schema\\nobject({ a: number(), b: number(), c: number() });\\n```\\n\\n```ts\\npg.line({ mode: \\'tuple\\' });\\n\\n// Schema\\ntuple([number(), number(), number()]);\\n```\\n\\n```ts\\npg.json();\\npg.jsonb();\\n\\nmysql.json();\\n\\nsqlite.blob({ mode: \\'json\\' });\\nsqlite.text({ mode: \\'json\\' });\\n\\n// Schema\\nunion([union([string(), number(), boolean(), null_()]), array(any()), record(string(), any())]);\\n```\\n\\n```ts\\nsqlite.blob({ mode: \\'buffer\\' });\\n\\n// Schema\\ncustom<Buffer>((v) => v instanceof Buffer);\\n```\\n\\n```ts\\npg.dataType().array(...);\\n\\n// Schema\\npipe(array(baseDataTypeSchema), length(size));\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('views.mdx'), name='views.mdx', displayName='views.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Tab from \\'@mdx/Tab.astro\\';\\nimport Tabs from \\'@mdx/Tabs.astro\\';\\nimport IsSupportedChipGroup from \\'@mdx/IsSupportedChipGroup.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\nimport Section from \\'@mdx/Section.astro\\';\\n\\n# Views\\n\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'SQLite\\': true, \\'MySQL\\': true, \\'SingleStore\\': false }} />\\nThere\\'re several ways you can declare views with Drizzle ORM.  \\n\\nYou can declare views that have to be created or you can declare views that already exist in the database. \\n\\nYou can declare views statements with an inline `query builder` syntax, with `standalone query builder` and with raw `sql` operators. \\n\\nWhen views are created with either inlined or standalone query builders, view columns schema will be automatically inferred, \\nyet when you use `sql` you have to explicitly declare view columns schema.\\n\\n### Declaring views\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {13-14}\\n      import { pgTable, pgView, serial, text, timestamp } from \"drizzle-orm/pg-core\";\\n\\n      export const user = pgTable(\"user\", {\\n        id: serial(),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: timestamp(\"created_at\"),\\n        updatedAt: timestamp(\"updated_at\"),\\n      });\\n\\n      export const userView = pgView(\"user_view\").as((qb) => qb.select().from(user));\\n      export const customersView = pgView(\"customers_view\").as((qb) => qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {13-14}\\n      import { text, mysqlTable, mysqlView, int, timestamp } from \"drizzle-orm/mysql-core\";\\n\\n      export const user = mysqlTable(\"user\", {\\n        id: int().primaryKey().autoincrement(),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: timestamp(\"created_at\"),\\n        updatedAt: timestamp(\"updated_at\"),\\n      });\\n\\n      export const userView = mysqlView(\"user_view\").as((qb) => qb.select().from(user));\\n      export const customersView = mysqlView(\"customers_view\").as((qb) => qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {13-14}\\n      import { integer, text, sqliteView, sqliteTable } from \"drizzle-orm/sqlite-core\";\\n\\n      export const user = sqliteTable(\"user\", {\\n        id: integer().primaryKey({ autoIncrement: true }),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: integer(\"created_at\"),\\n        updatedAt: integer(\"updated_at\"),\\n      });\\n\\n      export const userView = sqliteView(\"user_view\").as((qb) => qb.select().from(user));\\n      export const customersView = sqliteView(\"customers_view\").as((qb) => qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n\\nIf you need a subset of columns you can use `.select({ ... })` method in query builder, like this:\\n<Section>\\n  ```ts {4-6}\\n  export const customersView = pgView(\"customers_view\").as((qb) => {\\n    return qb\\n      .select({\\n        id: user.id,\\n        name: user.name,\\n        email: user.email,\\n      })\\n      .from(user);\\n  });\\n  ```\\n  ```sql\\n  CREATE VIEW \"customers_view\" AS SELECT \"id\", \"name\", \"email\" FROM \"user\" WHERE \"role\" = \\'customer\\';\\n  ```\\n</Section>\\n\\nYou can also declare views using `standalone query builder`, it works exactly the same way:\\n<Tabs items={[\\'PostgreSQL\\', \\'MySQL\\', \\'SQLite\\']}>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {3, 15-16}\\n      import { pgTable, pgView, serial, text, timestamp, QueryBuilder} from \"drizzle-orm/pg-core\";\\n      \\n      const qb = new QueryBuilder();\\n\\n      export const user = pgTable(\"user\", {\\n        id: serial(),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: timestamp(\"created_at\"),\\n        updatedAt: timestamp(\"updated_at\"),\\n      });\\n\\n      export const userView = pgView(\"user_view\").as(qb.select().from(user));\\n      export const customersView = pgView(\"customers_view\").as(qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {3, 15-16}\\n      import { text, mysqlTable, mysqlView, int, timestamp, QueryBuilder } from \"drizzle-orm/mysql-core\";\\n\\n      const qb = new QueryBuilder();\\n\\n      export const user = mysqlTable(\"user\", {\\n        id: int().primaryKey().autoincrement(),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: timestamp(\"created_at\"),\\n        updatedAt: timestamp(\"updated_at\"),\\n      });\\n\\n      export const userView = mysqlView(\"user_view\").as(qb.select().from(user));\\n      export const customersView = mysqlView(\"customers_view\").as(qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n  <Tab>\\n    <Section>\\n      ```ts filename=\"schema.ts\" copy {3, 15-16}\\n      import { integer, text, sqliteView, sqliteTable, QueryBuilder } from \"drizzle-orm/sqlite-core\";\\n\\n      const qb = new QueryBuilder();\\n\\n      export const user = sqliteTable(\"user\", {\\n        id: integer().primaryKey({ autoIncrement: true }),\\n        name: text(),\\n        email: text(),\\n        password: text(),\\n        role: text().$type<\"admin\" | \"customer\">(),\\n        createdAt: integer(\"created_at\"),\\n        updatedAt: integer(\"updated_at\"),\\n      });\\n\\n      export const userView = sqliteView(\"user_view\").as((qb) => qb.select().from(user));\\n      export const customerView = sqliteView(\"customers_view\").as((qb) => qb.select().from(user).where(eq(user.role, \"customer\")));\\n      ```\\n      ```sql\\n      CREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\\n      CREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = \\'customer\\';\\n      ```\\n    </Section>\\n  </Tab>\\n</Tabs>\\n\\n### Declaring views with raw SQL\\nWhenever you need to declare view using a syntax that is not supported by the query builder, \\nyou can directly use `sql` operator and explicitly specify view columns schema.\\n\\n```ts copy\\n// regular view\\nconst newYorkers = pgView(\\'new_yorkers\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  cityId: integer(\\'city_id\\').notNull(),\\n}).as(sql`select * from ${users} where ${eq(users.cityId, 1)}`);\\n\\n// materialized view\\nconst newYorkers = pgMaterializedView(\\'new_yorkers\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: text(\\'name\\').notNull(),\\n  cityId: integer(\\'city_id\\').notNull(),\\n}).as(sql`select * from ${users} where ${eq(users.cityId, 1)}`);\\n```\\n\\n### Declaring existing views\\nWhen you\\'re provided with a read only access to an existing view in the database you should use `.existing()` view configuration, \\n`drizzle-kit` will ignore and will not generate a `create view` statement in the generated migration.\\n```ts\\nexport const user = pgTable(\"user\", {\\n  id: serial(),\\n  name: text(),\\n  email: text(),\\n  password: text(),\\n  role: text().$type<\"admin\" | \"customer\">(),\\n  createdAt: timestamp(\"created_at\"),\\n  updatedAt: timestamp(\"updated_at\"),\\n});\\n\\n// regular view\\nexport const trimmedUser = pgView(\"trimmed_user\", {\\n  id: serial(\"id\"),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n}).existing();\\n\\n// materialized view won\\'t make any difference, yet you can use it for consistency\\nexport const trimmedUser = pgMaterializedView(\"trimmed_user\", {\\n  id: serial(\"id\"),\\n  name: text(\"name\"),\\n  email: text(\"email\"),\\n}).existing();\\n```\\n\\n### Materialized views\\n<IsSupportedChipGroup chips={{ \\'PostgreSQL\\': true, \\'MySQL\\': false, \\'SQLite\\': false }} />\\n\\nAccording to the official docs, PostgreSQL has both **[`regular`](https://www.postgresql.org/docs/current/sql-createview.html)**\\nand **[`materialized`](https://www.postgresql.org/docs/current/sql-creatematerializedview.html)** views.\\n  \\nMaterialized views in PostgreSQL use the rule system like views do, but persist the results in a table-like form.\\n{/* This means that when a query is executed against a materialized view, the results are returned directly from the materialized view,\\nlike from a table, rather than being reconstructed by executing the query against the underlying base tables that make up the view. */}\\n\\nDrizzle ORM natively supports PostgreSQL materialized views:\\n\\n<Section>\\n```ts filename=\"schema.ts\" copy\\nconst newYorkers = pgMaterializedView(\\'new_yorkers\\').as((qb) => qb.select().from(users).where(eq(users.cityId, 1)));\\n```\\n```sql\\nCREATE MATERIALIZED VIEW \"new_yorkers\" AS SELECT * FROM \"users\";\\n```\\n</Section>\\n\\nYou can then refresh materialized views in the application runtime:\\n```ts copy\\nawait db.refreshMaterializedView(newYorkers);\\n\\nawait db.refreshMaterializedView(newYorkers).concurrently();\\n\\nawait db.refreshMaterializedView(newYorkers).withNoData();\\n```\\n\\n### Extended example\\n<Callout type=\"info\" emoji=\"â„¹ï¸\">\\nAll the parameters inside the query will be inlined, instead of replaced by `$1`, `$2`, etc.\\n</Callout>\\n\\n```ts copy\\n// regular view\\nconst newYorkers = pgView(\\'new_yorkers\\')\\n  .with({\\n    checkOption: \\'cascaded\\',\\n    securityBarrier: true,\\n    securityInvoker: true,\\n  })\\n  .as((qb) => {\\n    const sq = qb\\n      .$with(\\'sq\\')\\n      .as(\\n        qb.select({ userId: users.id, cityId: cities.id })\\n          .from(users)\\n          .leftJoin(cities, eq(cities.id, users.homeCity))\\n          .where(sql`${users.age1} > 18`),\\n      );\\n    return qb.with(sq).select().from(sq).where(sql`${users.homeCity} = 1`);\\n  });\\n\\n// materialized view\\nconst newYorkers2 = pgMaterializedView(\\'new_yorkers\\')\\n  .using(\\'btree\\')\\n  .with({\\n    fillfactor: 90,\\n    toast_tuple_target: 0.5,\\n    autovacuum_enabled: true,\\n    ...\\n  })\\n  .tablespace(\\'custom_tablespace\\')\\n  .withNoData()\\n  .as((qb) => {\\n    const sq = qb\\n      .$with(\\'sq\\')\\n      .as(\\n        qb.select({ userId: users.id, cityId: cities.id })\\n          .from(users)\\n          .leftJoin(cities, eq(cities.id, users.homeCity))\\n          .where(sql`${users.age1} > 18`),\\n      );\\n    return qb.with(sq).select().from(sq).where(sql`${users.homeCity} = 1`);\\n  });\\n```\\n', children=[]),\n",
       " DocItem(origPath=Path('why-drizzle.mdx'), name='why-drizzle.mdx', displayName='why-drizzle.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Callout from \\'@mdx/Callout.astro\\';\\nimport CodeTabs from \\'@mdx/CodeTabs.astro\\';\\nimport YoutubeCards from \\'@mdx/YoutubeCards.astro\\';\\n\\n# Drizzle ORM  \\n> Drizzle is a good friend who\\'s there for you when necessary and doesn\\'t bother when you need some space.\\n\\nDrizzle ORM is a headless TypeScript ORM with a head. ðŸ²\\n\\nIt looks and feels simple, performs on day _1000_ of your project, \\nlets you do things your way, and is there when you need it.  \\n\\n**It\\'s the only ORM with both [relational](/docs/rqb) and [SQL-like](/docs/select) query APIs**, \\nproviding you the best of both worlds when it comes to accessing your relational data. \\nDrizzle is lightweight, performant, typesafe, non-lactose, gluten-free, sober, flexible and **serverless-ready by design**.\\nDrizzle is not just a library, it\\'s an experience. ðŸ¤©\\n\\n[![Drizzle bestofjs](@/assets/images/bestofjs.jpg)](https://bestofjs.org/projects/drizzle-orm)\\n\\n## Headless ORM? \\nFirst and foremost, Drizzle is a library and a collection of complementary opt-in tools. \\n\\n**ORM** stands for _object relational mapping_, and developers tend to call Django-like or Spring-like tools an ORM. \\nWe truly believe it\\'s a misconception based on legacy nomenclature, and we call them **data frameworks**.\\n\\n<Callout type=\"error\" emoji=\"ï¸ðŸ’”\">\\n  With data frameworks you have to build projects **around them** and not **with them**.\\n</Callout>\\n\\n**Drizzle** lets you build your project the way you want, without interfering with your project or structure. \\n\\nUsing Drizzle you can define and manage database schemas in TypeScript, access your data in a SQL-like \\nor relational way, and take advantage of opt-in tools \\nto push your developer experience _through the roof_. ðŸ¤¯ \\n\\n## Why SQL-like?\\n**If you know SQL, you know Drizzle.**\\n\\nOther ORMs and data frameworks tend to deviate/abstract you away from SQL, which \\nleads to a double learning curve: needing to know both SQL and the framework\\'s API.  \\n\\nDrizzle is the opposite. \\nWe embrace SQL and built Drizzle to be SQL-like at its core, so you can have zero to no \\nlearning curve and access to the full power of SQL.  \\n\\nWe bring all the familiar **[SQL schema](/docs/sql-schema-declaration)**, **[queries](/docs/select)**, \\n**[automatic migrations](/docs/migrations)** and **[one more thing](/docs/rqb)**. âœ¨\\n\\n<CodeTabs items={[\"index.ts\", \"schema.ts\", \"migration.sql\"]}>\\n```typescript copy\\n// Access your data\\nawait db\\n\\t.select()\\n\\t.from(countries)\\n\\t.leftJoin(cities, eq(cities.countryId, countries.id))\\n\\t.where(eq(countries.id, 10))\\n```\\n```typescript copy\\n// manage your schema\\nexport const countries = pgTable(\\'countries\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: varchar(\\'name\\', { length: 256 }),\\n});\\n\\nexport const cities = pgTable(\\'cities\\', {\\n  id: serial(\\'id\\').primaryKey(),\\n  name: varchar(\\'name\\', { length: 256 }),\\n  countryId: integer(\\'country_id\\').references(() => countries.id),\\n});\\n```\\n```sql\\n-- generate migrations\\nCREATE TABLE IF NOT EXISTS \"countries\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" varchar(256)\\n);\\n\\nCREATE TABLE IF NOT EXISTS \"cities\" (\\n\\t\"id\" serial PRIMARY KEY NOT NULL,\\n\\t\"name\" varchar(256),\\n\\t\"country_id\" integer\\n);\\n\\nALTER TABLE \"cities\" ADD CONSTRAINT \"cities_country_id_countries_id_fk\" FOREIGN KEY (\"country_id\") REFERENCES \"countries\"(\"id\") ON DELETE no action ON UPDATE no action;\\n```\\n</CodeTabs>\\n\\n## Why not SQL-like?\\nWe\\'re always striving for a perfectly balanced solution, and while SQL-like does cover 100% of the needs, \\nthere are certain common scenarios where you can query data in a better way.  \\n\\nWe\\'ve built the **[Queries API](/docs/rqb)** for you, so you can fetch relational nested data from the database \\nin the most convenient and performant way, and never think about joins and data mapping.  \\n\\n**Drizzle always outputs exactly 1 SQL query.** Feel free to use it with serverless databases and never worry about performance or roundtrip costs!\\n\\n```ts\\nconst result = await db.query.users.findMany({\\n\\twith: {\\n\\t\\tposts: true\\n\\t},\\n});\\n```\\n\\n## Serverless?\\n<Callout type=\"info\" emoji=\"ðŸ¥³\">\\n  The best part is no part. **Drizzle has exactly 0 dependencies!**\\n</Callout>\\n\\n\\n![Drizzle is slim an Serverless ready](@/assets/images/drizzle31kb.jpg)\\n  \\nDrizzle ORM is dialect-specific, slim, performant and serverless-ready **by design**.  \\n\\nWe\\'ve spent a lot of time to make sure you have best-in-class SQL dialect support, including Postgres, MySQL, and others.\\n\\nDrizzle operates natively through industry-standard database drivers. We support all major **[PostgreSQL](/docs/get-started-postgresql)**, **[MySQL](/docs/get-started-mysql)** or **[SQLite](/docs/get-started-sqlite)** drivers out there, and we\\'re adding new ones **[really fast](https://twitter.com/DrizzleORM/status/1653082492742647811?s=20)**.  \\n\\n\\n## Welcome on board!\\nMore and more companies are adopting Drizzle in production, experiencing immense benefits in both DX and performance.\\n\\n**We\\'re always there to help, so don\\'t hesitate to reach out. We\\'ll gladly assist you in your Drizzle journey!**\\n\\nWe have an outstanding **[Discord community](https://driz.link/discord)** and welcome all builders to our **[Twitter](https://twitter.com/drizzleorm)**.\\n  \\nNow go build something awesome with Drizzle and your **[PostgreSQL](/docs/get-started-postgresql)**, **[MySQL](/docs/get-started-mysql)** or **[SQLite](/docs/get-started-sqlite)** database. ðŸš€\\n\\n### Video Showcase\\n\\n{/* tRPC + NextJS App Router = Simple Typesafe APIs\\nJack Herrington 19:17\\nhttps://www.youtube.com/watch?v=qCLV0Iaq9zU */}\\n{/* https://www.youtube.com/watch?v=qDunJ0wVIec */}\\n{/* https://www.youtube.com/watch?v=NZpPMlSAez0 */}\\n\\n {/* https://www.youtube.com/watch?v=-A0kMiJqQRY */}\\n\\n<YoutubeCards cards={[\\n\\t{\\n\\t\\tid: \"vyU5mJGCJMw\",\\n\\t\\ttitle: \"Full Drizzle Course for Beginners\",\\n\\t\\tdescription: \"Code Genix\",\\n\\t\\ttime: \"1:37:39\",\\n\\t},\\n\\t{\\n\\t\\tid: \"7-NZ0MlPpJA\",\\n\\t\\ttitle: \"Learn Drizzle In 60 Minutes\",\\n\\t\\tdescription: \"Web Dev Simplified\",\\n\\t\\ttime: \"56:09\"\\n\\t},\\n\\t{\\n\\t\\tid: \"i_mAHOhpBSA\",\\n\\t\\ttitle: \"Drizzle ORM in 100 Seconds\",\\n\\t\\tdescription: \"Fireship\",\\n\\t\\ttime: \"2:55\"\\n\\t},\\n\\t{\\n\\t\\tid: \"hIYNOiZXQ7Y\",\\n\\t\\ttitle: \"Learn Drizzle ORM in 13 mins (crash course)\",\\n\\t\\tdescription: \"Neon\",\\n\\t\\ttime: \"14:00\"\\n\\t},\\n\\t{\\n\\t\\tid: \"4ZhtoOFKFP8\",\\n\\t\\ttitle: \"Easiest Database Setup in Next.js&nbsp;14 with Turso&nbsp;&&nbsp;Drizzle\",\\n\\t\\tdescription: \"Sam Meech-Ward\",\\n\\t\\ttime: \\'38:08\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"NfVELsEZFsA\",\\n\\t\\ttitle: \"Next.js Project with Vercel, Neon, Drizzle, TailwindCSS, FlowBite and more!\",\\n\\t\\tdescription: \"CodingEntrepreneurs\",\\n\\t\\ttime: \\'5:46:28\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"_SLxGYzv6jo\",\\n\\t\\ttitle: \"I Have A New Favorite Database&nbsp;Tool\",\\n\\t\\tdescription: \"Theo - t3.gg\",\\n\\t\\ttime: \\'5:46\\'\\n\\t}, \\n\\t{\\n\\t\\tid: \"Qo-RXkSwOtc\",\\n\\t\\ttitle: \"Drizzle ORM First impressions - migrations, relations, queries!\",\\n\\t\\tdescription: \"Marius Espejo\",\\n\\t\\ttime: \\'33:52\\'\\n\\t},\\n\\t{\\n\\t\\tid: \"yXNEqyvA0OY\",\\n\\t\\ttitle: \"I want to learn Drizzle ORM, so I\\'m starting another next14 project\",\\n\\t\\tdescription: \"Web Dev Cody\",\\n\\t\\ttime: \"9:00\"\\n\\t},\\n\\t{\\n\\t\\tid: \"h7vVhR-dFYo\",\\n\\t\\ttitle: \"Picking an ORM is Getting Harder...\",\\n\\t\\tdescription: \"Ben Davis\",\\n\\t\\ttime: \"5:18\"\\n\\t},\\n\\t{\\n\\t\\tid: \"8met6WTk0mQ\",\\n\\t\\ttitle: \"This New Database Tool is a Game-Changer\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"8:49\"\\n\\t},\\n\\t{\\n\\t\\tid: \"woWW1T9DXEY\",\\n\\t\\ttitle: \"My Favorite Database Tool Just Got EVEN Better\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"4:23\"\\n\\t},\\n\\t{\\n\\t\\tid: \"A3l6YYkXzzg\",\\n\\t\\ttitle: \"SaaS Notion Clone with Realtime cursors, Nextjs 13, Stripe, Drizzle ORM, Tailwind, Supabase, Sockets\",\\n\\t\\tdescription: \"Web Prodigies\",\\n\\t\\ttime: \"11:41:46\"\\n\\t},\\n\\t{\\n\\t\\tid: \"EQfaw5bDE1s\",\\n\\t\\ttitle: \"SvelteKit + Drizzle Code Breakdown\",\\n\\t\\tdescription: \"Ben Davis\",\\n\\t\\ttime: \"12:18\"\\n\\t},\\n\\t{\\n\\t\\tid: \"b6VhN_HHDiQ\",\\n\\t\\ttitle: \"Build a Multi-Tenanted, Role-Based Access Control System\",\\n\\t\\tdescription: \"TomDoesTech\",\\n\\t\\ttime: \"2:01:29\"\\n\\t},\\n\\t{\\n\\t\\tid: \"3tl9XCiQErA\",\\n\\t\\ttitle: \"The Prisma killer is finally here\",\\n\\t\\tdescription: \"SST\",\\n\\t\\ttime: \"5:42\"\\n\\t},\\n\\t{\\n\\t\\tid: \"VQFjyEa8vGE\",\\n\\t\\ttitle: \"Learning Drizzle ORM and working on a next14 project\",\\n\\t\\tdescription: \"Web Dev Cody\",\\n\\t\\ttime: \"1:07:41\"\\n\\t},\\n\\t{\\n\\t\\tid: \"5G0upg4sxgE\",\\n\\t\\ttitle: \"This Trick Makes My Favorite Database Tool Even Better\",\\n\\t\\tdescription: \"Josh tried coding\",\\n\\t\\ttime: \"6:01\"\\n\\t},\\n\\t{\\n\\t\\tid: \"-JnEuvPmt-Q\",\\n\\t\\ttitle: \"Effortless Auth in Next.js 14: Use Auth.js & Drizzle ORM for Secure Login\",\\n\\t\\tdescription: \"Sam Meech-Ward\",\\n\\t\\ttime: \"26:29\"\\n\\t},\\n]} />\\n', children=[]),\n",
       " DocItem(origPath=Path('zod.mdx'), name='zod.mdx', displayName='zod.mdx', digest='', short_digest='', essence='', relevant=True, usage=Usage(input=0, output=0, details=None), token_counts=TokenCounts(fulltext=0, digest=0, short_digest=0), fulltext='import Npm from \\'@mdx/Npm.astro\\';\\nimport Callout from \\'@mdx/Callout.astro\\';\\n\\n# drizzle-zod\\n\\n`drizzle-zod` is a plugin for **[Drizzle ORM](https://github.com/drizzle-team/drizzle-orm)** that allows you to generate **[Zod](https://github.com/colinhacks/zod)** schemas from Drizzle ORM schemas.\\n\\n### Install the dependencies\\n\\n<Npm>\\ndrizzle-zod\\n</Npm>\\n\\n<Callout type=\"warning\">\\nThis documentation is for `drizzle-zod@0.6.0` and higher\\n\\nYou must also have Drizzle ORM v0.36.0 or greater and Zod v3.25.1 or greater installed.\\n</Callout>\\n\\n### Select schema\\n\\nDefines the shape of data queried from the database - can be used to validate API responses.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-zod\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users);\\n\\nconst rows = await db.select({ id: users.id, name: users.name }).from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = userSelectSchema.parse(rows[0]); // Error: `age` is not returned in the above query\\n\\nconst rows = await db.select().from(users).limit(1);\\nconst parsed: { id: number; name: string; age: number } = userSelectSchema.parse(rows[0]); // Will parse successfully\\n```\\n\\nViews and enums are also supported.\\n\\n```ts copy\\nimport { pgEnum } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-zod\\';\\n\\nconst roles = pgEnum(\\'roles\\', [\\'admin\\', \\'basic\\']);\\nconst rolesSchema = createSelectSchema(roles);\\nconst parsed: \\'admin\\' | \\'basic\\' = rolesSchema.parse(...);\\n\\nconst usersView = pgView(\\'users_view\\').as((qb) => qb.select().from(users).where(gt(users.age, 18)));\\nconst usersViewSchema = createSelectSchema(usersView);\\nconst parsed: { id: number; name: string; age: number } = usersViewSchema.parse(...);\\n```\\n\\n### Insert schema\\n\\nDefines the shape of data to be inserted into the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createInsertSchema } from \\'drizzle-zod\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userInsertSchema = createInsertSchema(users);\\n\\nconst user = { name: \\'John\\' };\\nconst parsed: { name: string, age: number } = userInsertSchema.parse(user); // Error: `age` is not defined\\n\\nconst user = { name: \\'Jane\\', age: 30 };\\nconst parsed: { name: string, age: number } = userInsertSchema.parse(user); // Will parse successfully\\nawait db.insert(users).values(parsed);\\n```\\n\\n### Update schema\\n\\nDefines the shape of data to be updated in the database - can be used to validate API requests.\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createUpdateSchema } from \\'drizzle-zod\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst userUpdateSchema = createUpdateSchema(users);\\n\\nconst user = { id: 5, name: \\'John\\' };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = userUpdateSchema.parse(user); // Error: `id` is a generated column, it can\\'t be updated\\n\\nconst user = { age: 35 };\\nconst parsed: { name?: string | undefined, age?: number | undefined } = userUpdateSchema.parse(user); // Will parse successfully\\nawait db.update(users).set(parsed).where(eq(users.name, \\'Jane\\'));\\n```\\n\\n### Refinements\\n\\nEach create schema function accepts an additional optional parameter that you can used to extend, modify or completely overwite a field\\'s schema. Defining a callback function will extend or modify while providing a Zod schema will overwrite it.\\n\\n```ts copy\\nimport { pgTable, text, integer, json } from \\'drizzle-orm/pg-core\\';\\nimport { createSelectSchema } from \\'drizzle-zod\\';\\nimport { z } from \\'zod/v4\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().primaryKey(),\\n  name: text().notNull(),\\n  bio: text(),\\n  preferences: json()\\n});\\n\\nconst userSelectSchema = createSelectSchema(users, {\\n  name: (schema) => schema.max(20), // Extends schema\\n  bio: (schema) => schema.max(1000), // Extends schema before becoming nullable/optional\\n  preferences: z.object({ theme: z.string() }) // Overwrites the field, including its nullability\\n});\\n\\nconst parsed: {\\n  id: number;\\n  name: string,\\n  bio?: string | undefined;\\n  preferences: {\\n    theme: string;\\n  };\\n} = userSelectSchema.parse(...);\\n```\\n\\n### Factory functions\\n\\nFor more advanced use cases, you can use the `createSchemaFactory` function.\\n\\n**Use case: Using an extended Zod instance**\\n\\n```ts copy\\nimport { pgTable, text, integer } from \\'drizzle-orm/pg-core\\';\\nimport { createSchemaFactory } from \\'drizzle-zod\\';\\nimport { z } from \\'@hono/zod-openapi\\'; // Extended Zod instance\\n\\nconst users = pgTable(\\'users\\', {\\n  id: integer().generatedAlwaysAsIdentity().primaryKey(),\\n  name: text().notNull(),\\n  age: integer().notNull()\\n});\\n\\nconst { createInsertSchema } = createSchemaFactory({ zodInstance: z });\\n\\nconst userInsertSchema = createInsertSchema(users, {\\n  // We can now use the extended instance\\n  name: (schema) => schema.openapi({ example: \\'John\\' })\\n});\\n```\\n\\n**Use case: Type coercion**\\n\\n```ts copy\\nimport { pgTable, timestamp } from \\'drizzle-orm/pg-core\\';\\nimport { createSchemaFactory } from \\'drizzle-zod\\';\\nimport { z } from \\'zod/v4\\';\\n\\nconst users = pgTable(\\'users\\', {\\n  ...,\\n  createdAt: timestamp().notNull()\\n});\\n\\nconst { createInsertSchema } = createSchemaFactory({\\n  // This configuration will only coerce dates. Set `coerce` to `true` to coerce all data types or specify others\\n  coerce: {\\n    date: true\\n  }\\n});\\n\\nconst userInsertSchema = createInsertSchema(users);\\n// The above is the same as this:\\nconst userInsertSchema = z.object({\\n  ...,\\n  createdAt: z.coerce.date()\\n});\\n```\\n\\n### Data type reference\\n\\n```ts\\npg.boolean();\\n\\nmysql.boolean();\\n\\nsqlite.integer({ mode: \\'boolean\\' });\\n\\n// Schema\\nz.boolean();\\n```\\n\\n```ts\\npg.date({ mode: \\'date\\' });\\npg.timestamp({ mode: \\'date\\' });\\n\\nmysql.date({ mode: \\'date\\' });\\nmysql.datetime({ mode: \\'date\\' });\\nmysql.timestamp({ mode: \\'date\\' });\\n\\nsqlite.integer({ mode: \\'timestamp\\' });\\nsqlite.integer({ mode: \\'timestamp_ms\\' });\\n\\n// Schema\\nz.date();\\n```\\n\\n```ts\\npg.date({ mode: \\'string\\' });\\npg.timestamp({ mode: \\'string\\' });\\npg.cidr();\\npg.inet();\\npg.interval();\\npg.macaddr();\\npg.macaddr8();\\npg.numeric();\\npg.text();\\npg.sparsevec();\\npg.time();\\n\\nmysql.binary();\\nmysql.date({ mode: \\'string\\' });\\nmysql.datetime({ mode: \\'string\\' });\\nmysql.decimal();\\nmysql.time();\\nmysql.timestamp({ mode: \\'string\\' });\\nmysql.varbinary();\\n\\nsqlite.numeric();\\nsqlite.text({ mode: \\'text\\' });\\n\\n// Schema\\nz.string();\\n```\\n\\n```ts\\npg.bit({ dimensions: ... });\\n\\n// Schema\\nz.string().regex(/^[01]+$/).max(dimensions);\\n```\\n\\n```ts\\npg.uuid();\\n\\n// Schema\\nz.string().uuid();\\n```\\n\\n```ts\\npg.char({ length: ... });\\n\\nmysql.char({ length: ... });\\n\\n// Schema\\nz.string().length(length);\\n```\\n\\n```ts\\npg.varchar({ length: ... });\\n\\nmysql.varchar({ length: ... });\\n\\nsqlite.text({ mode: \\'text\\', length: ... });\\n\\n// Schema\\nz.string().max(length);\\n```\\n\\n```ts\\nmysql.tinytext();\\n\\n// Schema\\nz.string().max(255); // unsigned 8-bit integer limit\\n```\\n\\n```ts\\nmysql.text();\\n\\n// Schema\\nz.string().max(65_535); // unsigned 16-bit integer limit\\n```\\n\\n```ts\\nmysql.mediumtext();\\n\\n// Schema\\nz.string().max(16_777_215); // unsigned 24-bit integer limit\\n```\\n\\n```ts\\nmysql.longtext();\\n\\n// Schema\\nz.string().max(4_294_967_295); // unsigned 32-bit integer limit\\n```\\n\\n```ts\\npg.text({ enum: ... });\\npg.char({ enum: ... });\\npg.varchar({ enum: ... });\\n\\nmysql.tinytext({ enum: ... });\\nmysql.mediumtext({ enum: ... });\\nmysql.text({ enum: ... });\\nmysql.longtext({ enum: ... });\\nmysql.char({ enum: ... });\\nmysql.varchar({ enum: ... });\\nmysql.mysqlEnum(..., ...);\\n\\nsqlite.text({ mode: \\'text\\', enum: ... });\\n\\n// Schema\\nz.enum(enum);\\n```\\n\\n```ts\\nmysql.tinyint();\\n\\n// Schema\\nz.number().min(-128).max(127).int(); // 8-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.tinyint({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(255).int(); // unsigned 8-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.smallint();\\npg.smallserial();\\n\\nmysql.smallint();\\n\\n// Schema\\nz.number().min(-32_768).max(32_767).int(); // 16-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.smallint({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(65_535).int(); // unsigned 16-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.real();\\n\\nmysql.float();\\n\\n// Schema\\nz.number().min(-8_388_608).max(8_388_607); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint();\\n\\n// Schema\\nz.number().min(-8_388_608).max(8_388_607).int(); // 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.float({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(16_777_215); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.mediumint({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(16_777_215).int(); // unsigned 24-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.integer();\\npg.serial();\\n\\nmysql.int();\\n\\n// Schema\\nz.number().min(-2_147_483_648).max(2_147_483_647).int(); // 32-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.int({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(4_294_967_295).int(); // unsgined 32-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.doublePrecision();\\n\\nmysql.double();\\nmysql.real();\\n\\nsqlite.real();\\n\\n// Schema\\nz.number().min(-140_737_488_355_328).max(140_737_488_355_327); // 48-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.double({ unsigned: true });\\n\\n// Schema\\nz.number().min(0).max(281_474_976_710_655); // unsigned 48-bit integer lower and upper limit\\n```\\n\\n```ts\\npg.bigint({ mode: \\'number\\' });\\npg.bigserial({ mode: \\'number\\' });\\n\\nmysql.bigint({ mode: \\'number\\' });\\nmysql.bigserial({ mode: \\'number\\' });\\n\\nsqlite.integer({ mode: \\'number\\' });\\n\\n// Schema\\nz.number().min(-9_007_199_254_740_991).max(9_007_199_254_740_991).int(); // Javascript min. and max. safe integers\\n```\\n\\n```ts\\nmysql.serial();\\n\\n// Schema\\nz.number().min(0).max(9_007_199_254_740_991).int(); // Javascript max. safe integer\\n```\\n\\n```ts\\npg.bigint({ mode: \\'bigint\\' });\\npg.bigserial({ mode: \\'bigint\\' });\\n\\nmysql.bigint({ mode: \\'bigint\\' });\\n\\nsqlite.blob({ mode: \\'bigint\\' });\\n\\n// Schema\\nz.bigint().min(-9_223_372_036_854_775_808n).max(9_223_372_036_854_775_807n); // 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.bigint({ mode: \\'bigint\\', unsigned: true });\\n\\n// Schema\\nz.bigint().min(0).max(18_446_744_073_709_551_615n); // unsigned 64-bit integer lower and upper limit\\n```\\n\\n```ts\\nmysql.year();\\n\\n// Schema\\nz.number().min(1_901).max(2_155).int();\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'tuple\\' });\\npg.point({ mode: \\'tuple\\' });\\n\\n// Schema\\nz.tuple([z.number(), z.number()]);\\n```\\n\\n```ts\\npg.geometry({ type: \\'point\\', mode: \\'xy\\' });\\npg.point({ mode: \\'xy\\' });\\n\\n// Schema\\nz.object({ x: z.number(), y: z.number() });\\n```\\n\\n```ts\\npg.halfvec({ dimensions: ... });\\npg.vector({ dimensions: ... });\\n\\n// Schema\\nz.array(z.number()).length(dimensions);\\n```\\n\\n```ts\\npg.line({ mode: \\'abc\\' });\\n\\n// Schema\\nz.object({ a: z.number(), b: z.number(), c: z.number() });\\n```\\n\\n```ts\\npg.line({ mode: \\'tuple\\' });\\n\\n// Schema\\nz.tuple([z.number(), z.number(), z.number()]);\\n```\\n\\n```ts\\npg.json();\\npg.jsonb();\\n\\nmysql.json();\\n\\nsqlite.blob({ mode: \\'json\\' });\\nsqlite.text({ mode: \\'json\\' });\\n\\n// Schema\\nz.union([z.union([z.string(), z.number(), z.boolean(), z.null()]), z.record(z.any()), z.array(z.any())]);\\n```\\n\\n```ts\\nsqlite.blob({ mode: \\'buffer\\' });\\n\\n// Schema\\nz.custom<Buffer>((v) => v instanceof Buffer);\\n```\\n\\n```ts\\npg.dataType().array(...);\\n\\n// Schema\\nz.array(baseDataTypeSchema).length(size);\\n```\\n', children=[])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "tree = build_markdown_doc_tree(clone_dir / source.doc_dir, extensions=['.mdx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14119f1a",
   "metadata": {},
   "source": [
    "#### Process the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963b70f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+24.877s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing column-types/mysql.mdx\u001b[0m\n",
      "+0.317s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing column-types/pg.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing column-types/singlestore.mdx\u001b[0m\n",
      "+0.023s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing column-types/sqlite.mdx\u001b[0m\n",
      "+0.020s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing extensions/mysql.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing extensions/pg.mdx\u001b[0m\n",
      "+0.022s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing extensions/singlestore.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing extensions/sqlite.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/bun-sql-existing.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/bun-sql-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/bun-sqlite-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/bun-sqlite-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/d1-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/do-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/expo-existing.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/expo-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/gel-existing.mdx\u001b[0m\n",
      "+0.020s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/gel-new.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/mysql-existing.mdx\u001b[0m\n",
      "+0.020s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/mysql-new.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/neon-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/neon-new.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/nile-existing.mdx\u001b[0m\n",
      "+0.019s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/nile-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/op-sqlite-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/op-sqlite-new.mdx\u001b[0m\n",
      "+0.019s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/pglite-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/pglite-new.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/planetscale-existing.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/planetscale-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/postgresql-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/postgresql-new.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/singlestore-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/singlestore-new.mdx\u001b[0m\n",
      "+0.021s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/sqlite-cloud-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/sqlite-cloud-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/sqlite-existing.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/sqlite-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/supabase-existing.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/supabase-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/tidb-existing.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/tidb-new.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/turso-database-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/turso-database-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/turso-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/turso-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/vercel-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/vercel-new.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/xata-existing.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started/xata-new.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/conditional-filters-in-query.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/count-rows.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/cursor-based-pagination.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/d1-http-with-drizzle-kit.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/decrementing-a-value.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/empty-array-default-value.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/full-text-search-with-generated-columns.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/gel-ext-auth.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/include-or-exclude-columns.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/incrementing-a-value.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/limit-offset-pagination.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/mysql-local-setup.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/point-datatype-psql.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/postgis-geometry-point.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/postgresql-full-text-search.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/postgresql-local-setup.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/seeding-using-with-option.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/seeding-with-partially-exposed-schema.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/select-parent-rows-with-at-least-one-related-child-row.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/timestamp-default-value.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/toggling-a-boolean-field.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/unique-case-insensitive-email.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/update-many-with-different-value.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/upsert.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides/vector-similarity-search.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-kit-v0232.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0110.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0162.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0272.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0280.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0281.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0282.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0283.mdx\u001b[0m\n",
      "+0.014s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0284.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0285.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0286.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0290.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0291.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0292.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0293.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0294.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0295.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0300.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0301.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v03010.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0302.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0303.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0304.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0305.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0306.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0307.mdx\u001b[0m\n",
      "+0.019s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0308.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0309.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0310.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0311.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0312.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0313.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0314.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0320.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0321.mdx\u001b[0m\n",
      "+0.022s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases/drizzle-orm-v0322.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing migrate/components.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing migrate/migrate-from-prisma.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing migrate/migrate-from-sequelize.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing migrate/migrate-from-typeorm.mdx\u001b[0m\n",
      "+0.019s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-on-the-edge/drizzle-with-netlify-edge-functions-neon.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-on-the-edge/drizzle-with-netlify-edge-functions-supabase.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-on-the-edge/drizzle-with-supabase-edge-functions.mdx\u001b[0m\n",
      "+0.023s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-on-the-edge/drizzle-with-vercel-edge-functions.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-neon.mdx\u001b[0m\n",
      "+0.023s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-nile.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-supabase.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-turso.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-vercel.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-db/drizzle-with-xata.mdx\u001b[0m\n",
      "+12.771s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing extensions\u001b[0m\n",
      "+10.106s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing column-types\u001b[0m\n",
      "+13.742s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing get-started\u001b[0m\n",
      "+1.274s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing guides\u001b[0m\n",
      "+2.524s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing tutorials/drizzle-on-the-edge\u001b[0m\n",
      "+6.037s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing tutorials/drizzle-with-db\u001b[0m\n",
      "+0.371s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing migrate\u001b[0m\n",
      "+1.203s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing latest-releases\u001b[0m\n",
      "+10.271s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials/drizzle-with-frameworks/drizzle-nextjs-neon.mdx\u001b[0m\n",
      "+21.868s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing tutorials\u001b[0m\n",
      "+15.929s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing arktype.mdx\u001b[0m\n",
      "+0.020s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing batch-api.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing cache.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-aws-data-api-mysql.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-aws-data-api-pg.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-bun-sql.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-bun-sqlite.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-cloudflare-d1.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-cloudflare-do.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-drizzle-proxy.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-expo-sqlite.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-neon.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-nile.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-op-sqlite.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-overview.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-pglite.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-planetscale.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-prisma-postgres.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-react-native-sqlite.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-sqlite-cloud.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-supabase.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-tidb.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-turso-database.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-turso.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-vercel-postgres.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing connect-xata.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing custom-types.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing data-querying.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing delete.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-config-file.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-check.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-export.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-generate.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-migrate.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-pull.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-push.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-studio.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing drizzle-kit-up.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing dynamic-query-building.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing eslint-plugin.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing faq.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing generated-columns.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started-gel.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started-mysql.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started-postgresql.mdx\u001b[0m\n",
      "+0.021s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started-singlestore.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started-sqlite.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing get-started.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing goodies.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing gotchas.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing graphql.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing guides.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing indexes-constraints.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing insert.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing joins.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing kit-custom-migrations.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing kit-migrations-for-teams.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing kit-overview.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing kit-seed-data.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing kit-web-mobile.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing latest-releases.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing migrations.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing operators.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing overview.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing perf-queries.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing perf-serverless.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing prisma.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing query-utils.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing quick.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing read-replicas.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing relations.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing rls.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing rqb.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing schemas.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing seed-functions.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing seed-limitations.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing seed-overview.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing seed-versioning.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing select.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing sequences.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing set-operations.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing sql-schema-declaration.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing sql.mdx\u001b[0m\n",
      "+0.018s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing transactions.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing tutorials.mdx\u001b[0m\n",
      "+0.017s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing typebox.mdx\u001b[0m\n",
      "+0.016s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing update.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing upgrade-21.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing valibot.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing views.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing why-drizzle.mdx\u001b[0m\n",
      "+0.015s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:153\u001b[0m llm_process_page Processing zod.mdx\u001b[0m\n",
      "+66.566s \u001b[36mDEBUG\u001b[0m \u001b[34mlovely_docs/docs.py:255\u001b[0m llm_process_directory Processing .\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "processed_tree = await process_tree_depth_first(settings, tree, source.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1ce361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Usage:\n",
      "  Input tokens: 839,415\n",
      "  Output tokens: 243,778\n",
      "  Total tokens: 1,083,193\n",
      "Cost:\n",
      "  Total: $2.06\n",
      "  Input: $0.84\n",
      "  Output: $1.22\n"
     ]
    }
   ],
   "source": [
    "usage = calculate_total_usage(processed_tree)\n",
    "print(f\"\\nTotal Usage:\")\n",
    "print(f\"  Input tokens: {usage.input:,}\")\n",
    "print(f\"  Output tokens: {usage.output:,}\")\n",
    "print(f\"  Total tokens: {(usage.input + usage.output):,}\")\n",
    "\n",
    "cost, input_cost, output_cost = calculate_cost(usage, 1, 5)\n",
    "\n",
    "print(f\"Cost:\")\n",
    "print(f\"  Total: ${cost:.2f}\")\n",
    "print(f\"  Input: ${input_cost:.2f}\")\n",
    "print(f\"  Output: ${output_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5da3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage: Usage(input=839415, output=243778, details=None)\n",
      "Total cost: (2.058305, 0.839415, 1.21889)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "save_processed_documents(source, settings.output_dir / source.name.replace(\"/\", \"_\"), processed_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
